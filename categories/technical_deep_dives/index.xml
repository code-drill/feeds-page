<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Technical_deep_dives on Daily Tech Articles Feed</title>
    <link>/categories/technical_deep_dives/</link>
    <description>Recent content in Technical_deep_dives on Daily Tech Articles Feed</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 Oct 2025 12:00:06 +0000</lastBuildDate>
    <atom:link href="/categories/technical_deep_dives/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Addressing 3 Failure Points of Multiregion Incident Response</title>
      <link>/articles/article-2025-10-30-11482/</link>
      <pubDate>Thu, 30 Oct 2025 12:00:06 +0000</pubDate>
      <guid>/articles/article-2025-10-30-11482/</guid>
      <description>üåç As organizations expand globally, managing incidents across multiple cloud regions becomes more complex. Key challenges include fragmented tools, context loss during handoffs, and increased debugging needs. Each region often uses different systems, leading to confusion and inefficiencies. To address these issues, standardizing tools and processes is essential. This ensures that all teams can respond effectively, regardless of location. Adopting AI-assisted scheduling can also help optimize&amp;hellip;</description>
    </item>
    <item>
      <title>Machine-learning predictive autoscaling for Flink</title>
      <link>/articles/article-2025-10-30-11473/</link>
      <pubDate>Thu, 30 Oct 2025 00:00:10 +0000</pubDate>
      <guid>/articles/article-2025-10-30-11473/</guid>
      <description>üöÄ Grab is enhancing its Flink applications to meet growing demands for stream processing. With a 2.5x increase in Flink applications, the internal team is focusing on efficient, self-service CPU provisioning. Current reactive autoscaling methods face challenges like restart spikes and resource waste, leading to a need for a predictive solution. The new Predictive Resource Advisor optimizes CPU usage by forecasting workload and adjusting resources proactively, resulting in significant cost&amp;hellip;</description>
    </item>
    <item>
      <title>Improving performance by prefetching product pages from Etsy Search</title>
      <link>/articles/article-2025-10-29-11463/</link>
      <pubDate>Wed, 29 Oct 2025 17:14:09 +0000</pubDate>
      <guid>/articles/article-2025-10-29-11463/</guid>
      <description>üöÄ Etsy&amp;rsquo;s search team has implemented the Speculation Rules API (SRA) to enhance product page performance significantly. By prefetching pages, they&amp;rsquo;ve achieved improvements of 20-24% across various metrics. Key highlights include two methods of prefetching: traditional and speculative, with SRA offering advantages in caching and performance. The team also learned valuable lessons about user interaction and analytics during the implementation process. #Etsy #WebPerformance #SRA #TechInnovation&amp;hellip;</description>
    </item>
    <item>
      <title>SPH Media shares its custom HCP Terraform operational dashboard</title>
      <link>/articles/article-2025-10-29-11462/</link>
      <pubDate>Wed, 29 Oct 2025 15:30:00 +0000</pubDate>
      <guid>/articles/article-2025-10-29-11462/</guid>
      <description>üöÄ SPH Media has developed a custom operational dashboard for HCP Terraform to enhance visibility into their infrastructure. This initiative addresses several challenges, including operational blind spots, security vulnerabilities, and compliance risks. By integrating data from HCP Terraform‚Äôs Explorer API with their AWS data lake, they created a unified view for better resource management. The dashboard aids in monitoring usage patterns and identifying cost inefficiencies, ultimately&amp;hellip;</description>
    </item>
    <item>
      <title>One IP address, many users: detecting CGNAT to reduce collateral effects</title>
      <link>/articles/article-2025-10-29-11448/</link>
      <pubDate>Wed, 29 Oct 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-29-11448/</guid>
      <description>üåê IPv4 scarcity leads to widespread use of Carrier-Grade Network Address Translation (CGNAT), placing multiple users behind a single IP address. This shift complicates security measures that rely on individual IP accountability, especially impacting users in developing regions where IP addresses are limited. Our article discusses a method to detect large-scale IP sharing to mitigate these biases and enhance digital equity. üìà Explore how our approach can help address socioeconomic disparities&amp;hellip;</description>
    </item>
    <item>
      <title>So long, and thanks for all the fish: how to escape the Linux networking stack</title>
      <link>/articles/article-2025-10-29-11451/</link>
      <pubDate>Wed, 29 Oct 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-29-11451/</guid>
      <description>üöÄ Cloudflare continuously pushes the boundaries of network hardware and software to enhance performance and efficiency. One key innovation is soft-unicast, allowing IP address sharing across data centers. The article discusses challenges related to Linux‚Äôs networking stack when implementing this feature. To simplify operations, Cloudflare developed a dedicated service, dubbed &amp;ldquo;fish,&amp;rdquo; to manage IP packets effectively. This service addresses complexities in IP address leasing and socket&amp;hellip;</description>
    </item>
    <item>
      <title>Finding Order in the Mayhem: A Novel Concurrency Testing Tool that Improved the Kotlin Compiler</title>
      <link>/articles/article-2025-10-29-11442/</link>
      <pubDate>Wed, 29 Oct 2025 12:12:14 +0000</pubDate>
      <guid>/articles/article-2025-10-29-11442/</guid>
      <description>üöÄ Exciting advancements in concurrent programming! JetBrains Research introduces LitmusKt, a novel testing tool for Kotlin&amp;rsquo;s multiplatform concurrency. This tool is designed to identify complex, platform-specific concurrency bugs that traditional methods miss. LitmusKt enhances the Kotlin compiler by systematically uncovering hidden issues, improving reliability in concurrent applications. Learn more about the challenges of concurrent programming and how LitmusKt is transforming Kotlin&amp;hellip;</description>
    </item>
    <item>
      <title>Accelerating AV Simulation with Neural Reconstruction and World Foundation Models</title>
      <link>/articles/article-2025-10-28-11376/</link>
      <pubDate>Tue, 28 Oct 2025 18:30:00 +0000</pubDate>
      <guid>/articles/article-2025-10-28-11376/</guid>
      <description>Autonomous vehicle (AV) technology is advancing towards integrated end-to-end architectures using foundation models. This shift emphasizes the need for a robust AV data flywheel to create synthetic data and enhance sensor datasets. NVIDIA has introduced tools such as the Omniverse and Cosmos workflows to support developers in building these data pipelines. Key features include access to real AV data, data processing tools, and libraries for neural reconstruction. With over 1,700 hours of&amp;hellip;</description>
    </item>
    <item>
      <title>Architecting Multi-System Production Platform: Event Processing Driving $400M&#43; Across 15,000&#43; Orgs</title>
      <link>/articles/article-2025-10-28-11367/</link>
      <pubDate>Tue, 28 Oct 2025 15:42:11 +0000</pubDate>
      <guid>/articles/article-2025-10-28-11367/</guid>
      <description>üöÄ Exciting developments in Salesforce! Madhura Kasinadhuni, Senior Director of Software Engineering, led the creation of Digital Wallet, a platform that provides real-time consumption-based pricing visibility. Since its launch in July 2024, it has reached over 15,000 organizations and generated $400M+ in annual contract value. üí∞ The platform focuses on transparency, self-service management, proactive support, and intelligent insights. It aims to enhance customer decision-making and optimize&amp;hellip;</description>
    </item>
    <item>
      <title>A framework for measuring Internet resilience</title>
      <link>/articles/article-2025-10-28-11348/</link>
      <pubDate>Tue, 28 Oct 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-28-11348/</guid>
      <description>A recent article introduces a data-driven framework for measuring Internet resilience. üåê The framework aims to quantify how networks can withstand and recover from disruptions, highlighting the importance of diverse routing paths and competitive markets. It emphasizes that local decisions by Autonomous Systems significantly impact global connectivity, making resilience a collective effort. By sharing concrete metrics, the goal is to enhance the reliability and security of the Internet for all&amp;hellip;</description>
    </item>
    <item>
      <title>Streaming datasets: 100x More Efficient</title>
      <link>/articles/article-2025-10-27-11298/</link>
      <pubDate>Mon, 27 Oct 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-27-11298/</guid>
      <description>Discover the latest advancements in streaming datasets, reported to be 100 times more efficient than traditional methods. üìä This breakthrough can significantly enhance data processing and real-time analytics across various industries. For developers and data scientists, this opens new avenues for improved performance and resource management. Stay updated on tech innovations! üöÄüíª #DataScience #StreamingData #TechInnovation #Efficiency #Analytics</description>
    </item>
    <item>
      <title>Virtual Pine Grove | UE5 [4K]</title>
      <link>/articles/article-2025-10-26-11456/</link>
      <pubDate>Sun, 26 Oct 2025 08:33:36 +0000</pubDate>
      <guid>/articles/article-2025-10-26-11456/</guid>
      <description>Explore the serene beauty of a pine grove, brought to life in Unreal Engine 5.6.1! üå≤‚ú® This virtual environment showcases summer vibes using a blend of Quixel assets, third-party resources, and custom models. It&amp;rsquo;s all rendered in real-time on an RTX 3090. Experience nature in a new way! üå≥üíª #UnrealEngine #VirtualReality #GameDevelopment #3DModeling #RTX3090</description>
    </item>
    <item>
      <title>Post-Training Generative Recommenders with Advantage-Weighted Supervised Finetuning</title>
      <link>/articles/article-2025-10-25-11281/</link>
      <pubDate>Sat, 25 Oct 2025 22:01:00 +0000</pubDate>
      <guid>/articles/article-2025-10-25-11281/</guid>
      <description>üöÄ Exciting developments in generative recommender systems! The article discusses how post-training generative recommenders (GRs) can enhance user experience by modeling behavior over time. It highlights the challenges of relying solely on observed user patterns, which can lead to poor recommendations. A new approach, Advantage-Weighted Supervised Fine-tuning (A-SFT), addresses issues with noisy reward models and limited counterfactual feedback. This method combines supervised fine-tuning with&amp;hellip;</description>
    </item>
    <item>
      <title>2 Fixes Vastly Cut TiKV Write Stalls From SST File Ingestion</title>
      <link>/articles/article-2025-10-24-11259/</link>
      <pubDate>Fri, 24 Oct 2025 18:00:13 +0000</pubDate>
      <guid>/articles/article-2025-10-24-11259/</guid>
      <description>üöÄ TiKV, the open-source key-value database, has addressed write stalls during SST file ingestion. üîç The issue arose when SST ingestion blocked foreground writes to maintain sequence order, leading to latency spikes. üí° Two enhancements were implemented: reducing unnecessary flushes and allowing concurrent writes during ingestion with safety mechanisms. These changes significantly improve performance and reduce stall times. #TiKV #Database #OpenSource #Performance #TechNews</description>
    </item>
    <item>
      <title>How NVIDIA DGX Spark‚Äôs Performance Enables Intensive AI Tasks</title>
      <link>/articles/article-2025-10-24-11264/</link>
      <pubDate>Fri, 24 Oct 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-24-11264/</guid>
      <description>NVIDIA DGX Spark is designed to meet the needs of AI developers requiring high memory and powerful computing without relying on cloud resources. This compact supercomputer offers 1 petaflop of FP4 AI performance and 128 GB of coherent memory, making it suitable for intensive tasks like fine-tuning and image generation. Benchmark tests show impressive performance in fine-tuning models, with peak speeds of over 82,000 tokens per second. Additionally, it supports high-resolution image&amp;hellip;</description>
    </item>
    <item>
      <title>Beyond Basic Scaling: Advanced Kubernetes Resource Strategies</title>
      <link>/articles/article-2025-10-24-10258/</link>
      <pubDate>Fri, 24 Oct 2025 14:30:49 +0000</pubDate>
      <guid>/articles/article-2025-10-24-10258/</guid>
      <description>Navigating Kubernetes resource management can be challenging. Overprovisioning wastes resources, while underprovisioning frustrates developers and slows down product delivery. ‚öôÔ∏è The right balance is crucial for application stability and efficient cluster utilization. A reliable, automated resource management system can help teams optimize their Kubernetes environment. Join the free webinar on Oct. 21 at 11 a.m. PT to learn best practices and strategies for effective resource management. üìÖ&amp;hellip;</description>
    </item>
    <item>
      <title>Multipass: Fast, Scriptable Ubuntu VMs for Modern DevOps</title>
      <link>/articles/article-2025-10-24-11251/</link>
      <pubDate>Fri, 24 Oct 2025 14:00:14 +0000</pubDate>
      <guid>/articles/article-2025-10-24-11251/</guid>
      <description>Unlock the power of Ubuntu VMs with Canonical&amp;rsquo;s Multipass! üöÄ This tool simplifies the launch and management of lightweight Ubuntu virtual machines across macOS, Windows, and Linux. It&amp;rsquo;s designed for developers and ops teams, enabling quick VM provisioning through command line or scripts. Multipass features a client-server architecture for enhanced security and automation. It smartly selects the best hypervisor for your OS, optimizing performance and resource management. Ready to streamline&amp;hellip;</description>
    </item>
    <item>
      <title>Establish secure private connections for HCP Vault Dedicated for multi-cloud architectures</title>
      <link>/articles/article-2025-10-24-11246/</link>
      <pubDate>Fri, 24 Oct 2025 07:12:17 +0000</pubDate>
      <guid>/articles/article-2025-10-24-11246/</guid>
      <description>Establishing secure connections for HashiCorp Cloud Platform (HCP) Vault Dedicated in multi-cloud architectures can be complex. üåê This article discusses strategies for maintaining private access across providers like Azure and AWS, including the use of AWS Transit Gateway and site-to-site VPN. It also highlights alternatives such as AWS PrivateLink and VPC peering. üîí For detailed implementation guidance and decision-making criteria, check out the full article! #MultiCloud #HCPVault&amp;hellip;</description>
    </item>
    <item>
      <title>Advanced vector search in air-gapped environments</title>
      <link>/articles/article-2025-10-24-11255/</link>
      <pubDate>Fri, 24 Oct 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-24-11255/</guid>
      <description>üåê Organizations in air-gapped environments face unique challenges when implementing AI and vector search technology. Elastic&amp;rsquo;s solutions have been vital for sectors like national security, enabling effective data analysis without external connections. Key issues include a lack of developers, high data volumes, and complex data formats that hinder AI utilization. Understanding these challenges is essential for optimizing AI in sensitive industries. #AISolutions #DataAnalysis #AirGapped&amp;hellip;</description>
    </item>
    <item>
      <title>How BoldSign Modernized Development at Scale With JetBrains dotUltimate</title>
      <link>/articles/article-2025-10-23-11231/</link>
      <pubDate>Thu, 23 Oct 2025 19:47:22 +0000</pubDate>
      <guid>/articles/article-2025-10-23-11231/</guid>
      <description>üöÄ Exciting advancements at BoldSign! The Syncfusion engineering team revamped their modern e-signature platform to support over 40,000 organizations. They faced performance challenges as adoption grew, but the integration of JetBrains dotUltimate transformed their development process. With tools like Rider, dotTrace, and dotMemory, build times are now just 15‚Äì20 seconds, and issues are identified earlier. This shift has enhanced code quality and reduced debugging cycles significantly&amp;hellip;.</description>
    </item>
    <item>
      <title>Multi-Agent Supervisor Architecture: Orchestrating Enterprise AI at Scale</title>
      <link>/articles/article-2025-10-23-11232/</link>
      <pubDate>Thu, 23 Oct 2025 18:40:00 +0000</pubDate>
      <guid>/articles/article-2025-10-23-11232/</guid>
      <description>BASF is leveraging a Multi-Agent Supervisor Architecture to enhance its enterprise AI capabilities. This approach aims to accelerate the deployment of Agentic AI within BASF Coatings. The focus is on delivering faster value, improving productivity, ensuring compliance, and supporting scalable growth. This innovative strategy highlights the potential of AI in transforming business operations. ü§ñ‚ú® #BASF #AI #Innovation #EnterpriseAI #Growth</description>
    </item>
    <item>
      <title>Advancing Our Chef Infrastructure: Safety Without Disruption</title>
      <link>/articles/article-2025-10-23-11235/</link>
      <pubDate>Thu, 23 Oct 2025 18:17:56 +0000</pubDate>
      <guid>/articles/article-2025-10-23-11235/</guid>
      <description>üöÄ Last year, we discussed the evolution of our Chef infrastructure and its transition from a single stack to a multi-stack model. At Slack, service reliability is key. We explored moving to Chef Policyfiles but opted to enhance our existing EC2 framework instead. This approach minimizes disruption while improving deployment safety. We split our production Chef environment into multiple isolated buckets, increasing resilience and allowing independent updates. This strategy helps mitigate risks&amp;hellip;</description>
    </item>
    <item>
      <title>Breaking the ‚ÄòShared-Nothing‚Äô Bottleneck: A NoSQL Paradigm</title>
      <link>/articles/article-2025-10-23-11190/</link>
      <pubDate>Thu, 23 Oct 2025 15:00:18 +0000</pubDate>
      <guid>/articles/article-2025-10-23-11190/</guid>
      <description>Exploring the NoSQL paradigm reveals that a shared-nothing architecture is often favored for its high performance and low latency. üñ•Ô∏è Using direct-attached storage (DAS), NoSQL databases like Cassandra and MongoDB can achieve efficient data management. However, DAS can hinder sustainability efforts due to increased hardware needs and underutilization. üå± Modern SAN solutions provide a way to maintain performance while enhancing efficiency and resilience. üîÑ #NoSQL #DataManagement #TechTrends&amp;hellip;</description>
    </item>
    <item>
      <title>Enabling Deep Model Explainability with Integrated Gradients at Uber</title>
      <link>/articles/article-2025-10-23-11200/</link>
      <pubDate>Thu, 23 Oct 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-23-11200/</guid>
      <description>üöÄ Uber&amp;rsquo;s ML platform, Michelangelo, now integrates Integrated Gradients for enhanced model explainability in TensorFlow‚Ñ¢ and PyTorch‚Ñ¢. This development supports transparency and trust in machine learning, aiding debugging and informed decision-making during the ML life cycle. Discover how this feature transforms the approach to model interpretability! #MachineLearning #ModelExplainability #DataScience #AI #UberTech</description>
    </item>
    <item>
      <title>A verifiable quantum advantage</title>
      <link>/articles/article-2025-10-22-11153/</link>
      <pubDate>Wed, 22 Oct 2025 15:07:38 +0000</pubDate>
      <guid>/articles/article-2025-10-22-11153/</guid>
      <description>üåü Exciting developments in quantum computing! A recent study in Nature introduces a new computational task measuring Out-of-Time-Order Correlators (OTOCs), showcasing a verifiable quantum advantage. This breakthrough could help tackle real-world challenges, such as Hamiltonian learning in Nuclear Magnetic Resonance (NMR). The research highlights chaos in both macroscopic and quantum systems, emphasizing how quantum computers can effectively simulate these complex, chaotic behaviors. üîç&amp;hellip;</description>
    </item>
    <item>
      <title>Half-Quadratic Quantization of large machine learning models</title>
      <link>/articles/article-2025-10-22-11199/</link>
      <pubDate>Wed, 22 Oct 2025 12:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-22-11199/</guid>
      <description>üöÄ Explore Half-Quadratic Quantization (HQQ), a new method for compressing large AI models without needing calibration data. This technique significantly speeds up quantization, processing models like Llama-2-70B in under 5 minutes‚Äîover 50x faster than traditional methods. HQQ maintains competitive compression quality, enabling efficient deployment of large language models. #MachineLearning #AI #Quantization #HQQ #Llama2</description>
    </item>
    <item>
      <title>Identify User Journeys at Pinterest</title>
      <link>/articles/article-2025-10-21-11135/</link>
      <pubDate>Tue, 21 Oct 2025 21:42:27 +0000</pubDate>
      <guid>/articles/article-2025-10-21-11135/</guid>
      <description>üìå Pinterest is enhancing its platform by introducing user journeys, focusing on understanding users&amp;rsquo; long-term goals beyond immediate interests. A user journey combines interests, intent, and context, enabling personalized recommendations for projects like wedding planning or home renovations. To implement this, Pinterest is using a dynamic keyword extraction approach for greater adaptability and personalization. This shift aims to help users achieve their aspirations effectively. #Pinterest&amp;hellip;</description>
    </item>
    <item>
      <title>Fast PEFT Serving at Scale</title>
      <link>/articles/article-2025-10-21-11127/</link>
      <pubDate>Tue, 21 Oct 2025 17:09:15 +0000</pubDate>
      <guid>/articles/article-2025-10-21-11127/</guid>
      <description>At Databricks, we&amp;rsquo;ve developed a custom inference engine that significantly enhances AI performance for our customers. üöÄ Our engine not only doubles the speed of some open-source alternatives but also reduces errors on common benchmarks. This achievement supports the efficient serving of fine-tuned AI models. We focus on building an infrastructure that ensures scalability, reliability, and security, addressing various challenges like load balancing and health monitoring. With this innovative&amp;hellip;</description>
    </item>
    <item>
      <title>Beyond Namespaces: Why Kubernetes Needs Real Workload Isolation</title>
      <link>/articles/article-2025-10-21-11101/</link>
      <pubDate>Tue, 21 Oct 2025 15:00:54 +0000</pubDate>
      <guid>/articles/article-2025-10-21-11101/</guid>
      <description>Kubernetes namespaces are essential for managing resources, but they provide only logical separation, not true workload isolation. üõ†Ô∏è This means that while namespaces help teams share clusters, they do not prevent compromised containers from affecting others on the same node. Real security is needed to protect against vulnerabilities and potential breaches. üîí Modern attack patterns highlight the risks, showing that relying solely on namespaces can lead to significant security issues. ‚ö†Ô∏è For&amp;hellip;</description>
    </item>
    <item>
      <title>A deep dive into BPF LPM trie performance and optimization</title>
      <link>/articles/article-2025-10-21-11125/</link>
      <pubDate>Tue, 21 Oct 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-21-11125/</guid>
      <description>üöÄ A recent article delves into the performance of BPF LPM tries, crucial for IP matching in network routing. It began with a soft lockup issue, highlighting performance bottlenecks in BPF LPM trie maps, including slow entry lookups and CPU lockups. These problems have impacted services like Cloudflare‚Äôs Magic Firewall, causing packet loss for users. The article also explains trie structures and their efficiency in storing and searching data, making them ideal for tasks like longest prefix&amp;hellip;</description>
    </item>
    <item>
      <title>Requirement Adherence: Boosting Data Labeling Quality Using LLMs</title>
      <link>/articles/article-2025-10-21-11112/</link>
      <pubDate>Tue, 21 Oct 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-21-11112/</guid>
      <description>Uber AI Solutions has developed a system that leverages Large Language Models (LLMs) to enhance data labeling quality. This innovative approach has led to an impressive 80% reduction in data labeling audits by effectively detecting labeling errors. Learn more about how this system is improving data quality in the field of machine learning. #DataLabeling #MachineLearning #AI #UberAI #TechInnovation üöÄüìä</description>
    </item>
    <item>
      <title>Krkn-AI: A feedback-driven approach to chaos engineering</title>
      <link>/articles/article-2025-10-21-11095/</link>
      <pubDate>Tue, 21 Oct 2025 07:01:41 +0000</pubDate>
      <guid>/articles/article-2025-10-21-11095/</guid>
      <description>Introducing &lt;strong&gt;Krkn-AI&lt;/strong&gt;: a new framework for AI-assisted chaos engineering. It addresses the challenges of testing modern systems, especially in dynamic environments like Kubernetes. Chaos engineering helps identify weaknesses by simulating failures, but traditional methods can be manual and static. Krkn-AI automates experiment discovery and execution, allowing teams to focus on insights rather than manual setups. Key features include cluster-aware discoverability, enhanced test coverage, and&amp;hellip;</description>
    </item>
    <item>
      <title>Behind the Streams: Real-Time Recommendations for Live Events Part 3</title>
      <link>/articles/article-2025-10-21-11092/</link>
      <pubDate>Tue, 21 Oct 2025 00:53:29 +0000</pubDate>
      <guid>/articles/article-2025-10-21-11092/</guid>
      <description>üöÄ Exciting insights from Netflix&amp;rsquo;s latest article on enhancing live event experiences! As live events attract millions of viewers, Netflix has engineered a system for real-time recommendations. This ensures fans receive timely updates without overwhelming cloud services. Key strategies include prefetching data and adaptive broadcasting, effectively synchronizing devices and managing traffic spikes. Stay tuned for more on Netflix&amp;rsquo;s innovative solutions! üé•üì° #Netflix #LiveEvents #TechInnovation&amp;hellip;</description>
    </item>
    <item>
      <title>Modernising Grab‚Äôs model serving platform with NVIDIA Triton Inference Server</title>
      <link>/articles/article-2025-10-21-11093/</link>
      <pubDate>Tue, 21 Oct 2025 00:00:10 +0000</pubDate>
      <guid>/articles/article-2025-10-21-11093/</guid>
      <description>üöÄ Grab is enhancing its machine learning model serving platform, Catwalk, by integrating NVIDIA Triton Inference Server. This upgrade addresses performance issues caused by maintaining multiple legacy inference engines. Key benefits of Triton include multi-framework support, a unified API, and optimized hardware performance. Early results show over 50% of online deployments successfully migrated with improved latency and cost savings. Stay tuned for more updates on this transformation! üåü&amp;hellip;</description>
    </item>
    <item>
      <title>Unreal Engine 5 helps Frogwares deliver a different sort of horror in The Sinking City 2</title>
      <link>/articles/article-2025-10-21-11107/</link>
      <pubDate>Tue, 21 Oct 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-21-11107/</guid>
      <description>Frogwares has shared insights on how Unreal Engine 5 has enhanced the development of ‚ÄòThe Sinking City 2.‚Äô üéÆ The team leveraged UE5 to craft Lovecraftian horror elements while integrating survival gameplay with investigative mechanics. This approach aims to immerse players in a unique and chilling experience. üïµÔ∏è‚Äç‚ôÇÔ∏èüîç Discover more about their innovative techniques and design choices! #TheSinkingCity2 #Frogwares #UnrealEngine5 #GamingNews #HorrorGames</description>
    </item>
    <item>
      <title>Agentforce‚Äôs Agent Graph: Toward Guided Determinism with Hybrid Reasoning</title>
      <link>/articles/article-2025-10-20-11089/</link>
      <pubDate>Mon, 20 Oct 2025 22:05:42 +0000</pubDate>
      <guid>/articles/article-2025-10-20-11089/</guid>
      <description>üöÄ Exciting developments in enterprise AI! In a recent Q&amp;amp;A, Phil Mui, SVP of Agentforce Software Engineering, discusses Agent Graph, the technology behind hybrid reasoning. This approach focuses on externalizing reasoning into design-time graphs, enhancing reliability while maintaining natural conversations. The team addresses common &amp;ldquo;drop-off&amp;rdquo; issues in enterprise applications, aiming for consistency and control in LLMs. A General Availability release is expected later this year. Learn more&amp;hellip;</description>
    </item>
    <item>
      <title>A picture&#39;s worth a thousand (private) words: Hierarchical generation of coherent synthetic photo albums</title>
      <link>/articles/article-2025-10-20-11090/</link>
      <pubDate>Mon, 20 Oct 2025 21:54:00 +0000</pubDate>
      <guid>/articles/article-2025-10-20-11090/</guid>
      <description>Introducing a new method for generating differentially private synthetic photo albums! üì∑‚ú® This approach uses an intermediate text representation to create albums hierarchically, ensuring individual data privacy while maintaining thematic coherence across images. By leveraging generative AI models, organizations can simplify their data analysis workflows, safeguarding sensitive information without compromising quality. Explore the potential of this innovative technique! #DifferentialPrivacy&amp;hellip;</description>
    </item>
    <item>
      <title>How DoorDash slashed web developer build times</title>
      <link>/articles/article-2025-10-20-11080/</link>
      <pubDate>Mon, 20 Oct 2025 16:30:31 +0000</pubDate>
      <guid>/articles/article-2025-10-20-11080/</guid>
      <description>DoorDash faced challenges with lengthy CI pipeline durations as web projects grew in complexity. By optimizing tooling and adopting a new monorepo system, they reduced build and test times by 75%, saving over 500 engineering hours monthly. Key strategies included leveraging cobuilds and enhancing parallelization techniques. These changes have significantly improved developer productivity. üöÄüíª #DoorDash #WebDevelopment #ContinuousIntegration #EngineeringEfficiency #TechInnovation</description>
    </item>
    <item>
      <title>Disaggregated Scheduled Fabric: Scaling Meta‚Äôs AI Journey</title>
      <link>/articles/article-2025-10-20-11091/</link>
      <pubDate>Mon, 20 Oct 2025 16:00:37 +0000</pubDate>
      <guid>/articles/article-2025-10-20-11091/</guid>
      <description>üöÄ Meta introduces the Disaggregated Schedule Fabric (DSF), a cutting-edge network technology designed for AI training. This innovation addresses the limitations of traditional Clos-based networks. DSF enables scalable AI networks by separating hardware components into interconnected devices, enhancing performance and load balancing. It supports large clusters of GPUs, crucial for handling the growing demand for high-performance AI. The article highlights challenges faced with traditional IP&amp;hellip;</description>
    </item>
    <item>
      <title>Scaling Large MoE Models with Wide Expert Parallelism on NVL72 Rack Scale Systems</title>
      <link>/articles/article-2025-10-20-11075/</link>
      <pubDate>Mon, 20 Oct 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-20-11075/</guid>
      <description>Modern AI workloads are evolving beyond single-GPU setups. Model parallelism is now key for scalable deployments, especially with mixture-of-experts (MoE) architectures, which activate only a portion of parameters per token. Expert parallelism (EP) is crucial for managing the complexities of scaling these models. With tools like NVIDIA Tensor RT-LLM‚Äôs Wide Expert Parallelism, large-scale deployments become more efficient, enhancing performance and cost-effectiveness. Learn how large-scale EP&amp;hellip;</description>
    </item>
    <item>
      <title>MCP vs. API Gateways: They‚Äôre Not Interchangeable</title>
      <link>/articles/article-2025-10-20-11062/</link>
      <pubDate>Mon, 20 Oct 2025 15:00:02 +0000</pubDate>
      <guid>/articles/article-2025-10-20-11062/</guid>
      <description>Organizations are increasingly adopting the Model Context Protocol (MCP) to link their services and data with AI models. However, they face challenges in securing access to MCP servers while ensuring effective routing and observability. üîê A common question arises: Can existing API gateways be used for MCP? The answer is complex. API gateways were designed for stateless interactions, while MCP operates with stateful sessions. This fundamental difference means that current API gateways may need&amp;hellip;</description>
    </item>
    <item>
      <title>A case study in Kubelet regression in OpenShift</title>
      <link>/articles/article-2025-10-20-11059/</link>
      <pubDate>Mon, 20 Oct 2025 07:01:19 +0000</pubDate>
      <guid>/articles/article-2025-10-20-11059/</guid>
      <description>In the latest analysis of Red Hat OpenShift, a kubelet regression was detected that increased CPU usage by 30% and pod readiness latency by 50%. Our performance engineering team utilized the changepoint detection tool, Orion, to identify these issues during automated scale tests. The regression was linked to kubelet 1.33, which was resolved by reverting to version 1.32.6, restoring normal performance metrics. This case highlights the importance of continuous testing and collaboration to&amp;hellip;</description>
    </item>
    <item>
      <title>End to End Testing on PRs</title>
      <link>/articles/article-2025-10-20-11058/</link>
      <pubDate>Mon, 20 Oct 2025 03:15:00 +0000</pubDate>
      <guid>/articles/article-2025-10-20-11058/</guid>
      <description>At LY Corporation, we are enhancing our pre-release testing process to minimize outages. Our end-to-end testing tool simulates real network calls, providing better insights than traditional unit tests. Recently, we&amp;rsquo;ve integrated this tool into our PR process to identify issues early and improve test coverage. üöÄ This initiative has been years in the making, leveraging advancements from multiple teams to ensure isolated testing environments. We are excited about the progress and the potential&amp;hellip;</description>
    </item>
    <item>
      <title>How Airties migrated from ArcSight to Elastic and cut investigation times from hours to seconds</title>
      <link>/articles/article-2025-10-20-11076/</link>
      <pubDate>Mon, 20 Oct 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-20-11076/</guid>
      <description>Airties has successfully migrated from ArcSight to Elastic, significantly reducing security investigation times from hours to mere seconds. ‚è±Ô∏è As a leader in Wi-Fi mesh technology, Airties handles vast amounts of data to assist telecom partners in network monitoring and troubleshooting. This transition supports their shift to a software-first model, enhancing data management capabilities. üìà Discover more about their innovative approach! #Cybersecurity #DataManagement #TechInnovation #Airties&amp;hellip;</description>
    </item>
    <item>
      <title>Server rendering benchmarks: Railway vs Cloudflare vs Vercel</title>
      <link>/articles/article-2025-10-20-11120/</link>
      <pubDate>Mon, 20 Oct 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-20-11120/</guid>
      <description>üîç A recent benchmark compares the CPU performance of server-side rendering across Railway, Vercel, and Cloudflare. The analysis highlights key differences in efficiency and speed among these platforms, providing insights for developers choosing a server rendering solution. Understanding these metrics can help optimize performance in web applications. #ServerRendering #WebDevelopment #PerformanceBenchmark ‚öôÔ∏èüíª</description>
    </item>
    <item>
      <title>When JSDOM and Fetch Collide: Cross-Environment Lessons</title>
      <link>/articles/article-2025-10-18-11052/</link>
      <pubDate>Sat, 18 Oct 2025 17:00:46 +0000</pubDate>
      <guid>/articles/article-2025-10-18-11052/</guid>
      <description>üöÄ Developing cross-environment JavaScript code can be challenging. An article explores issues with relative URLs in JSDOM compared to browsers. üìù JSDOM, used in testing frameworks, defaults to about:blank, causing relative URLs to fail unless configured correctly. üîç Even with Jest and Vitest preconfiguring JSDOM, issues can arise due to differences in how location objects are handled. #JavaScript #JSDOM #WebDevelopment #Coding #TestingTools</description>
    </item>
    <item>
      <title>How and Why Netflix Built a Real-Time Distributed Graph: Part 1‚Ää‚Äî‚ÄäIngesting and Processing Data‚Ä¶</title>
      <link>/articles/article-2025-10-17-11044/</link>
      <pubDate>Fri, 17 Oct 2025 18:42:37 +0000</pubDate>
      <guid>/articles/article-2025-10-17-11044/</guid>
      <description>üåê Netflix has developed a Real-Time Distributed Graph (RDG) to analyze member interactions across various services effectively. In Part 1 of their blog series, they outline the motivation behind the RDG and its data processing architecture. The transition from a single streaming service to multi-faceted offerings like live events and games necessitated a new approach to data analysis. By leveraging a graph system, Netflix can connect user activities across devices rapidly, enhancing&amp;hellip;</description>
    </item>
    <item>
      <title>Solving virtual machine puzzles: How AI is optimizing cloud computing</title>
      <link>/articles/article-2025-10-17-11037/</link>
      <pubDate>Fri, 17 Oct 2025 17:56:35 +0000</pubDate>
      <guid>/articles/article-2025-10-17-11037/</guid>
      <description>Introducing LAVA, a new AI-driven scheduling algorithm designed to enhance resource efficiency in cloud data centers. ‚òÅÔ∏èüíª LAVA adapts to the lifetimes of virtual machines (VMs) by continuously updating predictions, addressing the challenges of VM allocation. This system helps prevent resource stranding and optimizes server usage for both economic and environmental benefits. üå±üìà The approach includes three algorithms: NILAS, LAVA, and LARS, which work together to improve VM fitting on physical&amp;hellip;</description>
    </item>
    <item>
      <title>Accelerating GenAI Workloads With Seekable OCI</title>
      <link>/articles/article-2025-10-17-11032/</link>
      <pubDate>Fri, 17 Oct 2025 17:00:49 +0000</pubDate>
      <guid>/articles/article-2025-10-17-11032/</guid>
      <description>üöÄ The rise of generative AI (GenAI) is transforming containerized applications. Organizations are focusing on optimizing container image sizes and network performance for better deployment efficiency. Reducing image pull times can significantly impact application startup speed. ‚è±Ô∏è Seekable OCI (SOCI) offers innovative solutions like parallel pull and lazy loading to enhance container operations. These methods improve performance and resource utilization during AI/ML deployments. Learn more&amp;hellip;</description>
    </item>
    <item>
      <title>Tracking Down Mysterious ML Training Stalls</title>
      <link>/articles/article-2025-10-17-11036/</link>
      <pubDate>Fri, 17 Oct 2025 16:01:48 +0000</pubDate>
      <guid>/articles/article-2025-10-17-11036/</guid>
      <description>üîç Pinterest recently tackled a significant challenge during a PyTorch upgrade, experiencing a 50% drop in ML training throughput. The team meticulously traced the issue, identifying low-level Linux kernels and a monitoring process as major culprits. Their systematic debugging provided insights into optimizing performance and enhancing training efficiency. This journey highlights the importance of thorough analysis and innovative solutions in tackling complex tech issues. üíª‚ú® #MachineLearning&amp;hellip;</description>
    </item>
    <item>
      <title>Scaling LLM Inference: Innovations in Tensor Parallelism, Context Parallelism, and Expert Parallelism</title>
      <link>/articles/article-2025-10-17-11038/</link>
      <pubDate>Fri, 17 Oct 2025 16:00:50 +0000</pubDate>
      <guid>/articles/article-2025-10-17-11038/</guid>
      <description>At Meta, we are advancing LLM inference systems to enhance applications like the Meta AI App. We focus on optimizing resource efficiency, throughput, and latency using techniques like tensor, context, and expert parallelism. These methods help manage the demands of large language models during both the prefill and decoding stages. Our goal is to improve GPU utilization, increase query handling, and minimize response times for a smooth user experience. #MetaAI #LLMInference #Parallelism #AI&amp;hellip;</description>
    </item>
    <item>
      <title>Enterprise-Scale Governance: Migrating from Hive Metastore to Unity Catalog</title>
      <link>/articles/article-2025-10-17-11035/</link>
      <pubDate>Fri, 17 Oct 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-17-11035/</guid>
      <description>üìä Businesses are navigating complex data landscapes as they scale their digital capabilities. This article discusses the process of migrating from Hive Metastore to Unity Catalog. It highlights how organizations can manage large-scale workloads while maintaining data governance and optimizing performance. Learn more about this migration strategy to enhance your data management! üîÑüìà #DataGovernance #UnityCatalog #HiveMetastore #DataManagement #TechTrends</description>
    </item>
    <item>
      <title>Why rent a cloud when you can build one?</title>
      <link>/articles/article-2025-10-17-11018/</link>
      <pubDate>Fri, 17 Oct 2025 07:40:00 +0000</pubDate>
      <guid>/articles/article-2025-10-17-11018/</guid>
      <description>üå•Ô∏è Andrei Kvapil, founder of √Ünix and core developer of Cozystack, discusses building a private cloud from scratch. He explains the role of Kubernetes and open-source technology in achieving digital sovereignty. Cozystack offers a platform for managed services, moving beyond traditional virtual machines. Learn more about the future of cloud technology! #CloudComputing #Kubernetes #OpenSource #TechTalk #DigitalSovereignty</description>
    </item>
    <item>
      <title>From Lakehouse to Digital Mind: Architecting a Multi-Agent AI Ecosystem on Databricks</title>
      <link>/articles/article-2025-10-17-11015/</link>
      <pubDate>Fri, 17 Oct 2025 01:45:00 +0000</pubDate>
      <guid>/articles/article-2025-10-17-11015/</guid>
      <description>Discover how Edmunds transformed its data lakehouse into a multi-agent AI platform using Databricks. This shift enables enhanced activation, automation, and ongoing innovation in enterprise operations. The article highlights the importance of a unified data approach in today‚Äôs digital landscape. Learn more about this innovative architecture and its impact on business. üåêüí° #DataLakehouse #AI #Innovation #Databricks #DigitalTransformation</description>
    </item>
    <item>
      <title>Branching in a Sapling Monorepo</title>
      <link>/articles/article-2025-10-16-11005/</link>
      <pubDate>Thu, 16 Oct 2025 17:10:43 +0000</pubDate>
      <guid>/articles/article-2025-10-16-11005/</guid>
      <description>üå± Exciting insights from the GitMerge 2024 conference on branching in Sapling, Meta&amp;rsquo;s open-source source control system! Sapling supports a large monorepo, addressing the challenges of branching workflows. The article discusses tradeoffs between scalability and developer experience, highlighting two effective workflows: non-mergeable full-repo branching and mergeable directory branching. Key takeaways include how these workflows resolved branching issues for diverse products at Meta. The&amp;hellip;</description>
    </item>
    <item>
      <title>10X Backbone: How Meta Is Scaling Backbone Connectivity for AI</title>
      <link>/articles/article-2025-10-16-11006/</link>
      <pubDate>Thu, 16 Oct 2025 16:30:02 +0000</pubDate>
      <guid>/articles/article-2025-10-16-11006/</guid>
      <description>Meta is enhancing its Backbone network to meet the growing demands of AI workloads. üåê The Backbone consists of two main networks: Classic Backbone (CBB) for global reach and Express Backbone (EBB) for scalable data center interconnections. EBB, which has been growing since 2015, faces significant scalability challenges. üöÄ Meta&amp;rsquo;s focus is on evolving EBB to ensure reliable, high-capacity connections as new data centers are built. #Meta #AI #Networking #DataCenters #TechInnovation</description>
    </item>
    <item>
      <title>Network performance in distributed training: Maximizing GPU utilization on OpenShift</title>
      <link>/articles/article-2025-10-16-10999/</link>
      <pubDate>Thu, 16 Oct 2025 15:07:18 +0000</pubDate>
      <guid>/articles/article-2025-10-16-10999/</guid>
      <description>üöÄ Key findings from a recent study on GPU clusters for distributed training highlight the importance of network architecture. Using IBM Cloud, tests showed that the standard OpenShift pod network creates bottlenecks. For L40S GPUs, secondary vNICs increased performance by up to 132% at scale. For H100 GPUs, switching to SR-IOV led to a 3x increase in throughput. Recommendations emphasize investing in high-performance networks to maximize GPU utilization. #DistributedTraining #GPUPerformance&amp;hellip;</description>
    </item>
    <item>
      <title>Accelerated and Distributed UPF for the Era of Agentic AI and 6G</title>
      <link>/articles/article-2025-10-15-10956/</link>
      <pubDate>Wed, 15 Oct 2025 18:06:57 +0000</pubDate>
      <guid>/articles/article-2025-10-15-10956/</guid>
      <description>The telecommunications sector is rapidly advancing towards 6G, focusing on AI-native Radio Access Networks (AI-RAN) and AI-Core. A key development is the distributed User Plane Function (dUPF), which processes data closer to users, reducing latency and enhancing throughput. üì∂ The article discusses the architectural benefits of dUPF, particularly for agentic AI applications. It showcases a reference implementation using NVIDIA DOCA Flow, which supports energy-efficient, low-latency operations&amp;hellip;</description>
    </item>
    <item>
      <title>Building Data Cloud One: Enterprise Metadata Synchronization Across 850&#43; Orgs in Days, Not Weeks</title>
      <link>/articles/article-2025-10-15-10961/</link>
      <pubDate>Wed, 15 Oct 2025 15:40:01 +0000</pubDate>
      <guid>/articles/article-2025-10-15-10961/</guid>
      <description>üöÄ Exciting news from Salesforce! Hari Priyanka Nunna, Director of Software Engineering, led the development of Data Cloud One. This solution connects multiple Salesforce orgs to a single Data Cloud instance, cutting down on implementation time. The team achieved strong transactional consistency using an outbox pattern architecture and managed to scale from zero to over 850 connections in just nine months. üåê Data Cloud One simplifies metadata synchronization, helping enterprise customers&amp;hellip;</description>
    </item>
    <item>
      <title>Building a Real-Time System Monitor in Rust Terminal</title>
      <link>/articles/article-2025-10-15-10933/</link>
      <pubDate>Wed, 15 Oct 2025 14:05:48 +0000</pubDate>
      <guid>/articles/article-2025-10-15-10933/</guid>
      <description>üöÄ Discover how to build a real-time system monitor using Rust! The article outlines the creation of monitor-rs, a terminal dashboard that tracks CPU usage, memory, disk I/O, and network activity in real-time. It emphasizes Rust&amp;rsquo;s unique features like zero-cost abstractions and fearless concurrency for efficient system programming. Before starting, familiarity with Rust, command-line interfaces, and a Linux or macOS system is recommended. Monitor-rs also includes an alerting system for&amp;hellip;</description>
    </item>
    <item>
      <title>Running Next.js inside ChatGPT: A deep dive into native app integration</title>
      <link>/articles/article-2025-10-15-10969/</link>
      <pubDate>Wed, 15 Oct 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-15-10969/</guid>
      <description>OpenAI&amp;rsquo;s recent Apps SDK now supports embedding web applications in ChatGPT, enabling a new level of integration. This article explores how a Next.js app can operate within ChatGPT&amp;rsquo;s triple-iframe structure. It highlights features like client-side navigation and dynamic routing, showcasing the advancements in web app functionality. Discover how this integration works! üåêü§ñ #NextJS #ChatGPT #WebDevelopment #OpenAI #Innovation</description>
    </item>
    <item>
      <title>Clang bytecode interpreter update</title>
      <link>/articles/article-2025-10-15-10924/</link>
      <pubDate>Wed, 15 Oct 2025 07:16:20 +0000</pubDate>
      <guid>/articles/article-2025-10-15-10924/</guid>
      <description>üöÄ This October, an update on the Clang bytecode interpreter reveals significant progress! With about 500 commits since last year, the implementation has become more robust. Test failures in the clang suite have decreased from 155 to 90. A working version of &lt;code&gt;builtin_constant_p&lt;/code&gt; is now available, supporting real-world use cases. Key enhancements include optimizations for constant expressions, improving performance in certain scenarios. The inclusion of libc++ testing has also led to better&amp;hellip;</description>
    </item>
    <item>
      <title>Unpacking Cloudflare Workers CPU Performance Benchmarks</title>
      <link>/articles/article-2025-10-14-10914/</link>
      <pubDate>Tue, 14 Oct 2025 20:00:25 +0000</pubDate>
      <guid>/articles/article-2025-10-14-10914/</guid>
      <description>Cloudflare has addressed CPU performance issues in its Workers platform following benchmarks by developer Theo Browne. The initial results showed Cloudflare Workers lagging behind Vercel in CPU-intensive tasks. Investigations revealed various small problems in infrastructure and JavaScript libraries contributing to this disparity. Recent changes have improved performance, bringing Cloudflare in line with Vercel in most benchmark cases. Future enhancements aim to close remaining gaps,&amp;hellip;</description>
    </item>
    <item>
      <title>Accelerate Qubit Research with NVIDIA cuQuantum Integrations in QuTip and scQubits</title>
      <link>/articles/article-2025-10-14-10913/</link>
      <pubDate>Tue, 14 Oct 2025 19:23:57 +0000</pubDate>
      <guid>/articles/article-2025-10-14-10913/</guid>
      <description>üöÄ NVIDIA cuQuantum is now integrated into QuTip and scQubits, enhancing quantum simulations at both circuit and device levels. This integration allows researchers to design and study novel qubit types more efficiently. With a 4000x speedup on AWS, users can explore complex quantum systems effectively. QuTip and scQubits are now optimized for better performance and scalability, paving the way for future advancements in quantum computing. #QuantumComputing #NVIDIA #QuantumSimulations #QuTip&amp;hellip;</description>
    </item>
    <item>
      <title>Understanding Memory Management on Hardware-Coherent Platforms</title>
      <link>/articles/article-2025-10-14-10901/</link>
      <pubDate>Tue, 14 Oct 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-14-10901/</guid>
      <description>Discover how memory management affects application performance on hardware-coherent platforms. NVIDIA&amp;rsquo;s Coherent Driver-based Memory Management (CDMM) mode offers improved control over GPU memory compared to the default NUMA mode. This allows applications to optimize memory placement for better performance. Learn about the implications for Kubernetes and more in the full article. üíªüöÄ #NVIDIA #MemoryManagement #Kubernetes #TechInsights #PerformanceOptimization</description>
    </item>
    <item>
      <title>Benchmarking Postgres 17 vs 18</title>
      <link>/articles/article-2025-10-14-10905/</link>
      <pubDate>Tue, 14 Oct 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-14-10905/</guid>
      <description>üöÄ Postgres 18 has arrived, showcasing major enhancements in read performance with async I/O and new I/O worker threads. The new io_method option allows users to control disk I/O behavior, introducing worker and io_uring modes. These aim to optimize performance, particularly for read operations. Benchmark tests using sysbench focused on read-only scenarios across various EC2 configurations. Results show that Postgres 18 in sync and worker modes outperformed version 17 on network-attached&amp;hellip;</description>
    </item>
    <item>
      <title>Understanding Etsy‚Äôs Vast Inventory with LLMs</title>
      <link>/articles/article-2025-10-13-10874/</link>
      <pubDate>Mon, 13 Oct 2025 17:58:39 +0000</pubDate>
      <guid>/articles/article-2025-10-13-10874/</guid>
      <description>Etsy has over 100 million unique items from 5 million sellers, showcasing human creativity. However, this vast inventory presents challenges in accurately capturing product attributes, from standard to niche details. The platform collects both structured data, which is easy to process, and unstructured data, which is harder to interpret. To address this, Etsy is leveraging LLMs to transform unstructured data into structured attributes, enhancing search and buyer experiences. This innovative&amp;hellip;</description>
    </item>
    <item>
      <title>Protecting virtual machines from storage and secondary network node failures</title>
      <link>/articles/article-2025-10-13-10865/</link>
      <pubDate>Mon, 13 Oct 2025 07:01:04 +0000</pubDate>
      <guid>/articles/article-2025-10-13-10865/</guid>
      <description>Kubernetes provides basic health monitoring for nodes but lacks adequate support for storage and secondary network failures, crucial for virtual machines and telco deployments. The kubelet detects node issues, focusing mainly on resource availability and control plane connectivity. However, it does not monitor storage or network health directly, leading to potential inconsistencies and downtime. To address this, the Node Problem Detector (NPD) operator can be implemented, allowing for&amp;hellip;</description>
    </item>
    <item>
      <title>Cars24 Improves Search For 300 Million Users With MongoDB Atlas</title>
      <link>/articles/article-2025-10-12-10864/</link>
      <pubDate>Sun, 12 Oct 2025 23:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-12-10864/</guid>
      <description>üöó Cars24, an online car marketplace serving 300 million users, has transformed its search capabilities using MongoDB Atlas. Pradeep Sharma, Cars24&amp;rsquo;s Head of Technology, discussed how MongoDB streamlined their operations by eliminating data synchronization challenges. This shift allowed developers to focus on building new features rather than managing complex systems. The transition also led to a 50% reduction in costs and enhanced scalability, supporting Cars24&amp;rsquo;s global growth. For more&amp;hellip;</description>
    </item>
    <item>
      <title>Engineering Real-Time Multimodal AI Pipelines: Scaling File Processing to 50M Daily Uploads</title>
      <link>/articles/article-2025-10-10-10637/</link>
      <pubDate>Fri, 10 Oct 2025 23:43:48 +0000</pubDate>
      <guid>/articles/article-2025-10-10-10637/</guid>
      <description>üöÄ Exciting advancements in AI at Salesforce! Vaibhav Raizada, a Senior Software Engineer, is leading the development of multimodal AI capabilities for Salesforce Prompt Builder. This innovation unlocks file-based data, enhancing AI&amp;rsquo;s ability to process previously invisible information. Key challenges addressed include real-time file processing and integrating diverse data sources. This allows for automated document field extraction and improved customer support through efficient case&amp;hellip;</description>
    </item>
    <item>
      <title>Build a Log Analysis Multi-Agent Self-Corrective RAG System with NVIDIA Nemotron</title>
      <link>/articles/article-2025-10-10-10625/</link>
      <pubDate>Fri, 10 Oct 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-10-10625/</guid>
      <description>Unlock the potential of log analysis with NVIDIA&amp;rsquo;s AI-powered solution! üöÄ As applications scale, logs can become overwhelming, making it difficult to identify issues. NVIDIA introduces a log analysis agent that automates log parsing and improves root-cause detection. This solution supports QA teams, engineering, DevOps, CloudOps, and observability managers by unifying log sources and delivering actionable insights. Discover the architecture and components that make this self-corrective,&amp;hellip;</description>
    </item>
    <item>
      <title>Node.js 20&#43; memory management in containers</title>
      <link>/articles/article-2025-10-10-10617/</link>
      <pubDate>Fri, 10 Oct 2025 07:00:55 +0000</pubDate>
      <guid>/articles/article-2025-10-10-10617/</guid>
      <description>Node.js 20 enhances memory management in containers by being container-aware, limiting heap size based on cgroup limits. This adaptation helps prevent memory overflow issues on platforms like OpenShift. The maximum heap size is 50% of the container size, capping at 2 GiB for larger containers. Developers can also set specific limits using the &lt;code&gt;--max-old-space-size&lt;/code&gt; flag. For efficient CPU allocation, combining &lt;code&gt;worker_threads&lt;/code&gt; with multiple CPU limits can improve performance, but balance is&amp;hellip;</description>
    </item>
    <item>
      <title>From Static Rate Limiting to Adaptive Traffic Management in Airbnb‚Äôs Key-Value Store</title>
      <link>/articles/article-2025-10-09-10595/</link>
      <pubDate>Thu, 09 Oct 2025 16:01:55 +0000</pubDate>
      <guid>/articles/article-2025-10-09-10595/</guid>
      <description>Airbnb has enhanced its key-value store, Mussel, with advanced traffic management techniques. üåê The updated system includes resource-aware rate control, which measures the real cost of requests, and load shedding to prioritize critical traffic during peak times. üö¶ Additionally, hot-key detection helps manage sudden spikes from bots or DDoS attacks, ensuring stability and performance for users. Read more about these improvements and their impact on service reliability. üìà #AirbnbTech&amp;hellip;</description>
    </item>
    <item>
      <title>The Cost of Not Knowing MongoDB, Part 3: appV6R0 to appV6R4</title>
      <link>/articles/article-2025-10-09-10592/</link>
      <pubDate>Thu, 09 Oct 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-09-10592/</guid>
      <description>üöÄ In the final part of &amp;ldquo;The Cost of Not Knowing MongoDB,&amp;rdquo; the focus is on advanced design patterns to enhance application performance. Key improvements include reducing document size using a dynamic schema and optimizing storage compression. The article discusses the transition from appV5R4 to appV6R0, demonstrating significant performance enhancements. üìä The implementation of a dynamic monthly bucket document aims to alleviate disk throughput bottlenecks, showcasing the effectiveness of&amp;hellip;</description>
    </item>
    <item>
      <title>Unlocking Faster Insights with Experimenter-Defined Segmentations</title>
      <link>/articles/article-2025-10-08-10544/</link>
      <pubDate>Wed, 08 Oct 2025 15:32:02 +0000</pubDate>
      <guid>/articles/article-2025-10-08-10544/</guid>
      <description>Etsy is enhancing its experimentation capabilities by empowering teams to define their own segmentations. üìä Previously limited to 13 hard-coded segmentations, the new Segmentation Library allows for 3x more custom options, leading to faster insights. Experimenters can quickly analyze data tailored to user groups, improving decision-making. This innovation has already saved teams 2-5 hours monthly. ‚è≥ #Etsy #Experimentation #DataInsights #Segmentation #Innovation</description>
    </item>
    <item>
      <title>One model is not enough, too many models is hard: Technical deep dive</title>
      <link>/articles/article-2025-10-08-10542/</link>
      <pubDate>Wed, 08 Oct 2025 14:16:08 +0000</pubDate>
      <guid>/articles/article-2025-10-08-10542/</guid>
      <description>üöÄ Discover how to efficiently manage hundreds to thousands of machine learning models with a systematic approach! This guide outlines a model lifecycle assembly line, focusing on configuration-driven pipelines, version control, and GitOps promotion. Key features include: - Continuous training and versioned pipelines - Data lineage for reproducibility - Safe, automated deployments Learn how to implement these practices in your environment! üîó Check out the full details and demo on YouTube!&amp;hellip;</description>
    </item>
    <item>
      <title>How we found a bug in Go&#39;s arm64 compiler</title>
      <link>/articles/article-2025-10-08-10545/</link>
      <pubDate>Wed, 08 Oct 2025 14:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-08-10545/</guid>
      <description>Cloudflare recently uncovered a race condition in Go&amp;rsquo;s arm64 compiler, triggered by their high volume of HTTP requests‚Äî84 million per second. The investigation began after sporadic panics were detected in their services, which indicated potential stack corruption. Despite initial mitigation efforts, fatal panics persisted, prompting a deeper analysis. This situation highlights the complexities of maintaining software at scale. ‚öôÔ∏èüîç #GoLang #Cloudflare #SoftwareEngineering #Debugging #CompilerBug</description>
    </item>
    <item>
      <title>Kubernetes v1.34 Introduces Benefits but Also New Blind Spots</title>
      <link>/articles/article-2025-10-07-10504/</link>
      <pubDate>Tue, 07 Oct 2025 17:30:12 +0000</pubDate>
      <guid>/articles/article-2025-10-07-10504/</guid>
      <description>üöÄ Kubernetes v1.34 brings new features like Dynamic Resource Allocation and Linux node swap support, enhancing flexibility for AI and ML workloads. However, these updates also introduce complexities and potential risks. Engineers must ensure thorough testing and monitoring to prevent misconfigurations and unexpected costs. Pod-level resource requests ease quota management, but may obscure issues with individual containers. Stay informed and adjust your strategies accordingly! #Kubernetes&amp;hellip;</description>
    </item>
    <item>
      <title>Building Apache Phoenix DynamoDB Compatibility: Zero-Code Multi-Cloud Database Migrations at Scale</title>
      <link>/articles/article-2025-10-07-10501/</link>
      <pubDate>Tue, 07 Oct 2025 13:52:35 +0000</pubDate>
      <guid>/articles/article-2025-10-07-10501/</guid>
      <description>üöÄ Exciting developments in multi-cloud database migration! Viraj Jasani, a Principal Software Engineer at Salesforce, led the creation of DynamoDB-compatible REST services on Apache Phoenix. This innovation allows teams to migrate across cloud platforms without changing application code. The team tackled significant challenges, including reverse-engineering Amazon‚Äôs database APIs and ensuring reliability across multiple clouds like AWS and GCP. This effort prevents vendor lock-in and&amp;hellip;</description>
    </item>
    <item>
      <title>Master KV cache aware routing with llm-d for efficient AI inference</title>
      <link>/articles/article-2025-10-07-10481/</link>
      <pubDate>Tue, 07 Oct 2025 07:00:56 +0000</pubDate>
      <guid>/articles/article-2025-10-07-10481/</guid>
      <description>Unlock efficient AI inference with llm-d! üöÄ This Kubernetes-native framework introduces KV cache aware routing, reducing latency and improving throughput by directing requests to pods with relevant context in GPU memory. Key features include an External Processing Pod and intelligent routing. With a recent test showing an impressive 87.4% cache hit rate, llm-d enhances performance and optimizes resource use. Learn more about maximizing AI infrastructure efficiency! üìäüí° #AIInference #Kubernetes&amp;hellip;</description>
    </item>
    <item>
      <title>Speeding Up Data Decompression with nvCOMP and the NVIDIA Blackwell Decompression Engine</title>
      <link>/articles/article-2025-10-06-10452/</link>
      <pubDate>Mon, 06 Oct 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-06-10452/</guid>
      <description>NVIDIA has introduced the Decompression Engine (DE) in its Blackwell architecture to enhance data decompression speed while reducing latency and compute resource usage. üìä Working alongside the nvCOMP library, DE accelerates decompression for popular formats like Snappy and LZ4, optimizing data transfers directly across PCIe or C2C. This innovation allows for better utilization of GPU resources, especially in data-intensive applications. üöÄ Developers are encouraged to use DE via nvCOMP APIs,&amp;hellip;</description>
    </item>
    <item>
      <title>Accelerating Large-Scale Data Analytics with GPU-Native Velox and NVIDIA cuDF</title>
      <link>/articles/article-2025-10-06-10443/</link>
      <pubDate>Mon, 06 Oct 2025 12:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-06-10443/</guid>
      <description>üöÄ Accelerating data analytics is crucial as workloads grow. GPU-accelerated databases, like those using NVIDIA cuDF and Velox, provide significant performance gains over traditional CPU systems. üîç These advancements enable real-time insights for analysts, supporting complex queries with large datasets. ü§ù IBM and NVIDIA are collaborating to enhance platforms like Presto and Apache Spark, allowing for efficient GPU-native query execution. #DataAnalytics #GPUComputing #NVIDIA #IBM #BigData</description>
    </item>
    <item>
      <title>Medium Android App‚Ää‚Äî‚ÄäMigrating from Apollo Kotlin 3 to 4: Lessons Learned</title>
      <link>/articles/article-2025-10-06-10439/</link>
      <pubDate>Mon, 06 Oct 2025 08:18:42 +0000</pubDate>
      <guid>/articles/article-2025-10-06-10439/</guid>
      <description>üöÄ The Medium Android app has successfully migrated from Apollo Kotlin 3 to 4! Key updates include a new group ID and improved exception handling. The migration revealed issues with cache configuration, leading to CacheMissExceptions. The team switched to Declarative Cache IDs and added &lt;code&gt;__typename&lt;/code&gt; to operations for better cache performance. Learn more about the challenges faced and solutions implemented in this detailed post! üì±üí° #ApolloKotlin #GraphQL #AndroidDevelopment #TechUpdates&amp;hellip;</description>
    </item>
    <item>
      <title>Highly concurrent in-memory counter in GoLang</title>
      <link>/articles/article-2025-10-06-10433/</link>
      <pubDate>Mon, 06 Oct 2025 00:00:10 +0000</pubDate>
      <guid>/articles/article-2025-10-06-10433/</guid>
      <description>üö® Facing high database CPU utilization during heavy traffic? This article explores a scenario where migrating from SQL to NoSQL seemed easy but tackling the problem through optimization proved more effective. The focus was on real-time usage count tracking for marketing campaigns, utilizing highly concurrent in-memory caching to reduce database load. By periodically flushing data, the team achieved significant efficiency improvements. The implementation of GoLang&amp;rsquo;s Sync.Map led to a 68%&amp;hellip;</description>
    </item>
    <item>
      <title>Eliminating the Precision‚ÄìLatency Trade-Off in Large-Scale RAG</title>
      <link>/articles/article-2025-10-03-10408/</link>
      <pubDate>Fri, 03 Oct 2025 16:00:09 +0000</pubDate>
      <guid>/articles/article-2025-10-03-10408/</guid>
      <description>üöÄ &lt;strong&gt;RAG Systems Redefined!&lt;/strong&gt; Retrieval-Augmented Generation (RAG) systems face a common challenge: balancing precision with latency. A new approach suggests redesigning retrieval to eliminate this trade-off. Key techniques include: 1Ô∏è‚É£ &lt;strong&gt;Multiphase Ranking&lt;/strong&gt; - This method refines results incrementally, combining fast and deep machine learning models to enhance precision while managing costs. 2Ô∏è‚É£ &lt;strong&gt;Layered Retrieval&lt;/strong&gt; - By selecting optimal retrieval units, systems can maintain quality and&amp;hellip;</description>
    </item>
    <item>
      <title>Scaling subscriptions at The New York Times with real-time causal machine learning</title>
      <link>/articles/article-2025-10-03-10413/</link>
      <pubDate>Fri, 03 Oct 2025 15:19:24 +0000</pubDate>
      <guid>/articles/article-2025-10-03-10413/</guid>
      <description>üöÄ The New York Times has advanced its subscription strategy by implementing real-time causal machine learning algorithms. These algorithms enhance decision-making for paywalls and registration walls, optimizing access based on user behavior. This dynamic approach allows for personalized experiences, improving both subscription and registration rates. The collaboration between data science and business leadership is key to this success. üìà #MachineLearning #DigitalMedia #NYTimes&amp;hellip;</description>
    </item>
    <item>
      <title>One is not the loneliest number for API calls</title>
      <link>/articles/article-2025-10-03-10426/</link>
      <pubDate>Fri, 03 Oct 2025 07:40:00 +0000</pubDate>
      <guid>/articles/article-2025-10-03-10426/</guid>
      <description>üéß In the latest Stack Overflow Podcast, Gil Feig, co-founder and CTO at Merge, shares insights on simplifying third-party API integrations. Merge aims to reduce multiple API calls to a single connection, addressing the complexities of data normalization. The discussion also touches on the role of AI and MCP in enhancing API functionality. For more details, listen to the episode! #APIs #DataIntegration #TechTalk #Merge #AI</description>
    </item>
    <item>
      <title>Koog √ó A2A: Building Connected AI Agents in Kotlin</title>
      <link>/articles/article-2025-10-02-10369/</link>
      <pubDate>Thu, 02 Oct 2025 14:48:45 +0000</pubDate>
      <guid>/articles/article-2025-10-02-10369/</guid>
      <description>üöÄ Building connected AI agents just got easier! The Koog framework in Kotlin simplifies the creation and management of AI agents. It allows for complex workflows and integrates seamlessly with the A2A Protocol, enabling efficient communication between agents. With A2A, agents can connect and collaborate effortlessly, eliminating the need for custom integrations and allowing developers to focus on enhancing agent capabilities. Together, Koog and A2A streamline the AI agent ecosystem. #AI&amp;hellip;</description>
    </item>
    <item>
      <title>How Uber Standardized Mobile Analytics for Cross-Platform Insights</title>
      <link>/articles/article-2025-10-02-10389/</link>
      <pubDate>Thu, 02 Oct 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-02-10389/</guid>
      <description>üöÄ Uber has standardized its mobile analytics to enhance cross-platform insights. The company focused on unifying event instrumentation and collecting consistent metadata. This approach aims to reduce development effort while ensuring quality insights across platforms. Learn more about Uber&amp;rsquo;s transformative journey in mobile analytics. üìäüì± #Uber #MobileAnalytics #DataInsights #TechInnovation #CrossPlatform</description>
    </item>
    <item>
      <title>Filtering packets from anywhere in the networking stack</title>
      <link>/articles/article-2025-10-02-10359/</link>
      <pubDate>Thu, 02 Oct 2025 07:00:56 +0000</pubDate>
      <guid>/articles/article-2025-10-02-10359/</guid>
      <description>Discover the potential of packet filtering with Retis! üåê This article explores how Retis allows packet dumps from anywhere in the networking stack. It highlights its unique filtering methods: packet filtering and metadata filtering, which help manage data, ensuring accurate captures and reducing overhead. Learn how Retis compares to tools like tcpdump and tshark, emphasizing the importance of precise filtering for effective network debugging. #NetworkEngineering #PacketFiltering #Retis&amp;hellip;</description>
    </item>
    <item>
      <title>How GitLab transforms embedded systems testing cycles</title>
      <link>/articles/article-2025-10-02-10368/</link>
      <pubDate>Thu, 02 Oct 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-02-10368/</guid>
      <description>üöÄ Embedded developers face long waits for testing cycles, often leading to delays in bug fixes and product releases. GitLab addresses these challenges with managed lifecycle environments, which automate virtual testing without the complexities of traditional setups. This innovative approach ties testing environments to merge requests, ensuring persistence throughout feature development while eliminating unnecessary rebuilds and reducing costs. Discover how GitLab transforms embedded systems&amp;hellip;</description>
    </item>
    <item>
      <title>SOTA OCR on-device with Core ML and dots.ocr</title>
      <link>/articles/article-2025-10-02-10377/</link>
      <pubDate>Thu, 02 Oct 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-02-10377/</guid>
      <description>üöÄ Exciting advancements in on-device OCR technology have emerged with dots.ocr from RedNote, a model outperforming Gemini 2.5 Pro. This 3B parameter model is designed for seamless on-device performance, eliminating the need for API keys and internet access. Key to this is Apple&amp;rsquo;s Neural Engine, which offers impressive power efficiency. üîã However, converting models to Core ML can be challenging. Apple also provides MLX for GPU targeting, enhancing flexibility. Stay tuned for a three-part&amp;hellip;</description>
    </item>
    <item>
      <title>Accelerating our Android apps with Baseline Profiles</title>
      <link>/articles/article-2025-10-01-10330/</link>
      <pubDate>Wed, 01 Oct 2025 16:00:17 +0000</pubDate>
      <guid>/articles/article-2025-10-01-10330/</guid>
      <description>üöÄ Exciting advancements in Android app performance at Meta! We&amp;rsquo;ve leveraged Android‚Äôs Baseline Profiles to enhance app efficiency, addressing user needs that have become more complex over time. üìà By using user data and fine-tuning our approach, we&amp;rsquo;ve improved performance metrics by up to 40%. This helps tackle slow startups and responsiveness issues, ensuring a smoother experience for billions of users. Learn more about our infrastructure and the challenges we faced! #AndroidDevelopment #Meta&amp;hellip;</description>
    </item>
    <item>
      <title>Intelligent Kubernetes Load Balancing at Databricks</title>
      <link>/articles/article-2025-10-01-10304/</link>
      <pubDate>Wed, 01 Oct 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-01-10304/</guid>
      <description>At Databricks, Kubernetes is central to our systems. The article discusses our innovative approach to client-side load balancing, which utilizes real-time service discovery for both internal and ingress traffic. This method enhances efficiency and performance. Future directions include further exploration of load balancing strategies. #Kubernetes #LoadBalancing #Databricks #TechInnovation #CloudComputing üöÄüîß‚ú®</description>
    </item>
    <item>
      <title>Larger than RAM Vector Indexes for Relational Databases</title>
      <link>/articles/article-2025-10-01-10325/</link>
      <pubDate>Wed, 01 Oct 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-01-10325/</guid>
      <description>üöÄ A new hybrid design for scalable vector indexes is making waves in relational databases like MySQL. This innovative approach addresses the challenges of indexing multi-dimensional vectors for real-world applications. Existing research often overlooks the practical needs of relational databases, particularly in terms of storage and transactional requirements. The solution incorporates a well-known data structure, Hierarchical Navigable Small Worlds (HNSW), that enhances approximate nearest&amp;hellip;</description>
    </item>
    <item>
      <title>Tailoring digital play by age: How StoryToys built the LEGO¬Æ Bluey app</title>
      <link>/articles/article-2025-10-01-10324/</link>
      <pubDate>Wed, 01 Oct 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-01-10324/</guid>
      <description>üéÆ StoryToys has launched the LEGO¬Æ Bluey app, aimed at kids ages 2-4, blending fun with early learning. üë∂ The development team faced challenges in designing for different age groups, focusing on varied engagement styles. Younger players explore through tapping, while older ones aim to master interactions. üõ†Ô∏è The app features 2D and 3D building experiences, allowing for skill progression. Communication relies on visual cues instead of text, promoting discovery through play. üîß Using Unity&amp;rsquo;s&amp;hellip;</description>
    </item>
    <item>
      <title>AI as a research partner: Advancing theoretical computer science with AlphaEvolve</title>
      <link>/articles/article-2025-09-30-10274/</link>
      <pubDate>Tue, 30 Sep 2025 16:57:45 +0000</pubDate>
      <guid>/articles/article-2025-09-30-10274/</guid>
      <description>Discover how AlphaEvolve, a coding agent powered by LLMs, is advancing theoretical computer science. This innovative tool helps find and verify combinatorial structures that enhance our understanding of optimization problems. The study highlights AlphaEvolve&amp;rsquo;s iterative process to improve code snippets, resulting in significant findings in complexity theory. Learn more about the potential of AI in mathematical discovery! ü§ñüìä #TheoreticalComputerScience #AI #AlphaEvolve #Mathematics #Research</description>
    </item>
    <item>
      <title>Revolutionizing Data Cloud: Unleashing the Power of the New ML Recommendations System</title>
      <link>/articles/article-2025-09-30-10271/</link>
      <pubDate>Tue, 30 Sep 2025 16:24:25 +0000</pubDate>
      <guid>/articles/article-2025-09-30-10271/</guid>
      <description>üöÄ Exciting developments in Salesforce&amp;rsquo;s Data Cloud! Andrew Patti and his team have launched the first Data Cloud-native ML recommendations system. This innovative system utilizes a flexible schema and a unique multi-cluster architecture to enhance personalization capabilities. Their mission ensures seamless migration for customers transitioning from legacy systems, maintaining high performance and availability. With a focus on scalability and ethical ML use, they are set to meet evolving&amp;hellip;</description>
    </item>
    <item>
      <title>Beyond Basic Scaling: Advanced Kubernetes Resource Strategies</title>
      <link>/articles/article-2025-09-30-10258/</link>
      <pubDate>Tue, 30 Sep 2025 16:00:49 +0000</pubDate>
      <guid>/articles/article-2025-09-30-10258/</guid>
      <description>Navigating Kubernetes resource management can be challenging. Overprovisioning wastes resources, while underprovisioning frustrates developers and slows down product delivery. ‚öôÔ∏è The right balance is crucial for application stability and efficient cluster utilization. A reliable, automated resource management system can help teams optimize their Kubernetes environment. Join the free webinar on Oct. 21 at 11 a.m. PT to learn best practices and strategies for effective resource management. üìÖ&amp;hellip;</description>
    </item>
    <item>
      <title>Payload on Workers: a full-fledged CMS, running entirely on Cloudflare‚Äôs stack</title>
      <link>/articles/article-2025-09-30-10269/</link>
      <pubDate>Tue, 30 Sep 2025 15:50:00 +0000</pubDate>
      <guid>/articles/article-2025-09-30-10269/</guid>
      <description>Discover how Payload, the open-source CMS with over 35,000 stars on GitHub, has been successfully ported to run entirely on Cloudflare&amp;rsquo;s platform! üöÄ This new deployment allows users to set up a fully-configured CMS in just one click, offering serverless functionality. No more constant server maintenance or costs during inactive hours. The integration supports various use cases, making it easy for non-technical users to manage content effectively. Explore the possibilities! üíª‚ú® #PayloadCMS&amp;hellip;</description>
    </item>
    <item>
      <title>How id Software Used Neural Rendering and Path Tracing in DOOM: The Dark Ages</title>
      <link>/articles/article-2025-09-30-10251/</link>
      <pubDate>Tue, 30 Sep 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-30-10251/</guid>
      <description>üöÄ DOOM: The Dark Ages is redefining real-time graphics with RTX neural rendering and path tracing. Billy Khan from id Software explains that path tracing enhances lighting and realism, pushing visual boundaries while maintaining gameplay fluidity. This technique offers superior lighting accuracy and more realistic reflections compared to traditional ray tracing. The team focuses on optimizing GPU performance to ensure scalability across various hardware, making advanced graphics accessible to&amp;hellip;</description>
    </item>
    <item>
      <title>vLLM or llama.cpp: Choosing the right LLM inference engine for your use case</title>
      <link>/articles/article-2025-09-30-10241/</link>
      <pubDate>Tue, 30 Sep 2025 07:00:52 +0000</pubDate>
      <guid>/articles/article-2025-09-30-10241/</guid>
      <description>üîç Exploring LLM Inference Engines: vLLM vs. llama.cpp This article compares two powerful inference engines, highlighting their distinct features. vLLM is built for high-throughput, multi-user scenarios, excelling in scalability and responsiveness. It delivers rapid responses even under heavy loads. In contrast, llama.cpp focuses on efficiency and portability, ideal for single-user tasks and consumer-grade hardware. Its C++ architecture allows for quick loading and minimal dependencies. For&amp;hellip;</description>
    </item>
    <item>
      <title>Unlock GPU Performance: Global Memory Access in CUDA</title>
      <link>/articles/article-2025-09-29-10210/</link>
      <pubDate>Mon, 29 Sep 2025 16:16:37 +0000</pubDate>
      <guid>/articles/article-2025-09-29-10210/</guid>
      <description>Managing memory effectively is crucial for optimizing GPU performance in CUDA. Global memory, the main memory space on CUDA devices, can be accessed by both the host and threads within a kernel grid. It is allocated using the &lt;strong&gt;device&lt;/strong&gt; declaration or CUDA runtime APIs like cudaMalloc(). Data transfers between host and device are done using cudaMemcpy(), while memory can be freed with cudaFree(). Future discussions will cover more on global memory complexities. #CUDA #GPU #MemoryManagement&amp;hellip;</description>
    </item>
    <item>
      <title>100X Faster: How We Supercharged Netflix Maestro‚Äôs Workflow Engine</title>
      <link>/articles/article-2025-09-29-10221/</link>
      <pubDate>Mon, 29 Sep 2025 16:10:40 +0000</pubDate>
      <guid>/articles/article-2025-09-29-10221/</guid>
      <description>üöÄ Exciting improvements to Netflix&amp;rsquo;s Maestro engine! The recent upgrade boosts performance by 100X, reducing workflow overhead from seconds to milliseconds. This redesign enhances scalability and meets evolving business needs, supporting more complex workflows. Explore the updated Maestro on GitHub and enhance your workflow orchestration today! üåê #Netflix #Maestro #DataEngineering #WorkflowOptimization #OpenSource</description>
    </item>
    <item>
      <title>Using LLMs to infer grocery preferences from DoorDash restaurant orders</title>
      <link>/articles/article-2025-09-29-10218/</link>
      <pubDate>Mon, 29 Sep 2025 16:07:33 +0000</pubDate>
      <guid>/articles/article-2025-09-29-10218/</guid>
      <description>üöÄ DoorDash is enhancing grocery delivery by leveraging restaurant order histories to recommend items. By using large language models (LLMs), they analyze consumer preferences to provide personalized grocery suggestions. This approach addresses the &amp;ldquo;cold start problem&amp;rdquo; for new customers in grocery shopping. The system translates order history into relevant grocery recommendations, making it easier for users to find items they love. For more details, check out the article! üì¶üçúü•° #DoorDash&amp;hellip;</description>
    </item>
    <item>
      <title>Advancing Robotics Development with Neural Dynamics in Newton</title>
      <link>/articles/article-2025-09-29-10215/</link>
      <pubDate>Mon, 29 Sep 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-29-10215/</guid>
      <description>üåü Modern robotics is evolving with the introduction of Neural Robot Dynamics (NeRD). NeRD addresses limitations of classical dynamics by offering models that predict stable states and capture complex physics. It can generalize across various tasks and environments, bridging the gap between simulation and real-world applications. As a drop-in backend for physics engines like Newton, NeRD allows teams to enhance their existing frameworks easily. This innovation paves the way for continuous&amp;hellip;</description>
    </item>
    <item>
      <title>Analysis of OpenShift node-system-admin-client lifespan</title>
      <link>/articles/article-2025-09-29-10193/</link>
      <pubDate>Mon, 29 Sep 2025 07:00:55 +0000</pubDate>
      <guid>/articles/article-2025-09-29-10193/</guid>
      <description>In the Red Hat OpenShift Container Platform, the node-system-admin-client certificate plays a vital role in securing internal communication. This article analyzes its lifecycle, revealing a mismatch between its intended two-year validity and the actual one-year expiration due to constraints from its signing Certificate Authority (CA). It also highlights the manual rotation of certificates and the steps needed to renew them effectively. üîÑüîç #OpenShift #PKI #Certificates #RedHat #ContainerSecurity</description>
    </item>
    <item>
      <title>Accelerating Qwen3-8B Agent on Intel¬Æ Core‚Ñ¢ Ultra with Depth-Pruned Draft Models</title>
      <link>/articles/article-2025-09-29-10234/</link>
      <pubDate>Mon, 29 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-29-10234/</guid>
      <description>üöÄ Exciting advancements in AI with the Qwen3-8B model! Recent updates reveal a significant acceleration in performance on Intel¬Æ Core‚Ñ¢ Ultra using Depth-Pruned Draft Models. By implementing speculative decoding, generation speeds have improved by approximately 1.4x. These enhancements enable the efficient operation of a fast, local AI agent. #AI #MachineLearning #Intel #Qwen3 #OpenVINO</description>
    </item>
    <item>
      <title>Building a Resilient Data Platform with Write-Ahead Log at Netflix</title>
      <link>/articles/article-2025-09-26-10173/</link>
      <pubDate>Fri, 26 Sep 2025 18:57:07 +0000</pubDate>
      <guid>/articles/article-2025-09-26-10173/</guid>
      <description>üìä Netflix faces unique challenges in data management at scale, including data loss, corruption, and system entropy. To tackle these issues, they developed the Write-Ahead Log (WAL), a system that enhances data consistency and reliability. WAL ensures durable data changes and efficient message retries, crucial for Netflix‚Äôs real-time data pipelines. The simplified API allows teams to easily integrate different storage solutions while maintaining high performance. Learn more about how WAL is&amp;hellip;</description>
    </item>
    <item>
      <title>Code Mode: the better way to use MCP</title>
      <link>/articles/article-2025-09-26-10145/</link>
      <pubDate>Fri, 26 Sep 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-26-10145/</guid>
      <description>üîç Recent insights reveal a better way to utilize Model Context Protocol (MCP). Many agents currently expose tools directly to LLMs, but converting these tools into a TypeScript API yields better results. This method allows LLMs to manage more complex tools efficiently. When agents string multiple calls, this API approach simplifies the process and enhances performance. For more on MCP‚Äôs impact on AI capabilities, check the full article! #AI #MCP #TechInnovation #TypeScript #LLM</description>
    </item>
    <item>
      <title>Eliminating Cold Starts 2: shard and conquer</title>
      <link>/articles/article-2025-09-26-10146/</link>
      <pubDate>Fri, 26 Sep 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-26-10146/</guid>
      <description>Cloudflare has made significant strides in reducing cold starts for Workers, achieving a 10x improvement. The new technique, called &amp;ldquo;Worker sharding,&amp;rdquo; utilizes a consistent hash ring to enhance routing efficiency across their global network. This builds on the previous method of pre-warming Workers during TLS handshakes. Cold starts, the time taken to initiate a Worker, can now be minimized, ensuring requests are handled more swiftly. Learn more about these advancements! üöÄüåê #Cloudflare&amp;hellip;</description>
    </item>
    <item>
      <title>How Cloudflare uses the world‚Äôs greatest collection of performance data to make the world‚Äôs fastest global network even faster</title>
      <link>/articles/article-2025-09-26-10148/</link>
      <pubDate>Fri, 26 Sep 2025 06:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-26-10148/</guid>
      <description>Cloudflare has announced enhancements to its global network performance. By analyzing extensive traffic data, they are optimizing their congestion control system to handle Internet-scale congestion more efficiently. üåê Early results show an average speed increase of 10% across their network. This improvement is driven by new algorithmic methods that leverage insights from their vast Free Plan user base. üöÄ These updates aim to ensure faster and more reliable connections for all customers. üìà&amp;hellip;</description>
    </item>
    <item>
      <title>User foundation models for Grab</title>
      <link>/articles/article-2025-09-26-10119/</link>
      <pubDate>Fri, 26 Sep 2025 00:00:10 +0000</pubDate>
      <guid>/articles/article-2025-09-26-10119/</guid>
      <description>üåü Grab is enhancing user experiences through a custom AI foundation model designed to understand individual preferences across Southeast Asia. This model combines both tabular and time-series data to create user embeddings, leading to improved personalization and performance in various applications like ad targeting and fraud detection. By leveraging diverse data types, Grab aims for a unified understanding of user behavior, ultimately driving better services. #AI #MachineLearning #Grab&amp;hellip;</description>
    </item>
    <item>
      <title>Apigee Operator for Kubernetes and GKE Inference Gateway integration for  Auth and AI/LLM policies</title>
      <link>/articles/article-2025-09-26-10123/</link>
      <pubDate>Fri, 26 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-26-10123/</guid>
      <description>Unlocking the power of generative AI relies heavily on APIs. üåê The GKE Inference Gateway enhances AI workloads with features like optimized load balancing, dynamic model serving, and autoscaling. It also prioritizes latency-sensitive requests and integrates AI safety checks. Discover how these tools streamline AI model management! ü§ñüìà #AI #Kubernetes #GKE #APIs #TechInnovation</description>
    </item>
    <item>
      <title>R¬≤D¬≤: Three Neural Breakthroughs Transforming Robot Learning from NVIDIA Research</title>
      <link>/articles/article-2025-09-25-10106/</link>
      <pubDate>Thu, 25 Sep 2025 18:47:35 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10106/</guid>
      <description>üåê Exciting advancements in robot learning are highlighted in NVIDIA&amp;rsquo;s R¬≤D¬≤ edition. Today‚Äôs robots excel in controlled environments but face challenges with real-world unpredictability and dexterity. Traditional approaches are limited, struggling with complex dynamics and translating human demonstrations. NVIDIA introduces three neural innovations: 1Ô∏è‚É£ &lt;strong&gt;NeRD&lt;/strong&gt;: Enhances simulation with learned dynamics for better task generalization. 2Ô∏è‚É£ &lt;strong&gt;Dexplore&lt;/strong&gt;: Achieves human-level dexterity using&amp;hellip;</description>
    </item>
    <item>
      <title>Carrying Complexity, Delivering Agility</title>
      <link>/articles/article-2025-09-25-10086/</link>
      <pubDate>Thu, 25 Sep 2025 16:15:00 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10086/</guid>
      <description>MongoDB&amp;rsquo;s engineering vision focuses on three key principles: resilience, intelligence, and simplicity. These principles aim to enhance developer agility by ensuring quick production deployment and easy scalability across multiple clouds. üõ†Ô∏è‚òÅÔ∏è Security is prioritized from the design phase, using architectural isolation and layered defenses to protect data. MongoDB Atlas provides dedicated clusters, minimizing shared resources to enhance performance and security. üîê The platform also&amp;hellip;</description>
    </item>
    <item>
      <title>Why Monitoring Your AI Infrastructure Isn‚Äôt Optional: A Deep Dive into Performance and Reliability</title>
      <link>/articles/article-2025-09-25-10152/</link>
      <pubDate>Thu, 25 Sep 2025 15:42:49 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10152/</guid>
      <description>üåê In today&amp;rsquo;s tech landscape, monitoring AI infrastructure is essential for performance and reliability. AI and machine learning drive innovation, but their effectiveness relies on a robust infrastructure. Minor issues can lead to significant setbacks, impacting model accuracy and increasing latency. A proactive, layer-by-layer monitoring approach ensures that all components work together efficiently, preventing costly downtime. #AIMonitoring #TechInfrastructure #AI #MachineLearning&amp;hellip;</description>
    </item>
    <item>
      <title>Terraform &amp; Ansible: Unifying infrastructure provisioning and configuration management</title>
      <link>/articles/article-2025-09-25-10130/</link>
      <pubDate>Thu, 25 Sep 2025 15:29:00 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10130/</guid>
      <description>üöÄ Terraform and Ansible are transforming how we manage infrastructure in hybrid and multi-cloud environments. As the demand for cloud applications rises, organizations face increasing complexity in infrastructure management. Terraform excels in provisioning resources, while Ansible specializes in configuration management. Together, they streamline Day 2 operations, ensuring infrastructure remains healthy over time. Introducing Terraform actions aims to unify these workflows, reducing&amp;hellip;</description>
    </item>
    <item>
      <title>The New York Times Games‚Äô Path to Dark Mode</title>
      <link>/articles/article-2025-09-25-10079/</link>
      <pubDate>Thu, 25 Sep 2025 15:25:52 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10079/</guid>
      <description>The New York Times Games team has been working on a much-requested Dark Mode feature, aimed at improving player experience, especially for nighttime gameplay. üåô Designing Dark Mode involved more than just inverting colors; it required careful consideration of accessibility and brand consistency across various games. The process revealed years of design complexities that needed addressing. To streamline development, the team focused on the Games app first, ensuring a cohesive user experience&amp;hellip;</description>
    </item>
    <item>
      <title>Consistency at Scale: Unifying Temporal and YugabyteDB</title>
      <link>/articles/article-2025-09-25-10071/</link>
      <pubDate>Thu, 25 Sep 2025 15:00:25 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10071/</guid>
      <description>Manetu has unified Temporal and YugabyteDB, creating a robust data platform that enhances AI reliability and governance. This open-source integration simplifies operations and strengthens trust at scale. By merging orchestration and persistence, Manetu addresses critical infrastructure challenges, ensuring workflows execute smoothly even under stress. This advancement not only boosts performance but also reinforces customer confidence in data integrity and governance. #DataIntegration #AI&amp;hellip;</description>
    </item>
    <item>
      <title>R2 SQL: a deep dive into our new distributed query engine</title>
      <link>/articles/article-2025-09-25-10061/</link>
      <pubDate>Thu, 25 Sep 2025 14:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10061/</guid>
      <description>üöÄ Excited to introduce R2 SQL, a serverless query engine that enables quick analytics on vast datasets without the need for separate services! üîç This innovative tool allows retrieval SQL queries directly against your R2 Data Catalog, utilizing Apache Iceberg for efficient data management. üåê R2 SQL tackles challenges in data I/O and compute by intelligently pruning data and distributing tasks globally, ensuring efficiency and speed. #Cloudflare #R2SQL #DataAnalytics #Serverless #ApacheIceberg</description>
    </item>
    <item>
      <title>Why Your App‚Äôs Biggest Performance Bottleneck Might Be SSL/TLS</title>
      <link>/articles/article-2025-09-25-10049/</link>
      <pubDate>Thu, 25 Sep 2025 13:00:08 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10049/</guid>
      <description>Is your app&amp;rsquo;s performance lagging despite optimizations? The culprit may be SSL/TLS. üîí While we often see it as a security feature, SSL/TLS can be a significant performance bottleneck. Each secure connection requires CPU-intensive handshakes that can compete with your app&amp;rsquo;s logic. Understanding the negotiation process is essential. It involves greeting, certificate exchange, and key generation‚Äîeach step adds overhead. Stay aware of these factors to improve your app&amp;rsquo;s efficiency! üíª&amp;hellip;</description>
    </item>
    <item>
      <title>Uber‚Äôs Strategy to Upgrading 2M&#43; Spark Jobs</title>
      <link>/articles/article-2025-09-25-10068/</link>
      <pubDate>Thu, 25 Sep 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10068/</guid>
      <description>üöÄ Uber successfully migrated over 2 million daily Apache Spark jobs to Spark 3.3. This upgrade utilized automation and safe shadow testing, resulting in significant improvements and over $4 million in savings. Learn more about Uber&amp;rsquo;s innovative approach to enhancing their data processing capabilities. #Uber #ApacheSpark #DataEngineering #Innovation #TechNews</description>
    </item>
    <item>
      <title>Building Omnichannel Customer Connections at HubSpot: A Look Under the Hood</title>
      <link>/articles/article-2025-09-25-10054/</link>
      <pubDate>Thu, 25 Sep 2025 12:00:01 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10054/</guid>
      <description>üåü HubSpot is addressing the challenge of meeting customer expectations for seamless communication across channels like chat, email, voice, and social media. With a focus on developers, HubSpot is making omnichannel experiences practical and scalable. They aim to unify customer data and streamline integrations, moving away from fragmented systems. Their Custom Channels API allows businesses to create tailored messaging experiences, syncing third-party apps with HubSpot‚Äôs Help Desk and CRM for&amp;hellip;</description>
    </item>
    <item>
      <title>Unlocking the power of OpenShift Service Mesh 3</title>
      <link>/articles/article-2025-09-25-10047/</link>
      <pubDate>Thu, 25 Sep 2025 07:00:54 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10047/</guid>
      <description>üöÄ Red Hat OpenShift Service Mesh 3 enhances traffic management, observability, and security for microservices. As applications grow, so do the complexities of routing and securing communications. OSSM 3 introduces Envoy proxies to streamline these processes, ensuring secure service interactions and better traffic control. With features like mutual TLS for security, canary deployments for testing, and enhanced observability tools, teams can manage their microservices more effectively&amp;hellip;.</description>
    </item>
    <item>
      <title>Mafia: The Old Country: Making the old feel new with Unreal Engine 5</title>
      <link>/articles/article-2025-09-25-10083/</link>
      <pubDate>Thu, 25 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10083/</guid>
      <description>Discover how Hangar 13 is bringing the Mafia franchise to life with Unreal Engine 5. The team focuses on creating an authentic world and characters, enhancing the gaming experience for players. Stay tuned for more updates on this exciting project! üéÆüåç‚ú® #MafiaGame #UnrealEngine5 #GameDevelopment #Hangar13</description>
    </item>
    <item>
      <title>Building State-of-the-Art Enterprise Agents 90x Cheaper with Automated Prompt Optimization</title>
      <link>/articles/article-2025-09-24-10042/</link>
      <pubDate>Wed, 24 Sep 2025 21:25:00 +0000</pubDate>
      <guid>/articles/article-2025-09-24-10042/</guid>
      <description>Unlock the potential of AI with Databricks Agent Bricks! üöÄ This platform enables the creation and deployment of high-quality AI agents tailored for enterprise workflows. Key features include automated prompt optimization, which enhances prompt performance while reducing costs significantly. Recent evaluations show that open-source models can outperform proprietary ones at a fraction of the cost. üí° Learn how to leverage these techniques for superior quality-cost tradeoffs in your AI&amp;hellip;</description>
    </item>
    <item>
      <title>Rebuilding Heroku on Kubernetes: Platform Modernization, Operational Complexity, and Technical Debt Resolution</title>
      <link>/articles/article-2025-09-24-10037/</link>
      <pubDate>Wed, 24 Sep 2025 17:41:19 +0000</pubDate>
      <guid>/articles/article-2025-09-24-10037/</guid>
      <description>üöÄ Exciting advancements at Heroku! Jillian Wilmarth, Director of Platform Engineering, led the team in a major overhaul, transitioning the platform to Kubernetes. This shift addresses operational complexities and modernizes infrastructure to enhance user experience. Key improvements include IPv6 support and expanded Dyno sizing options. The move ensures Heroku remains competitive and adaptable in a fast-evolving tech landscape. üåê #Heroku #Kubernetes #PlatformEngineering #TechInnovation&amp;hellip;</description>
    </item>
    <item>
      <title>Building a Next-Generation Key-Value Store at Airbnb</title>
      <link>/articles/article-2025-09-24-10027/</link>
      <pubDate>Wed, 24 Sep 2025 16:02:09 +0000</pubDate>
      <guid>/articles/article-2025-09-24-10027/</guid>
      <description>üöÄ Exciting updates from Airbnb! The team has successfully migrated from Mussel v1 to a rearchitected Mussel v2, enhancing their key-value store for derived data. Mussel v2 addresses issues like operational complexity and performance consistency, now offering real-time streaming and bulk ingestion capabilities. The new architecture utilizes Kubernetes for efficiency, ensuring quick scaling and minimal manual efforts. Airbnb&amp;rsquo;s migration strategy focused on zero data loss and service&amp;hellip;</description>
    </item>
    <item>
      <title>The Case for Microfrontends and Moving Beyond One Framework</title>
      <link>/articles/article-2025-09-24-9983/</link>
      <pubDate>Wed, 24 Sep 2025 16:00:39 +0000</pubDate>
      <guid>/articles/article-2025-09-24-9983/</guid>
      <description>Building large applications today presents unique challenges, especially for the frontend. üñ•Ô∏è The article discusses the shift from monolithic frontends to microfrontends. This approach allows teams to create independently deployable slices of code, improving deployment safety and reducing bottlenecks. üöÄ However, this model introduces complexity in shared state and design consistency. Organizations can benefit from flexibility in choosing frameworks without being locked into one, but they must&amp;hellip;</description>
    </item>
    <item>
      <title>From Lag to Agility: Reinventing Freshworks‚Äô Data Ingestion Architecture</title>
      <link>/articles/article-2025-09-24-9961/</link>
      <pubDate>Wed, 24 Sep 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-24-9961/</guid>
      <description>Freshworks is transforming its data ingestion architecture to enhance data processing capabilities. üåê This shift aims to improve agility in handling data at scale using Databricks, a platform designed for efficient data streaming. üöÄ The focus is on implementing intuitive, AI-driven solutions for better business outcomes. #DataIngestion #SaaS #AI #Databricks #BusinessSolutions</description>
    </item>
    <item>
      <title>How DoorDash Ads keep consumers first with budget A/B experimentation</title>
      <link>/articles/article-2025-09-23-9962/</link>
      <pubDate>Tue, 23 Sep 2025 18:03:33 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9962/</guid>
      <description>üöÄ DoorDash Ads is enhancing consumer experience by implementing a budget A/B framework for ad testing. This innovative approach helps maintain low delivery fees while ensuring relevant ads. The framework addresses challenges in a three-sided marketplace, where classic A/B tests often fall short due to issues like cannibalization and network effects. By creating separate budget pools, DoorDash can achieve unbiased results. Learn more about how this strategy supports consumers, restaurants, and&amp;hellip;</description>
    </item>
    <item>
      <title>Time series foundation models can be few-shot learners</title>
      <link>/articles/article-2025-09-23-9951/</link>
      <pubDate>Tue, 23 Sep 2025 18:00:43 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9951/</guid>
      <description>üöÄ Exciting advancements in time-series forecasting! A new approach allows time-series foundation models to learn from just a few examples, enhancing prediction accuracy without the need for extensive training. This builds on the existing TimesFM model, which previously functioned as a zero-shot learner. The method, highlighted in &amp;ldquo;In-Context Fine-Tuning for Time-Series Foundation Models,&amp;rdquo; simplifies the forecasting process, making it more efficient for businesses to adapt to various needs&amp;hellip;.</description>
    </item>
    <item>
      <title>Faster Training Throughput in FP8 Precision with NVIDIA NeMo</title>
      <link>/articles/article-2025-09-23-9931/</link>
      <pubDate>Tue, 23 Sep 2025 16:36:21 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9931/</guid>
      <description>Unlocking faster training throughput in FP8 precision with NVIDIA NeMo is the focus of the latest insights. üöÄ The article discusses the benefits of FP8 training, emphasizing real-world speed improvements and potential overheads. It compares various FP8 scaling recipes using NVIDIA GPUs, assessing efficiency, stability, and scalability across large models. Reducing numerical precision to 8 bits enhances computational efficiency, lowers costs, and diminishes communication overhead in&amp;hellip;</description>
    </item>
    <item>
      <title>Defensive Databases: Optimizing Index-Refresh Semantics</title>
      <link>/articles/article-2025-09-23-9936/</link>
      <pubDate>Tue, 23 Sep 2025 16:28:34 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9936/</guid>
      <description>üöÄ Palantir&amp;rsquo;s Foundations team is enhancing Elasticsearch (ES) to boost stability without forking the source code. This post discusses how they customize ES by optimizing indexing refresh semantics to avoid bad access patterns. With over 300 ES clusters in various environments, maintaining reliability is crucial. The team aims to share insights with the Elastic community for potential improvements in the mainline offering. üîó Read more about their approach and solutions in the full article!&amp;hellip;</description>
    </item>
    <item>
      <title>Reasoning Through Molecular Synthetic Pathways with Generative AI</title>
      <link>/articles/article-2025-09-23-9934/</link>
      <pubDate>Tue, 23 Sep 2025 15:30:00 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9934/</guid>
      <description>üåç In molecular design, synthesizing viable molecules is a major challenge. Assessing synthesizability often involves mapping complex synthesis pathways. üî¨ NVIDIA&amp;rsquo;s ReaSyn model addresses this by predicting molecular synthesis pathways using a novel approach that combines chain-of-thought reasoning with test-time search methods. üß™ This framework treats synthetic pathways as sequences of reactions, helping chemists deduce effective routes to valuable target molecules. #MolecularDesign&amp;hellip;</description>
    </item>
    <item>
      <title>Why You Can‚Äôt Debug a Running Quantum Computer Program</title>
      <link>/articles/article-2025-09-23-9907/</link>
      <pubDate>Tue, 23 Sep 2025 13:00:59 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9907/</guid>
      <description>üîç Debugging quantum computer programs poses unique challenges. Unlike traditional programming, errors cannot be fixed once the code is running due to high costs and limited capabilities of quantum hardware. üíª Mariia Mykhailova from PsiQuantum highlights the importance of thorough pre-execution testing and outlines a structured workflow for quantum software development. üìä She emphasizes that not all tasks are suitable for quantum computing, particularly those involving large data sets. The&amp;hellip;</description>
    </item>
    <item>
      <title>Powering Partner Gateway metrics with Apache Pinot</title>
      <link>/articles/article-2025-09-23-9900/</link>
      <pubDate>Tue, 23 Sep 2025 00:00:10 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9900/</guid>
      <description>üåê Grab is enhancing its Partner Gateway with Apache Pinot to provide real-time analytics and insights for its partners. üîç The integration supports API management, offering advanced metrics tracking through time-series charts. This allows partners like Alpha, a perishable goods distributor, to optimize operations by monitoring API performance and response times. üìä Key features include a dashboard for real-time insights and Star-tree indexing for improved query performance. This ensures&amp;hellip;</description>
    </item>
    <item>
      <title>Smol2Operator: Post-Training GUI Agents for Computer Use</title>
      <link>/articles/article-2025-09-23-9914/</link>
      <pubDate>Tue, 23 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9914/</guid>
      <description>Introducing Smol2Operator: a vision-language model that learns GUI skills and evolves into an agentic GUI coder. The project shares training recipes, data-processing tools, and demo datasets to support reproducibility and further research. Check out the full collection on GitHub! üñ•Ô∏èüìäü§ñ #AI #MachineLearning #Research #GitHub #TechInnovation</description>
    </item>
    <item>
      <title>Scaling Muse: How Netflix Powers Data-Driven Creative Insights at Trillion-Row Scale</title>
      <link>/articles/article-2025-09-22-9898/</link>
      <pubDate>Mon, 22 Sep 2025 21:24:20 +0000</pubDate>
      <guid>/articles/article-2025-09-22-9898/</guid>
      <description>üöÄ At Netflix, our Muse application plays a vital role in delivering data-driven insights to enhance content discovery for members. Muse helps creative teams identify effective promotional media by analyzing audience engagement with various assets. As user demands evolved, we upgraded Muse&amp;rsquo;s architecture to support advanced features while ensuring high performance. We implemented techniques like HyperLogLog sketches for efficient data processing and utilized the Hollow library for faster&amp;hellip;</description>
    </item>
    <item>
      <title>How We Cut Telemetry Queries to Under 10 Milliseconds</title>
      <link>/articles/article-2025-09-22-9877/</link>
      <pubDate>Mon, 22 Sep 2025 15:00:52 +0000</pubDate>
      <guid>/articles/article-2025-09-22-9877/</guid>
      <description>üöÄ We developed a telemetry pipeline that processes over 5,400 data points per second with response times under 10 milliseconds. üìä By utilizing techniques from flight simulator data, we improved query performance significantly. Traditional queries took over 30 seconds, but with caching and batching, we reduced this to less than 10ms. ‚öôÔ∏è Key strategies included implementing Last Value Cache and batch writing, resulting in thousands of metrics processed with no data loss. #Telemetry&amp;hellip;</description>
    </item>
    <item>
      <title>Breaking the Monolith: How We Used the Strangler Fig Pattern to Transform Segment‚Äôs Notification Architecture</title>
      <link>/articles/article-2025-09-22-9896/</link>
      <pubDate>Mon, 22 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-22-9896/</guid>
      <description>üöÄ Exciting advancements in notification architecture! Segment has adopted the Strangler Fig pattern to modernize its alerts and notifications. This approach promotes modularity, reliability, and reusability in workflows. Learn how this transformation enhances the overall system performance. #TechInnovation #SoftwareDevelopment #Notifications #StranglerFig #ModularDesign</description>
    </item>
    <item>
      <title>Deep researcher with test-time diffusion</title>
      <link>/articles/article-2025-09-19-9847/</link>
      <pubDate>Fri, 19 Sep 2025 20:43:00 +0000</pubDate>
      <guid>/articles/article-2025-09-19-9847/</guid>
      <description>Introducing Test-Time Diffusion Deep Researcher (TTD-DR), a groundbreaking framework in machine intelligence. ü§ñüìö TTD-DR utilizes a Deep Research agent to draft and refine research reports using high-quality information. This method leads to state-of-the-art results in long-form writing and complex reasoning tasks. Unlike traditional DR agents, TTD-DR emulates the iterative human research process, enhancing drafts through research and revision. This innovative approach mirrors the retrieval-&amp;hellip;</description>
    </item>
    <item>
      <title>Six Frameworks for Efficient LLM Inferencing</title>
      <link>/articles/article-2025-09-19-9815/</link>
      <pubDate>Fri, 19 Sep 2025 13:00:38 +0000</pubDate>
      <guid>/articles/article-2025-09-19-9815/</guid>
      <description>Explore the latest advancements in Large Language Model (LLM) inferencing! üöÄ The article discusses six frameworks designed for efficient inferencing, focusing on low latency and high throughput. Key players include vLLM, Hugging Face TGI, and SGLang, each offering unique features for scaling and performance. üîç vLLM enhances memory management with PagedAttention, while Hugging Face TGI supports enterprise-level orchestration. SGLang provides programmable control for complex workflows. Discover&amp;hellip;</description>
    </item>
    <item>
      <title>How we made global routing faster with Bloom filters</title>
      <link>/articles/article-2025-09-19-9838/</link>
      <pubDate>Fri, 19 Sep 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-19-9838/</guid>
      <description>üöÄ We recently optimized our global routing service, achieving a 15% reduction in memory usage. This update improved time-to-first-byte (TTFB) by 10% for the 75th percentile and enhanced routing speeds for sites with numerous static paths. By implementing a Bloom filter instead of slow JSON parsing, we significantly decreased path lookup latency, benefiting all users. #TechUpdate #RoutingOptimization #PerformanceEnhancement #WebDevelopment #Innovation</description>
    </item>
    <item>
      <title>Kubernetes v1.34: DRA Consumable Capacity</title>
      <link>/articles/article-2025-09-18-9799/</link>
      <pubDate>Thu, 18 Sep 2025 18:30:00 +0000</pubDate>
      <guid>/articles/article-2025-09-18-9799/</guid>
      <description>üöÄ Kubernetes v1.34 introduces DRA Consumable Capacity, enhancing Dynamic Resource Allocation (DRA) for better resource management. This feature allows multiple Pods to share devices more efficiently, accommodating specific workload needs. üîë Key benefits include: - Device sharing across multiple ResourceClaims. - Improved resource allocation for portions of devices. - New DistinctAttribute constraint to prevent duplicate allocations. To explore more about enabling this feature and its&amp;hellip;</description>
    </item>
    <item>
      <title>How to Reduce KV Cache Bottlenecks with NVIDIA Dynamo</title>
      <link>/articles/article-2025-09-18-9782/</link>
      <pubDate>Thu, 18 Sep 2025 16:30:00 +0000</pubDate>
      <guid>/articles/article-2025-09-18-9782/</guid>
      <description>As AI models expand, managing inference has become a significant challenge due to the Key-Value (KV) Cache requirements. üß† The KV Cache stores crucial attention data but grows with prompt length, leading to bottlenecks in GPU memory. This can affect performance and increase costs. üí∞ NVIDIA Dynamo&amp;rsquo;s latest release addresses this by offloading the KV Cache to more affordable storage, enabling faster access without disrupting inference. ‚ö° Explore how these optimizations can enhance user&amp;hellip;</description>
    </item>
    <item>
      <title>Modernizing Core Insurance Systems: Breaking the Batch Bottleneck</title>
      <link>/articles/article-2025-09-18-9790/</link>
      <pubDate>Thu, 18 Sep 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-18-9790/</guid>
      <description>Modernizing legacy databases to Java + MongoDB Atlas can enhance batch performance without sacrificing efficiency. By utilizing bulk operations, intelligent prefetching, and parallel execution, we developed a framework that significantly improves execution times‚Äîoften achieving 10-15x better performance compared to legacy systems. üåêüìä This modernization allows for flexibility, scalability, and real-time insights, addressing common challenges in batch job performance. Adapting to today&amp;rsquo;s&amp;hellip;</description>
    </item>
    <item>
      <title>Reach native speed with MacOS llama.cpp container inference</title>
      <link>/articles/article-2025-09-18-9764/</link>
      <pubDate>Thu, 18 Sep 2025 07:00:55 +0000</pubDate>
      <guid>/articles/article-2025-09-18-9764/</guid>
      <description>üöÄ New advancements in GPU acceleration for AI inference on macOS! Recent developments showcase how llama.cpp now achieves native speed performance in most use cases. By leveraging a thin virtualization layer, containers can run efficiently on macOS. This enhancement utilizes the API remoting architecture, allowing optimized GPU access in virtualized environments. Key components include ggml-remoting and libkrun&amp;rsquo;s virtio-gpu, which enable seamless communication between the virtual machine and&amp;hellip;</description>
    </item>
    <item>
      <title>An Introduction to Speculative Decoding for Reducing Latency in AI Inference</title>
      <link>/articles/article-2025-09-17-9746/</link>
      <pubDate>Wed, 17 Sep 2025 18:09:12 +0000</pubDate>
      <guid>/articles/article-2025-09-17-9746/</guid>
      <description>üöÄ Speculative decoding is a key technique for reducing latency in AI inference with large language models (LLMs). It addresses the bottleneck caused by the sequential nature of autoregressive generation, which can lead to underutilization of GPU power. By predicting multiple tokens at once, it enhances efficiency without sacrificing output quality. This method pairs a target model with a lightweight draft mechanism to speed up text generation, making AI systems more responsive. Explore how&amp;hellip;</description>
    </item>
    <item>
      <title>Making LLMs more accurate by using all of their layers</title>
      <link>/articles/article-2025-09-17-9743/</link>
      <pubDate>Wed, 17 Sep 2025 17:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-17-9743/</guid>
      <description>Introducing SLED, a new decoding strategy aimed at improving the accuracy of large language models (LLMs) by utilizing all model layers. This method aligns outputs with intrinsic knowledge, tackling the issue of &amp;ldquo;hallucination,&amp;rdquo; where models generate incorrect information. SLED enhances factuality without requiring external data or additional fine-tuning. Learn more about this innovative approach presented at NeurIPS 2024! üìäüí°‚ú® #AI #MachineLearning #LLMs #SLED #NeurIPS2024</description>
    </item>
    <item>
      <title>A deep dive into Apache Kafka&#39;s KRaft protocol</title>
      <link>/articles/article-2025-09-17-9720/</link>
      <pubDate>Wed, 17 Sep 2025 12:33:25 +0000</pubDate>
      <guid>/articles/article-2025-09-17-9720/</guid>
      <description>üöÄ Dive into the KRaft protocol of Apache Kafka! This article explores the key concepts and implementation of KRaft in version 4.1.0. It highlights how KRaft simplifies Kafka operations by eliminating the need for ZooKeeper and addressing scalability and consistency issues. The guide covers important elements like consensus algorithms, leader election, log replication, and safety rules essential for distributed systems. Developers and engineers looking to enhance their understanding will find&amp;hellip;</description>
    </item>
    <item>
      <title>Staying ahead of artificial intelligence threats</title>
      <link>/articles/article-2025-09-17-9715/</link>
      <pubDate>Wed, 17 Sep 2025 07:01:06 +0000</pubDate>
      <guid>/articles/article-2025-09-17-9715/</guid>
      <description>üöÄ In 2024, over 40,000 Common Vulnerabilities and Exposures (CVEs) were reported, marking a 38% rise from 2023. The trend of increasing CVEs is expected to continue into 2025, with projections of up to 58,956 new CVEs. üîí Kernel live patching has emerged as a crucial practice for applying security updates without downtime. This allows OpenStack Services on OpenShift users to maintain system integrity while minimizing interruptions. üñ•Ô∏è For more details, check out the article on kernel live&amp;hellip;</description>
    </item>
    <item>
      <title>Bringing the urban Paris of La Haine to the stage with UE5</title>
      <link>/articles/article-2025-09-17-9724/</link>
      <pubDate>Wed, 17 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-17-9724/</guid>
      <description>Silent Partners Studio has utilized 3D scans of Parisian housing projects to recreate the aesthetic of the film La Haine in Unreal Engine. This innovative approach aims to deliver an immersive theater experience that is both technically impressive and emotionally impactful. Explore how technology can enhance storytelling in the arts! üé≠üèôÔ∏è #LaHaine #Theater #UnrealEngine #ImmersiveArt #SilentPartnersStudio</description>
    </item>
    <item>
      <title>Split-screen and GameShare networking in Survival Kids</title>
      <link>/articles/article-2025-09-17-9819/</link>
      <pubDate>Wed, 17 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-17-9819/</guid>
      <description>üåü Exciting news from Unity and KONAMI! This summer, they launched &lt;strong&gt;Survival Kids&lt;/strong&gt;, a fresh take on a classic game, exclusively for Nintendo Switch‚Ñ¢ 2. The development team faced unique challenges while building robust multiplayer options using Unity 6. They crafted a split-screen mode and GameShare capabilities, allowing players to enjoy diverse gaming experiences. By implementing virtual input players, they ensured smooth gameplay with up to two local players, while optimizing for&amp;hellip;</description>
    </item>
    <item>
      <title>What an MCP implementation looks like at a CRM company</title>
      <link>/articles/article-2025-09-16-9673/</link>
      <pubDate>Tue, 16 Sep 2025 19:08:00 +0000</pubDate>
      <guid>/articles/article-2025-09-16-9673/</guid>
      <description>Ryan discusses Model Context Protocol (MCP) with Karen Ng, EVP of Product at HubSpot. They delve into its role as a standard for agentic interactions and the challenges faced in integrating MCP within HubSpot&amp;rsquo;s ecosystem. MCP, developed by Anthropic, aims to enhance connections between AI agents and external systems. üîóüí°ü§ñ #AI #CRM #HubSpot #MCP #Technology</description>
    </item>
    <item>
      <title>Taming Service-Oriented Architecture Using A Data-Oriented Service Mesh</title>
      <link>/articles/article-2025-09-16-9706/</link>
      <pubDate>Tue, 16 Sep 2025 18:37:58 +0000</pubDate>
      <guid>/articles/article-2025-09-16-9706/</guid>
      <description>üöÄ Exciting news from Airbnb! At the Hasura Enterprise GraphQL Conf, the team introduced Viaduct, a data-oriented service mesh aimed at improving modularity in microservices-based Service-Oriented Architecture (SOA). Viaduct utilizes GraphQL to manage complex dependencies, moving away from traditional procedure-oriented designs. This new approach facilitates data access and enhances productivity for teams. üõ†Ô∏è Learn more about how Viaduct is shaping modern SOA. #Airbnb #GraphQL #ServiceMesh&amp;hellip;</description>
    </item>
    <item>
      <title>Reducing Cold Start Latency for LLM Inference with NVIDIA Run:ai Model Streamer</title>
      <link>/articles/article-2025-09-16-9702/</link>
      <pubDate>Tue, 16 Sep 2025 17:35:13 +0000</pubDate>
      <guid>/articles/article-2025-09-16-9702/</guid>
      <description>üöÄ Deploying large language models (LLMs) can be challenging due to cold start delays, which hinder performance and scalability. üñ•Ô∏è The article discusses the NVIDIA Run:ai Model Streamer, an open-source SDK that reduces loading times by concurrently streaming model weights into GPU memory. üìä Benchmark tests show significant improvements in cold start latency, especially in cloud environments, while maintaining compatibility with Safetensor formats. #AI #MachineLearning #NVIDIA #Inference&amp;hellip;</description>
    </item>
    <item>
      <title>Autodesk Research Brings Warp Speed to Computational Fluid Dynamics on NVIDIA GH200</title>
      <link>/articles/article-2025-09-16-9692/</link>
      <pubDate>Tue, 16 Sep 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-16-9692/</guid>
      <description>üöÄ Autodesk Research has made strides in computational fluid dynamics (CFD) with its Accelerated Lattice Boltzmann (XLB) library. This open-source solver bridges the gap between traditional CAE and AI/ML ecosystems. By leveraging NVIDIA Warp and the GH200 Superchip, XLB achieves an ~8x speedup in performance, allowing for high-fidelity simulations at scale. This advancement demonstrates the potential of Python in high-performance scenarios. #CFD #AutodeskResearch #NVIDIAWarp&amp;hellip;</description>
    </item>
    <item>
      <title>Defending 20 Trillion Transactions: How Hyperforce‚Äôs Trusted Perimeter Stops DDoS Attacks with AI</title>
      <link>/articles/article-2025-09-16-9686/</link>
      <pubDate>Tue, 16 Sep 2025 14:29:29 +0000</pubDate>
      <guid>/articles/article-2025-09-16-9686/</guid>
      <description>üöÄ Salesforce&amp;rsquo;s Hyperforce team has developed the Trusted Perimeter, a robust platform that protects over 4.5 million domains from DDoS attacks. üõ°Ô∏è This system can handle attacks up to 1.6 terabytes per second, ensuring seamless security and performance globally. üîç It integrates AI for real-time threat detection and supports 20 trillion transactions annually, allowing businesses to focus on operations without security concerns. #CyberSecurity #DDoSProtection #Salesforce #AI #TrustedPerimeter</description>
    </item>
    <item>
      <title>Taming the monorepo beast: Our journey to a leaner, faster GitLab repo</title>
      <link>/articles/article-2025-09-16-9675/</link>
      <pubDate>Tue, 16 Sep 2025 00:23:00 +0000</pubDate>
      <guid>/articles/article-2025-09-16-9675/</guid>
      <description>üöÄ At Grab, our engineering team tackled the challenges of a massive Go monorepo that had become a bottleneck over the years. We discovered that replication delays and a hefty repository size were crippling our developer workflows. With 12.7 million commits and 22.1 million Git trees, performance suffered significantly. To address this, we implemented a custom migration strategy that reduced commits by 99.9%, improving replication time from minutes to seconds! This transformation not only&amp;hellip;</description>
    </item>
    <item>
      <title>How we built it: Real-time analytics for Stripe Billing</title>
      <link>/articles/article-2025-09-16-9741/</link>
      <pubDate>Tue, 16 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-16-9741/</guid>
      <description>üöÄ A recent Stripe survey found that 84% of global business leaders believe quick pricing adaptation is crucial for competitive advantage. To support this need, Stripe has launched a real-time analytics system for Billing. This allows businesses to track subscription metrics like MRR growth and churn rates with minimal latency‚Äîup to 15 minutes. The upgrade replaces traditional batch processing, enhancing data visibility and accuracy for fast-moving trends. #RealTimeAnalytics #StripeBilling&amp;hellip;</description>
    </item>
    <item>
      <title>Building an anomaly detection platform at DoorDash to catch fraud trends early</title>
      <link>/articles/article-2025-09-15-9668/</link>
      <pubDate>Mon, 15 Sep 2025 18:57:44 +0000</pubDate>
      <guid>/articles/article-2025-09-15-9668/</guid>
      <description>üö® DoorDash has developed an anomaly detection platform aimed at identifying fraud trends earlier. The system scans millions of user segments to detect subtle behavioral changes that may indicate emerging fraud patterns. Key concepts include anomalous trend detection, focusing on collective user behavior, and anomalous outlier detection, which identifies individual anomalies. This proactive approach seeks to mitigate potential losses before they escalate. #FraudDetection #DoorDash&amp;hellip;</description>
    </item>
    <item>
      <title>Why some agentic AI developers are moving code from Python to Rust</title>
      <link>/articles/article-2025-09-15-9636/</link>
      <pubDate>Mon, 15 Sep 2025 07:00:53 +0000</pubDate>
      <guid>/articles/article-2025-09-15-9636/</guid>
      <description>AI developers are exploring a shift from Python to Rust for agentic AI solutions. While Python is popular for its simplicity and rich libraries, its Global Interpreter Lock (GIL) limits performance in CPU-bound tasks, especially as systems scale from 5 to 500 agents. Rust offers a solution with better concurrency and scalability, allowing more efficient handling of multiple agents and CPU-intensive tasks. Developers are finding that a hybrid approach‚Äîprototyping in Python and optimizing with&amp;hellip;</description>
    </item>
    <item>
      <title>Confidential VMs: The core of confidential containers</title>
      <link>/articles/article-2025-09-15-9637/</link>
      <pubDate>Mon, 15 Sep 2025 07:00:51 +0000</pubDate>
      <guid>/articles/article-2025-09-15-9637/</guid>
      <description>üîç Discover the essentials of Confidential Virtual Machines (CVMs) and their role in enhancing the security of confidential containers (CoCo). CVMs utilize hardware and software to ensure data confidentiality, isolating workloads from the host environment. This integration with Red Hat Enterprise Linux (RHEL) and OpenShift boosts security standards for data in use. üõ°Ô∏è Learn about features like Unified Kernel Images (UKI) and remote attestation that enhance the protection of workloads&amp;hellip;.</description>
    </item>
    <item>
      <title>How we supercharged GitLab CI statuses with WebSockets</title>
      <link>/articles/article-2025-09-15-9666/</link>
      <pubDate>Mon, 15 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-15-9666/</guid>
      <description>üöÄ We&amp;rsquo;ve made significant improvements to GitLab&amp;rsquo;s CI job status updates by reducing API calls by 92.56%! In 2025, we&amp;rsquo;ve shifted from legacy polling to WebSockets, allowing real-time updates without unnecessary network traffic. This change means users now see job status updates instantly instead of waiting up to 30 seconds. With GraphQL subscriptions, we‚Äôve transformed how data is fetched, resulting in just 3.4 million calls per day, down from 45 million. Stay tuned as we work on implementing&amp;hellip;</description>
    </item>
    <item>
      <title>A deep dive into Cloudflare‚Äôs September 12, 2025 dashboard and API outage</title>
      <link>/articles/article-2025-09-13-9629/</link>
      <pubDate>Sat, 13 Sep 2025 07:19:00 +0000</pubDate>
      <guid>/articles/article-2025-09-13-9629/</guid>
      <description>üö® On September 12, 2025, Cloudflare experienced a significant outage affecting its Dashboard and several APIs. The disruption lasted for about an hour, triggered by a bug that caused excessive calls to the Tenant Service API. This led to instability and authorization failures across the platform. Cloudflare has since detailed the timeline of events and corrective measures taken to prevent future occurrences. For more insights, check out their full post. #Cloudflare #APIOutage #TechUpdate&amp;hellip;</description>
    </item>
    <item>
      <title>Databricks on Databricks: Scaling Database Reliability</title>
      <link>/articles/article-2025-09-12-9623/</link>
      <pubDate>Fri, 12 Sep 2025 19:20:00 +0000</pubDate>
      <guid>/articles/article-2025-09-12-9623/</guid>
      <description>Databricks engineers share insights on enhancing database reliability through big data analytics tools. The article discusses strategies employed to scale their systems effectively, showcasing the role of advanced analytics in ensuring dependable performance. Learn how these techniques can benefit database management. üìäüîç #Databricks #DatabaseReliability #BigData #DataEngineering #Analytics</description>
    </item>
    <item>
      <title>Postgres High Availability with CDC</title>
      <link>/articles/article-2025-09-12-9622/</link>
      <pubDate>Fri, 12 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-12-9622/</guid>
      <description>Postgres High Availability can face challenges with Change Data Capture (CDC). The design of Postgres‚Äô replication introduces complexities that may stall failover. The primary system emits Write Ahead Logs (WAL) to standbys. However, if a CDC client lags, it can prevent effective failover, as the logical replication slot on the primary depends on the client&amp;rsquo;s progress. Postgres 17 introduced logical replication failover, but eligibility for promotion has specific requirements. If the CDC&amp;hellip;</description>
    </item>
    <item>
      <title>Speculative cascades ‚Äî A hybrid approach for smarter, faster LLM inference</title>
      <link>/articles/article-2025-09-11-9597/</link>
      <pubDate>Thu, 11 Sep 2025 22:01:00 +0000</pubDate>
      <guid>/articles/article-2025-09-11-9597/</guid>
      <description>Introducing &amp;ldquo;speculative cascades,&amp;rdquo; a new method enhancing the efficiency of LLMs by merging speculative decoding with standard cascades. This approach aims to reduce inference costs while maintaining output quality. It utilizes smaller models to handle simpler tasks, reserving larger models for complex queries. By combining these techniques, speculative cascades achieve faster results at lower costs, as demonstrated in tests with Gemma and T5 models. #AI #LLM #MachineLearning #TechInnovation&amp;hellip;</description>
    </item>
    <item>
      <title>High Performance Ratelimiting at Databricks</title>
      <link>/articles/article-2025-09-11-9593/</link>
      <pubDate>Thu, 11 Sep 2025 20:45:00 +0000</pubDate>
      <guid>/articles/article-2025-09-11-9593/</guid>
      <description>üöÄ Databricks engineers are tackling the complexities of distributed ratelimiting. The article outlines innovative approaches to enhance performance in this area, showcasing the team&amp;rsquo;s commitment to solving challenging problems. This could lead to significant improvements in data processing efficiency. Stay tuned for more insights from their engineering efforts! #Databricks #Engineering #DataProcessing #TechInnovation #Ratelimiting</description>
    </item>
    <item>
      <title>Smarter nucleic acid design with NucleoBench and AdaBeam</title>
      <link>/articles/article-2025-09-11-9561/</link>
      <pubDate>Thu, 11 Sep 2025 17:18:36 +0000</pubDate>
      <guid>/articles/article-2025-09-11-9561/</guid>
      <description>üöÄ Exciting advancements in nucleic acid design! Researchers have developed NucleoBench, an open-source benchmark for evaluating nucleic acid sequence design algorithms. This tool runs over 400,000 experiments across various biological challenges to improve therapeutic development. Alongside NucleoBench, they introduced AdaBeam, a new algorithm that outperforms existing methods on 11 out of 16 tasks, showing better scalability for complex models. Both NucleoBench and AdaBeam are available for&amp;hellip;</description>
    </item>
    <item>
      <title>Why Multi-Agent Systems Need Memory Engineering</title>
      <link>/articles/article-2025-09-11-9558/</link>
      <pubDate>Thu, 11 Sep 2025 15:12:47 +0000</pubDate>
      <guid>/articles/article-2025-09-11-9558/</guid>
      <description>Multi-agent AI systems often struggle not due to communication issues, but because of memory limitations. Agents frequently duplicate tasks and work from inconsistent states, which worsens as more agents join. A solution lies in memory engineering, which provides a structured approach to manage agent memory. This allows for better coordination and efficiency in complex tasks. Understanding and implementing shared memory infrastructure is crucial for successful multi-agent deployments. #AI&amp;hellip;</description>
    </item>
    <item>
      <title>How Quantization Aware Training Enables Low-Precision Accuracy Recovery</title>
      <link>/articles/article-2025-09-11-9553/</link>
      <pubDate>Thu, 11 Sep 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-11-9553/</guid>
      <description>Optimizing AI models for deployment involves various compression techniques. Post-training quantization (PTQ) is common, but quantization aware training (QAT) and quantization aware distillation (QAD) provide significant advantages. These methods prepare models for lower precision by simulating quantization effects, enhancing accuracy recovery. Learn more about these techniques and their impact on model performance! üìäü§ñ #AI #Quantization #MachineLearning #ModelOptimization #TechTrends</description>
    </item>
    <item>
      <title>Next Gen Data Processing at Massive Scale At Pinterest With Moka (Part 2 of 2)</title>
      <link>/articles/article-2025-09-10-9530/</link>
      <pubDate>Wed, 10 Sep 2025 16:01:44 +0000</pubDate>
      <guid>/articles/article-2025-09-10-9530/</guid>
      <description>Pinterest is evolving its data processing capabilities with Moka, a next-gen platform built on AWS EKS. üåê The new infrastructure includes standardized cluster environments like test, dev, staging, and production, allowing for effective resource management and security. Key features include enhanced logging using Fluent Bit and observability metrics via OTEL, improving insights into performance and stability. üìä Learn more about Moka&amp;rsquo;s architecture and its future developments. #DataProcessing&amp;hellip;</description>
    </item>
    <item>
      <title>Maximizing Low-Latency Networking Performance for Financial Services with NVIDIA Rivermax and NEIO FastSocket</title>
      <link>/articles/article-2025-09-10-9521/</link>
      <pubDate>Wed, 10 Sep 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-10-9521/</guid>
      <description>Ultra-low latency and reliable packet delivery are essential in sectors like financial services, cloud gaming, and media. Delays or packet losses can lead to significant issues, including financial losses and poor user experiences. NVIDIA Rivermax offers a high-performance solution for these challenges. It utilizes GPU-accelerated technologies to ensure high throughput, low latency, and minimal CPU usage, making it ideal for demanding applications. Learn more about how Rivermax is&amp;hellip;</description>
    </item>
    <item>
      <title>Building a Scalable Document Processing Pipeline With LlamaParse, Confluent Cloud, and MongoDB</title>
      <link>/articles/article-2025-09-10-9515/</link>
      <pubDate>Wed, 10 Sep 2025 14:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-10-9515/</guid>
      <description>As data volumes grow, organizations face challenges in extracting insights from unstructured documents. This article introduces a scalable document processing pipeline using AWS S3, LlamaParse, Confluent Cloud, and MongoDB. The architecture enables real-time processing and semantic enrichment of documents, enhancing applications like search and recommendation systems. Key components include intelligent parsing, streaming data management, and flexible storage solutions. Explore how this system&amp;hellip;</description>
    </item>
    <item>
      <title>AI search with style: Fashion on OpenShift AI with EDB</title>
      <link>/articles/article-2025-09-10-9508/</link>
      <pubDate>Wed, 10 Sep 2025 07:00:53 +0000</pubDate>
      <guid>/articles/article-2025-09-10-9508/</guid>
      <description>Unlocking fashion e-commerce with AI! üõçÔ∏è‚ú® Traditional keyword searches often miss the mark in understanding customers&amp;rsquo; true intent. This article highlights a solution using semantic search, which captures meaning and intent in fashion searches. EDB Postgres AI and Red Hat OpenShift AI work together to process AI data, enabling seamless visual and text searches. Users can upload images or describe items without needing exact terms. This innovative approach not only enhances search accuracy but&amp;hellip;</description>
    </item>
    <item>
      <title>Inside the Survival Kids multiplayer network infrastructure</title>
      <link>/articles/article-2025-09-10-9533/</link>
      <pubDate>Wed, 10 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-10-9533/</guid>
      <description>üöÄ This summer, &lt;em&gt;Survival Kids&lt;/em&gt; launched on Nintendo Switch‚Ñ¢ 2, built on Unity 6. A small, experienced team of about 10 developers led the project, utilizing their extensive knowledge to navigate challenges effectively. üïπÔ∏è The game‚Äôs multiplayer network supports various play styles: single-player, local co-op, and online. Unique features like GameShare allow players to connect across devices. üí° The team utilized Netcode for Entities, enabling flexible multiplayer experiences. Their focus on&amp;hellip;</description>
    </item>
    <item>
      <title>Jupyter Agents: training LLMs to reason with notebooks</title>
      <link>/articles/article-2025-09-10-9512/</link>
      <pubDate>Wed, 10 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-10-9512/</guid>
      <description>üöÄ Jupyter Agents aim to enhance LLMs by enabling code execution directly in Jupyter Notebooks. This integration helps tackle complex data science tasks more efficiently. The initiative focuses on improving smaller models to compete with larger ones through high-quality training data and fine-tuning methods. Stay tuned for updates on this innovative project! üß†üíª #Jupyter #LLM #DataScience #AI #MachineLearning</description>
    </item>
    <item>
      <title>Migrating Lyft‚Äôs Android Codebase to Kotlin</title>
      <link>/articles/article-2025-09-09-9494/</link>
      <pubDate>Tue, 09 Sep 2025 20:34:03 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9494/</guid>
      <description>üöÄ Lyft has successfully migrated its Android codebase to Kotlin, a journey that began in 2018. The Rider, Driver, and Urban Solutions apps are now fully Kotlin-based. This transition offers benefits like concise code, faster compile speeds with the K2 compiler, and support for modern UI frameworks like Compose. To manage the migration, Lyft utilized a tool called Migration Tracker, which monitors progress and helps automate the process. Challenges included issues with the migration tool and&amp;hellip;</description>
    </item>
    <item>
      <title>Real-Time Materialized Views With MongoDB Atlas Stream Processing</title>
      <link>/articles/article-2025-09-09-9490/</link>
      <pubDate>Tue, 09 Sep 2025 17:45:42 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9490/</guid>
      <description>üöÄ Developers transitioning from relational databases may struggle with MongoDB‚Äôs avoidance of joins, which can lead to performance issues. Instead of using joins, MongoDB encourages data duplication and denormalization for better efficiency. This method reduces query latency and simplifies architecture. MongoDB Atlas Stream Processing facilitates real-time materialized views, enhancing query optimization without the overhead of traditional ETL processes. Explore how to leverage these modern&amp;hellip;</description>
    </item>
    <item>
      <title>How to Connect Distributed Data Centers Into Large AI Factories with Scale-Across Networking</title>
      <link>/articles/article-2025-09-09-9465/</link>
      <pubDate>Tue, 09 Sep 2025 17:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9465/</guid>
      <description>AI scaling faces challenges due to physical limitations in data centers, such as power and cooling capacity. üåê Traditional long-haul Ethernet solutions can lead to high latency and unpredictable data delivery, which is problematic for AI workloads. NVIDIA&amp;rsquo;s Spectrum-XGS Ethernet technology introduces scale-across networking, allowing multiple data centers to function as one large AI factory, enhancing performance for training and inference tasks. üöÄ #ArtificialIntelligence #DataCenters&amp;hellip;</description>
    </item>
    <item>
      <title>Investigating IntelliJ Platform UI Freezes</title>
      <link>/articles/article-2025-09-09-9473/</link>
      <pubDate>Tue, 09 Sep 2025 12:26:47 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9473/</guid>
      <description>Have you ever experienced UI freezes in JetBrains IDEs? ü§î This article delves into the reasons behind these freezes, primarily caused by the single-threaded nature of the Java AWT framework. When the event dispatch thread (EDT) is blocked, user interactions become unresponsive. To investigate, start by examining the thread dump, focusing on the AWT-EventQueue thread. Look for signs of lock acquisition issues, particularly the read-write lock, which can indicate background threads causing the&amp;hellip;</description>
    </item>
    <item>
      <title>Extracting trending keywords from OpenChat messages</title>
      <link>/articles/article-2025-09-09-9457/</link>
      <pubDate>Tue, 09 Sep 2025 09:30:00 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9457/</guid>
      <description>üîç Heewoong Park, a machine learning engineer, shares insights on enhancing LINE OpenChat. The article discusses how the AI Services Lab aims to extract trending keywords from OpenChat messages to improve user engagement. By analyzing message content, they hope to display relevant topics on the main screen, making it more appealing for users to explore new chatrooms. Currently, the focus on chatroom recommendations may not encourage frequent visits. The team‚Äôs approach aims to group similar&amp;hellip;</description>
    </item>
    <item>
      <title>Built with UE5, Borderlands 4 delivers ambitious scale with World Partition, Nanite, Lumen, and more</title>
      <link>/articles/article-2025-09-09-9474/</link>
      <pubDate>Tue, 09 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9474/</guid>
      <description>üöÄ Exciting advancements are coming to the Borderlands series with Borderlands 4! Gearbox Software highlights how Unreal Engine 5 features like World Partition and Nanite enhance gameplay. These technologies allow for larger, more detailed environments, improving player experience. Stay tuned for more updates on this ambitious installment! üéÆ‚ú® #Borderlands4 #GameDevelopment #UE5 #GearboxSoftware #GamingNews</description>
    </item>
    <item>
      <title>Form follows function: Building resilient form submissions at scale</title>
      <link>/articles/article-2025-09-09-9476/</link>
      <pubDate>Tue, 09 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9476/</guid>
      <description>Webflow is enhancing its system resiliency to ensure reliable form submissions, crucial for businesses. Key features include: - &lt;strong&gt;Durability&lt;/strong&gt;: Submissions are preserved even during database failures. - &lt;strong&gt;Non-blocking&lt;/strong&gt;: Recovery mechanisms do not slow down requests. - &lt;strong&gt;Idempotent&lt;/strong&gt;: Submissions can be safely replayed without duplicates. The process involves write-ahead backups stored in Amazon S3, allowing for both targeted and global replay of submissions during outages. #Webflow&amp;hellip;</description>
    </item>
    <item>
      <title>mmBERT: ModernBERT goes Multilingual</title>
      <link>/articles/article-2025-09-09-9477/</link>
      <pubDate>Tue, 09 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9477/</guid>
      <description>üåê Exciting developments in AI! The article discusses mmBERT, a new multilingual model built on ModernBERT. It aims to enhance language processing across various languages. Key features include improved understanding and generation of text in multiple languages, making it a versatile tool for global applications. For more details, check out the full article! #AI #MachineLearning #NLP #mmBERT #Multilingual</description>
    </item>
    <item>
      <title>Triage and Fix with Confidence: heroku run and OTel on Heroku Fir</title>
      <link>/articles/article-2025-09-08-9446/</link>
      <pubDate>Mon, 08 Sep 2025 21:33:43 +0000</pubDate>
      <guid>/articles/article-2025-09-08-9446/</guid>
      <description>üö® When production issues arise, Heroku‚Äôs new capabilities can help. With the heroku run command, developers can launch a dedicated dyno for troubleshooting without risking the stability of live applications. This interactive session allows for real-time diagnostics and efficient problem resolution. üõ†Ô∏è Additionally, OpenTelemetry (OTel) enhancements provide valuable insights into application performance after fixes are applied. #Heroku #DevOps #Troubleshooting #OpenTelemetry #DatabaseMigration</description>
    </item>
    <item>
      <title>Scaling DeepSeek and Sparse MoE models in vLLM with llm-d</title>
      <link>/articles/article-2025-09-08-9429/</link>
      <pubDate>Mon, 08 Sep 2025 14:02:38 +0000</pubDate>
      <guid>/articles/article-2025-09-08-9429/</guid>
      <description>üöÄ Exciting advancements in scaling Mixture of Experts (MoE) models with vLLM and the llm-d project are transforming open-source LLM capabilities. üåê This article discusses innovations like multi-head latent attention and sparse configurations, enabling efficient deployment in Kubernetes. Learn how vLLM enhances expert parallelism and communication for large models. For detailed insights, check the full article! üìä #MachineLearning #AI #Kubernetes #DeepLearning #OpenSource</description>
    </item>
    <item>
      <title>Scaling DeepSeek-style MoEs with vLLM and llm-d using Wide EP</title>
      <link>/articles/article-2025-09-08-9551/</link>
      <pubDate>Mon, 08 Sep 2025 14:02:38 +0000</pubDate>
      <guid>/articles/article-2025-09-08-9551/</guid>
      <description>üîç Exciting advancements in serving large-scale Mixture of Experts (MoE) language models are discussed in a recent article on vLLM and llm-d. The article covers the architectural changes in vLLM that enhance the efficiency of DeepSeek-style models. Key innovations include multi-head latent attention and sparse configurations with hundreds of experts. llm-d enables high-performance deployments in Kubernetes, offering intelligent scheduling and expert parallelism for efficient scaling. Learn&amp;hellip;</description>
    </item>
    <item>
      <title>Accelerate Large-Scale LLM Inference and KV Cache Offload with CPU-GPU Memory Sharing</title>
      <link>/articles/article-2025-09-05-7790/</link>
      <pubDate>Fri, 05 Sep 2025 17:24:06 +0000</pubDate>
      <guid>/articles/article-2025-09-05-7790/</guid>
      <description>Large Language Models (LLMs) like Llama 3 70B and Llama 4 Scout 109B are pushing AI boundaries but pose memory challenges for inference efficiency. These models can require significant memory, with Llama 3 needing around 140 GB and Llama 4 about 218 GB. The key-value (KV) cache also demands additional memory as context and batch sizes increase. NVIDIA&amp;rsquo;s Grace Hopper and Blackwell architectures use NVLink-C2C, allowing CPU-GPU memory sharing. This innovation enhances data access and&amp;hellip;</description>
    </item>
    <item>
      <title>Accelerate Large-Scale LLM Inference and KV Cache Offload with CPU-GPU Memory Sharing</title>
      <link>/articles/article-2025-09-05-7826/</link>
      <pubDate>Fri, 05 Sep 2025 17:24:06 +0000</pubDate>
      <guid>/articles/article-2025-09-05-7826/</guid>
      <description>Large Language Models (LLMs) like Llama 3 70B and Llama 4 Scout 109B face challenges with inference due to their size. These models can require significant memory, often exceeding GPU limits, especially with large context windows. The NVIDIA Grace architectures address this by utilizing NVLink C2C, allowing CPU and GPU to share memory efficiently. This setup enhances the processing of large datasets and enables quicker access, minimizing the risk of out-of-memory errors during inference&amp;hellip;.</description>
    </item>
    <item>
      <title>Accelerate Large-Scale LLM Inference and KV Cache Offload with CPU-GPU Memory Sharing</title>
      <link>/articles/article-2025-09-05-8229/</link>
      <pubDate>Fri, 05 Sep 2025 17:24:06 +0000</pubDate>
      <guid>/articles/article-2025-09-05-8229/</guid>
      <description>Large Language Models (LLMs) like Llama 3 and Llama 4 are pushing AI boundaries, but their size poses challenges for inference efficiency. These models can require substantial GPU memory, often leading to out-of-memory errors during inference. The NVIDIA Grace architectures address this with NVLink C2C, offering a high-bandwidth connection that shares CPU and GPU memory. This innovation enhances processing capabilities, making it easier to handle large datasets and models. #AI #NVIDIA&amp;hellip;</description>
    </item>
    <item>
      <title>Multi-Agentic Ticket-Based Complaint Resolution System</title>
      <link>/articles/article-2025-09-04-7746/</link>
      <pubDate>Thu, 04 Sep 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7746/</guid>
      <description>In the AI-driven landscape, financial institutions must enhance customer service efficiency. A new multi-agentic ticket-based complaint resolution system, developed with MongoDB and Confluent, aims to automate this process. It allows banks to quickly resolve common issues like card declines and authentication problems through AI agents. By leveraging real-time event streaming, this system significantly improves resolution times, ultimately boosting customer satisfaction. üìàü§ñ&amp;hellip;</description>
    </item>
    <item>
      <title>Building Uber‚Äôs Data Lake: Batch Data Replication Using HiveSync</title>
      <link>/articles/article-2025-09-04-7734/</link>
      <pubDate>Thu, 04 Sep 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7734/</guid>
      <description>üöÄ Dive into how Uber efficiently manages batch data replication using HiveSync! This technology ensures their data lake remains consistent, reliable, and high-performing. The article highlights the engineering efforts behind maintaining data integrity at scale. Learn more about Uber&amp;rsquo;s innovative approach to data management! üìäüíª #DataEngineering #Uber #HiveSync #DataManagement #TechInnovation</description>
    </item>
    <item>
      <title>Improved Annotation Handling in Kotlin 2.2: Less Boilerplate, Fewer Surprises</title>
      <link>/articles/article-2025-09-04-7728/</link>
      <pubDate>Thu, 04 Sep 2025 11:56:15 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7728/</guid>
      <description>Kotlin 2.2 introduces improved annotation handling, addressing common issues developers faced with annotations in frameworks like Spring and JPA. Previously, annotations applied to constructor parameters often did not validate properties during updates, leading to unexpected behavior. The new default rule ensures that annotations are applied to both constructor parameters and properties, streamlining code and reducing boilerplate. This update enhances validation consistency, allowing for&amp;hellip;</description>
    </item>
    <item>
      <title>Improved Annotation Handling in Kotlin 2.2: Less Boilerplate, Fewer Surprises</title>
      <link>/articles/article-2025-09-04-7896/</link>
      <pubDate>Thu, 04 Sep 2025 11:56:15 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7896/</guid>
      <description>Kotlin 2.2 introduces improved annotation handling, addressing common issues developers faced with frameworks like Spring and JPA. Previously, annotations could only validate object construction, leading to unexpected bugs. Now, with the new default rule, annotations will apply to both constructor parameters and properties, ensuring they function as intended during updates. This change reduces boilerplate code and aligns better with framework expectations. üîó Kotlin 2.2 is required to enable&amp;hellip;</description>
    </item>
    <item>
      <title>Building Slack‚Äôs Anomaly Event Response</title>
      <link>/articles/article-2025-09-04-7723/</link>
      <pubDate>Thu, 04 Sep 2025 10:00:02 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7723/</guid>
      <description>In response to evolving cyber threats, Slack has introduced Anomaly Event Response (AER), a proactive security measure. üåê AER utilizes real-time monitoring and advanced analytics to quickly identify and respond to suspicious activities on the platform, reducing detection-to-response time from hours to minutes. ‚è±Ô∏è This system helps prevent potential data breaches without the need for additional security tools. Slack also provides comprehensive audit logs to enhance security for Enterprise&amp;hellip;</description>
    </item>
    <item>
      <title>Building Slack‚Äôs Anomaly Event Response</title>
      <link>/articles/article-2025-09-04-8172/</link>
      <pubDate>Thu, 04 Sep 2025 10:00:02 +0000</pubDate>
      <guid>/articles/article-2025-09-04-8172/</guid>
      <description>Cyberattacks are becoming more sophisticated, making rapid breach detection and response essential. Traditional methods often respond too late, giving attackers an advantage. To combat this, Slack has introduced Anomaly Event Response (AER). This proactive defense mechanism uses real-time monitoring and advanced analytics to identify threats and respond automatically, reducing detection-to-response time to minutes. üöÄüîç AER helps prevent data breaches without needing extra tools or human&amp;hellip;</description>
    </item>
    <item>
      <title>Building Etsy Buyer Profiles with LLMs</title>
      <link>/articles/article-2025-09-03-7694/</link>
      <pubDate>Wed, 03 Sep 2025 21:40:15 +0000</pubDate>
      <guid>/articles/article-2025-09-03-7694/</guid>
      <description>Etsy is enhancing buyer experiences by using large language models (LLMs) to create detailed buyer profiles based on shopping behaviors. üõçÔ∏è These profiles capture individual interests, helping to tailor search results for nearly 90 million users while maintaining privacy compliance. Users have the option to opt-out of profile generation. üîç Technical improvements have reduced the time for profile generation from 21 days to just 3 days, making personalization more efficient and cost-effective&amp;hellip;.</description>
    </item>
    <item>
      <title>You are Doing MCP Wrong: 3 Big Misconceptions</title>
      <link>/articles/article-2025-09-03-7692/</link>
      <pubDate>Wed, 03 Sep 2025 16:59:46 +0000</pubDate>
      <guid>/articles/article-2025-09-03-7692/</guid>
      <description>üîç Understanding the Model Context Protocol (MCP) is crucial for developers. Many mistakenly view MCP as just another API, which can disrupt agent designs and execution reliability. MCP is designed for LLM tool use, not replacing RPC but enhancing it. Another common misconception is that tools are agents. While tools execute tasks, agents plan and evaluate until goals are met. For effective use, define tool preconditions, validate inputs, and maintain clear logs. #ModelContextProtocol #MCP&amp;hellip;</description>
    </item>
    <item>
      <title>North‚ÄìSouth Networks: The Key to Faster Enterprise AI Workloads</title>
      <link>/articles/article-2025-09-03-7684/</link>
      <pubDate>Wed, 03 Sep 2025 15:04:24 +0000</pubDate>
      <guid>/articles/article-2025-09-03-7684/</guid>
      <description>In the realm of AI infrastructure, data movement is crucial for performance. As enterprises adopt advanced AI systems, they face challenges in quickly and reliably moving data. NVIDIA‚Äôs Enterprise Reference Architectures (RAs) provide guidance on optimizing north-south networks, essential for tasks like model loading and inference queries. By utilizing NVIDIA Spectrum-X Ethernet, organizations can enhance data flow, particularly for data-intensive AI applications. Legacy networks often&amp;hellip;</description>
    </item>
    <item>
      <title>vLLM with torch.compile: Efficient LLM inference on PyTorch</title>
      <link>/articles/article-2025-09-03-7653/</link>
      <pubDate>Wed, 03 Sep 2025 07:01:11 +0000</pubDate>
      <guid>/articles/article-2025-09-03-7653/</guid>
      <description>üöÄ Efficient LLM inference is crucial in today‚Äôs diverse tech landscape. The article discusses how &lt;strong&gt;torch.compile&lt;/strong&gt;, PyTorch&amp;rsquo;s JIT compiler, streamlines performance by automatically optimizing kernels. This reduces the burden on developers, allowing them to focus on model design rather than manual tuning. Incorporated into &lt;strong&gt;vLLM&lt;/strong&gt;, torch.compile enhances usability and performance through custom compiler passes. It supports dynamic batch sizes and improves startup times with caching&amp;hellip;</description>
    </item>
    <item>
      <title>Calculating Character Count of RCS Messages</title>
      <link>/articles/article-2025-09-03-7770/</link>
      <pubDate>Wed, 03 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-03-7770/</guid>
      <description>Understanding RCS message character count is crucial for effective customer engagement. üì± This article delves into the differences in message length and encoding between RCS and SMS. It highlights the importance of these factors in communication strategies. For developers, these insights can optimize message delivery and enhance user experiences. #RCS #SMS #CustomerEngagement #TechInsights #Messaging</description>
    </item>
    <item>
      <title>Cut Model Deployment Costs While Keeping Performance With GPU Memory Swap</title>
      <link>/articles/article-2025-09-02-7629/</link>
      <pubDate>Tue, 02 Sep 2025 18:44:27 +0000</pubDate>
      <guid>/articles/article-2025-09-02-7629/</guid>
      <description>Deploying large language models (LLMs) at scale involves balancing fast responsiveness and GPU costs. Organizations often face tough choices: over-provisioning GPUs or risking user experience with latency spikes. NVIDIA&amp;rsquo;s GPU memory swap, or model hot-swapping, offers a solution. This innovation allows multiple models to share GPUs, dynamically offloading inactive models to CPU memory, enabling rapid activation when needed. Benchmark tests show promising results with lower costs and improved&amp;hellip;</description>
    </item>
    <item>
      <title>Kubernetes v1.34: Introducing CPU Manager Static Policy Option for Uncore Cache Alignment</title>
      <link>/articles/article-2025-09-02-7647/</link>
      <pubDate>Tue, 02 Sep 2025 18:30:00 +0000</pubDate>
      <guid>/articles/article-2025-09-02-7647/</guid>
      <description>üöÄ Kubernetes v1.34 has introduced a new feature: the CPU Manager Static Policy Option, prefer-align-cpus-by-uncorecache, now in beta. This option optimizes performance for workloads on processors with a split uncore cache architecture, enhancing efficiency by reducing latency between CPU cores. To enable it, update your kubelet configuration. This feature is particularly beneficial for applications like telco systems but may vary based on workload types. #Kubernetes #CloudComputing&amp;hellip;</description>
    </item>
    <item>
      <title>Improving GEMM Kernel Auto-Tuning Efficiency on NVIDIA GPUs with Heuristics and CUTLASS 4.2</title>
      <link>/articles/article-2025-09-02-7630/</link>
      <pubDate>Tue, 02 Sep 2025 17:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-02-7630/</guid>
      <description>üöÄ Selecting the optimal GEMM kernel for specific hardware is challenging due to the many performance-determining parameters. NVIDIA introduces &lt;strong&gt;nvMatmulHeuristics&lt;/strong&gt; to enhance the process. This module identifies a small set of top-performing kernel configurations, simplifying the tuning workflow and saving time. ‚è±Ô∏è With nvMatmulHeuristics and CUTLASS 4.2, users can quickly generate and auto-tune kernels, leading to faster model compilation and better performance. #NVIDIA #GEMM #CUDA&amp;hellip;</description>
    </item>
    <item>
      <title>A New Ranking Framework for Better Notification Quality on Instagram</title>
      <link>/articles/article-2025-09-02-7650/</link>
      <pubDate>Tue, 02 Sep 2025 16:00:08 +0000</pubDate>
      <guid>/articles/article-2025-09-02-7650/</guid>
      <description>Meta is enhancing Instagram notifications using machine learning and diversity algorithms. A new framework aims to reduce uniformity, offering a varied mix of notifications while lowering overall volume. This approach boosts engagement rates by ensuring users discover diverse content and creators. The goal is to balance personalization with a richer notification experience, avoiding overexposure to the same authors. #InstagramUpdates #MachineLearning #UserExperience #Diversity #SocialMedia</description>
    </item>
    <item>
      <title>Building AI for consumer applications isn‚Äôt all fun and games</title>
      <link>/articles/article-2025-09-02-7600/</link>
      <pubDate>Tue, 02 Sep 2025 07:40:00 +0000</pubDate>
      <guid>/articles/article-2025-09-02-7600/</guid>
      <description>üöÄ Kylan Gibbs, CEO of Inworld, shares insights on the technical challenges of developing interactive AI for virtual worlds and games. He highlights the importance of user experience, accessibility, and cost-efficiency in AI deployment. Inworld aims to streamline workload management and enhance iteration speed for teams. üëè Congratulations to MrWhite for earning an Illuminator badge by answering 500 questions in just 12 hours! #AI #VirtualWorlds #UserExperience #Inworld #TechInsights</description>
    </item>
    <item>
      <title>Architecting a High-Concurrency, Low-Latency Data Warehouse on Databricks That Scales</title>
      <link>/articles/article-2025-09-02-7642/</link>
      <pubDate>Tue, 02 Sep 2025 07:28:59 +0000</pubDate>
      <guid>/articles/article-2025-09-02-7642/</guid>
      <description>Unlock the potential of your data with a high-concurrency, low-latency data warehouse on Databricks. The article outlines key architectural considerations and a technical solution breakdown for implementing production-grade analytics. It also discusses real-world scenarios and trade-offs to keep in mind. Explore practical insights to achieve cost-efficient performance at scale. üìäüí° #DataWarehouse #Databricks #Analytics #BigData #CloudComputing</description>
    </item>
    <item>
      <title>Your LLM is too large: How I generate production-ready failure analysis on a toaster</title>
      <link>/articles/article-2025-09-02-7602/</link>
      <pubDate>Tue, 02 Sep 2025 07:00:53 +0000</pubDate>
      <guid>/articles/article-2025-09-02-7602/</guid>
      <description>Running production-grade Kubernetes failure analysis on a cost-effective edge device can streamline troubleshooting. Using Llama 3.2:3B with 4-bit quantization, root cause analysis is achieved in just 70 seconds. This method incorporates pattern preprocessing to efficiently identify known failures without overwhelming the system with raw logs. Real-world results show a significant cost reduction, from $0.30-3.00 per analysis to less than $0.001, while providing actionable insights. Explore&amp;hellip;</description>
    </item>
    <item>
      <title>Cronos: The New Dawn is set to deliver pulse-pounding survival horror using UE5</title>
      <link>/articles/article-2025-09-02-7620/</link>
      <pubDate>Tue, 02 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-02-7620/</guid>
      <description>üïπÔ∏è Exciting developments in survival horror! The Bloober Team shared insights on &amp;ldquo;Cronos: The New Dawn,&amp;rdquo; highlighting their use of Unreal Engine 5 features like Lumen and Nanite. These technologies enhance combat mechanics and create a chilling atmosphere for players. Stay tuned for more updates on this intense gaming experience! üéÆüåå #CronosTheNewDawn #SurvivalHorror #UnrealEngine5 #GameDevelopment #BlooberTeam</description>
    </item>
    <item>
      <title>1 Billion Build Minutes Later: How we reinvented CI/CD at Atlassian</title>
      <link>/articles/article-2025-08-29-7560/</link>
      <pubDate>Fri, 29 Aug 2025 17:28:23 +0000</pubDate>
      <guid>/articles/article-2025-08-29-7560/</guid>
      <description>üöÄ In 2022, Atlassian recognized the need to streamline its CI/CD process due to fragmentation and inefficiencies. üõ†Ô∏è The solution? Consolidating efforts on Bitbucket Pipelines to support over 9,000 users, enhancing reliability and flexibility while maintaining team autonomy. Key focus areas included enterprise-grade scale, centralized standards, and preparing for AI advancements. Discover how Atlassian is transforming its development landscape! üåê #Atlassian #CICD #SoftwareDevelopment&amp;hellip;</description>
    </item>
    <item>
      <title>Fine-Tuning gpt-oss for Accuracy and Performance with Quantization Aware Training</title>
      <link>/articles/article-2025-08-29-7545/</link>
      <pubDate>Fri, 29 Aug 2025 14:47:04 +0000</pubDate>
      <guid>/articles/article-2025-08-29-7545/</guid>
      <description>OpenAI&amp;rsquo;s gpt-oss model has made waves in the AI community with its innovative architecture and performance capabilities. üìàüß† It features a mixture of expert architecture and a 128K context length, competing closely with OpenAI&amp;rsquo;s closed-source models. However, deploying foundational models like gpt-oss in critical fields requires careful fine-tuning. The article discusses employing Supervised Fine-Tuning (SFT) and Quantization-Aware Training (QAT) to enhance model accuracy while maintaining&amp;hellip;</description>
    </item>
    <item>
      <title>Moving the public Stack Overflow sites to the cloud: Part 1</title>
      <link>/articles/article-2025-08-28-7471/</link>
      <pubDate>Thu, 28 Aug 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-28-7471/</guid>
      <description>üöÄ Stack Overflow is transitioning from physical servers to the cloud! This move marks a significant shift from their traditional data center model, primarily based in the US. The journey began with Stack Overflow for Teams successfully migrating to Azure, but challenges remain for the public site. üåê Key project deadlines are set for July 31, 2025, coinciding with the data center&amp;rsquo;s closure. The team is focused on setting milestones to ensure a smooth transition while maintaining flexibility&amp;hellip;</description>
    </item>
    <item>
      <title>Controlling the Rollout of Large-Scale Monorepo Changes</title>
      <link>/articles/article-2025-08-28-7472/</link>
      <pubDate>Thu, 28 Aug 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-28-7472/</guid>
      <description>Uber is enhancing its deployment strategy by managing the impact of large-scale changes through effective orchestration. As the company moves towards fully automated continuous deployment, implementing robust safety practices is essential to minimize risks. This approach ensures smoother transitions and maintains system integrity during significant updates. #Deployment #Uber #TechUpdates #ContinuousIntegration #SoftwareEngineering üöÄüîßüìà</description>
    </item>
    <item>
      <title>Multicluster resiliency with global load balancing and mesh federation</title>
      <link>/articles/article-2025-08-28-7451/</link>
      <pubDate>Thu, 28 Aug 2025 07:01:21 +0000</pubDate>
      <guid>/articles/article-2025-08-28-7451/</guid>
      <description>Explore the new architecture for multicluster resiliency using global load balancing and mesh federation! üåê This approach combines a global load balancer and a federated service mesh to enhance service availability and disaster recovery, particularly for stateless workloads. New capabilities in Red Hat OpenShift Service Mesh 3.0 and Red Hat Connectivity Link now allow for more robust deployments. Learn how to configure these tools for optimal performance! #Multicluster #RedHat #CloudComputing&amp;hellip;</description>
    </item>
    <item>
      <title>How We Oops-Proofed Infrastructure Deletion on Railway</title>
      <link>/articles/article-2025-08-28-7508/</link>
      <pubDate>Thu, 28 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-28-7508/</guid>
      <description>Railway enhances cloud infrastructure safety with a focus on staged changes and undoable deletions. This approach ensures that destructive actions, such as deleting infrastructure, are carefully managed from the dashboard to the underlying physical resources. Learn more about how these methods protect users and improve overall reliability. #CloudInfrastructure #SafetyFirst #TechInnovation üåêüîßüí°</description>
    </item>
    <item>
      <title>Breaking AI Testing Barriers: Dynamic Assertions and AI Automation Deliver 1000%&#43; Productivity Gains</title>
      <link>/articles/article-2025-08-27-7448/</link>
      <pubDate>Wed, 27 Aug 2025 19:28:13 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7448/</guid>
      <description>üöÄ Discover how Gayathri Rajan and her team at Salesforce are revolutionizing AI quality testing! Their innovative approach tackles non-deterministic AI responses and complex integration challenges. By implementing dynamic assertions, they enhance validation processes and boost productivity by over 1000%. Their mission is to ensure reliable AI experiences, empowering teams while transforming quality into a competitive advantage. #AI #QualityTesting #Salesforce #Innovation #Productivity</description>
    </item>
    <item>
      <title>How to Improve CUDA Kernel Performance with Shared Memory Register Spilling</title>
      <link>/articles/article-2025-08-27-7273/</link>
      <pubDate>Wed, 27 Aug 2025 16:30:00 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7273/</guid>
      <description>üöÄ New in CUDA Toolkit 13.0: Shared Memory Register Spilling! This feature helps improve CUDA kernel performance by allowing the compiler to use shared memory for excess variables instead of local memory. This reduces spill latency and L2 pressure for register-heavy kernels. To enable shared memory spilling, use the pragma command in your kernel definition. With this optimization, kernels can perform better, especially in critical regions where registers are heavily used. Learn more about how&amp;hellip;</description>
    </item>
    <item>
      <title>How Cloudflare runs more AI models on fewer GPUs: A technical deep-dive</title>
      <link>/articles/article-2025-08-27-7236/</link>
      <pubDate>Wed, 27 Aug 2025 14:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7236/</guid>
      <description>üöÄ Cloudflare has developed a new platform called Omni to optimize GPU usage for AI models. Omni employs lightweight isolation and memory over-commitment, allowing multiple models to run on a single GPU. This innovation enhances model availability and reduces latency, making AI services more efficient. The platform also simplifies management by using a single control plane to handle model provisioning and scaling automatically. #AI #Cloudflare #TechInnovation #GPU #Omni</description>
    </item>
    <item>
      <title>How we built the most efficient inference engine for Cloudflare‚Äôs network</title>
      <link>/articles/article-2025-08-27-7289/</link>
      <pubDate>Wed, 27 Aug 2025 14:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7289/</guid>
      <description>üöÄ Cloudflare has developed Infire, a new LLM inference engine designed to enhance resource efficiency for AI tasks. Infire uses advanced techniques to optimize memory, network I/O, and GPU utilization, allowing it to serve more requests with fewer resources. Initial tests show it completes tasks up to 7% faster than the previous vLLM engine. Currently, Infire supports the Llama 3.1 model for Workers AI, demonstrating significant performance improvements for Cloudflare‚Äôs unique distributed&amp;hellip;</description>
    </item>
    <item>
      <title>Smart deployments at scale: Leveraging ApplicationSets and Helm with cluster labels in Red Hat Advanced Cluster Management for Kubernetes</title>
      <link>/articles/article-2025-08-27-7203/</link>
      <pubDate>Wed, 27 Aug 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7203/</guid>
      <description>Managing multiple Kubernetes clusters can be complex, but Red Hat Advanced Cluster Management simplifies this process. üåê It offers a centralized platform to oversee the entire lifecycle of Kubernetes clusters, ensuring consistent health monitoring and policy enforcement across environments. Combining ApplicationSets and Helm with cluster labels allows for tailored deployments, adapting configurations based on specific cluster characteristics. This integration streamlines operations and&amp;hellip;</description>
    </item>
    <item>
      <title>BGP dynamic routing with Fast Data Path on RHOSO 18</title>
      <link>/articles/article-2025-08-27-7206/</link>
      <pubDate>Wed, 27 Aug 2025 07:01:08 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7206/</guid>
      <description>Exploring the performance of dynamic routing with OVN-BGP-Agent and Fast Data Path on RHOSO 18 has yielded insightful findings. üöÄ A recent Proof of Concept assessed throughput, packet loss, stability, and resource utilization using Trex and BIRD. The results show high throughput, especially with large frames, and stable performance over extended periods. üìà However, there are limitations, including bottlenecks for small packets and some manual configuration challenges. Insights from this study&amp;hellip;</description>
    </item>
    <item>
      <title>Graphics and rendering tips from Survival Kids</title>
      <link>/articles/article-2025-08-27-7217/</link>
      <pubDate>Wed, 27 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7217/</guid>
      <description>üöÄ This summer, Unity launched the co-op game &amp;ldquo;Survival Kids,&amp;rdquo; developed in-house with a small team. With limited resources, they focused on innovative graphics and rendering techniques. üåü Using the Universal Render Pipeline, they balanced artistic goals with performance needs. Custom shaders and dynamic lighting were key to achieving their visual style. üåä The ocean rendering was inspired by existing projects, utilizing signed distance fields for unique effects. Stay tuned for more insights on&amp;hellip;</description>
    </item>
    <item>
      <title>How Uber Serves over 150 Million Reads per Second from Integrated Cache with Stronger Consistency Guarantees</title>
      <link>/articles/article-2025-08-26-7249/</link>
      <pubDate>Tue, 26 Aug 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-26-7249/</guid>
      <description>üöÄ Uber&amp;rsquo;s integrated cache, CacheFront, now handles over 150 million reads per second, achieving impressive hit rates exceeding 99.9%. Recent enhancements have strengthened the consistency guarantees of this infrastructure, ensuring reliable performance for users. For more insights, check out the full article. #Uber #CacheFront #TechInnovation #DataInfrastructure #Performance</description>
    </item>
    <item>
      <title>Engineering stories behind the Medium Daily Digest Algorithm: Part 1</title>
      <link>/articles/article-2025-08-26-7243/</link>
      <pubDate>Tue, 26 Aug 2025 11:31:37 +0000</pubDate>
      <guid>/articles/article-2025-08-26-7243/</guid>
      <description>üöÄ Exciting improvements to Medium&amp;rsquo;s Daily Digest algorithm are highlighted in a new article series! Part 1 details how adjustments led to a 7% increase in reading time for users. The engineering team identified filtering issues affecting recommendations, particularly due to Apple‚Äôs Mail Privacy Protection. The changes made resulted in a 10% rise in user conversions and enhanced story quality for all readers. Stay tuned for more insights as the series continues! üìàüìß #Medium #DataScience&amp;hellip;</description>
    </item>
    <item>
      <title>Unveiling Ruby Debuggers: byebug, debug gem, and the Power of RubyMine</title>
      <link>/articles/article-2025-08-26-7177/</link>
      <pubDate>Tue, 26 Aug 2025 07:11:53 +0000</pubDate>
      <guid>/articles/article-2025-08-26-7177/</guid>
      <description>üöÄ Attention Ruby developers! In the latest blog post from RubyMine, the focus is on the importance of mastering debuggers like byebug and the debug gem. These tools are essential for tracking down bugs effectively. The article also explores RubyMine&amp;rsquo;s debugging architecture and provides insights from Dmitry Pogrebnoy&amp;rsquo;s talk, &amp;ldquo;Demystifying Debugger&amp;rdquo;. An interesting experiment on the performance of these debuggers is included as well. Learn how often Ruby developers rely on debuggers, with data&amp;hellip;</description>
    </item>
    <item>
      <title>A VM tuning case study: Balancing power and performance on AMD processors</title>
      <link>/articles/article-2025-08-26-7173/</link>
      <pubDate>Tue, 26 Aug 2025 07:01:25 +0000</pubDate>
      <guid>/articles/article-2025-08-26-7173/</guid>
      <description>During a server deployment, a significant performance gap was found between bare metal and virtual machine (VM) workloads. Optimizations, including adjusting system profiles and enabling CPU scaling drivers, were implemented. These changes resulted in notable improvements in VM performance, with the tuned VM even surpassing the original bare-metal completion times. The study highlights how targeted adjustments can lead to substantial gains in efficiency. üîßüíª‚ö°Ô∏è #VMTuning&amp;hellip;</description>
    </item>
    <item>
      <title>The future of Riot‚Äôs VALORANT is built on UE5</title>
      <link>/articles/article-2025-08-26-7215/</link>
      <pubDate>Tue, 26 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-26-7215/</guid>
      <description>Riot Games is upgrading VALORANT from Unreal Engine 4 to Unreal Engine 5. Marcus Reid explains that this shift aims to enhance gameplay and graphics, ensuring the game remains competitive and appealing. The transition is part of Riot&amp;rsquo;s strategy to secure VALORANT&amp;rsquo;s future in the gaming landscape. üéÆ‚ú® #VALORANT #RiotGames #GamingNews #UE5 #GameDevelopment</description>
    </item>
    <item>
      <title>Comment ranker ‚Äì An ML-based classifier to improve LLM code review quality using Atlassian‚Äôs proprietary data</title>
      <link>/articles/article-2025-08-25-7192/</link>
      <pubDate>Mon, 25 Aug 2025 23:22:23 +0000</pubDate>
      <guid>/articles/article-2025-08-25-7192/</guid>
      <description>Atlassian has introduced an ML-based comment ranker to enhance code review quality using proprietary data. This tool, part of the Rovo Dev agents, helps developers by filtering comments generated by LLMs, significantly improving efficiency. In its open beta, it has already supported over 43K PRs monthly and reduced PR cycle time by 30%. The comment ranker optimizes comment selection based on success metrics, ensuring only valuable feedback is highlighted for developers. #Atlassian #CodeReview&amp;hellip;</description>
    </item>
    <item>
      <title>Driving Airport Efficiency with MongoDB and Dataworkz</title>
      <link>/articles/article-2025-08-25-6474/</link>
      <pubDate>Mon, 25 Aug 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-25-6474/</guid>
      <description>In 2024, over 40 million flights were supported globally, leading to complex ground operations that involve numerous tasks. üöÄ With approximately 30,000 daily flight delays, a new smart airport operations application using MongoDB Atlas and Dataworkz aims to enhance efficiency. The solution features an AI voice assistant that provides real-time information and guides staff through checklists, potentially reducing human errors and improving safety. This technology harnesses Google Cloud&amp;hellip;</description>
    </item>
    <item>
      <title>What is an image mode 3-way merge?</title>
      <link>/articles/article-2025-08-25-6331/</link>
      <pubDate>Mon, 25 Aug 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-08-25-6331/</guid>
      <description>üîç Curious about the 3-way merge in Red Hat Enterprise Linux (RHEL)? In image mode, a new filesystem image is created to manage updates. This process includes a third version, older than the current and new images, to reduce conflicts. The merge prioritizes local changes, ensuring personalized settings remain intact. Utilizing OSTree, RHEL manages multiple OS installations effectively, making the merging process smoother. üñ•Ô∏è‚ú® #RedHat #Linux #3WayMerge #OSTree #TechUpdates</description>
    </item>
    <item>
      <title>Forest in a (Water) Bottle | Virtual Aquarium</title>
      <link>/articles/article-2025-08-24-7507/</link>
      <pubDate>Sun, 24 Aug 2025 23:33:53 +0000</pubDate>
      <guid>/articles/article-2025-08-24-7507/</guid>
      <description>üå≥üíß Exploring the potential of Unreal Engine 5, this article discusses a test-bench scene featuring a virtual aquarium. The focus was on experimenting with new features during UE5&amp;rsquo;s Early Access phase. This project highlights the innovative possibilities for developers in creating immersive environments. #UnrealEngine5 #GameDevelopment #VirtualReality #Innovation</description>
    </item>
    <item>
      <title>Developer Experience at Pinterest: The Journey to PinConsole</title>
      <link>/articles/article-2025-08-22-6316/</link>
      <pubDate>Fri, 22 Aug 2025 20:12:18 +0000</pubDate>
      <guid>/articles/article-2025-08-22-6316/</guid>
      <description>üöÄ Pinterest has introduced PinConsole, an Internal Developer Platform (IDP) aimed at simplifying the developer experience. This initiative addresses increasing complexity and improves engineering velocity for over 550 million users. üîç The team identified challenges such as tool fragmentation and inconsistent workflows, which were hindering productivity. By leveraging Backstage, PinConsole creates a unified interface, allowing engineers to focus on business logic. üìà Early adoption shows&amp;hellip;</description>
    </item>
    <item>
      <title>Processing Millions of Events from Thousands of Aircraft with One Declarative Pipeline</title>
      <link>/articles/article-2025-08-22-6310/</link>
      <pubDate>Fri, 22 Aug 2025 18:30:00 +0000</pubDate>
      <guid>/articles/article-2025-08-22-6310/</guid>
      <description>A new article discusses how tens of thousands of aircraft generate IoT events every second. It highlights the use of Lakeflow declarative pipelines and PySpark custom data sources to process millions of these events efficiently. The focus is on building scalable systems to manage this vast amount of data effectively. ‚úàÔ∏èüåêüìä #Aviation #DataProcessing #IoT #CloudComputing #ScalableSystems</description>
    </item>
    <item>
      <title>Inside NVIDIA Blackwell Ultra: The Chip Powering the AI Factory Era</title>
      <link>/articles/article-2025-08-22-6299/</link>
      <pubDate>Fri, 22 Aug 2025 17:58:00 +0000</pubDate>
      <guid>/articles/article-2025-08-22-6299/</guid>
      <description>Introducing the NVIDIA Blackwell Ultra GPU, a key advancement in the Blackwell architecture. This GPU enhances AI training and reasoning with innovative technology. Key features include a dual-reticle design, high bandwidth, and energy-efficient performance. It boasts 208 billion transistors and provides significant scalability for AI tasks. With 15 PetaFLOPS performance and improved memory access, the Blackwell Ultra sets a new standard for accelerated computing. #NVIDIA #AI #BlackwellUltra&amp;hellip;</description>
    </item>
    <item>
      <title>How Tipalti mastered Elasticsearch performance with AutoOps</title>
      <link>/articles/article-2025-08-22-6300/</link>
      <pubDate>Fri, 22 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-22-6300/</guid>
      <description>Tipalti, a leader in payables automation, has transformed its approach to Elasticsearch performance. By switching from manual monitoring to the automated AutoOps system, they achieved a 10% annual cost saving while managing a complex database ecosystem with a small team. Oz Levy, a data operations manager at Tipalti, shared insights on this transition and its impact on operational efficiency. #Tipalti #Elasticsearch #AutoOps #Efficiency #CostSaving üíºüìàüîç</description>
    </item>
    <item>
      <title>From massive models to mobile magic: The tech behind YouTube real-time generative AI effects</title>
      <link>/articles/article-2025-08-21-5179/</link>
      <pubDate>Thu, 21 Aug 2025 18:05:35 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5179/</guid>
      <description>YouTube is enhancing user experience on mobile with real-time generative AI effects. üì±‚ú® By utilizing knowledge distillation and MediaPipe, YouTube has developed a solution to deliver over 20 effects directly on creators&amp;rsquo; phones. This process involves creating smaller, efficient models tailored for specific tasks, allowing for seamless video processing. These advancements make features like cartoon style transfer not only possible but also fun and interactive for creators on YouTube Shorts. üé®üé•&amp;hellip;</description>
    </item>
    <item>
      <title>From Facts &amp; Metrics to Media Machine Learning: Evolving the Data Engineering Function at Netflix</title>
      <link>/articles/article-2025-08-21-5177/</link>
      <pubDate>Thu, 21 Aug 2025 17:39:40 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5177/</guid>
      <description>At Netflix, we are evolving our data engineering function with the introduction of Media ML Data Engineering. üé•üìä This new specialization focuses on managing complex media data, allowing for centralized access to various media assets like video, audio, and text. The initiative aims to enhance machine learning capabilities and improve analytics through the Media Data Lake, which supports advanced technologies. Key responsibilities include standardizing media assets and enriching metadata to&amp;hellip;</description>
    </item>
    <item>
      <title>Converged Datastore for Agentic AI</title>
      <link>/articles/article-2025-08-21-6475/</link>
      <pubDate>Thu, 21 Aug 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-21-6475/</guid>
      <description>As AI evolves, traditional data architectures struggle to keep pace. Fragmented systems hinder efficiency, especially in data-heavy sectors like insurance. üå©Ô∏è The article advocates for converged datastores that unify structured and unstructured data. This shift allows AI agents to analyze, reason, and act in real-time, streamlining processes and enhancing customer experiences. üìä A new approach is essential, integrating advanced tools to support intelligent automation and cognitive decision-&amp;hellip;</description>
    </item>
    <item>
      <title>Improve Data Integrity and Security with Accelerated Hash Functions and Merkle Trees in cuPQC 0.4</title>
      <link>/articles/article-2025-08-21-5039/</link>
      <pubDate>Thu, 21 Aug 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5039/</guid>
      <description>üîí As data sizes grow, ensuring security and integrity is vital. The cuPQC SDK v0.4 offers advanced cryptographic techniques, including inclusion proofs and digital signatures, to enhance data protection. New features include expanded hash function support and efficient Merkle tree calculations, improving performance in data verification. üå≥ Discover how these updates can benefit your cryptographic tasks! #DataIntegrity #Cryptography #cuPQC #MerkleTrees #CyberSecurity</description>
    </item>
    <item>
      <title>Scaling AI Inference Performance and Flexibility with NVIDIA NVLink and NVLink Fusion</title>
      <link>/articles/article-2025-08-21-5040/</link>
      <pubDate>Thu, 21 Aug 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5040/</guid>
      <description>The rise of AI model complexity has increased parameter counts from millions to trillions, demanding more computational power. üåê NVIDIA NVLink and NVLink Fusion are key technologies enhancing AI inference performance. They enable large-scale parallelization strategies, essential for handling advanced AI architectures like mixture-of-experts (MoE). ü§ñ This evolution in AI systems highlights the need for interconnected GPUs acting as a unified pool of compute and memory. #AI #NVIDIA #NVLink&amp;hellip;</description>
    </item>
    <item>
      <title>Building Hyperforce Service Mesh: Blast Radius Reduction, Scale Optimization, and Open Source Innovation</title>
      <link>/articles/article-2025-08-21-5162/</link>
      <pubDate>Thu, 21 Aug 2025 13:52:48 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5162/</guid>
      <description>üöÄ In the latest &amp;ldquo;Engineering Energizers&amp;rdquo; Q&amp;amp;A, we spotlight Pratima Nambiar, a Distinguished Architect at Salesforce. She has been pivotal in developing the service mesh architecture for the Hyperforce platform. üîç This architecture secures communication among thousands of services, addressing challenges like blast radius reduction and scale optimization. The team leverages open source tools like Envoy and Istio to enhance service connectivity. üí° The shift to public cloud infrastructure has&amp;hellip;</description>
    </item>
    <item>
      <title>New Benchmark Tests Reveal Key Vector Search Performance Factors</title>
      <link>/articles/article-2025-08-21-6476/</link>
      <pubDate>Thu, 21 Aug 2025 11:55:00 +0000</pubDate>
      <guid>/articles/article-2025-08-21-6476/</guid>
      <description>üöÄ New benchmarks for vector search performance are here! The MongoDB Benchmark for Atlas Vector Search provides essential strategies for optimizing search at scale, especially for datasets exceeding 10M vectors. Key factors like accuracy, cost, and throughput are explored, offering insights into quantization, dimensionality, and more. The guide aims to simplify initial tests and enhance understanding of system behavior. Explore the full guide in our documentation! üìäüìà #VectorSearch #MongoDB&amp;hellip;</description>
    </item>
    <item>
      <title>The hidden pitfalls of Kafka tiered storage</title>
      <link>/articles/article-2025-08-21-5019/</link>
      <pubDate>Thu, 21 Aug 2025 07:01:29 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5019/</guid>
      <description>üöÄ Apache Kafka 3.9.0 introduces tiered storage for improved long-term data retention and cost efficiency. This feature allows independent scaling of compute and storage resources, leading to better client isolation. However, challenges remain in reading remote data. The article outlines two key problems and offers solutions, emphasizing important configurations like &lt;code&gt;fetch.max.bytes&lt;/code&gt; and &lt;code&gt;max.partition.fetch.bytes&lt;/code&gt;. Kafka 4.2.0 promises improvements to address these issues, enhancing&amp;hellip;</description>
    </item>
    <item>
      <title>Reinforcement Learning with NVIDIA NeMo-RL: Megatron-Core Support for Optimized Training Throughput</title>
      <link>/articles/article-2025-08-20-5041/</link>
      <pubDate>Wed, 20 Aug 2025 15:15:16 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5041/</guid>
      <description>üöÄ Exciting updates in reinforcement learning with NVIDIA NeMo-RL! The latest release introduces support for the Megatron-Core library, enhancing training throughput for massive language models. This integration addresses limitations found in the PyTorch DTensor backend, particularly for models with hundreds of billions of parameters. With GPU-optimized techniques and simplified configuration options, NeMo-RL makes it easier for developers to harness the power of Megatron-Core. Explore&amp;hellip;</description>
    </item>
    <item>
      <title>&lt;script type=&#34;text/llms.txt&#34;&gt;</title>
      <link>/articles/article-2025-08-20-5082/</link>
      <pubDate>Wed, 20 Aug 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5082/</guid>
      <description>Discover a new approach for AI agents interacting with protected pages. The emerging standard, llms.txt, proposes including instructions directly in HTML responses using the &lt;script type=&#34;text/llms.txt&#34;&gt; tag. This could simplify how AIs access and consume documentation without relying on external sources. Learn more about this innovative concept! üíªüìÑ #AI #HTML #llms #Innovation #TechNews</description>
    </item>
    <item>
      <title>Your agent, your rules: A deep dive into the Responses API with Llama Stack</title>
      <link>/articles/article-2025-08-20-5021/</link>
      <pubDate>Wed, 20 Aug 2025 07:01:24 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5021/</guid>
      <description>üîç The OpenAI Responses API simplifies AI application development by managing complex orchestration. However, it is tied to specific models and a proprietary cloud service. Enter Llama Stack, an open-source server that offers a compatible Responses API and lets you deploy on your hardware with your chosen models. It supports advanced features like Retrieval-augmented Generation (RAG) for accurate answers without compromising document privacy. Explore how Llama Stack can transform your AI&amp;hellip;</description>
    </item>
    <item>
      <title>How I built an agentic application for Docling with MCP</title>
      <link>/articles/article-2025-08-20-5025/</link>
      <pubDate>Wed, 20 Aug 2025 07:01:20 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5025/</guid>
      <description>üåê Exciting developments in AI with the Model Context Protocol (MCP) from Anthropic! Released in November 2024, MCP enables large language models to communicate seamlessly with various tools. üõ†Ô∏è With thousands of open-source MCP servers available, many developers are now creating agentic applications. However, there&amp;rsquo;s still untapped potential in fully utilizing MCP‚Äôs capabilities. üìÑ My journey began during my internship at Red Hat, where I worked with Docling, an open-source data preprocessor&amp;hellip;.</description>
    </item>
    <item>
      <title>Context engineering case studies: Etsy-specific question answering</title>
      <link>/articles/article-2025-08-19-5133/</link>
      <pubDate>Tue, 19 Aug 2025 20:04:41 +0000</pubDate>
      <guid>/articles/article-2025-08-19-5133/</guid>
      <description>Exploring prompt engineering in AI-assisted onboarding at Etsy reveals both benefits and limitations. The study focused on how well LLMs provide reliable answers to Etsy-specific questions, particularly in the Travel &amp;amp; Entertainment domain. Initial findings indicate that concise prompts improve answer accuracy. However, some instances showcased LLM &amp;ldquo;hallucinations,&amp;rdquo; emphasizing the need for careful prompt design. For more insights, check out the full article! üìùü§ñ #AIEducation #Etsy&amp;hellip;</description>
    </item>
    <item>
      <title>Tuning Linux Swap for Kubernetes: A Deep Dive</title>
      <link>/articles/article-2025-08-19-5779/</link>
      <pubDate>Tue, 19 Aug 2025 18:30:00 +0000</pubDate>
      <guid>/articles/article-2025-08-19-5779/</guid>
      <description>Kubernetes is set to introduce the NodeSwap feature in version 1.34, allowing Linux nodes to utilize swap for improved resource management. This marks a shift from the traditional approach of disabling swap for performance. However, enabling swap requires careful tuning of Linux kernel parameters to avoid performance issues and manage memory pressure effectively. Key parameters include &lt;code&gt;vm.swappiness&lt;/code&gt;, &lt;code&gt;vm.min_free_kbytes&lt;/code&gt;, and &lt;code&gt;vm.watermark_scale_factor&lt;/code&gt;. Testing various configurations can&amp;hellip;</description>
    </item>
    <item>
      <title>Constitutional AI: Ethical Governance with MongoDB Atlas</title>
      <link>/articles/article-2025-08-19-6478/</link>
      <pubDate>Tue, 19 Aug 2025 17:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-19-6478/</guid>
      <description>As AI systems evolve, ensuring ethical governance becomes essential. The article discusses Constitutional AI (CAI), a method by Anthropic that allows AI models to self-govern using predefined ethical principles. This approach moves beyond traditional human oversight, integrating with MongoDB&amp;rsquo;s governance tools for effective implementation. CAI utilizes a two-phase process: self-critique and AI feedback, making ethical decisions transparent. However, scaling CAI requires robust data governance&amp;hellip;</description>
    </item>
    <item>
      <title>Building an Agentic AI Fleet Management Solution</title>
      <link>/articles/article-2025-08-19-6479/</link>
      <pubDate>Tue, 19 Aug 2025 14:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-19-6479/</guid>
      <description>Artificial intelligence is transforming fleet management with real-time insights that enhance route planning and maintenance. üöóüí° Modern vehicles generate vast data, creating challenges in processing and operational costs. An efficient architecture using MongoDB can streamline this by managing various data types effectively. Features like geospatial queries and time-series collections empower fleet managers to make informed decisions quickly. üìä‚ú® Explore how AI-driven systems can optimize your&amp;hellip;</description>
    </item>
    <item>
      <title>How TitanApps Migrated Smart Checklist to Forge (and Got It to Run on Atlassian)</title>
      <link>/articles/article-2025-08-18-6540/</link>
      <pubDate>Mon, 18 Aug 2025 23:44:27 +0000</pubDate>
      <guid>/articles/article-2025-08-18-6540/</guid>
      <description>üöÄ TitanApps shares the journey of migrating Smart Checklist to Forge, ensuring it meets security standards and runs smoothly on Atlassian. The team tackled challenges like data migration without downtime, all while retaining the app&amp;rsquo;s reliability for thousands of users. This migration highlights the importance of planning and adapting to new technologies. For those considering a similar move, this post offers valuable insights. #Atlassian #SmartChecklist #ForgeMigration #TechInnovation&amp;hellip;</description>
    </item>
    <item>
      <title>A scalable LLM approach to enhancing chatbot knowledge with user-generated content</title>
      <link>/articles/article-2025-08-18-7161/</link>
      <pubDate>Mon, 18 Aug 2025 21:49:22 +0000</pubDate>
      <guid>/articles/article-2025-08-18-7161/</guid>
      <description>DoorDash&amp;rsquo;s support chatbot efficiently addresses numerous questions from Dashers and customers daily. As their marketplace grows, so does the complexity of inquiries. To enhance chatbot knowledge, DoorDash employs large language models (LLMs) paired with clustering algorithms. This method identifies content gaps and drafts articles quickly, streamlining the knowledge base update process. By analyzing escalated chat transcripts, they pinpoint areas needing improvement. This data-driven&amp;hellip;</description>
    </item>
    <item>
      <title>Reranking in Mosaic AI Vector Search for Faster, Smarter Retrieval in RAG Agents</title>
      <link>/articles/article-2025-08-18-5108/</link>
      <pubDate>Mon, 18 Aug 2025 19:30:00 +0000</pubDate>
      <guid>/articles/article-2025-08-18-5108/</guid>
      <description>Unlock faster, smarter retrieval in AI with the latest advancements in Mosaic AI Vector Search. Organizations can now enhance their RAG agents to deliver more relevant answers efficiently, all with a simple line of code. This innovation addresses challenges faced in handling unstructured data. Stay ahead in AI technology! üöÄüí° #AI #Mosaic #VectorSearch #Innovation #TechTrends</description>
    </item>
    <item>
      <title>ML Observability: Bringing Transparency to Payments and Beyond</title>
      <link>/articles/article-2025-08-18-5178/</link>
      <pubDate>Mon, 18 Aug 2025 18:15:00 +0000</pubDate>
      <guid>/articles/article-2025-08-18-5178/</guid>
      <description>At Netflix, ML observability is crucial for monitoring and understanding machine learning models in production. It allows teams to track performance, detect anomalies, and ensure reliability. This is particularly important in payment processing, where optimizing transactions helps reduce friction for users. By utilizing ML observability tools, we can enhance model performance and maintain stakeholder trust through clear insights into model behavior. Examples include logging, monitoring, and&amp;hellip;</description>
    </item>
    <item>
      <title>How Cursor AI Cut Legacy Code Coverage Time by 85%</title>
      <link>/articles/article-2025-08-18-5163/</link>
      <pubDate>Mon, 18 Aug 2025 15:32:39 +0000</pubDate>
      <guid>/articles/article-2025-08-18-5163/</guid>
      <description>üöÄ Exciting advancements in software engineering at Salesforce! Rachna Singh and her team tackled the challenge of achieving 80% code coverage on legacy systems. By utilizing Cursor AI, they reduced unit test development time from 26 days to just 4! üìâ This innovative approach not only met the coverage requirement but also improved feature delivery and code quality across multiple repositories. #Salesforce #AI #SoftwareEngineering #CodeCoverage #Innovation</description>
    </item>
    <item>
      <title>Unlock Multi-Agent AI Predictive Maintenance with MongoDB</title>
      <link>/articles/article-2025-08-18-6480/</link>
      <pubDate>Mon, 18 Aug 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-18-6480/</guid>
      <description>üöÄ The manufacturing sector faces challenges like evolving demands and a skilled labor shortage. Digital transformation is key, with data-driven strategies at the forefront. üîß Predictive maintenance is vital for operational excellence, using data to foresee machine failures and reduce costly downtime. ü§ñ The rise of multi-agent AI systems is revolutionizing this process. MongoDB enables the development of these agents, enhancing automation and efficiency on the shop floor. Explore how Agentic&amp;hellip;</description>
    </item>
    <item>
      <title>Beyond billion-parameter burdens: Unlocking data synthesis with a conditional generator</title>
      <link>/articles/article-2025-08-14-5181/</link>
      <pubDate>Thu, 14 Aug 2025 19:06:20 +0000</pubDate>
      <guid>/articles/article-2025-08-14-5181/</guid>
      <description>Unlocking data synthesis in AI just got easier! üåê A new algorithm, CTCL, enables the generation of synthetic data while preserving privacy, using a lightweight 140 million parameter model. This approach avoids the complexities of fine-tuning billion-scale models, making it accessible for resource-constrained applications. CTCL conditions data on topic information, ensuring better topic distribution matching. It also allows for unlimited synthetic data generation without additional privacy&amp;hellip;</description>
    </item>
    <item>
      <title>Solving secret zero with Vault and OpenShift Virtualization</title>
      <link>/articles/article-2025-08-14-5114/</link>
      <pubDate>Thu, 14 Aug 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-14-5114/</guid>
      <description>Discover how Red Hat OpenShift Virtualization and HashiCorp Vault can address the secret zero problem in virtualized environments. Organizations face challenges in establishing machine identity as they adopt identity-based security. Traditional virtualization solutions often lack inherent machine identity, leading to reliance on initial credentials for secure communication with Vault. Red Hat OpenShift Virtualization offers a solution by enabling virtual machines to leverage Kubernetes&amp;hellip;</description>
    </item>
    <item>
      <title>Migrating Airbnb‚Äôs JVM Monorepo to Bazel</title>
      <link>/articles/article-2025-08-13-4964/</link>
      <pubDate>Wed, 13 Aug 2025 17:01:58 +0000</pubDate>
      <guid>/articles/article-2025-08-13-4964/</guid>
      <description>üöÄ Exciting updates from Airbnb! We have successfully migrated our largest repo, the JVM monorepo, to Bazel after 4.5 years of dedicated work. This transition has significantly improved our build process, achieving a Build CSAT increase from 38% to 68%. Key benefits include: - 3‚Äì5x faster local build and test times - 2‚Äì3x faster IntelliJ syncs - 2‚Äì3x faster deploys to the development environment We chose Bazel for its speed, reliability, and uniform infrastructure. The migration involved&amp;hellip;</description>
    </item>
    <item>
      <title>The real serverless compute to database connection problem, solved</title>
      <link>/articles/article-2025-08-13-4936/</link>
      <pubDate>Wed, 13 Aug 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-13-4936/</guid>
      <description>The article addresses a common misconception about serverless compute and its connection to traditional databases. It highlights that the challenge lies not in the number of connections during normal operation but in potential connection leaks when serverless functions are suspended. The piece provides clarity on the actual cause and offers a simple solution to this issue. üîçüíªüîó #Serverless #Database #TechSolutions #CloudComputing #SoftwareDevelopment</description>
    </item>
    <item>
      <title>How UiPath Built a Scalable Real-Time ETL pipeline on Databricks</title>
      <link>/articles/article-2025-08-13-4950/</link>
      <pubDate>Wed, 13 Aug 2025 08:12:58 +0000</pubDate>
      <guid>/articles/article-2025-08-13-4950/</guid>
      <description>üöÄ UiPath has developed a scalable real-time ETL pipeline using Databricks to enhance automation processes. This pipeline aims to deliver fast and reliable data processing, which is crucial for effective decision-making. By leveraging Databricks, UiPath is focused on improving operational efficiency and customer satisfaction. #UiPath #Databricks #ETL #Automation #DataProcessing</description>
    </item>
    <item>
      <title>Accelerating Video Quality Control at Netflix with Pixel Error Detection</title>
      <link>/articles/article-2025-08-11-4969/</link>
      <pubDate>Mon, 11 Aug 2025 21:29:57 +0000</pubDate>
      <guid>/articles/article-2025-08-11-4969/</guid>
      <description>üöÄ Netflix has developed an automated method for video quality control that detects pixel-level artifacts, reducing manual reviews. This new system identifies hot pixels that can distract viewers, ensuring a seamless viewing experience. By using a specialized neural network, Netflix speeds up the QC process from hours to minutes. This innovation allows creative teams to focus more on storytelling rather than technical issues. üé•‚ú® #Netflix #VideoQuality #Innovation #TechForGood #Filmmaking</description>
    </item>
    <item>
      <title>Optimizing Materialized Views Recomputes</title>
      <link>/articles/article-2025-08-11-4953/</link>
      <pubDate>Mon, 11 Aug 2025 19:35:00 +0000</pubDate>
      <guid>/articles/article-2025-08-11-4953/</guid>
      <description>üöÄ Discover strategies for optimizing the incremental computation of materialized views in data management. The article discusses techniques that digital-native companies can implement to enhance efficiency. It highlights the importance of improving performance while managing data effectively. Learn how to leverage these strategies for better data handling and quicker insights! üìäüîç #DataManagement #MaterializedViews #Optimization #TechInsights</description>
    </item>
    <item>
      <title>Disaster recovery approaches for Red Hat OpenShift Virtualization, part 2</title>
      <link>/articles/article-2025-08-11-4857/</link>
      <pubDate>Mon, 11 Aug 2025 15:31:15 +0000</pubDate>
      <guid>/articles/article-2025-08-11-4857/</guid>
      <description>üåê Discover effective disaster recovery strategies for Red Hat OpenShift Virtualization! This follow-up article explores orchestrating application failover using Kubernetes-native constructs and GitOps workflows. It emphasizes how to manage workloads during disruptions, focusing on redeployment and prioritization. Key practices include using Node Selectors and automation tools like Ansible and Helm for seamless transitions between primary and DR sites. Regular DR rehearsals and clear&amp;hellip;</description>
    </item>
    <item>
      <title>Boost Connected Car Developments with MongoDB Atlas and AWS</title>
      <link>/articles/article-2025-08-11-6482/</link>
      <pubDate>Mon, 11 Aug 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-11-6482/</guid>
      <description>The automotive industry is transforming with connected, software-defined vehicles generating vast amounts of data daily. üöóüíª A recent survey highlights that 40% of US consumers value connectivity enough to switch brands. OEMs are responding by leveraging data for predictive maintenance and personalized services. Combining MongoDB Atlas with AWS tools enables innovative applications like real-time diagnostics and tailored insurance models. üìäüîß Explore how this architecture can enhance mobility&amp;hellip;</description>
    </item>
    <item>
      <title>How Salesforce Delivers Reliable, Low-Latency AI Inference</title>
      <link>/articles/article-2025-08-11-4854/</link>
      <pubDate>Mon, 11 Aug 2025 14:15:02 +0000</pubDate>
      <guid>/articles/article-2025-08-11-4854/</guid>
      <description>üöÄ Meet Nilesh Salpe, an engineer at Salesforce focusing on the AI Metadata Service (AIMS). This service offers tenant-specific configurations for AI inferences, crucial for applications like Agentforce. üîß His team developed a multi-layered caching system to address a 400ms latency issue, enhancing performance to sub-millisecond levels while ensuring reliability against backend outages. üåê AIMS plays a key role in managing diverse AI models and configurations across Salesforce‚Äôs multi-cloud&amp;hellip;</description>
    </item>
    <item>
      <title>Why Can&#39;t I Just Use an API? Because Your AI Agent Needs MCP</title>
      <link>/articles/article-2025-08-11-4849/</link>
      <pubDate>Mon, 11 Aug 2025 13:55:00 +0000</pubDate>
      <guid>/articles/article-2025-08-11-4849/</guid>
      <description>Understanding the limitations of traditional APIs for AI agents is crucial. ü§ñ The article discusses how APIs can confuse AI agents due to excessive choices and the need for manual translation of information. This often hampers performance and adaptability. Introducing the Model Context Protocol (MCP), which streamlines AI reasoning by providing high-level capabilities instead of overwhelming details. MCP enhances the agent&amp;rsquo;s ability to focus on tasks efficiently. #AI #MCP #TechInnovation&amp;hellip;</description>
    </item>
    <item>
      <title>CrowdStrike‚Äôs Approach to Better Machine Learning Evaluation Using Strategic Data Splitting</title>
      <link>/articles/article-2025-08-11-7444/</link>
      <pubDate>Mon, 11 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-11-7444/</guid>
      <description>CrowdStrike is enhancing machine learning evaluation by tackling data leakage, which can lead to inaccurate threat detection in cybersecurity. To combat this, they implement strategic data splitting during model training. This method carefully manages how data is divided, ensuring that similar data points do not skew results, ultimately leading to more reliable detection of new threats. By focusing on this strategy, CrowdStrike aims to improve the performance of their AI-native platform&amp;hellip;</description>
    </item>
    <item>
      <title>R¬≤D¬≤: Boost Robot Training with World Foundation Models and Workflows from NVIDIA Research</title>
      <link>/articles/article-2025-08-08-4714/</link>
      <pubDate>Fri, 08 Aug 2025 18:33:16 +0000</pubDate>
      <guid>/articles/article-2025-08-08-4714/</guid>
      <description>üöÄ The latest edition of NVIDIA&amp;rsquo;s R¬≤D¬≤ highlights the role of World Foundation Models (WFMs) in enhancing robot training. WFMs address the growing need for labeled datasets by simulating real-world dynamics. Key components include Cosmos Predict, Transfer, and Reason, each designed for specific applications in robotics and autonomous vehicles. Cosmos Predict generates future world states through various input types. Cosmos Transfer facilitates photorealistic style transfers, while Cosmos&amp;hellip;</description>
    </item>
    <item>
      <title>Ollama vs. vLLM: A deep dive into performance benchmarking</title>
      <link>/articles/article-2025-08-08-4711/</link>
      <pubDate>Fri, 08 Aug 2025 07:16:15 +0000</pubDate>
      <guid>/articles/article-2025-08-08-4711/</guid>
      <description>Ollama and vLLM serve distinct roles in the AI landscape. Ollama is designed for local development and prototyping, while vLLM excels in high-performance production environments. In benchmarks, vLLM outperformed Ollama with a peak throughput of 793 TPS compared to Ollama&amp;rsquo;s 41 TPS and lower latency across all concurrency levels. Ollama prioritizes ease of use, making it suitable for individual developers, whereas vLLM is built for scalability, catering to enterprise applications. For detailed&amp;hellip;</description>
    </item>
    <item>
      <title>Improving code quality - Session 41: &#34;Architecture&#34; under construction</title>
      <link>/articles/article-2025-08-08-5832/</link>
      <pubDate>Fri, 08 Aug 2025 02:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-08-5832/</guid>
      <description>üì¢ Exciting insights from &amp;ldquo;Improving Code Quality&amp;rdquo; Session 41! Munetoshi Ishikawa discusses application architecture for a messaging app. The article outlines a data model defining messages, featuring various types like Text, Image, and External Resource. The message type is identified by the first character of its ID, which is crucial for maintaining historical compatibility. Discover more about managing different message types and their unique creation logic! #CodeQuality #AppDevelopment&amp;hellip;</description>
    </item>
    <item>
      <title>Efficient Transforms in cuDF Using JIT Compilation</title>
      <link>/articles/article-2025-08-07-4715/</link>
      <pubDate>Thu, 07 Aug 2025 21:06:42 +0000</pubDate>
      <guid>/articles/article-2025-08-07-4715/</guid>
      <description>Unlock efficient data processing with RAPIDS cuDF! üöÄ cuDF offers a wide range of ETL algorithms optimized for GPUs, allowing for seamless integration with pandas. Users can leverage accelerated algorithms without changing their existing code. For advanced developers, the cuDF C++ submodule enhances functionality through non-owning views and kernel fusion, boosting performance and reducing unnecessary GPU memory transfers. Learn how JIT compilation improves throughput and resource utilization&amp;hellip;</description>
    </item>
    <item>
      <title>7x Faster Medical Image Ingestion with Python Data Source API</title>
      <link>/articles/article-2025-08-07-4758/</link>
      <pubDate>Thu, 07 Aug 2025 20:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-07-4758/</guid>
      <description>üöÄ Exciting advancements in medical imaging! A recent article discusses a new Python Data Source API that enhances DICOM data ingestion speed by seven times. This development utilizes industry-standard libraries like pydicom and zipfile. This improvement aims to streamline processes in healthcare and life sciences, addressing the challenges of handling medical images effectively. #MedicalImaging #HealthcareInnovation #Python #DICOM #DataScience</description>
    </item>
    <item>
      <title>Train with Terabyte-Scale Datasets on a Single NVIDIA Grace Hopper Superchip Using XGBoost 3.0</title>
      <link>/articles/article-2025-08-07-4716/</link>
      <pubDate>Thu, 07 Aug 2025 18:25:36 +0000</pubDate>
      <guid>/articles/article-2025-08-07-4716/</guid>
      <description>üöÄ Exciting advancements in machine learning with XGBoost 3.0! This version leverages the NVIDIA Grace Hopper Superchip to process datasets up to 1 TB, significantly speeding up training times‚Äîup to 8x faster than traditional CPUs. Key enhancements include a new external-memory engine, simplifying scalability and reducing reliance on complex GPU clusters. Major banks like RBC are already benefiting, reporting 16x speedups and 94% reductions in training costs. #XGBoost #MachineLearning #NVIDIA&amp;hellip;</description>
    </item>
    <item>
      <title>Seamless Istio Upgrades at Scale</title>
      <link>/articles/article-2025-08-07-4768/</link>
      <pubDate>Thu, 07 Aug 2025 17:01:42 +0000</pubDate>
      <guid>/articles/article-2025-08-07-4768/</guid>
      <description>Airbnb has successfully upgraded Istio 14 times since 2019, managing thousands of pods and VMs across multiple Kubernetes clusters. Their upgrade strategy focuses on zero downtime for users and gradual rollouts, allowing for controlled upgrades and rollbacks without coordinating individual teams. The process involves running two Istiod versions simultaneously, ensuring seamless transitions for workloads. Learn more about their innovative approach in the full article! üöÄüîß #AirbnbTech #Istio&amp;hellip;</description>
    </item>
    <item>
      <title>Achieving 10,000x training data reduction with high-fidelity labels</title>
      <link>/articles/article-2025-08-07-5183/</link>
      <pubDate>Thu, 07 Aug 2025 09:46:00 +0000</pubDate>
      <guid>/articles/article-2025-08-07-5183/</guid>
      <description>A new method in active learning significantly reduces the training data needed for fine-tuning large language models (LLMs). üìâ This innovative approach addresses the challenges in classifying unsafe ad content, which requires deep contextual understanding. Traditional methods are costly and often ineffective with evolving safety policies. The new curation process can cut training data from 100,000 examples to under 500, while improving model alignment with human experts by up to 65%. This is&amp;hellip;</description>
    </item>
    <item>
      <title>Five Myths About JWTs Debunked</title>
      <link>/articles/article-2025-08-07-4707/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-07-4707/</guid>
      <description>üîç Understanding JSON Web Tokens (JWTs) is crucial for secure application and API management. This article debunks five common myths about JWTs, highlighting misconceptions that can lead to vulnerabilities. One key point is that JWTs are not just another type of token; they are structured and self-contained, offering stateless validation. Learn more about JWTs and their proper usage to enhance your security practices. #JWT #WebSecurity #APIProtection #TechMyths #Cybersecurity</description>
    </item>
    <item>
      <title>Hash, store, join: A modern solution to log deduplication with ES|QL LOOKUP JOIN</title>
      <link>/articles/article-2025-08-07-4692/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-07-4692/</guid>
      <description>In the realm of cybersecurity, the challenge of balancing data fidelity with budget constraints is critical, especially with PowerShell logging. üìä Comprehensive logging is essential for threat hunting, yet it can lead to massive data storage costs. This article introduces an innovative approach using the Elastic Stack and ES|QL LOOKUP JOIN to optimize log management. The strategy focuses on intelligent data deduplication, allowing organizations to store references rather than full logs,&amp;hellip;</description>
    </item>
    <item>
      <title>Vision Language Model Alignment in TRL ‚ö°Ô∏è</title>
      <link>/articles/article-2025-08-07-4695/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-07-4695/</guid>
      <description>üîç The article discusses the alignment of Vision Language Models (VLMs) in the context of Technology Readiness Levels (TRL). It highlights the importance of aligning VLMs with real-world applications to enhance their effectiveness. üí° The piece outlines key strategies for achieving this alignment, focusing on practical implementation and evaluation methods. For those interested in AI development, this is a valuable read! #VisionLanguageModel #AIAlignment #TechnologyReadiness #MachineLearning&amp;hellip;</description>
    </item>
    <item>
      <title>Diff Risk Score: AI-driven risk-aware software development</title>
      <link>/articles/article-2025-08-06-4160/</link>
      <pubDate>Wed, 06 Aug 2025 17:50:51 +0000</pubDate>
      <guid>/articles/article-2025-08-06-4160/</guid>
      <description>üöÄ Introducing the Diff Risk Score (DRS) from Meta! This AI-driven technology predicts the likelihood of code changes causing production incidents, enhancing software development processes. By analyzing code changes and metadata, DRS generates risk scores, allowing developers to identify potentially risky code. üõ†Ô∏è DRS has notably reduced code freezes during critical periods, boosting productivity while maintaining user experience. For instance, during a key event in 2024, over 10,000 code&amp;hellip;</description>
    </item>
    <item>
      <title>Highly accurate genome polishing with DeepPolisher: Enhancing the foundation of genomic research</title>
      <link>/articles/article-2025-08-06-5185/</link>
      <pubDate>Wed, 06 Aug 2025 16:13:00 +0000</pubDate>
      <guid>/articles/article-2025-08-06-5185/</guid>
      <description>Introducing DeepPolisher, a new deep learning tool that enhances the accuracy of genome assemblies by correcting base-level errors. üß¨ This advancement plays a crucial role in refining the Human Pangenome Reference, making it easier to study heredity, disease, and evolution. DeepPolisher reduces assembly errors by 50% and indel errors by 70%, improving gene identification significantly. This open-source method was developed in collaboration with UC Santa Cruz Genomics Institute, marking a step&amp;hellip;</description>
    </item>
    <item>
      <title>From Intern Project to Production: How I Shipped the Draw Tool for Canva&#39;s Present Mode</title>
      <link>/articles/article-2025-08-06-4694/</link>
      <pubDate>Wed, 06 Aug 2025 00:00:01 +0000</pubDate>
      <guid>/articles/article-2025-08-06-4694/</guid>
      <description>üöÄ Exciting progress at Canva! A recent blog post details the journey of transforming an intern project into the Draw Tool for Present Mode. The author shares the technical challenges faced and how they were successfully addressed to enhance user experience. Learn about this innovative feature and the engineering practices behind it. #Canva #Engineering #UserExperience #Innovation #TechJourney</description>
    </item>
    <item>
      <title>Reducing double spend latency from 40 ms to &lt; 1 ms on privacy proxy</title>
      <link>/articles/article-2025-08-05-2076/</link>
      <pubDate>Tue, 05 Aug 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-05-2076/</guid>
      <description>We recently improved the performance of our privacy proxy service by reducing double-spend check latency from 40 ms to less than 1 ms. üöÄ This enhancement helps users browse the web securely without compromising their privacy. It also boosts the efficiency of our service, as we handle millions of requests each second. üîí Using a tracing platform and metrics, we identified bottlenecks and optimized our processes. This change is part of Cloudflare&amp;rsquo;s commitment to making the Internet faster for&amp;hellip;</description>
    </item>
    <item>
      <title>Made with UE5, Wildgate blends emergent gameplay with explosive spaceship combat</title>
      <link>/articles/article-2025-08-05-4081/</link>
      <pubDate>Tue, 05 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-05-4081/</guid>
      <description>üöÄ Exciting developments in gaming! Moonshot Games is using Unreal Engine 5 features like Nanite, Lumen, and Chaos in their debut project, the PvP space shooter Wildgate. These technologies enhance graphics and gameplay. Discover how these tools are shaping the future of gaming. #Wildgate #MoonshotGames #UE5 #GamingNews #SpaceShooter</description>
    </item>
    <item>
      <title>CUDA Pro Tip: Increase Performance with Vectorized Memory Access</title>
      <link>/articles/article-2025-08-04-212/</link>
      <pubDate>Mon, 04 Aug 2025 21:05:00 +0000</pubDate>
      <guid>/articles/article-2025-08-04-212/</guid>
      <description>Boost your CUDA performance by addressing bandwidth limitations! üåê Bandwidth-bound kernels are becoming more common due to the increasing ratio of flops to bandwidth in new hardware. To enhance bandwidth utilization, consider using vector loads and stores in your CUDA C++ code. Check out the provided memory copy kernel example, which uses grid-stride loops to improve efficiency. üìä #CUDA #PerformanceOptimization #ProgrammingTips #TechInsights #NVIDIA</description>
    </item>
    <item>
      <title>How to Enhance RAG Pipelines with Reasoning Using NVIDIA Llama Nemotron Models</title>
      <link>/articles/article-2025-08-04-215/</link>
      <pubDate>Mon, 04 Aug 2025 17:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-04-215/</guid>
      <description>Unlocking the potential of retrieval-augmented generation (RAG) systems involves addressing user queries that are vague or carry implicit intent. ü§î The article discusses how NVIDIA&amp;rsquo;s Nemotron LLMs enhance RAG pipelines through advanced query rewriting techniques. This process optimizes user prompts for better information retrieval, improving the relevance of results. üìà Techniques like Q2E, Q2D, and chain-of-thought query rewriting help bridge gaps in understanding, leading to more accurate&amp;hellip;</description>
    </item>
    <item>
      <title>Agent Learning from Human Feedback (ALHF): A Databricks Knowledge Assistant Case Study</title>
      <link>/articles/article-2025-08-04-3181/</link>
      <pubDate>Mon, 04 Aug 2025 16:15:29 +0000</pubDate>
      <guid>/articles/article-2025-08-04-3181/</guid>
      <description>Discover the innovative concept of Agent Learning from Human Feedback (ALHF) in the latest Databricks blog. ALHF allows agents to learn from minimal natural language feedback, enhancing their adaptability in specialized enterprise environments. The case study highlights its application in the Databricks Agent Bricks Knowledge Assistant, showcasing significant improvements in answer quality with limited expert feedback. This approach addresses the challenges of tuning AI systems by enabling&amp;hellip;</description>
    </item>
    <item>
      <title>Building a human-computer interface for everyone</title>
      <link>/articles/article-2025-08-04-11/</link>
      <pubDate>Mon, 04 Aug 2025 14:00:25 +0000</pubDate>
      <guid>/articles/article-2025-08-04-11/</guid>
      <description>Discover how Meta&amp;rsquo;s Reality Labs is advancing human-computer interaction with wrist-worn devices using surface electromyography (sEMG). ü§ñ Their research focuses on creating a universal input device that adapts to different users. Generalization remains a key challenge, as existing models often cater to individual gestures. Listen to the latest episode of the Meta Tech Podcast to learn more about this innovative approach! üéß‚ú® #HumanComputerInteraction #TechInnovation #MetaTech #sEMG #Podcast</description>
    </item>
    <item>
      <title>Optimizing LLMs for Performance and Accuracy with Post-Training Quantization</title>
      <link>/articles/article-2025-08-01-217/</link>
      <pubDate>Fri, 01 Aug 2025 21:27:23 +0000</pubDate>
      <guid>/articles/article-2025-08-01-217/</guid>
      <description>üöÄ Quantization is a key method for developers looking to enhance AI model performance with minimal overhead. It allows for significant improvements in latency, throughput, and memory efficiency by reducing model precision without retraining. Models typically use FP16 or BF16, while advancing to FP4 can yield even better efficiency. NVIDIA&amp;rsquo;s TensorRT Model Optimizer offers a flexible framework for post-training quantization, supporting various formats and integrating calibration techniques for&amp;hellip;</description>
    </item>
    <item>
      <title>Solving Dispatch in a Ridesharing Problem Space</title>
      <link>/articles/article-2025-07-31-2045/</link>
      <pubDate>Thu, 31 Jul 2025 17:43:14 +0000</pubDate>
      <guid>/articles/article-2025-07-31-2045/</guid>
      <description>üöóüí° Ridesharing platforms like Lyft tackle complex matching challenges daily. Each rider and driver represents a unique piece in a dynamic puzzle, requiring real-time solutions for efficient urban mobility. Graph theory helps model these matches, particularly through bipartite graphs. This allows for flexible connections based on factors like distance and time. Lyft&amp;rsquo;s dispatch team continually processes millions of potential decisions, aiming to optimize pickups and driver earnings. Stay tuned&amp;hellip;</description>
    </item>
    <item>
      <title>July 28 Incident report: Service availability disruption</title>
      <link>/articles/article-2025-07-31-5655/</link>
      <pubDate>Thu, 31 Jul 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-07-31-5655/</guid>
      <description>Webflow faced service disruptions from July 28-31, impacting the Designer, Dashboard, Marketplace, and user sign-ups. While hosted sites remained operational, core functionalities were affected. The incident involved multiple phases of malicious attacks leading to elevated latency and outages. Mitigation efforts included firewall protections and database optimizations. Full stability was restored through configuration changes and adopting a more efficient CPU architecture. For a deeper&amp;hellip;</description>
    </item>
  </channel>
</rss>
