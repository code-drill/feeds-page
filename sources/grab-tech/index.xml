<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Grab-Tech on Daily Tech Articles Feed</title>
    <link>/sources/grab-tech/</link>
    <description>Recent content in Grab-Tech on Daily Tech Articles Feed</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Nov 2025 00:00:05 +0000</lastBuildDate>
    <atom:link href="/sources/grab-tech/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Grab&#39;s Mac Cloud Exit supercharges macOS CI/CD</title>
      <link>/articles/article-2025-11-06-11924/</link>
      <pubDate>Thu, 06 Nov 2025 00:00:05 +0000</pubDate>
      <guid>/articles/article-2025-11-06-11924/</guid>
      <description>üöÄ Grab has successfully relocated its macOS CI/CD infrastructure from a US cloud vendor to a colocation cluster in Southeast Asia. This move has significantly improved build performance and reduced operational costs. With a transition from 1 Mac Pro to over 250 Mac minis, Grab is now better equipped to meet growing demands. The new setup has led to estimated savings of $2.4 million over three years. Explore how this strategic decision enhances efficiency and supports Grab&amp;rsquo;s mission in the&amp;hellip;</description>
    </item>
    <item>
      <title>How We Built a Custom Vision LLM to Improve Document Processing at Grab</title>
      <link>/articles/article-2025-11-04-11680/</link>
      <pubDate>Tue, 04 Nov 2025 00:00:10 +0000</pubDate>
      <guid>/articles/article-2025-11-04-11680/</guid>
      <description>üöÄ Exciting advancements in document processing at Grab! We&amp;rsquo;ve developed a specialized Vision LLM to tackle the challenges of extracting information from diverse documents in Southeast Asia. Traditional OCR systems faced limitations, especially with local languages. Our journey included fine-tuning the Qwen2-VL 2B model and creating a lightweight Vision LLM from scratch, resulting in significant accuracy improvements for various document types. This custom model outperforms existing solutions&amp;hellip;</description>
    </item>
    <item>
      <title>Machine-learning predictive autoscaling for Flink</title>
      <link>/articles/article-2025-10-30-11473/</link>
      <pubDate>Thu, 30 Oct 2025 00:00:10 +0000</pubDate>
      <guid>/articles/article-2025-10-30-11473/</guid>
      <description>üöÄ Grab is enhancing its Flink applications to meet growing demands for stream processing. With a 2.5x increase in Flink applications, the internal team is focusing on efficient, self-service CPU provisioning. Current reactive autoscaling methods face challenges like restart spikes and resource waste, leading to a need for a predictive solution. The new Predictive Resource Advisor optimizes CPU usage by forecasting workload and adjusting resources proactively, resulting in significant cost&amp;hellip;</description>
    </item>
    <item>
      <title>Modernising Grab‚Äôs model serving platform with NVIDIA Triton Inference Server</title>
      <link>/articles/article-2025-10-21-11093/</link>
      <pubDate>Tue, 21 Oct 2025 00:00:10 +0000</pubDate>
      <guid>/articles/article-2025-10-21-11093/</guid>
      <description>üöÄ Grab is enhancing its machine learning model serving platform, Catwalk, by integrating NVIDIA Triton Inference Server. This upgrade addresses performance issues caused by maintaining multiple legacy inference engines. Key benefits of Triton include multi-framework support, a unified API, and optimized hardware performance. Early results show over 50% of online deployments successfully migrated with improved latency and cost savings. Stay tuned for more updates on this transformation! üåü&amp;hellip;</description>
    </item>
    <item>
      <title>Highly concurrent in-memory counter in GoLang</title>
      <link>/articles/article-2025-10-06-10433/</link>
      <pubDate>Mon, 06 Oct 2025 00:00:10 +0000</pubDate>
      <guid>/articles/article-2025-10-06-10433/</guid>
      <description>üö® Facing high database CPU utilization during heavy traffic? This article explores a scenario where migrating from SQL to NoSQL seemed easy but tackling the problem through optimization proved more effective. The focus was on real-time usage count tracking for marketing campaigns, utilizing highly concurrent in-memory caching to reduce database load. By periodically flushing data, the team achieved significant efficiency improvements. The implementation of GoLang&amp;rsquo;s Sync.Map led to a 68%&amp;hellip;</description>
    </item>
    <item>
      <title>User foundation models for Grab</title>
      <link>/articles/article-2025-09-26-10119/</link>
      <pubDate>Fri, 26 Sep 2025 00:00:10 +0000</pubDate>
      <guid>/articles/article-2025-09-26-10119/</guid>
      <description>üåü Grab is enhancing user experiences through a custom AI foundation model designed to understand individual preferences across Southeast Asia. This model combines both tabular and time-series data to create user embeddings, leading to improved personalization and performance in various applications like ad targeting and fraud detection. By leveraging diverse data types, Grab aims for a unified understanding of user behavior, ultimately driving better services. #AI #MachineLearning #Grab&amp;hellip;</description>
    </item>
    <item>
      <title>Powering Partner Gateway metrics with Apache Pinot</title>
      <link>/articles/article-2025-09-23-9900/</link>
      <pubDate>Tue, 23 Sep 2025 00:00:10 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9900/</guid>
      <description>üåê Grab is enhancing its Partner Gateway with Apache Pinot to provide real-time analytics and insights for its partners. üîç The integration supports API management, offering advanced metrics tracking through time-series charts. This allows partners like Alpha, a perishable goods distributor, to optimize operations by monitoring API performance and response times. üìä Key features include a dashboard for real-time insights and Star-tree indexing for improved query performance. This ensures&amp;hellip;</description>
    </item>
    <item>
      <title>Taming the monorepo beast: Our journey to a leaner, faster GitLab repo</title>
      <link>/articles/article-2025-09-16-9675/</link>
      <pubDate>Tue, 16 Sep 2025 00:23:00 +0000</pubDate>
      <guid>/articles/article-2025-09-16-9675/</guid>
      <description>üöÄ At Grab, our engineering team tackled the challenges of a massive Go monorepo that had become a bottleneck over the years. We discovered that replication delays and a hefty repository size were crippling our developer workflows. With 12.7 million commits and 22.1 million Git trees, performance suffered significantly. To address this, we implemented a custom migration strategy that reduced commits by 99.9%, improving replication time from minutes to seconds! This transformation not only&amp;hellip;</description>
    </item>
    <item>
      <title>Data mesh at Grab part I: Building trust through certification</title>
      <link>/articles/article-2025-08-19-5076/</link>
      <pubDate>Tue, 19 Aug 2025 00:23:00 +0000</pubDate>
      <guid>/articles/article-2025-08-19-5076/</guid>
      <description>At Grab, we are evolving our data ecosystem to better serve our diverse operations, including ride-hailing, food delivery, and financial services. üöÄ In 2024, we initiated the Signals Marketplace, a data mesh journey aimed at enhancing data quality and accessibility. This decentralized approach allows domain-specific teams to take ownership of their data, fostering reliability and trust. üìä Key challenges included high data volume, unclear ownership, and communication gaps. We introduced data&amp;hellip;</description>
    </item>
  </channel>
</rss>
