<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>All the tech news (Posts about hugging-face-blog)</title><link>https://feeds.code-drill.eu/</link><description></description><atom:link href="https://feeds.code-drill.eu/sources/hugging-face-blog.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents ¬© 2025 &lt;a href="mailto:michal@code-drill.eu"&gt;Micha≈Ç Rutkowski&lt;/a&gt; </copyright><lastBuildDate>Mon, 01 Sep 2025 10:29:43 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Generate Images with Claude and Hugging Face</title><link>https://feeds.code-drill.eu/posts/2025-08-19/generate-images-with-claude-and-hugging-face/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;Discover how to generate images using Claude and Hugging Face! ü§ñ‚ú®
The article outlines step-by-step methods for utilizing these tools
effectively. It highlights key features and provides tips for best
practices in image generation. Explore the potential of AI in creative
projects! #AI #ImageGeneration #HuggingFace #Claude #TechTrends&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://huggingface.co/blog/feed.xml"&gt;Hugging Face Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Unknown&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; educational&lt;/p&gt;</description><category>hugging-face-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-19/generate-images-with-claude-and-hugging-face/</guid><pubDate>Tue, 19 Aug 2025 00:00:00 GMT</pubDate></item><item><title>From Zero to GPU: A Guide to Building and Scaling Production-Ready CUDA Kernels</title><link>https://feeds.code-drill.eu/posts/2025-08-18/from-zero-to-gpu-a-guide-to-building-and-scaling-production-ready-cuda-kern/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üöÄ Excited to enhance your GPU capabilities? Check out the guide on
building production-ready CUDA kernels! It introduces the kernel-builder
library, designed to simplify the development of custom kernels for
various architectures. Learn how to create efficient and maintainable
systems while overcoming deployment challenges. Perfect for those
looking to elevate their models! #CUDA #GPUs #Programming #TechGuide
#MachineLearning&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://huggingface.co/blog/feed.xml"&gt;Hugging Face Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Unknown&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; educational&lt;/p&gt;</description><category>hugging-face-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-18/from-zero-to-gpu-a-guide-to-building-and-scaling-production-ready-cuda-kern/</guid><pubDate>Mon, 18 Aug 2025 00:00:00 GMT</pubDate></item><item><title>MCP for Research: How to Connect AI to Research Tools</title><link>https://feeds.code-drill.eu/posts/2025-08-18/mcp-for-research-how-to-connect-ai-to-research-tools/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üîç Academic research often requires navigating multiple platforms
like arXiv and GitHub. The Model Context Protocol (MCP) offers a
solution by enabling AI to communicate with these research tools. This
allows for natural language requests, streamlining the discovery process
and reducing the need for manual switching between sites. Explore how
MCP can enhance your research experience! üìäü§ñ #AIinResearch
#ModelContextProtocol #ResearchInnovation #AcademicTools&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://huggingface.co/blog/feed.xml"&gt;Hugging Face Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Unknown&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; educational&lt;/p&gt;</description><category>hugging-face-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-18/mcp-for-research-how-to-connect-ai-to-research-tools/</guid><pubDate>Mon, 18 Aug 2025 00:00:00 GMT</pubDate></item><item><title>TextQuests: How Good are LLMs at Text-Based Video Games?</title><link>https://feeds.code-drill.eu/posts/2025-08-12/textquests-how-good-are-llms-at-text-based-video-games/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üìö The article explores the capabilities of Large Language Models
(LLMs) in text-based video games. It highlights that while LLMs excel in
static knowledge benchmarks, they face challenges in dynamic,
interactive environments. Developing effective evaluation methods for
these models remains crucial. Two main approaches are suggested:
real-world environments with specific skills and simulated open-world
settings. The article introduces TextQuests as a new benchmark to assess
LLM performance in‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://huggingface.co/blog/feed.xml"&gt;Hugging Face Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Unknown&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; educational&lt;/p&gt;</description><category>hugging-face-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-12/textquests-how-good-are-llms-at-text-based-video-games/</guid><pubDate>Tue, 12 Aug 2025 00:00:00 GMT</pubDate></item><item><title>üáµüá≠ FilBench - Can LLMs Understand and Generate Filipino?</title><link>https://feeds.code-drill.eu/posts/2025-08-12/filbench-can-llms-understand-and-generate-filipino/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;Exploring the capabilities of LLMs in Filipino languages is
essential. üáµüá≠ FilBench, a new evaluation suite, assesses LLM fluency,
translation, and cultural knowledge in Tagalog and Cebuano. Despite high
ChatGPT usage in the Philippines, systematic evaluations are lacking.
The study evaluates over 20 LLMs, aiming to provide clear insights. üìÑ
Read the paper: &lt;a href="https://arxiv.org/abs/2508.03523"&gt;arxiv.org&lt;/a&gt;
üñ•Ô∏è Check GitHub: &lt;a href="https://github.com/filbench/filbench-eval"&gt;github.com&lt;/a&gt;
#FilBench #LLMs‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://huggingface.co/blog/feed.xml"&gt;Hugging Face Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Unknown&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; educational&lt;/p&gt;</description><category>hugging-face-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-12/filbench-can-llms-understand-and-generate-filipino/</guid><pubDate>Tue, 12 Aug 2025 00:00:00 GMT</pubDate></item><item><title>Accelerate ND-Parallel: A Guide to Efficient Multi-GPU Training</title><link>https://feeds.code-drill.eu/posts/2025-08-08/accelerate-nd-parallel-a-guide-to-efficient-multi-gpu-training/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üöÄ Training large models on multiple GPUs can be complex. The article
‚ÄúAccelerate ND-Parallel‚Äù discusses how to simplify this process using
the Accelerate library and Axolotl. It provides a step-by-step guide to
integrate various parallelism strategies in your training script,
enhancing efficiency. Key configurations for parallelism include Fully
Sharded Data Parallel and Data Parallel degrees. This approach requires
at least 2 nodes with 8 GPUs each for optimal performance.
#MultiGPU‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://huggingface.co/blog/feed.xml"&gt;Hugging Face Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Unknown&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; educational&lt;/p&gt;</description><category>hugging-face-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-08/accelerate-nd-parallel-a-guide-to-efficient-multi-gpu-training/</guid><pubDate>Fri, 08 Aug 2025 00:00:00 GMT</pubDate></item><item><title>Introducing AI Sheets: a tool to work with datasets using open AI models!</title><link>https://feeds.code-drill.eu/posts/2025-08-08/introducing-ai-sheets-a-tool-to-work-with-datasets-using-open-ai-models/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üöÄ Exciting news for data enthusiasts! Hugging Face has launched AI
Sheets, an open-source tool designed to build, enrich, and transform
datasets using AI models without any coding required. You can deploy it
locally or access it directly on the Hub, utilizing thousands of models,
including gpt-oss from OpenAI. Explore the tool for free here: &lt;a href="https://huggingface.co/spaces/aisheets/sheets"&gt;AI Sheets&lt;/a&gt; or
install it locally from GitHub! #AISheets #OpenSource #DataScience
#MachineLearning‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://huggingface.co/blog/feed.xml"&gt;Hugging Face Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Unknown&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; product_announcements&lt;/p&gt;</description><category>hugging-face-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-08/introducing-ai-sheets-a-tool-to-work-with-datasets-using-open-ai-models/</guid><pubDate>Fri, 08 Aug 2025 00:00:00 GMT</pubDate></item><item><title>Vision Language Model Alignment in TRL ‚ö°Ô∏è</title><link>https://feeds.code-drill.eu/posts/2025-08-07/vision-language-model-alignment-in-trl/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üîç The article discusses the alignment of Vision Language Models
(VLMs) in the context of Technology Readiness Levels (TRL). It
highlights the importance of aligning VLMs with real-world applications
to enhance their effectiveness. üí° The piece outlines key strategies for
achieving this alignment, focusing on practical implementation and
evaluation methods. For those interested in AI development, this is a
valuable read! #VisionLanguageModel #AIAlignment #TechnologyReadiness
#MachineLearning‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://huggingface.co/blog/feed.xml"&gt;Hugging Face Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Unknown&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; technical_deep_dives&lt;/p&gt;</description><category>hugging-face-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-07/vision-language-model-alignment-in-trl/</guid><pubDate>Thu, 07 Aug 2025 00:00:00 GMT</pubDate></item><item><title>Welcome GPT OSS, the new open-source model family from OpenAI!</title><link>https://feeds.code-drill.eu/posts/2025-08-05/welcome-gpt-oss-the-new-open-source-model-family-from-openai/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üöÄ Exciting news from OpenAI! They have launched GPT OSS, a new
open-source model family featuring two versions: gpt-oss-120b with 117B
parameters and gpt-oss-20b with 21B parameters. Both models utilize a
mixture-of-experts design for efficient performance. These models are
licensed under Apache 2.0, promoting safe and responsible use. OpenAI
aims to enhance accessibility in AI through this release. #OpenAI
#GPTOSS #MachineLearning #AICommunity #OpenSource&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://huggingface.co/blog/feed.xml"&gt;Hugging Face Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Unknown&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; product_announcements&lt;/p&gt;</description><category>hugging-face-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-05/welcome-gpt-oss-the-new-open-source-model-family-from-openai/</guid><pubDate>Tue, 05 Aug 2025 00:00:00 GMT</pubDate></item></channel></rss>