<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hugging-Face-Blog on Daily Tech Articles Feed</title>
    <link>/sources/hugging-face-blog/</link>
    <description>Recent content in Hugging-Face-Blog on Daily Tech Articles Feed</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Sep 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="/sources/hugging-face-blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Welcome EmbeddingGemma, Google&#39;s new efficient embedding model</title>
      <link>/articles/article-2025-09-04-7747/</link>
      <pubDate>Thu, 04 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7747/</guid>
      <description>üöÄ Exciting news in AI! Google has introduced EmbeddingGemma, a new embedding model designed for efficiency. This model aims to enhance various applications by improving performance while reducing resource consumption. Developers can explore its capabilities on GitHub. Stay tuned for more updates on AI advancements! #Google #EmbeddingGemma #AI #MachineLearning #TechInnovation</description>
    </item>
    <item>
      <title>Make your ZeroGPU Spaces go brrr with PyTorch ahead-of-time compilation</title>
      <link>/articles/article-2025-09-02-7606/</link>
      <pubDate>Tue, 02 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-02-7606/</guid>
      <description>Unlock the power of ZeroGPU Spaces with PyTorch ahead-of-time (AoT) compilation! üöÄ AoT improves performance by optimizing models once for faster reloading, making demos snappier. Users can expect speed boosts ranging from 1.3√ó to 1.8√ó on various models. Explore advanced techniques like FP8 quantization and dynamic shapes for an enhanced experience. Check out live demos on the zerogpu-aoti organization! #ZeroGPU #PyTorch #MachineLearning #AI #TechInnovation</description>
    </item>
    <item>
      <title>Generate Images with Claude and Hugging Face</title>
      <link>/articles/article-2025-08-19-5075/</link>
      <pubDate>Tue, 19 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-19-5075/</guid>
      <description>Discover how to generate images using Claude and Hugging Face! ü§ñ‚ú® The article outlines step-by-step methods for utilizing these tools effectively. It highlights key features and provides tips for best practices in image generation. Explore the potential of AI in creative projects! #AI #ImageGeneration #HuggingFace #Claude #TechTrends</description>
    </item>
    <item>
      <title>From Zero to GPU: A Guide to Building and Scaling Production-Ready CUDA Kernels</title>
      <link>/articles/article-2025-08-18-5077/</link>
      <pubDate>Mon, 18 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-18-5077/</guid>
      <description>üöÄ Excited to enhance your GPU capabilities? Check out the guide on building production-ready CUDA kernels! It introduces the kernel-builder library, designed to simplify the development of custom kernels for various architectures. Learn how to create efficient and maintainable systems while overcoming deployment challenges. Perfect for those looking to elevate their models! #CUDA #GPUs #Programming #TechGuide #MachineLearning</description>
    </item>
    <item>
      <title>MCP for Research: How to Connect AI to Research Tools</title>
      <link>/articles/article-2025-08-18-5078/</link>
      <pubDate>Mon, 18 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-18-5078/</guid>
      <description>üîç Academic research often requires navigating multiple platforms like arXiv and GitHub. The Model Context Protocol (MCP) offers a solution by enabling AI to communicate with these research tools. This allows for natural language requests, streamlining the discovery process and reducing the need for manual switching between sites. Explore how MCP can enhance your research experience! üìäü§ñ #AIinResearch #ModelContextProtocol #ResearchInnovation #AcademicTools</description>
    </item>
    <item>
      <title>üáµüá≠ FilBench - Can LLMs Understand and Generate Filipino?</title>
      <link>/articles/article-2025-08-12-4916/</link>
      <pubDate>Tue, 12 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-12-4916/</guid>
      <description>Exploring the capabilities of LLMs in Filipino languages is essential. üáµüá≠ FilBench, a new evaluation suite, assesses LLM fluency, translation, and cultural knowledge in Tagalog and Cebuano. Despite high ChatGPT usage in the Philippines, systematic evaluations are lacking. The study evaluates over 20 LLMs, aiming to provide clear insights. üìÑ Read the paper: &lt;a href=&#34;https://arxiv.org/abs/2508.03523&#34;&gt;arxiv.org&lt;/a&gt; üñ•Ô∏è Check GitHub: &lt;a href=&#34;https://github.com/filbench/filbench-eval&#34;&gt;github.com&lt;/a&gt; #FilBench #LLMs&amp;hellip;</description>
    </item>
    <item>
      <title>TextQuests: How Good are LLMs at Text-Based Video Games?</title>
      <link>/articles/article-2025-08-12-4915/</link>
      <pubDate>Tue, 12 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-12-4915/</guid>
      <description>üìö The article explores the capabilities of Large Language Models (LLMs) in text-based video games. It highlights that while LLMs excel in static knowledge benchmarks, they face challenges in dynamic, interactive environments. Developing effective evaluation methods for these models remains crucial. Two main approaches are suggested: real-world environments with specific skills and simulated open-world settings. The article introduces TextQuests as a new benchmark to assess LLM performance in&amp;hellip;</description>
    </item>
    <item>
      <title>Accelerate ND-Parallel: A Guide to Efficient Multi-GPU Training</title>
      <link>/articles/article-2025-08-08-4739/</link>
      <pubDate>Fri, 08 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-08-4739/</guid>
      <description>üöÄ Training large models on multiple GPUs can be complex. The article &amp;ldquo;Accelerate ND-Parallel&amp;rdquo; discusses how to simplify this process using the Accelerate library and Axolotl. It provides a step-by-step guide to integrate various parallelism strategies in your training script, enhancing efficiency. Key configurations for parallelism include Fully Sharded Data Parallel and Data Parallel degrees. This approach requires at least 2 nodes with 8 GPUs each for optimal performance. #MultiGPU&amp;hellip;</description>
    </item>
    <item>
      <title>Introducing AI Sheets: a tool to work with datasets using open AI models!</title>
      <link>/articles/article-2025-08-08-4738/</link>
      <pubDate>Fri, 08 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-08-4738/</guid>
      <description>üöÄ Exciting news for data enthusiasts! Hugging Face has launched AI Sheets, an open-source tool designed to build, enrich, and transform datasets using AI models without any coding required. You can deploy it locally or access it directly on the Hub, utilizing thousands of models, including gpt-oss from OpenAI. Explore the tool for free here: &lt;a href=&#34;https://huggingface.co/spaces/aisheets/sheets&#34;&gt;AI Sheets&lt;/a&gt; or install it locally from GitHub! #AISheets #OpenSource #DataScience #MachineLearning&amp;hellip;</description>
    </item>
    <item>
      <title>Vision Language Model Alignment in TRL ‚ö°Ô∏è</title>
      <link>/articles/article-2025-08-07-4695/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-07-4695/</guid>
      <description>üîç The article discusses the alignment of Vision Language Models (VLMs) in the context of Technology Readiness Levels (TRL). It highlights the importance of aligning VLMs with real-world applications to enhance their effectiveness. üí° The piece outlines key strategies for achieving this alignment, focusing on practical implementation and evaluation methods. For those interested in AI development, this is a valuable read! #VisionLanguageModel #AIAlignment #TechnologyReadiness #MachineLearning&amp;hellip;</description>
    </item>
    <item>
      <title>Welcome GPT OSS, the new open-source model family from OpenAI!</title>
      <link>/articles/article-2025-08-05-577/</link>
      <pubDate>Tue, 05 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-05-577/</guid>
      <description>üöÄ Exciting news from OpenAI! They have launched GPT OSS, a new open-source model family featuring two versions: gpt-oss-120b with 117B parameters and gpt-oss-20b with 21B parameters. Both models utilize a mixture-of-experts design for efficient performance. These models are licensed under Apache 2.0, promoting safe and responsible use. OpenAI aims to enhance accessibility in AI through this release. #OpenAI #GPTOSS #MachineLearning #AICommunity #OpenSource</description>
    </item>
    <item>
      <title>Build an AI Shopping Assistant with Gradio MCP Servers</title>
      <link>/articles/article-2025-07-31-578/</link>
      <pubDate>Thu, 31 Jul 2025 00:00:00 +0000</pubDate>
      <guid>/articles/article-2025-07-31-578/</guid>
      <description>üöÄ Python developers can supercharge their LLMs with Gradio&amp;rsquo;s Model Context Protocol (MCP)! Gradio simplifies the integration of AI models from Hugging Face, enabling LLMs to tackle real-world problems. Key features include automatic conversion of functions into LLM tools, real-time notifications, and seamless file uploads. Imagine an AI shopping assistant that finds clothes for you and even shows virtual try-ons! #AI #Python #Gradio #MachineLearning #Ecommerce</description>
    </item>
  </channel>
</rss>
