<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hugging-Face-Blog on Daily Tech Articles Feed</title>
    <link>http://localhost:1313/sources/hugging-face-blog/</link>
    <description>Recent content in Hugging-Face-Blog on Daily Tech Articles Feed</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Aug 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/sources/hugging-face-blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Generate Images with Claude and Hugging Face</title>
      <link>http://localhost:1313/articles/article-5075/</link>
      <pubDate>Tue, 19 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/articles/article-5075/</guid>
      <description>Discover how to generate images using Claude and Hugging Face! ð¤â¨ The article outlines step-by-step methods for utilizing these tools effectively. It highlights key features and provides tips for best practices in image generation. Explore the potential of AI in creative projects! #AI #ImageGeneration #HuggingFace #Claude #TechTrends</description>
    </item>
    <item>
      <title>From Zero to GPU: A Guide to Building and Scaling Production-Ready CUDA Kernels</title>
      <link>http://localhost:1313/articles/article-5077/</link>
      <pubDate>Mon, 18 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/articles/article-5077/</guid>
      <description>ð Excited to enhance your GPU capabilities? Check out the guide on building production-ready CUDA kernels! It introduces the kernel-builder library, designed to simplify the development of custom kernels for various architectures. Learn how to create efficient and maintainable systems while overcoming deployment challenges. Perfect for those looking to elevate their models! #CUDA #GPUs #Programming #TechGuide #MachineLearning</description>
    </item>
    <item>
      <title>MCP for Research: How to Connect AI to Research Tools</title>
      <link>http://localhost:1313/articles/article-5078/</link>
      <pubDate>Mon, 18 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/articles/article-5078/</guid>
      <description>ð Academic research often requires navigating multiple platforms like arXiv and GitHub. The Model Context Protocol (MCP) offers a solution by enabling AI to communicate with these research tools. This allows for natural language requests, streamlining the discovery process and reducing the need for manual switching between sites. Explore how MCP can enhance your research experience! ðð¤ #AIinResearch #ModelContextProtocol #ResearchInnovation #AcademicTools</description>
    </item>
    <item>
      <title>ðµð­ FilBench - Can LLMs Understand and Generate Filipino?</title>
      <link>http://localhost:1313/articles/article-4916/</link>
      <pubDate>Tue, 12 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/articles/article-4916/</guid>
      <description>Exploring the capabilities of LLMs in Filipino languages is essential. ðµð­ FilBench, a new evaluation suite, assesses LLM fluency, translation, and cultural knowledge in Tagalog and Cebuano. Despite high ChatGPT usage in the Philippines, systematic evaluations are lacking. The study evaluates over 20 LLMs, aiming to provide clear insights. ð Read the paper: &lt;a href=&#34;https://arxiv.org/abs/2508.03523&#34;&gt;arxiv.org&lt;/a&gt; ð¥ï¸ Check GitHub: &lt;a href=&#34;https://github.com/filbench/filbench-eval&#34;&gt;github.com&lt;/a&gt; #FilBench #LLMs&amp;hellip;</description>
    </item>
    <item>
      <title>TextQuests: How Good are LLMs at Text-Based Video Games?</title>
      <link>http://localhost:1313/articles/article-4915/</link>
      <pubDate>Tue, 12 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/articles/article-4915/</guid>
      <description>ð The article explores the capabilities of Large Language Models (LLMs) in text-based video games. It highlights that while LLMs excel in static knowledge benchmarks, they face challenges in dynamic, interactive environments. Developing effective evaluation methods for these models remains crucial. Two main approaches are suggested: real-world environments with specific skills and simulated open-world settings. The article introduces TextQuests as a new benchmark to assess LLM performance in&amp;hellip;</description>
    </item>
    <item>
      <title>Accelerate ND-Parallel: A Guide to Efficient Multi-GPU Training</title>
      <link>http://localhost:1313/articles/article-4739/</link>
      <pubDate>Fri, 08 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/articles/article-4739/</guid>
      <description>🚀 Training large models on multiple GPUs can be complex. The article &amp;ldquo;Accelerate ND-Parallel&amp;rdquo; discusses how to simplify this process using the Accelerate library and Axolotl. It provides a step-by-step guide to integrate various parallelism strategies in your training script, enhancing efficiency. Key configurations for parallelism include Fully Sharded Data Parallel and Data Parallel degrees. This approach requires at least 2 nodes with 8 GPUs each for optimal performance. #MultiGPU&amp;hellip;</description>
    </item>
    <item>
      <title>Introducing AI Sheets: a tool to work with datasets using open AI models!</title>
      <link>http://localhost:1313/articles/article-4738/</link>
      <pubDate>Fri, 08 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/articles/article-4738/</guid>
      <description>🚀 Exciting news for data enthusiasts! Hugging Face has launched AI Sheets, an open-source tool designed to build, enrich, and transform datasets using AI models without any coding required. You can deploy it locally or access it directly on the Hub, utilizing thousands of models, including gpt-oss from OpenAI. Explore the tool for free here: &lt;a href=&#34;https://huggingface.co/spaces/aisheets/sheets&#34;&gt;AI Sheets&lt;/a&gt; or install it locally from GitHub! #AISheets #OpenSource #DataScience #MachineLearning&amp;hellip;</description>
    </item>
    <item>
      <title>Vision Language Model Alignment in TRL ⚡️</title>
      <link>http://localhost:1313/articles/article-4695/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/articles/article-4695/</guid>
      <description>🔍 The article discusses the alignment of Vision Language Models (VLMs) in the context of Technology Readiness Levels (TRL). It highlights the importance of aligning VLMs with real-world applications to enhance their effectiveness. 💡 The piece outlines key strategies for achieving this alignment, focusing on practical implementation and evaluation methods. For those interested in AI development, this is a valuable read! #VisionLanguageModel #AIAlignment #TechnologyReadiness #MachineLearning&amp;hellip;</description>
    </item>
    <item>
      <title>Welcome GPT OSS, the new open-source model family from OpenAI!</title>
      <link>http://localhost:1313/articles/article-577/</link>
      <pubDate>Tue, 05 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/articles/article-577/</guid>
      <description>🚀 Exciting news from OpenAI! They have launched GPT OSS, a new open-source model family featuring two versions: gpt-oss-120b with 117B parameters and gpt-oss-20b with 21B parameters. Both models utilize a mixture-of-experts design for efficient performance. These models are licensed under Apache 2.0, promoting safe and responsible use. OpenAI aims to enhance accessibility in AI through this release. #OpenAI #GPTOSS #MachineLearning #AICommunity #OpenSource</description>
    </item>
  </channel>
</rss>
