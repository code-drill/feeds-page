<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>All the tech news (Posts about nvidia-developer-blog)</title><link>https://feeds.code-drill.eu/</link><description></description><atom:link href="https://feeds.code-drill.eu/sources/nvidia-developer-blog.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents ¬© 2025 &lt;a href="mailto:michal@code-drill.eu"&gt;Micha≈Ç Rutkowski&lt;/a&gt; </copyright><lastBuildDate>Thu, 28 Aug 2025 23:11:08 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Getting Started with NVIDIA Isaac for Healthcare Using the Telesurgery Workflow</title><link>https://feeds.code-drill.eu/posts/2025-08-28/getting-started-with-nvidia-isaac-for-healthcare-using-the-telesurgery-work/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üöÄ Telesurgery is transforming healthcare delivery as the shortage of
surgeons rises. With advancements in 5G and AI, experts can now operate
remotely, shifting from experimental to essential. üåç NVIDIA Isaac for
Healthcare offers a modular workflow that includes video streaming,
robot control, and simulation tools. This enables seamless training and
clinical deployment. Learn how this technology is paving the way for the
next generation of surgical robotics. ü§ñüí° #Telesurgery‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Michael Zephyr&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; educational&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-28/getting-started-with-nvidia-isaac-for-healthcare-using-the-telesurgery-work/</guid><pubDate>Thu, 28 Aug 2025 16:00:00 GMT</pubDate></item><item><title>How to Improve CUDA Kernel Performance with Shared Memory Register Spilling</title><link>https://feeds.code-drill.eu/posts/2025-08-27/how-to-improve-cuda-kernel-performance-with-shared-memory-register-spilling/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üöÄ New in CUDA Toolkit 13.0: Shared Memory Register Spilling! This
feature helps improve CUDA kernel performance by allowing the compiler
to use shared memory for excess variables instead of local memory. This
reduces spill latency and L2 pressure for register-heavy kernels. To
enable shared memory spilling, use the pragma command in your kernel
definition. With this optimization, kernels can perform better,
especially in critical regions where registers are heavily used. Learn
more about how‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Divya Shanmughan&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; technical_deep_dives&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-27/how-to-improve-cuda-kernel-performance-with-shared-memory-register-spilling/</guid><pubDate>Wed, 27 Aug 2025 16:30:00 GMT</pubDate></item><item><title>How to Scale Your LangGraph Agents in Production From A Single User to 1,000 Coworkers</title><link>https://feeds.code-drill.eu/posts/2025-08-27/how-to-scale-your-langgraph-agents-in-production-from-a-single-user-to-1000/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üìà Scaling your AI agent for production use? In a recent article, the
deployment of a deep-research agent using the AI-Q NVIDIA Blueprint is
explored. This article outlines how NVIDIA tackled the challenges of
sharing their AI tools with up to 1,000 coworkers. The focus was on
using the NeMo Agent Toolkit to ensure scalability and security while
accessing internal data. It details the architecture that supports
document processing and web search capabilities. Learn more about the
techniques‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Sean Lopp&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; educational&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-27/how-to-scale-your-langgraph-agents-in-production-from-a-single-user-to-1000/</guid><pubDate>Wed, 27 Aug 2025 16:00:00 GMT</pubDate></item><item><title>How Industry Collaboration Fosters NVIDIA Co-Packaged Optics</title><link>https://feeds.code-drill.eu/posts/2025-08-26/how-industry-collaboration-fosters-nvidia-co-packaged-optics/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;NVIDIA is transforming data-center connectivity by merging optical
and electrical components through strong industry partnerships. ü§ù Their
networking platform integrates advanced technologies from top partners,
focusing on scalable and efficient optical systems. Key innovations
include the Micro Ring Modulator, allowing high data throughput with a
compact design. Collaboration with TSMC has addressed manufacturing
challenges, ensuring reliable performance essential for modern data
centers‚Ä¶.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Ashkan Seyedi&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; industry_analysis&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-26/how-industry-collaboration-fosters-nvidia-co-packaged-optics/</guid><pubDate>Tue, 26 Aug 2025 17:00:00 GMT</pubDate></item><item><title>NVFP4 Trains with Precision of 16-Bit and Speed and Efficiency of 4-Bit</title><link>https://feeds.code-drill.eu/posts/2025-08-25/nvfp4-trains-with-precision-of-16-bit-and-speed-and-efficiency-of-4-bit/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üöÄ NVIDIA has introduced NVFP4, a 4-bit format designed to enhance AI
workloads during pretraining of large language models (LLMs). This
innovation aims to improve training efficiency and throughput while
maintaining accuracy. The shift from higher precision formats to 4-bit
is set to redefine scalability in AI development. Collaboration with
major organizations like Google Cloud and OpenAI is ongoing to explore
this technology‚Äôs full potential. #AI #NVIDIA #MachineLearning #LLMs
#Innovation&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Kirthi Devleker&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; product_announcements&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-25/nvfp4-trains-with-precision-of-16-bit-and-speed-and-efficiency-of-4-bit/</guid><pubDate>Mon, 25 Aug 2025 15:05:23 GMT</pubDate></item><item><title>Introducing NVIDIA Jetson Thor, the Ultimate Platform for Physical AI</title><link>https://feeds.code-drill.eu/posts/2025-08-25/introducing-nvidia-jetson-thor-the-ultimate-platform-for-physical-ai/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üöÄ Robotics is evolving! The shift from specialist machines to
adaptable robots marks a new era in generalist robotics. These robots
are designed to learn and perform various tasks, enhancing efficiency
across industries. With NVIDIA‚Äôs Jetson Thor platform, developers can
create flexible robots that streamline operations without constant
reprogramming. Key components include hardware integration, real-time
control, perception, and high-level reasoning to facilitate complex
interactions‚Ä¶.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Shashank Maheshwari&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; product_announcements&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-25/introducing-nvidia-jetson-thor-the-ultimate-platform-for-physical-ai/</guid><pubDate>Mon, 25 Aug 2025 15:00:00 GMT</pubDate></item><item><title>How to Spot (and Fix) 5 Common Performance Bottlenecks in pandas Workflows</title><link>https://feeds.code-drill.eu/posts/2025-08-22/how-to-spot-and-fix-5-common-performance-bottlenecks-in-pandas-workflows/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;Are you facing slow data loads and memory issues in your pandas
workflows? üêçüíª This article highlights five common performance
bottlenecks in pandas, including slow CSV parsing and memory-intensive
joins. It offers practical solutions to improve your workflow
efficiency, such as using the PyArrow engine for faster CSV reads and
exploring the cudf.pandas library for GPU acceleration. Don‚Äôt have a
GPU? You can use cudf.pandas for free in Google Colab! üöÄüìä #DataScience
#Python #Pandas #Performance‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Jamil Semaan&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; educational&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-22/how-to-spot-and-fix-5-common-performance-bottlenecks-in-pandas-workflows/</guid><pubDate>Fri, 22 Aug 2025 19:54:44 GMT</pubDate></item><item><title>Inside NVIDIA Blackwell Ultra: The Chip Powering the AI Factory Era</title><link>https://feeds.code-drill.eu/posts/2025-08-22/inside-nvidia-blackwell-ultra-the-chip-powering-the-ai-factory-era/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;Introducing the NVIDIA Blackwell Ultra GPU, a key advancement in the
Blackwell architecture. This GPU enhances AI training and reasoning with
innovative technology. Key features include a dual-reticle design, high
bandwidth, and energy-efficient performance. It boasts 208 billion
transistors and provides significant scalability for AI tasks. With 15
PetaFLOPS performance and improved memory access, the Blackwell Ultra
sets a new standard for accelerated computing. #NVIDIA #AI
#BlackwellUltra‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Kyle Aubrey&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; technical_deep_dives&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-22/inside-nvidia-blackwell-ultra-the-chip-powering-the-ai-factory-era/</guid><pubDate>Fri, 22 Aug 2025 15:00:00 GMT</pubDate></item><item><title>NVIDIA Hardware Innovations and Open Source Contributions Are Shaping AI</title><link>https://feeds.code-drill.eu/posts/2025-08-22/nvidia-hardware-innovations-and-open-source-contributions-are-shaping-ai/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;NVIDIA is making strides in AI through open source models like
Cosmos, DeepSeek, and Llama. üåê These models offer free access to AI
methodologies, enabling innovation across the globe. Their new Blackwell
GPU architecture enhances AI performance with advanced features like
NVFP4 and high-bandwidth interconnects. ‚ö°Ô∏è Additionally, NVIDIA provides
a wealth of open source tools and libraries, fostering an environment
for developers to build and scale AI efficiently. üíª Discover more about
these‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; George Chellapa&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; industry_analysis&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-22/nvidia-hardware-innovations-and-open-source-contributions-are-shaping-ai/</guid><pubDate>Fri, 22 Aug 2025 15:00:00 GMT</pubDate></item><item><title>Less Coding, More Science: Simplify Ocean Modeling on GPUs With OpenACC and Unified Memory</title><link>https://feeds.code-drill.eu/posts/2025-08-21/less-coding-more-science-simplify-ocean-modeling-on-gpus-with-openacc-and-u/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üöÄ Exciting advancements in ocean modeling are here! NVIDIA HPC SDK
v25.7 simplifies GPU programming for high-performance computing
applications. This update automates data movement between CPU and GPU,
reducing manual management and enhancing developer productivity. Notable
systems like the NVIDIA GH200 Grace Hopper Superchip are leading the
way. With unified memory programming, developers can focus more on
science and less on coding complexities. This change is already
benefiting projects,‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Anastasia Stulova&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; product_announcements&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-21/less-coding-more-science-simplify-ocean-modeling-on-gpus-with-openacc-and-u/</guid><pubDate>Thu, 21 Aug 2025 16:53:17 GMT</pubDate></item></channel></rss>