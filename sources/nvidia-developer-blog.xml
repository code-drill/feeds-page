<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>All the tech news (Posts about nvidia-developer-blog)</title><link>https://feeds.code-drill.eu/</link><description></description><atom:link href="https://feeds.code-drill.eu/sources/nvidia-developer-blog.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents ¬© 2025 &lt;a href="mailto:michal@code-drill.eu"&gt;Micha≈Ç Rutkowski&lt;/a&gt; </copyright><lastBuildDate>Mon, 01 Sep 2025 20:59:42 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>How Small Language Models Are Key to Scalable Agentic AI</title><link>https://feeds.code-drill.eu/posts/2025-08-29/how-small-language-models-are-key-to-scalable-agentic-ai/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;The rise of agentic AI is transforming how businesses approach
automation and productivity. ü§ñ Recent insights highlight the potential
of small language models (SLMs) as efficient alternatives to large
language models (LLMs) in agentic applications. SLMs can reduce costs
and improve operational flexibility while maintaining performance. This
shift enables enterprises to utilize SLMs for specific tasks, reserving
LLMs for more complex scenarios. Tools like NVIDIA‚Äôs Nemotron
demonstrate the‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Peter Belcak&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; industry_analysis&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-29/how-small-language-models-are-key-to-scalable-agentic-ai/</guid><pubDate>Fri, 29 Aug 2025 15:28:42 GMT</pubDate></item><item><title>Fine-Tuning gpt-oss for Accuracy and Performance with Quantization Aware Training</title><link>https://feeds.code-drill.eu/posts/2025-08-29/fine-tuning-gpt-oss-for-accuracy-and-performance-with-quantization-aware-tr/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;OpenAI‚Äôs gpt-oss model has made waves in the AI community with its
innovative architecture and performance capabilities. üìàüß† It features a
mixture of expert architecture and a 128K context length, competing
closely with OpenAI‚Äôs closed-source models. However, deploying
foundational models like gpt-oss in critical fields requires careful
fine-tuning. The article discusses employing Supervised Fine-Tuning
(SFT) and Quantization-Aware Training (QAT) to enhance model accuracy
while maintaining‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Eduardo Alvarez&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; technical_deep_dives&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-29/fine-tuning-gpt-oss-for-accuracy-and-performance-with-quantization-aware-tr/</guid><pubDate>Fri, 29 Aug 2025 14:47:04 GMT</pubDate></item><item><title>Getting Started with NVIDIA Isaac for Healthcare Using the Telesurgery Workflow</title><link>https://feeds.code-drill.eu/posts/2025-08-28/getting-started-with-nvidia-isaac-for-healthcare-using-the-telesurgery-work/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üöÄ Telesurgery is transforming healthcare delivery as the shortage of
surgeons rises. With advancements in 5G and AI, experts can now operate
remotely, shifting from experimental to essential. üåç NVIDIA Isaac for
Healthcare offers a modular workflow that includes video streaming,
robot control, and simulation tools. This enables seamless training and
clinical deployment. Learn how this technology is paving the way for the
next generation of surgical robotics. ü§ñüí° #Telesurgery‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Michael Zephyr&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; educational&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-28/getting-started-with-nvidia-isaac-for-healthcare-using-the-telesurgery-work/</guid><pubDate>Thu, 28 Aug 2025 16:00:00 GMT</pubDate></item><item><title>How to Improve CUDA Kernel Performance with Shared Memory Register Spilling</title><link>https://feeds.code-drill.eu/posts/2025-08-27/how-to-improve-cuda-kernel-performance-with-shared-memory-register-spilling/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üöÄ New in CUDA Toolkit 13.0: Shared Memory Register Spilling! This
feature helps improve CUDA kernel performance by allowing the compiler
to use shared memory for excess variables instead of local memory. This
reduces spill latency and L2 pressure for register-heavy kernels. To
enable shared memory spilling, use the pragma command in your kernel
definition. With this optimization, kernels can perform better,
especially in critical regions where registers are heavily used. Learn
more about how‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Divya Shanmughan&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; technical_deep_dives&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-27/how-to-improve-cuda-kernel-performance-with-shared-memory-register-spilling/</guid><pubDate>Wed, 27 Aug 2025 16:30:00 GMT</pubDate></item><item><title>How to Scale Your LangGraph Agents in Production From A Single User to 1,000 Coworkers</title><link>https://feeds.code-drill.eu/posts/2025-08-27/how-to-scale-your-langgraph-agents-in-production-from-a-single-user-to-1000/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üìà Scaling your AI agent for production use? In a recent article, the
deployment of a deep-research agent using the AI-Q NVIDIA Blueprint is
explored. This article outlines how NVIDIA tackled the challenges of
sharing their AI tools with up to 1,000 coworkers. The focus was on
using the NeMo Agent Toolkit to ensure scalability and security while
accessing internal data. It details the architecture that supports
document processing and web search capabilities. Learn more about the
techniques‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Sean Lopp&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; educational&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-27/how-to-scale-your-langgraph-agents-in-production-from-a-single-user-to-1000/</guid><pubDate>Wed, 27 Aug 2025 16:00:00 GMT</pubDate></item><item><title>How Industry Collaboration Fosters NVIDIA Co-Packaged Optics</title><link>https://feeds.code-drill.eu/posts/2025-08-26/how-industry-collaboration-fosters-nvidia-co-packaged-optics/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;NVIDIA is transforming data-center connectivity by merging optical
and electrical components through strong industry partnerships. ü§ù Their
networking platform integrates advanced technologies from top partners,
focusing on scalable and efficient optical systems. Key innovations
include the Micro Ring Modulator, allowing high data throughput with a
compact design. Collaboration with TSMC has addressed manufacturing
challenges, ensuring reliable performance essential for modern data
centers‚Ä¶.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Ashkan Seyedi&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; industry_analysis&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-26/how-industry-collaboration-fosters-nvidia-co-packaged-optics/</guid><pubDate>Tue, 26 Aug 2025 17:00:00 GMT</pubDate></item><item><title>NVFP4 Trains with Precision of 16-Bit and Speed and Efficiency of 4-Bit</title><link>https://feeds.code-drill.eu/posts/2025-08-25/nvfp4-trains-with-precision-of-16-bit-and-speed-and-efficiency-of-4-bit/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üöÄ NVIDIA has introduced NVFP4, a 4-bit format designed to enhance AI
workloads during pretraining of large language models (LLMs). This
innovation aims to improve training efficiency and throughput while
maintaining accuracy. The shift from higher precision formats to 4-bit
is set to redefine scalability in AI development. Collaboration with
major organizations like Google Cloud and OpenAI is ongoing to explore
this technology‚Äôs full potential. #AI #NVIDIA #MachineLearning #LLMs
#Innovation&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Kirthi Devleker&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; product_announcements&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-25/nvfp4-trains-with-precision-of-16-bit-and-speed-and-efficiency-of-4-bit/</guid><pubDate>Mon, 25 Aug 2025 15:05:23 GMT</pubDate></item><item><title>Introducing NVIDIA Jetson Thor, the Ultimate Platform for Physical AI</title><link>https://feeds.code-drill.eu/posts/2025-08-25/introducing-nvidia-jetson-thor-the-ultimate-platform-for-physical-ai/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;üöÄ Robotics is evolving! The shift from specialist machines to
adaptable robots marks a new era in generalist robotics. These robots
are designed to learn and perform various tasks, enhancing efficiency
across industries. With NVIDIA‚Äôs Jetson Thor platform, developers can
create flexible robots that streamline operations without constant
reprogramming. Key components include hardware integration, real-time
control, perception, and high-level reasoning to facilitate complex
interactions‚Ä¶.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Shashank Maheshwari&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; product_announcements&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-25/introducing-nvidia-jetson-thor-the-ultimate-platform-for-physical-ai/</guid><pubDate>Mon, 25 Aug 2025 15:00:00 GMT</pubDate></item><item><title>How to Spot (and Fix) 5 Common Performance Bottlenecks in pandas Workflows</title><link>https://feeds.code-drill.eu/posts/2025-08-22/how-to-spot-and-fix-5-common-performance-bottlenecks-in-pandas-workflows/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;Are you facing slow data loads and memory issues in your pandas
workflows? üêçüíª This article highlights five common performance
bottlenecks in pandas, including slow CSV parsing and memory-intensive
joins. It offers practical solutions to improve your workflow
efficiency, such as using the PyArrow engine for faster CSV reads and
exploring the cudf.pandas library for GPU acceleration. Don‚Äôt have a
GPU? You can use cudf.pandas for free in Google Colab! üöÄüìä #DataScience
#Python #Pandas #Performance‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Jamil Semaan&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; educational&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-22/how-to-spot-and-fix-5-common-performance-bottlenecks-in-pandas-workflows/</guid><pubDate>Fri, 22 Aug 2025 19:54:44 GMT</pubDate></item><item><title>Inside NVIDIA Blackwell Ultra: The Chip Powering the AI Factory Era</title><link>https://feeds.code-drill.eu/posts/2025-08-22/inside-nvidia-blackwell-ultra-the-chip-powering-the-ai-factory-era/</link><dc:creator>Micha≈Ç Rutkowski</dc:creator><description>&lt;p&gt;Introducing the NVIDIA Blackwell Ultra GPU, a key advancement in the
Blackwell architecture. This GPU enhances AI training and reasoning with
innovative technology. Key features include a dual-reticle design, high
bandwidth, and energy-efficient performance. It boasts 208 billion
transistors and provides significant scalability for AI tasks. With 15
PetaFLOPS performance and improved memory access, the Blackwell Ultra
sets a new standard for accelerated computing. #NVIDIA #AI
#BlackwellUltra‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://developer.nvidia.com/blog/feed"&gt;Nvidia Developer
Blog&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Author:&lt;/strong&gt; Kyle Aubrey&lt;br&gt;
&lt;strong&gt;Category:&lt;/strong&gt; technical_deep_dives&lt;/p&gt;</description><category>nvidia-developer-blog</category><guid>https://feeds.code-drill.eu/posts/2025-08-22/inside-nvidia-blackwell-ultra-the-chip-powering-the-ai-factory-era/</guid><pubDate>Fri, 22 Aug 2025 15:00:00 GMT</pubDate></item></channel></rss>