<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nvidia-Developer-Blog on Daily Tech Articles Feed</title>
    <link>/sources/nvidia-developer-blog/</link>
    <description>Recent content in Nvidia-Developer-Blog on Daily Tech Articles Feed</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Nov 2025 17:44:52 +0000</lastBuildDate>
    <atom:link href="/sources/nvidia-developer-blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Building an Interactive AI Agent for Lightning-Fast Machine Learning Tasks</title>
      <link>/articles/article-2025-11-07-11891/</link>
      <pubDate>Fri, 07 Nov 2025 17:44:52 +0000</pubDate>
      <guid>/articles/article-2025-11-07-11891/</guid>
      <description>üöÄ Data scientists often face challenges in preparing large datasets, which can slow down machine learning tasks. A new interactive AI agent has been prototyped to simplify this process. Using NVIDIA&amp;rsquo;s GPU acceleration, the agent helps translate user intent into optimized workflows, allowing for faster exploration and analysis of data. Developers can interact with the agent through natural language, speeding up tasks from data processing to model evaluation. Explore the architecture and&amp;hellip;</description>
    </item>
    <item>
      <title>Benchmarking LLMs on AI-Generated CUDA Code with ComputeEval 2025.2</title>
      <link>/articles/article-2025-11-07-11892/</link>
      <pubDate>Fri, 07 Nov 2025 16:30:00 +0000</pubDate>
      <guid>/articles/article-2025-11-07-11892/</guid>
      <description>üöÄ New insights on AI coding assistants! The latest update of ComputeEval has expanded CUDA challenges to 232, adding over 100 new problems that test advanced features like Tensor Cores and CUDA Graphs. This aims to elevate AI performance in CUDA programming. Recent evaluations show that scores for leading LLMs have declined, but this reflects the increased difficulty of the benchmark, not a drop in capability. The team plans to further extend dataset coverage and invites collaboration from&amp;hellip;</description>
    </item>
    <item>
      <title>Enhancing GPU-Accelerated Vector Search in Faiss with NVIDIA cuVS</title>
      <link>/articles/article-2025-11-06-11893/</link>
      <pubDate>Thu, 06 Nov 2025 20:41:38 +0000</pubDate>
      <guid>/articles/article-2025-11-06-11893/</guid>
      <description>Unlock faster data processing with NVIDIA cuVS and Meta Faiss! üöÄ As businesses handle more unstructured data, traditional systems struggle to keep up. cuVS enhances vector search efficiency, allowing for quicker index creation and searches. Key benefits include: - Up to 12x faster index building on GPU - 8x lower search latencies - Seamless index transfer between CPU and GPU üåê Explore the advancements in GPU-accelerated search! #NVIDIA #Faiss #DataProcessing #AI #MachineLearning</description>
    </item>
    <item>
      <title>Accelerating Large-Scale Mixture-of-Experts Training in PyTorch</title>
      <link>/articles/article-2025-11-06-11894/</link>
      <pubDate>Thu, 06 Nov 2025 17:00:00 +0000</pubDate>
      <guid>/articles/article-2025-11-06-11894/</guid>
      <description>üöÄ Exciting advancements in AI training! NVIDIA NeMo Automodel simplifies large-scale mixture-of-experts (MoE) training in PyTorch. Developers can now train billion-parameter models without complex setups. This open-source library allows scaling from 8 to over 1,000 GPUs efficiently, making powerful MoE architectures accessible to all. Discover the benefits and a quick-start guide to enhance your experiments! #NVIDIA #MachineLearning #PyTorch #AI #MoE</description>
    </item>
    <item>
      <title>How to Predict Biomolecular Structures Using the OpenFold3 NIM</title>
      <link>/articles/article-2025-11-04-11713/</link>
      <pubDate>Tue, 04 Nov 2025 18:00:00 +0000</pubDate>
      <guid>/articles/article-2025-11-04-11713/</guid>
      <description>Unlock the mystery of biomolecular structures with OpenFold3! üß¨ Deep learning has revolutionized how we predict protein folding, moving us closer to understanding biological architecture. OpenFold3 now extends this capability to multi-chain complexes and small molecules. Powered by NVIDIA, this tool offers rapid sequence search and privacy-preserving collaboration. üåê‚ú® Ready to get started? Check out the OpenFold3 API demo and access the source code today! #BiomolecularScience #DeepLearning&amp;hellip;</description>
    </item>
    <item>
      <title>R¬≤D¬≤: Perception-Guided Task &amp; Motion Planning for Long-Horizon Manipulation</title>
      <link>/articles/article-2025-11-04-11714/</link>
      <pubDate>Tue, 04 Nov 2025 17:00:00 +0000</pubDate>
      <guid>/articles/article-2025-11-04-11714/</guid>
      <description>üöÄ New advancements in robot manipulation are explored in the latest edition of NVIDIA&amp;rsquo;s R¬≤D¬≤. Traditional task and motion planning (TAMP) often struggles in new environments. The integration of perception allows robots to adapt plans in real-time, enhancing their capabilities. Key concepts include subgoals, affordances, and differentiable constraints, which help robots navigate complex tasks effectively. Innovative frameworks like OWL-TAMP and VLM-TAMP are highlighted, using vision and&amp;hellip;</description>
    </item>
    <item>
      <title>Make Sense of Video Analytics by Integrating NVIDIA AI Blueprints</title>
      <link>/articles/article-2025-11-03-11676/</link>
      <pubDate>Mon, 03 Nov 2025 21:48:11 +0000</pubDate>
      <guid>/articles/article-2025-11-03-11676/</guid>
      <description>Unlock insights from video and audio data with NVIDIA&amp;rsquo;s integrated approach! üìπüîç The article discusses how combining the Video Search and Summarization (VSS) and Retrieval-Augmented Generation (RAG) AI Blueprints enhances video analytics. This integration allows for richer insights by incorporating enterprise context into video workflows. Learn how to create scalable systems for real-time video Q&amp;amp;A and apply these solutions in various industries. #NVIDIA #VideoAnalytics #AI #DataInsights&amp;hellip;</description>
    </item>
    <item>
      <title>Join Us for the Blackwell NVFP4 Kernel Hackathon with NVIDIA and GPU MODE</title>
      <link>/articles/article-2025-11-03-11673/</link>
      <pubDate>Mon, 03 Nov 2025 20:00:00 +0000</pubDate>
      <guid>/articles/article-2025-11-03-11673/</guid>
      <description>üåü Join the Blackwell NVFP4 Kernel Hackathon! üåü This four-part performance challenge is hosted by NVIDIA in collaboration with GPU MODE, with support from Dell and Sesterce. Developers can showcase their skills and push performance limits. For event details and inquiries, reach out to the NVIDIA Developer Community Team. #Hackathon #NVIDIA #GPU #DeveloperCommunity #PerformanceChallenge</description>
    </item>
    <item>
      <title>Advancing Explainable AI in Radiology Research with NVIDIA Clara Reason</title>
      <link>/articles/article-2025-11-03-11663/</link>
      <pubDate>Mon, 03 Nov 2025 18:02:51 +0000</pubDate>
      <guid>/articles/article-2025-11-03-11663/</guid>
      <description>üöÄ Medical AI is evolving! NVIDIA Clara is advancing explainable AI in radiology by introducing Clara Reason. This innovative approach mirrors radiologists&amp;rsquo; thought processes, enabling step-by-step diagnostic reasoning with transparent explanations. ü©ª Clara NV-Reason-CXR-3B specializes in chest x-ray analysis, addressing the trust barrier in AI-assisted diagnoses. Learn how this model combines multimodal data and structured reasoning to enhance clinical decision-making. #MedicalAI #Radiology&amp;hellip;</description>
    </item>
    <item>
      <title>How Code Execution Drives Key Risks in Agentic AI Systems</title>
      <link>/articles/article-2025-11-03-11664/</link>
      <pubDate>Mon, 03 Nov 2025 17:54:01 +0000</pubDate>
      <guid>/articles/article-2025-11-03-11664/</guid>
      <description>AI-driven applications are shifting from passive tools to agentic systems capable of generating code and making decisions. This evolution presents significant security risks, especially concerning code execution. Strict controls are necessary to prevent malicious actors from exploiting AI-generated code. Traditional defenses, like sanitization, may not be sufficient as attackers can craft inputs to bypass these measures. The NVIDIA AI red team highlights the importance of treating LLM-&amp;hellip;</description>
    </item>
    <item>
      <title>Streamline AI Infrastructure with NVIDIA Run:ai on Microsoft Azure</title>
      <link>/articles/article-2025-10-30-11507/</link>
      <pubDate>Thu, 30 Oct 2025 17:10:00 +0000</pubDate>
      <guid>/articles/article-2025-10-30-11507/</guid>
      <description>Transform your AI infrastructure with NVIDIA Run:ai on Microsoft Azure! üåê This platform enhances GPU resource management in Kubernetes environments, addressing key challenges like inefficient utilization and governance. Key features include fractional GPU allocation, dynamic scheduling, and team-based quotas, all designed to optimize AI workloads. Learn how to streamline your AI operations for better performance and efficiency. üíªüöÄ #AI #NVIDIA #MicrosoftAzure #Kubernetes #CloudComputing</description>
    </item>
    <item>
      <title>Introducing the CodonFM Open Model for RNA Design and Analysis</title>
      <link>/articles/article-2025-10-28-11375/</link>
      <pubDate>Tue, 28 Oct 2025 20:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-28-11375/</guid>
      <description>üöÄ Exciting news from NVIDIA! They&amp;rsquo;ve introduced CodonFM, a new RNA language model as part of the Clara open model family. This model understands RNA by treating codons as words, enhancing its ability to predict mRNA design and variant effects. CodonFM was trained on 131 million protein-coding sequences, allowing it to accurately interpret complex genetic patterns. Explore more about CodonFM and its applications for RNA analysis! #NVIDIA #CodonFM #OpenResearch #RNA #Bioinformatics</description>
    </item>
    <item>
      <title>Accelerating AV Simulation with Neural Reconstruction and World Foundation Models</title>
      <link>/articles/article-2025-10-28-11376/</link>
      <pubDate>Tue, 28 Oct 2025 18:30:00 +0000</pubDate>
      <guid>/articles/article-2025-10-28-11376/</guid>
      <description>Autonomous vehicle (AV) technology is advancing towards integrated end-to-end architectures using foundation models. This shift emphasizes the need for a robust AV data flywheel to create synthetic data and enhance sensor datasets. NVIDIA has introduced tools such as the Omniverse and Cosmos workflows to support developers in building these data pipelines. Key features include access to real AV data, data processing tools, and libraries for neural reconstruction. With over 1,700 hours of&amp;hellip;</description>
    </item>
    <item>
      <title>Powering AI-Native 6G Research with the NVIDIA Sionna Research Kit</title>
      <link>/articles/article-2025-10-28-11358/</link>
      <pubDate>Tue, 28 Oct 2025 17:51:58 +0000</pubDate>
      <guid>/articles/article-2025-10-28-11358/</guid>
      <description>Unlock the future of wireless communication with the NVIDIA Sionna Research Kit! üì°‚ú® This open-source platform is designed for 6G research, enabling rapid prototyping and real-time simulations. With over 540 publications referencing Sionna, it‚Äôs paving the way for innovation in AI and ML applications. The Sionna Research Kit runs on the NVIDIA DGX Spark, offering a fully open platform for wireless research. Researchers can experiment across the entire telecommunications stack, promoting&amp;hellip;</description>
    </item>
    <item>
      <title>Develop Specialized AI Agents with New NVIDIA Nemotron Vision, RAG, and Guardrail Models</title>
      <link>/articles/article-2025-10-28-11359/</link>
      <pubDate>Tue, 28 Oct 2025 17:32:45 +0000</pubDate>
      <guid>/articles/article-2025-10-28-11359/</guid>
      <description>üöÄ NVIDIA introduces new Nemotron models aimed at enhancing Agentic AI. These specialized language and vision models enable effective planning, reasoning, and retrieval. Developers can now access open models and robust datasets to build AI agents for specific workflows, ensuring compliance and real-world deployment. Learn more about the features, performance, and tutorials for creating multimodal agents and RAG pipelines with a focus on content safety. #NVIDIA #AI #TechInnovation #AgenticAI&amp;hellip;</description>
    </item>
    <item>
      <title>Build Synthetic Data Pipelines to Train Smarter Robots with NVIDIA Isaac Sim</title>
      <link>/articles/article-2025-10-24-11268/</link>
      <pubDate>Fri, 24 Oct 2025 19:42:06 +0000</pubDate>
      <guid>/articles/article-2025-10-24-11268/</guid>
      <description>Unlock the potential of robotics with synthetic data pipelines! ü§ñ As robots tackle complex mobility tasks, developers require accurate simulations. NVIDIA Isaac Sim provides a solution by generating high-quality synthetic data, reducing the time and cost of real-world data collection. Key points include: - Creating simulated environments with NVIDIA Omniverse NuRec. - Utilizing SimReady assets for streamlined simulations. - Generating and augmenting synthetic data using MobilityGen and NVIDIA&amp;hellip;</description>
    </item>
    <item>
      <title>Unlocking Tensor Core Performance with Floating Point Emulation in cuBLAS</title>
      <link>/articles/article-2025-10-24-11262/</link>
      <pubDate>Fri, 24 Oct 2025 16:21:14 +0000</pubDate>
      <guid>/articles/article-2025-10-24-11262/</guid>
      <description>üöÄ NVIDIA&amp;rsquo;s latest cuBLAS update in CUDA Toolkit 13.0 Update 2 enhances double-precision (FP64) matrix multiplications through floating-point emulation on Tensor Cores. This update offers improved performance for both FP32 and FP64 operations, ensuring accuracy while maximizing efficiency. Developers can access Tensor Core performance easily via familiar APIs. For detailed GPU compatibility and implementation specifics, refer to the cuBLAS documentation. #NVIDIA #CUDA #cuBLAS #AI #MachineLearning</description>
    </item>
    <item>
      <title>How NVIDIA DGX Spark‚Äôs Performance Enables Intensive AI Tasks</title>
      <link>/articles/article-2025-10-24-11264/</link>
      <pubDate>Fri, 24 Oct 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-24-11264/</guid>
      <description>NVIDIA DGX Spark is designed to meet the needs of AI developers requiring high memory and powerful computing without relying on cloud resources. This compact supercomputer offers 1 petaflop of FP4 AI performance and 128 GB of coherent memory, making it suitable for intensive tasks like fine-tuning and image generation. Benchmark tests show impressive performance in fine-tuning models, with peak speeds of over 82,000 tokens per second. Additionally, it supports high-resolution image&amp;hellip;</description>
    </item>
    <item>
      <title>Solve Linear Programs Using the GPU-Accelerated Barrier Method in NVIDIA cuOpt</title>
      <link>/articles/article-2025-10-24-11263/</link>
      <pubDate>Fri, 24 Oct 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-24-11263/</guid>
      <description>Unlock the power of optimization with NVIDIA cuOpt! This open-source library enhances problem-solving for complex scenarios like sports scheduling and medical transplants. The latest update features a new barrier method solver for linear programs, offering significant speed improvements. Benchmarks show over 8x faster performance compared to leading CPU solvers. Discover how cuOpt is transforming optimization tasks! #Optimization #NVIDIA #cuOpt #LinearProgramming #TechInnovation üöÄüìàüíª</description>
    </item>
    <item>
      <title>Reconstruct a Scene in NVIDIA Isaac Sim Using Only a Smartphone</title>
      <link>/articles/article-2025-10-23-11238/</link>
      <pubDate>Thu, 23 Oct 2025 23:06:12 +0000</pubDate>
      <guid>/articles/article-2025-10-23-11238/</guid>
      <description>Transforming 3D environments for robotics simulation is now easier with NVIDIA Omniverse NuRec! üì±‚ú® Using just a smartphone, you can capture real-world scenes and create realistic 3D models. The process involves taking photos, generating a sparse reconstruction with COLMAP, and loading your scene into NVIDIA Isaac Sim. For detailed steps, including tips on capturing the best photos, check out the full article! #NVIDIA #3DModeling #Robotics #IsaacSim #Omniverse</description>
    </item>
    <item>
      <title>Train an LLM on an NVIDIA Blackwell Desktop with Unsloth‚Äîand Scale It</title>
      <link>/articles/article-2025-10-23-11207/</link>
      <pubDate>Thu, 23 Oct 2025 17:51:24 +0000</pubDate>
      <guid>/articles/article-2025-10-23-11207/</guid>
      <description>Unlock the potential of large language models (LLMs) with the Unsloth framework! üåü Unsloth simplifies fine-tuning and reinforcement learning, making it accessible for individuals and small teams. It pairs seamlessly with NVIDIA Blackwell GPUs, enhancing training speed and efficiency. With benchmarks showing 2x faster training and 70% less VRAM usage, LLM customization is now within reach! üéâ Explore how to train custom LLMs locally and scale to cloud instances for production workloads. #AI&amp;hellip;</description>
    </item>
    <item>
      <title>Bring Your Circuits to CUDA-Q Using QGEAR</title>
      <link>/articles/article-2025-10-23-11208/</link>
      <pubDate>Thu, 23 Oct 2025 16:55:33 +0000</pubDate>
      <guid>/articles/article-2025-10-23-11208/</guid>
      <description>üöÄ Exciting news for developers! You can now import Qiskit circuits into GPU-accelerated CUDA-Q kernels with NERSC‚Äôs QGEAR project. This makes integrating quantum circuits smoother and more efficient. To get started, simply install using: &lt;code&gt;bash pip install qgear-lightning &lt;/code&gt; Explore the future of quantum computing! üñ•Ô∏è‚ú® #QuantumComputing #QGEAR #CUDAQ #Qiskit #NERSC</description>
    </item>
    <item>
      <title>Create Your Own Bash Computer Use Agent with NVIDIA Nemotron in One Hour</title>
      <link>/articles/article-2025-10-22-11146/</link>
      <pubDate>Wed, 22 Oct 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-22-11146/</guid>
      <description>Unlock the power of voice with NVIDIA Nemotron Nano v2! üé§üíª This article guides you on creating a natural language Bash agent that executes commands without manual input. In just under an hour and about 200 lines of Python code, you can build this tool from scratch. It also introduces LangGraph for simplifying design. Ready to get started? #NVIDIA #BashAgent #NaturalLanguageProcessing #Python #TechInnovation</description>
    </item>
    <item>
      <title>Build Practical Deep-Learning Skills for Real-World AI Applications with the New NVIDIA Learning Path</title>
      <link>/articles/article-2025-10-21-11126/</link>
      <pubDate>Tue, 21 Oct 2025 20:05:06 +0000</pubDate>
      <guid>/articles/article-2025-10-21-11126/</guid>
      <description>üåü Enhance your deep-learning skills with NVIDIA&amp;rsquo;s new learning path! Explore a variety of courses, workshops, and certifications designed for real-world AI applications. Visit the learning path page to sign up and start your journey in developing practical expertise. #NVIDIA #DeepLearning #AI #LearningPath #SkillDevelopment</description>
    </item>
    <item>
      <title>NVIDIA ACE Adds Open Source Qwen3 SLM for On-Device Deployment in PC Games</title>
      <link>/articles/article-2025-10-21-11118/</link>
      <pubDate>Tue, 21 Oct 2025 17:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-21-11118/</guid>
      <description>üöÄ NVIDIA ACE now supports the open-source Qwen3-8B small language model for on-device NPC character development. This integration allows for real-time reasoning and dynamic responses in gaming, enhancing player interaction. The IGI SDK plugin also includes updates for multilingual text-to-speech capabilities and improved performance features. Developers can check out the latest tools and resources to elevate their gaming projects. üéÆ‚ú® #NVIDIA #Gaming #AI #GameDevelopment #Qwen3</description>
    </item>
    <item>
      <title>Build an AI Agent to Analyze IT Tickets with NVIDIA Nemotron</title>
      <link>/articles/article-2025-10-20-11073/</link>
      <pubDate>Mon, 20 Oct 2025 17:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-20-11073/</guid>
      <description>Unlock insights from IT tickets with NVIDIA&amp;rsquo;s AI agent! üñ•Ô∏è Modern organizations face challenges in analyzing vast amounts of data from ticketing systems. Traditional platforms often fall short in providing actionable insights. NVIDIA&amp;rsquo;s ITelligence combines AI reasoning and graph databases to reveal hidden patterns in support ticket data. This approach helps identify recurring issues and team performance gaps effectively. The architecture is adaptable, suitable for various domains beyond IT&amp;hellip;</description>
    </item>
    <item>
      <title>Enabling Scalable AI-Driven Molecular Dynamics Simulations</title>
      <link>/articles/article-2025-10-20-11074/</link>
      <pubDate>Mon, 20 Oct 2025 16:30:00 +0000</pubDate>
      <guid>/articles/article-2025-10-20-11074/</guid>
      <description>Unlock the power of scalable molecular dynamics (MD) simulations! üî¨‚ú® This article explores how integrating PyTorch-based machine learning interatomic potentials (MLIPs) with the LAMMPS MD package enhances simulation efficiency and accuracy. The ML-IAP-Kokkos interface, developed by NVIDIA and national labs, streamlines this integration for researchers. It supports efficient data transfer between GPUs, enabling large-scale simulations. Ready to get started? The article provides a step-by-step&amp;hellip;</description>
    </item>
    <item>
      <title>Scaling Large MoE Models with Wide Expert Parallelism on NVL72 Rack Scale Systems</title>
      <link>/articles/article-2025-10-20-11075/</link>
      <pubDate>Mon, 20 Oct 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-20-11075/</guid>
      <description>Modern AI workloads are evolving beyond single-GPU setups. Model parallelism is now key for scalable deployments, especially with mixture-of-experts (MoE) architectures, which activate only a portion of parameters per token. Expert parallelism (EP) is crucial for managing the complexities of scaling these models. With tools like NVIDIA Tensor RT-LLM‚Äôs Wide Expert Parallelism, large-scale deployments become more efficient, enhancing performance and cost-effectiveness. Learn how large-scale EP&amp;hellip;</description>
    </item>
    <item>
      <title>NVIDIA Blackwell Leads on SemiAnalysis InferenceMAX v1 Benchmarks</title>
      <link>/articles/article-2025-10-16-10611/</link>
      <pubDate>Thu, 16 Oct 2025 17:33:19 +0000</pubDate>
      <guid>/articles/article-2025-10-16-10611/</guid>
      <description>SemiAnalysis has launched InferenceMAX‚Ñ¢ v1, an open-source initiative for evaluating inference hardware performance. The results show NVIDIA GPUs, particularly the Blackwell model, achieving a 15x performance increase over the previous Hopper generation. This advancement is attributed to innovative hardware-software designs. The AI community is encouraged to utilize InferenceMAX v1 to validate NVIDIA&amp;rsquo;s performance across various inference scenarios. #NVIDIA #AI #InferenceMAX #TechInnovation&amp;hellip;</description>
    </item>
    <item>
      <title>Agentic AI Unleashed: Join the AWS &amp; NVIDIA Hackathon</title>
      <link>/articles/article-2025-10-15-10964/</link>
      <pubDate>Wed, 15 Oct 2025 19:39:20 +0000</pubDate>
      <guid>/articles/article-2025-10-15-10964/</guid>
      <description>üöÄ Ready to innovate? Join the AWS &amp;amp; NVIDIA Hackathon and build the future of Agentic AI! Create an autonomous application using advanced AI models and scalable infrastructure. This event offers hands-on experience, networking opportunities, and the chance to win prizes. Teams can request $100 in promotional credits to support their projects. Be sure to monitor your usage to maximize your resources! #AI #Hackathon #AWS #NVIDIA #Innovation</description>
    </item>
    <item>
      <title>Unlock Faster, Smarter Edge Models with 7x Gen AI Performance on NVIDIA Jetson AGX Thor</title>
      <link>/articles/article-2025-10-15-10965/</link>
      <pubDate>Wed, 15 Oct 2025 18:25:01 +0000</pubDate>
      <guid>/articles/article-2025-10-15-10965/</guid>
      <description>üöÄ Exciting advancements in AI with NVIDIA Jetson AGX Thor! Launched in August, it has achieved a remarkable 7x boost in generative AI performance since its release. This improvement benefits various models, including Llama and DeepSeek. Continuous software updates support the latest AI models, enhancing developer experimentation. Jetson Thor also optimizes inference with major quantization formats and innovative techniques like speculative decoding. #NVIDIA #AI #MachineLearning #JetsonThor&amp;hellip;</description>
    </item>
    <item>
      <title>Accelerated and Distributed UPF for the Era of Agentic AI and 6G</title>
      <link>/articles/article-2025-10-15-10956/</link>
      <pubDate>Wed, 15 Oct 2025 18:06:57 +0000</pubDate>
      <guid>/articles/article-2025-10-15-10956/</guid>
      <description>The telecommunications sector is rapidly advancing towards 6G, focusing on AI-native Radio Access Networks (AI-RAN) and AI-Core. A key development is the distributed User Plane Function (dUPF), which processes data closer to users, reducing latency and enhancing throughput. üì∂ The article discusses the architectural benefits of dUPF, particularly for agentic AI applications. It showcases a reference implementation using NVIDIA DOCA Flow, which supports energy-efficient, low-latency operations&amp;hellip;</description>
    </item>
    <item>
      <title>Accelerate Qubit Research with NVIDIA cuQuantum Integrations in QuTip and scQubits</title>
      <link>/articles/article-2025-10-14-10913/</link>
      <pubDate>Tue, 14 Oct 2025 19:23:57 +0000</pubDate>
      <guid>/articles/article-2025-10-14-10913/</guid>
      <description>üöÄ NVIDIA cuQuantum is now integrated into QuTip and scQubits, enhancing quantum simulations at both circuit and device levels. This integration allows researchers to design and study novel qubit types more efficiently. With a 4000x speedup on AWS, users can explore complex quantum systems effectively. QuTip and scQubits are now optimized for better performance and scalability, paving the way for future advancements in quantum computing. #QuantumComputing #NVIDIA #QuantumSimulations #QuTip&amp;hellip;</description>
    </item>
    <item>
      <title>Understanding Memory Management on Hardware-Coherent Platforms</title>
      <link>/articles/article-2025-10-14-10901/</link>
      <pubDate>Tue, 14 Oct 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-14-10901/</guid>
      <description>Discover how memory management affects application performance on hardware-coherent platforms. NVIDIA&amp;rsquo;s Coherent Driver-based Memory Management (CDMM) mode offers improved control over GPU memory compared to the default NUMA mode. This allows applications to optimize memory placement for better performance. Learn about the implications for Kubernetes and more in the full article. üíªüöÄ #NVIDIA #MemoryManagement #Kubernetes #TechInsights #PerformanceOptimization</description>
    </item>
    <item>
      <title>Improve Variant Calling Accuracy with NVIDIA Parabricks</title>
      <link>/articles/article-2025-10-14-10891/</link>
      <pubDate>Tue, 14 Oct 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-14-10891/</guid>
      <description>NVIDIA Parabricks is advancing genomic analysis with its scalable software suite designed for data scientists and bioinformaticians. The recent v4.6 update introduces support for Google&amp;rsquo;s DeepVariant and DeepSomatic 1.9, enhancing variant calling accuracy, especially for diverse populations. üåç Key features include pangenome-aware mode for DeepVariant and improved speed‚Äîup to 8x faster with GPUs! üöÄ Understanding genetic differences is crucial for disease research. This update aims to refine&amp;hellip;</description>
    </item>
    <item>
      <title>Building the 800 VDC Ecosystem for Efficient, Scalable AI Factories</title>
      <link>/articles/article-2025-10-13-10869/</link>
      <pubDate>Mon, 13 Oct 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-13-10869/</guid>
      <description>üöÄ The rise of generative AI is transforming data centers into AI factories, with power infrastructure now at the forefront of design. A shift to an 800 VDC power distribution system and integrated energy storage is essential for scalability and efficiency. AI workloads demand higher power and introduce volatility, requiring innovative solutions to manage rapid load swings effectively. #AI #DataCenters #PowerInfrastructure #Innovation #TechTrends</description>
    </item>
    <item>
      <title>Build a Log Analysis Multi-Agent Self-Corrective RAG System with NVIDIA Nemotron</title>
      <link>/articles/article-2025-10-10-10625/</link>
      <pubDate>Fri, 10 Oct 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-10-10625/</guid>
      <description>Unlock the potential of log analysis with NVIDIA&amp;rsquo;s AI-powered solution! üöÄ As applications scale, logs can become overwhelming, making it difficult to identify issues. NVIDIA introduces a log analysis agent that automates log parsing and improves root-cause detection. This solution supports QA teams, engineering, DevOps, CloudOps, and observability managers by unifying log sources and delivering actionable insights. Discover the architecture and components that make this self-corrective,&amp;hellip;</description>
    </item>
    <item>
      <title>NVIDIA Blackwell Leads on SemiAnalysis InferenceMAX‚Ñ¢ v1 Benchmarks</title>
      <link>/articles/article-2025-10-09-10611/</link>
      <pubDate>Thu, 09 Oct 2025 23:33:19 +0000</pubDate>
      <guid>/articles/article-2025-10-09-10611/</guid>
      <description>SemiAnalysis has launched InferenceMAX‚Ñ¢ v1, an open-source initiative for evaluating inference hardware performance. The results show NVIDIA GPUs, particularly the Blackwell model, achieving a 15x performance increase over the previous Hopper generation. This advancement is attributed to innovative hardware-software designs. The AI community is encouraged to utilize InferenceMAX v1 to validate NVIDIA&amp;rsquo;s performance across various inference scenarios. #NVIDIA #AI #InferenceMAX #TechInnovation&amp;hellip;</description>
    </item>
    <item>
      <title>From Assistant to Adversary: Exploiting Agentic AI Developer Tools</title>
      <link>/articles/article-2025-10-09-10584/</link>
      <pubDate>Thu, 09 Oct 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-09-10584/</guid>
      <description>Developers are increasingly using AI tools like OpenAI Codex and GitHub Copilot for coding. While these tools can enhance productivity, they also create new security risks. üõ°Ô∏è These agentic tools leverage LLMs, which can lead to unpredictable actions. Attackers can exploit this through techniques like watering hole attacks, potentially allowing remote code execution. Understanding the role and risks of computer use agents is crucial for maintaining security in development environments. üîçüíª&amp;hellip;</description>
    </item>
    <item>
      <title>Training Federated AI Models to Predict Protein Properties</title>
      <link>/articles/article-2025-10-08-10553/</link>
      <pubDate>Wed, 08 Oct 2025 16:58:05 +0000</pubDate>
      <guid>/articles/article-2025-10-08-10553/</guid>
      <description>Unlocking the mysteries of protein localization is essential for biology and drug discovery. Researchers are now using NVIDIA FLARE and BioNeMo Framework to collaboratively train AI models, enhancing predictions without sharing sensitive data. A new tutorial showcases fine-tuning the ESM-2nv model for subcellular localization, using FASTA formatted files. This approach could lead to breakthroughs in understanding cellular processes and therapeutic targets. üî¨üíªüß¨ #ProteinLocalization&amp;hellip;</description>
    </item>
    <item>
      <title>Pruning and Distilling LLMs Using NVIDIA TensorRT Model Optimizer</title>
      <link>/articles/article-2025-10-07-10507/</link>
      <pubDate>Tue, 07 Oct 2025 17:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-07-10507/</guid>
      <description>Discover how NVIDIA is tackling the challenges of deploying large language models (LLMs) through innovative techniques like model pruning and knowledge distillation. üåü These methods enable the creation of smaller, efficient models while maintaining performance. Pruning removes unnecessary parameters, leading to faster and cost-effective solutions in natural language processing. Learn how to apply these strategies using the NVIDIA TensorRT Model Optimizer. #NVIDIA #MachineLearning&amp;hellip;</description>
    </item>
    <item>
      <title>Speeding Up Data Decompression with nvCOMP and the NVIDIA Blackwell Decompression Engine</title>
      <link>/articles/article-2025-10-06-10452/</link>
      <pubDate>Mon, 06 Oct 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-06-10452/</guid>
      <description>NVIDIA has introduced the Decompression Engine (DE) in its Blackwell architecture to enhance data decompression speed while reducing latency and compute resource usage. üìä Working alongside the nvCOMP library, DE accelerates decompression for popular formats like Snappy and LZ4, optimizing data transfers directly across PCIe or C2C. This innovation allows for better utilization of GPU resources, especially in data-intensive applications. üöÄ Developers are encouraged to use DE via nvCOMP APIs,&amp;hellip;</description>
    </item>
    <item>
      <title>Accelerating Large-Scale Data Analytics with GPU-Native Velox and NVIDIA cuDF</title>
      <link>/articles/article-2025-10-06-10443/</link>
      <pubDate>Mon, 06 Oct 2025 12:00:00 +0000</pubDate>
      <guid>/articles/article-2025-10-06-10443/</guid>
      <description>üöÄ Accelerating data analytics is crucial as workloads grow. GPU-accelerated databases, like those using NVIDIA cuDF and Velox, provide significant performance gains over traditional CPU systems. üîç These advancements enable real-time insights for analysts, supporting complex queries with large datasets. ü§ù IBM and NVIDIA are collaborating to enhance platforms like Presto and Apache Spark, allowing for efficient GPU-native query execution. #DataAnalytics #GPUComputing #NVIDIA #IBM #BigData</description>
    </item>
    <item>
      <title>Smarter Anomaly Detection in Semiconductor Manufacturing with NVIDIA NV-Tesseract and NVIDIA NIM</title>
      <link>/articles/article-2025-10-03-10411/</link>
      <pubDate>Fri, 03 Oct 2025 15:29:00 +0000</pubDate>
      <guid>/articles/article-2025-10-03-10411/</guid>
      <description>üöÄ NVIDIA introduces NV-Tesseract, enhancing anomaly detection in semiconductor manufacturing. This model identifies anomalies in real-time across multiple sensors, shifting from reactive monitoring to proactive insights. With precise localization, fabs can address issues immediately, protecting yield and reducing costs. Explore how this innovation transforms data into actionable solutions! #Semiconductor #AnomalyDetection #NVIDIA #Manufacturing #Innovation</description>
    </item>
    <item>
      <title>Enable Gang Scheduling and Workload Prioritization in Ray with NVIDIA KAI Scheduler</title>
      <link>/articles/article-2025-10-03-10412/</link>
      <pubDate>Fri, 03 Oct 2025 14:22:41 +0000</pubDate>
      <guid>/articles/article-2025-10-03-10412/</guid>
      <description>üöÄ Exciting news for Ray users! NVIDIA KAI Scheduler is now integrated with KubeRay, enhancing your Ray clusters with advanced scheduling features. Key benefits include: üîπ Gang scheduling for coordinated job starts üîπ Autoscaling based on workload demands üîπ Workload prioritization for efficient resource use üîπ Hierarchical queuing for dynamic resource sharing This integration makes resource allocation smarter and more responsive. #NVIDIA #Ray #KubeRay #Scheduler #TechUpdate</description>
    </item>
    <item>
      <title>Practical LLM Security Advice from the NVIDIA AI Red Team</title>
      <link>/articles/article-2025-10-02-10362/</link>
      <pubDate>Thu, 02 Oct 2025 16:52:26 +0000</pubDate>
      <guid>/articles/article-2025-10-02-10362/</guid>
      <description>The NVIDIA AI Red Team (AIRT) has been assessing AI-enabled systems for security vulnerabilities. They identified key risks in LLM-based applications, particularly the danger of executing LLM-generated code without proper isolation. This can lead to remote code execution, exposing applications to potential attacks. Addressing these vulnerabilities during development is crucial for improving security. üîíüíª #AI #CyberSecurity #NVIDIA #LLM #SecurityAwareness</description>
    </item>
    <item>
      <title>Advancing Anomaly Detection for Industry Applications with NVIDIA NV-Tesseract-AD</title>
      <link>/articles/article-2025-09-30-10262/</link>
      <pubDate>Tue, 30 Sep 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-30-10262/</guid>
      <description>üöÄ Exciting advancements in anomaly detection are here with NVIDIA NV-Tesseract-AD! This model enhances the existing NV-Tesseract framework by integrating diffusion modeling and adaptive thresholding, specifically designed for complex, noisy time-series data. Version 2.0 now supports multivariate inputs, improving reliability in real-world applications. Learn more about addressing the challenges of anomaly detection in various industries! #AnomalyDetection #NVIDIA #DataScience #MachineLearning&amp;hellip;</description>
    </item>
    <item>
      <title>How id Software Used Neural Rendering and Path Tracing in DOOM: The Dark Ages</title>
      <link>/articles/article-2025-09-30-10251/</link>
      <pubDate>Tue, 30 Sep 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-30-10251/</guid>
      <description>üöÄ DOOM: The Dark Ages is redefining real-time graphics with RTX neural rendering and path tracing. Billy Khan from id Software explains that path tracing enhances lighting and realism, pushing visual boundaries while maintaining gameplay fluidity. This technique offers superior lighting accuracy and more realistic reflections compared to traditional ray tracing. The team focuses on optimizing GPU performance to ensure scalability across various hardware, making advanced graphics accessible to&amp;hellip;</description>
    </item>
    <item>
      <title>Unlock GPU Performance: Global Memory Access in CUDA</title>
      <link>/articles/article-2025-09-29-10210/</link>
      <pubDate>Mon, 29 Sep 2025 16:16:37 +0000</pubDate>
      <guid>/articles/article-2025-09-29-10210/</guid>
      <description>Managing memory effectively is crucial for optimizing GPU performance in CUDA. Global memory, the main memory space on CUDA devices, can be accessed by both the host and threads within a kernel grid. It is allocated using the &lt;strong&gt;device&lt;/strong&gt; declaration or CUDA runtime APIs like cudaMalloc(). Data transfers between host and device are done using cudaMemcpy(), while memory can be freed with cudaFree(). Future discussions will cover more on global memory complexities. #CUDA #GPU #MemoryManagement&amp;hellip;</description>
    </item>
    <item>
      <title>Streamline Robot Learning with Whole-Body Control and Enhanced Teleoperation in NVIDIA Isaac Lab 2.3</title>
      <link>/articles/article-2025-09-29-10211/</link>
      <pubDate>Mon, 29 Sep 2025 15:12:20 +0000</pubDate>
      <guid>/articles/article-2025-09-29-10211/</guid>
      <description>üöÄ Exciting updates in NVIDIA Isaac Lab 2.3 enhance robot learning! The new version focuses on streamlining robot policy training through a sim-first approach, improving whole-body control, and refining imitation learning for humanoid robots. Teleoperation capabilities have expanded, supporting devices like Meta Quest VR for data collection. New features aid dexterous manipulation tasks and reinforce scaling for reinforcement learning. Explore the advancements in robot technology! ü§ñ‚ú® #NVIDIA&amp;hellip;</description>
    </item>
    <item>
      <title>Train a Quadruped Locomotion Policy and Simulate Cloth Manipulation with NVIDIA Isaac Lab and Newton</title>
      <link>/articles/article-2025-09-29-10212/</link>
      <pubDate>Mon, 29 Sep 2025 15:11:31 +0000</pubDate>
      <guid>/articles/article-2025-09-29-10212/</guid>
      <description>Discover how physics enhances robotic simulation in the latest article on training a quadruped locomotion policy and simulating cloth manipulation using NVIDIA Isaac Lab and Newton. ü§ñ‚ú® The article explains the importance of accurate simulations for developing and testing robotic algorithms while addressing the challenges of the sim-to-real gap. Learn about Newton, an open-source physics engine that supports complex tasks and integrates with various robot learning frameworks. #Robotics&amp;hellip;</description>
    </item>
    <item>
      <title>3 Easy Ways to Supercharge Your Robotics Development Using OpenUSD</title>
      <link>/articles/article-2025-09-29-10214/</link>
      <pubDate>Mon, 29 Sep 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-29-10214/</guid>
      <description>üöÄ The demand for robotics is rising, highlighting the importance of physics-accurate simulation. OpenUSD is central to this evolution, providing a standard for creating virtual environments where robots can learn. Key points from the article include: 1. &lt;strong&gt;Data Ingestion&lt;/strong&gt;: Unifying CAD, URDF, and sensor data for effective simulation. 2. &lt;strong&gt;Data Aggregation&lt;/strong&gt;: Building expansive virtual worlds with OpenUSD to enhance training scenarios. 3. &lt;strong&gt;SimReady&lt;/strong&gt;: Streamlining robotics pipelines with&amp;hellip;</description>
    </item>
    <item>
      <title>Advancing Robotics Development with Neural Dynamics in Newton</title>
      <link>/articles/article-2025-09-29-10215/</link>
      <pubDate>Mon, 29 Sep 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-29-10215/</guid>
      <description>üåü Modern robotics is evolving with the introduction of Neural Robot Dynamics (NeRD). NeRD addresses limitations of classical dynamics by offering models that predict stable states and capture complex physics. It can generalize across various tasks and environments, bridging the gap between simulation and real-world applications. As a drop-in backend for physics engines like Newton, NeRD allows teams to enhance their existing frameworks easily. This innovation paves the way for continuous&amp;hellip;</description>
    </item>
    <item>
      <title>Smart Multi-Node Scheduling for Fast and Efficient LLM Inference with NVIDIA Run:ai and NVIDIA Dynamo</title>
      <link>/articles/article-2025-09-29-10213/</link>
      <pubDate>Mon, 29 Sep 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-29-10213/</guid>
      <description>üöÄ The rise of large language models brings new challenges in GPU capacity and workload efficiency. NVIDIA&amp;rsquo;s Run:ai v2.23 integrates with Dynamo to tackle these issues, enhancing distributed AI model inference. Key features include dynamic GPU scheduling and advanced request routing. Learn how to optimize your deployments with a step-by-step guide on setting up Dynamo. #AI #NVIDIA #Dynamo #MachineLearning #TechUpdates</description>
    </item>
    <item>
      <title>Upcoming Digital Event: Open Accelerated Computing Summit</title>
      <link>/articles/article-2025-09-28-10190/</link>
      <pubDate>Sun, 28 Sep 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-28-10190/</guid>
      <description>üåê Join the Open Accelerated Computing Summit on October 7-8! This digital event will explore new research at the intersection of AI and High-Performance Computing (HPC). Don&amp;rsquo;t miss this opportunity to gain insights and connect with experts in the field! üîó Sign up now: &lt;a href=&#34;https://zoom.us/signup&#34;&gt;Zoom Signup&lt;/a&gt; #OACSummit #AI #HPC #DigitalEvent #Research</description>
    </item>
    <item>
      <title>Why CVEs Belong in Frameworks and Apps, Not AI Models</title>
      <link>/articles/article-2025-09-26-10153/</link>
      <pubDate>Fri, 26 Sep 2025 16:31:23 +0000</pubDate>
      <guid>/articles/article-2025-09-26-10153/</guid>
      <description>The Common Vulnerabilities and Exposures (CVE) system catalogs software security flaws globally. As AI models integrate into enterprise systems, discussions arise about their inclusion in CVEs. However, vulnerabilities often reside in the frameworks and applications using AI models, not the models themselves. Issues like insecure session handling or supply chain risks are better addressed outside the CVE system. It&amp;rsquo;s essential to focus on the surrounding code for identifying and mitigating&amp;hellip;</description>
    </item>
    <item>
      <title>Just Released: NVIDIA HPC SDK v25.9</title>
      <link>/articles/article-2025-09-25-10114/</link>
      <pubDate>Thu, 25 Sep 2025 22:36:39 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10114/</guid>
      <description>üöÄ Just announced: NVIDIA has released the HPC SDK v25.9! This update brings support for CUDA 13.0, along with various updated library components, bug fixes, and performance enhancements. Download options are available for different target platforms. Make sure to review the installation instructions carefully! #NVIDIA #HPCSDK #CUDA #TechNews #SoftwareUpdate</description>
    </item>
    <item>
      <title>R¬≤D¬≤: Three Neural Breakthroughs Transforming Robot Learning from NVIDIA Research</title>
      <link>/articles/article-2025-09-25-10106/</link>
      <pubDate>Thu, 25 Sep 2025 18:47:35 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10106/</guid>
      <description>üåê Exciting advancements in robot learning are highlighted in NVIDIA&amp;rsquo;s R¬≤D¬≤ edition. Today‚Äôs robots excel in controlled environments but face challenges with real-world unpredictability and dexterity. Traditional approaches are limited, struggling with complex dynamics and translating human demonstrations. NVIDIA introduces three neural innovations: 1Ô∏è‚É£ &lt;strong&gt;NeRD&lt;/strong&gt;: Enhances simulation with learned dynamics for better task generalization. 2Ô∏è‚É£ &lt;strong&gt;Dexplore&lt;/strong&gt;: Achieves human-level dexterity using&amp;hellip;</description>
    </item>
    <item>
      <title>How to Integrate Computer Vision Pipelines with Generative AI and Reasoning</title>
      <link>/articles/article-2025-09-25-10077/</link>
      <pubDate>Thu, 25 Sep 2025 16:42:53 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10077/</guid>
      <description>üöÄ Generative AI is transforming video analytics, moving beyond simple object counting to real-time insights from video streams. üîç The NVIDIA AI Blueprint for Video Search and Summarization (VSS) integrates advanced technologies, enhancing video understanding for both stored and live content. üìà The recent VSS Blueprint 2.4 update includes major enhancements such as: 1. Improved physical world understanding with NVIDIA Cosmos Reason. 2. Enhanced Q&amp;amp;A capabilities with cross-camera support. 3&amp;hellip;.</description>
    </item>
    <item>
      <title>How to GPU-Accelerate Model Training with CUDA-X Data Science</title>
      <link>/articles/article-2025-09-25-10078/</link>
      <pubDate>Thu, 25 Sep 2025 16:30:00 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10078/</guid>
      <description>Unlock the potential of machine learning in manufacturing with GPU-accelerated model training! üöÄ This article discusses best practices for training models on structured manufacturing data. Tree-based models, like XGBoost, LightGBM, and CatBoost, are highlighted for their performance and interpretability. üìä Using GPU acceleration can significantly enhance training workflows, allowing for rapid iteration on hyperparameters. Explore how these methods can lead to improved yields and actionable&amp;hellip;</description>
    </item>
    <item>
      <title>NVIDIA Open Sources Audio2Face Animation Model</title>
      <link>/articles/article-2025-09-24-9985/</link>
      <pubDate>Wed, 24 Sep 2025 17:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-24-9985/</guid>
      <description>NVIDIA has announced the open sourcing of its Audio2Face technology, aimed at enhancing the creation of lifelike 3D avatars. üéÆü§ñ This innovation utilizes generative AI to animate characters&amp;rsquo; faces in real-time based on audio input, ensuring realistic lip-sync and emotional expressions. üìäüé§ The technology can be applied in various fields, from gaming to customer service, making interactions more engaging. #NVIDIA #Audio2Face #GenerativeAI #3DAnimation #TechInnovation</description>
    </item>
    <item>
      <title>Deploy High-Performance AI Models in Windows Applications on NVIDIA RTX AI PCs</title>
      <link>/articles/article-2025-09-23-9930/</link>
      <pubDate>Tue, 23 Sep 2025 19:20:46 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9930/</guid>
      <description>üöÄ Microsoft has launched Windows ML for developers, enabling C#, C++, and Python programmers to efficiently run AI models on PCs. üñ•Ô∏è This tool supports various hardware types, including CPU, NPU, and GPUs. On NVIDIA RTX GPUs, it leverages TensorRT for optimal AI inference performance. üìä Windows ML simplifies dependency management and helps developers build scalable AI applications seamlessly. #Microsoft #WindowsML #AI #NVIDIA #DeveloperTools</description>
    </item>
    <item>
      <title>Faster Training Throughput in FP8 Precision with NVIDIA NeMo</title>
      <link>/articles/article-2025-09-23-9931/</link>
      <pubDate>Tue, 23 Sep 2025 16:36:21 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9931/</guid>
      <description>Unlocking faster training throughput in FP8 precision with NVIDIA NeMo is the focus of the latest insights. üöÄ The article discusses the benefits of FP8 training, emphasizing real-world speed improvements and potential overheads. It compares various FP8 scaling recipes using NVIDIA GPUs, assessing efficiency, stability, and scalability across large models. Reducing numerical precision to 8 bits enhances computational efficiency, lowers costs, and diminishes communication overhead in&amp;hellip;</description>
    </item>
    <item>
      <title>How to Accelerate Community Detection in Python Using GPU-Powered Leiden</title>
      <link>/articles/article-2025-09-23-9932/</link>
      <pubDate>Tue, 23 Sep 2025 16:30:00 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9932/</guid>
      <description>üöÄ Community detection algorithms are vital for uncovering hidden relationships in networks. The Leiden algorithm, a popular choice among data scientists, offers improved performance for large-scale graphs in Python. üñ•Ô∏è With GPU acceleration from cuGraph, Leiden can be up to 47x faster than traditional CPU methods, making it suitable for real-world applications across various fields, including social network analysis, recommendation systems, and genomics. üîç This article explores Leiden&amp;rsquo;s&amp;hellip;</description>
    </item>
    <item>
      <title>Build a Real-Time Visual Inspection Pipeline with NVIDIA TAO 6 and NVIDIA DeepStream 8</title>
      <link>/articles/article-2025-09-23-9933/</link>
      <pubDate>Tue, 23 Sep 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9933/</guid>
      <description>üöÄ Building a visual inspection pipeline for defect detection can be challenging. Manufacturers often struggle with model customization, optimization for edge devices, and real-time deployment. NVIDIA Metropolis offers solutions through its tools like TAO 6 for fine-tuning models and DeepStream 8 for streaming analytics. These resources help streamline the entire process. üìä Learn how to effectively implement these technologies to enhance quality control in your workflows. #NVIDIA #AI&amp;hellip;</description>
    </item>
    <item>
      <title>Reasoning Through Molecular Synthetic Pathways with Generative AI</title>
      <link>/articles/article-2025-09-23-9934/</link>
      <pubDate>Tue, 23 Sep 2025 15:30:00 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9934/</guid>
      <description>üåç In molecular design, synthesizing viable molecules is a major challenge. Assessing synthesizability often involves mapping complex synthesis pathways. üî¨ NVIDIA&amp;rsquo;s ReaSyn model addresses this by predicting molecular synthesis pathways using a novel approach that combines chain-of-thought reasoning with test-time search methods. üß™ This framework treats synthetic pathways as sequences of reactions, helping chemists deduce effective routes to valuable target molecules. #MolecularDesign&amp;hellip;</description>
    </item>
    <item>
      <title>Build a Retrieval-Augmented Generation (RAG) Agent with NVIDIA Nemotron</title>
      <link>/articles/article-2025-09-23-9935/</link>
      <pubDate>Tue, 23 Sep 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9935/</guid>
      <description>Discover how to build a Retrieval-Augmented Generation (RAG) agent using NVIDIA Nemotron! This self-paced workshop covers the principles of agentic RAG, enabling systems to make decisions and adapt effectively. You&amp;rsquo;ll learn to create your customized RAG system with LangGraph and access a portable development environment. Join the journey towards advanced text generation! üöÄüíª #NVIDIA #RAG #AI #MachineLearning #TechWorkshop</description>
    </item>
    <item>
      <title>Predict Extreme Weather Events in Minutes Without a Supercomputer</title>
      <link>/articles/article-2025-09-19-9832/</link>
      <pubDate>Fri, 19 Sep 2025 19:19:10 +0000</pubDate>
      <guid>/articles/article-2025-09-19-9832/</guid>
      <description>üåßÔ∏è Scientists from NVIDIA and Lawrence Berkeley National Laboratory have launched a new machine learning tool called Huge Ensembles (HENS) for predicting extreme weather events. This tool delivers supercomputer-level forecasts with lower computational costs. HENS can predict high-impact weather events, offering forecasts from 6 hours up to 14 days ahead. ‚è±Ô∏è Utilizing 40 years of climate data, HENS can analyze vast amounts of weather patterns quickly, aiming to assist climate scientists and&amp;hellip;</description>
    </item>
    <item>
      <title>NVIDIA HGX B200 Reduces Embodied Carbon Emissions Intensity</title>
      <link>/articles/article-2025-09-19-9827/</link>
      <pubDate>Fri, 19 Sep 2025 16:30:00 +0000</pubDate>
      <guid>/articles/article-2025-09-19-9827/</guid>
      <description>üöÄ NVIDIA has unveiled the HGX B200, a game-changer in accelerated computing. This new platform shows a 24% reduction in embodied carbon emissions compared to its predecessor, the HGX H100. It achieves this through enhanced AI performance and energy efficiency. üå± With upgraded Blackwell B200 GPUs and significant memory improvements, the HGX B200 offers faster throughput and lower energy use for AI workloads. For more insights, check the latest product carbon footprint data! #NVIDIA&amp;hellip;</description>
    </item>
    <item>
      <title>The Kaggle Grandmasters Playbook: 7 Battle-Tested Modeling Techniques for Tabular Data</title>
      <link>/articles/article-2025-09-18-9781/</link>
      <pubDate>Thu, 18 Sep 2025 17:29:36 +0000</pubDate>
      <guid>/articles/article-2025-09-18-9781/</guid>
      <description>Unlock the secrets of Kaggle competitions with the &amp;ldquo;Kaggle Grandmasters Playbook&amp;rdquo;! üìä‚ú® This playbook outlines 7 proven techniques for tackling tabular data challenges, emphasizing fast experimentation and robust validation. By leveraging GPU acceleration, you can enhance your modeling process effectively. Key highlights include: - &lt;strong&gt;Fast Experimentation:&lt;/strong&gt; Optimize your pipeline for speed to uncover patterns quickly. - &lt;strong&gt;Local Validation:&lt;/strong&gt; Use k-fold cross-validation for reliable performance&amp;hellip;</description>
    </item>
    <item>
      <title>How to Reduce KV Cache Bottlenecks with NVIDIA Dynamo</title>
      <link>/articles/article-2025-09-18-9782/</link>
      <pubDate>Thu, 18 Sep 2025 16:30:00 +0000</pubDate>
      <guid>/articles/article-2025-09-18-9782/</guid>
      <description>As AI models expand, managing inference has become a significant challenge due to the Key-Value (KV) Cache requirements. üß† The KV Cache stores crucial attention data but grows with prompt length, leading to bottlenecks in GPU memory. This can affect performance and increase costs. üí∞ NVIDIA Dynamo&amp;rsquo;s latest release addresses this by offloading the KV Cache to more affordable storage, enabling faster access without disrupting inference. ‚ö° Explore how these optimizations can enhance user&amp;hellip;</description>
    </item>
    <item>
      <title>NVIDIA RAPIDS 25.08 Adds New Profiler for cuML, Updates to the Polars GPU Engine, Additional Algorithm Support, and More</title>
      <link>/articles/article-2025-09-17-9752/</link>
      <pubDate>Wed, 17 Sep 2025 22:29:09 +0000</pubDate>
      <guid>/articles/article-2025-09-17-9752/</guid>
      <description>üöÄ The latest RAPIDS 25.08 release enhances data science accessibility with several new features. üîç Two profiling tools for cuML have been added to help troubleshoot code performance. Users can now track GPU vs. CPU operations and their execution times. üìä Additionally, the Polars GPU engine now supports larger datasets, and new algorithms have been incorporated into cuML and cuml.accel. Learn more about these updates! #DataScience #NVIDIA #RAPIDS #MachineLearning #GPU</description>
    </item>
    <item>
      <title>An Introduction to Speculative Decoding for Reducing Latency in AI Inference</title>
      <link>/articles/article-2025-09-17-9746/</link>
      <pubDate>Wed, 17 Sep 2025 18:09:12 +0000</pubDate>
      <guid>/articles/article-2025-09-17-9746/</guid>
      <description>üöÄ Speculative decoding is a key technique for reducing latency in AI inference with large language models (LLMs). It addresses the bottleneck caused by the sequential nature of autoregressive generation, which can lead to underutilization of GPU power. By predicting multiple tokens at once, it enhances efficiency without sacrificing output quality. This method pairs a target model with a lightweight draft mechanism to speed up text generation, making AI systems more responsive. Explore how&amp;hellip;</description>
    </item>
    <item>
      <title>Just Released: Warp 1.9</title>
      <link>/articles/article-2025-09-16-9709/</link>
      <pubDate>Tue, 16 Sep 2025 20:51:02 +0000</pubDate>
      <guid>/articles/article-2025-09-16-9709/</guid>
      <description>üöÄ Just released: Warp 1.9! This update brings support for CUDA 13.0, enhancing compatibility and performance. Additionally, new functions for the ahead-of-time compilation module have been introduced, broadening development capabilities. Stay tuned for more updates! üîßüíª #Warp19 #CUDA #NVIDIA #TechUpdate #Programming</description>
    </item>
    <item>
      <title>Reducing Cold Start Latency for LLM Inference with NVIDIA Run:ai Model Streamer</title>
      <link>/articles/article-2025-09-16-9702/</link>
      <pubDate>Tue, 16 Sep 2025 17:35:13 +0000</pubDate>
      <guid>/articles/article-2025-09-16-9702/</guid>
      <description>üöÄ Deploying large language models (LLMs) can be challenging due to cold start delays, which hinder performance and scalability. üñ•Ô∏è The article discusses the NVIDIA Run:ai Model Streamer, an open-source SDK that reduces loading times by concurrently streaming model weights into GPU memory. üìä Benchmark tests show significant improvements in cold start latency, especially in cloud environments, while maintaining compatibility with Safetensor formats. #AI #MachineLearning #NVIDIA #Inference&amp;hellip;</description>
    </item>
    <item>
      <title>What‚Äôs New in PyNvVideoCodec 2.0 for Python GPU-Accelerated Video Processing</title>
      <link>/articles/article-2025-09-16-9703/</link>
      <pubDate>Tue, 16 Sep 2025 17:32:46 +0000</pubDate>
      <guid>/articles/article-2025-09-16-9703/</guid>
      <description>üöÄ Exciting news for video processing developers! PyNvVideoCodec 2.0 is an upgraded NVIDIA library for GPU-accelerated video encoding, decoding, and transcoding using Python. This lightweight, easy-to-install library offers performance on par with the native SDK. It supports projects in video analytics, AI preprocessing, media transcoding, and real-time streaming, combining the speed of C++ with the ease of Python. Discover the enhanced features and performance improvements in this latest&amp;hellip;</description>
    </item>
    <item>
      <title>Autodesk Research Brings Warp Speed to Computational Fluid Dynamics on NVIDIA GH200</title>
      <link>/articles/article-2025-09-16-9692/</link>
      <pubDate>Tue, 16 Sep 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-16-9692/</guid>
      <description>üöÄ Autodesk Research has made strides in computational fluid dynamics (CFD) with its Accelerated Lattice Boltzmann (XLB) library. This open-source solver bridges the gap between traditional CAE and AI/ML ecosystems. By leveraging NVIDIA Warp and the GH200 Superchip, XLB achieves an ~8x speedup in performance, allowing for high-fidelity simulations at scale. This advancement demonstrates the potential of Python in high-performance scenarios. #CFD #AutodeskResearch #NVIDIAWarp&amp;hellip;</description>
    </item>
    <item>
      <title>Build a Report Generator AI Agent with NVIDIA Nemotron on OpenRouter</title>
      <link>/articles/article-2025-09-15-9664/</link>
      <pubDate>Mon, 15 Sep 2025 19:31:45 +0000</pubDate>
      <guid>/articles/article-2025-09-15-9664/</guid>
      <description>üöÄ Discover how to build an AI report generator with NVIDIA Nemotron! This self-paced workshop covers essential topics including the four core considerations for AI agents, creating a document generation agent, and utilizing LangGraph and OpenRouter. Participants will have access to a portable development environment and can share their customized agents as NVIDIA Launchables. #AI #NVIDIA #MachineLearning #OpenSource #TechWorkshop</description>
    </item>
    <item>
      <title>New Open Source Qwen3-Next Models Preview Hybrid MoE Architecture Delivering Improved Accuracy and Accelerated Parallel Processing across NVIDIA Platform</title>
      <link>/articles/article-2025-09-15-9643/</link>
      <pubDate>Mon, 15 Sep 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-15-9643/</guid>
      <description>üöÄ Alibaba has unveiled two new open-source models: Qwen3-Next 80B-A3B-Thinking and Qwen3-Next 80B-A3B-Instruct. These models feature a hybrid Mixture of Experts (MoE) architecture designed for improved efficiency and accuracy. üîç The Qwen3-Next-80B-A3B-Thinking model is now available on build.nvidia.com, allowing developers to explore its advanced reasoning capabilities. üí° With 80 billion parameters, only a fraction is activated per token, optimizing processing for longer context lengths. The&amp;hellip;</description>
    </item>
    <item>
      <title>Modeling Attacks on AI-Powered Apps with the AI Kill Chain Framework</title>
      <link>/articles/article-2025-09-11-9552/</link>
      <pubDate>Thu, 11 Sep 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-11-9552/</guid>
      <description>AI-powered applications are facing new security challenges that traditional models may not address. The AI Kill Chain framework, developed by NVIDIA, outlines how adversaries target these systems. This framework emphasizes the stages of an attack: recon, poison, hijack, persist, and impact. It aims to help defenders identify where they can intervene effectively. Learn more about the evolving landscape of AI security! üîêüíªüõ°Ô∏è #AI #CyberSecurity #NVIDIA #AIKillChain #TechTrends</description>
    </item>
    <item>
      <title>How Quantization Aware Training Enables Low-Precision Accuracy Recovery</title>
      <link>/articles/article-2025-09-11-9553/</link>
      <pubDate>Thu, 11 Sep 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-11-9553/</guid>
      <description>Optimizing AI models for deployment involves various compression techniques. Post-training quantization (PTQ) is common, but quantization aware training (QAT) and quantization aware distillation (QAD) provide significant advantages. These methods prepare models for lower precision by simulating quantization effects, enhancing accuracy recovery. Learn more about these techniques and their impact on model performance! üìäü§ñ #AI #Quantization #MachineLearning #ModelOptimization #TechTrends</description>
    </item>
    <item>
      <title>Accelerate Protein Structure Inference Over 100x with NVIDIA RTX PRO 6000 Blackwell Server Edition</title>
      <link>/articles/article-2025-09-10-9519/</link>
      <pubDate>Wed, 10 Sep 2025 16:48:18 +0000</pubDate>
      <guid>/articles/article-2025-09-10-9519/</guid>
      <description>Unlocking the future of protein structure analysis is now possible with the NVIDIA RTX PRO 6000 Blackwell Server Edition. This new GPU significantly accelerates protein structure inference, enhancing research efficiency and reducing costs for organizations. üß¨üíª With advancements from NVIDIA&amp;rsquo;s Digital Biology Research labs, researchers can now utilize OpenFold for rapid analysis without sacrificing accuracy compared to AlphaFold2. Discover how this technology can transform large-scale protein&amp;hellip;</description>
    </item>
    <item>
      <title>Deploy Scalable AI Inference with NVIDIA NIM Operator 3.0.0</title>
      <link>/articles/article-2025-09-10-9520/</link>
      <pubDate>Wed, 10 Sep 2025 16:30:00 +0000</pubDate>
      <guid>/articles/article-2025-09-10-9520/</guid>
      <description>Unlock the potential of AI with NVIDIA NIM Operator 3.0.0! üöÄ This latest release enhances the deployment of NVIDIA NIM and NeMo microservices in Kubernetes environments, making it easier to manage complex AI inference pipelines. Key features include efficient resource utilization and seamless integration with existing infrastructures, including KServe. ü§ñ Collaboration with Red Hat further streamlines NIM deployment, supporting model caching and trusted AI capabilities. #NVIDIA #AI #Kubernetes&amp;hellip;</description>
    </item>
    <item>
      <title>Developers Can Now Get CUDA Directly from Their Favorite Third-Party Platforms</title>
      <link>/articles/article-2025-09-10-9522/</link>
      <pubDate>Wed, 10 Sep 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-10-9522/</guid>
      <description>üöÄ Developers can now access CUDA directly through popular third-party platforms, making application deployment easier. NVIDIA is collaborating with Canonical, CIQ, and others to simplify installation and maintain compatibility across various OS and package managers. This initiative helps streamline the integration of GPU support in applications like PyTorch and OpenCV. Key benefits include consistent CUDA naming, timely updates, and continued free access to CUDA. #NVIDIA #CUDA #DeveloperTools&amp;hellip;</description>
    </item>
    <item>
      <title>Maximizing Low-Latency Networking Performance for Financial Services with NVIDIA Rivermax and NEIO FastSocket</title>
      <link>/articles/article-2025-09-10-9521/</link>
      <pubDate>Wed, 10 Sep 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-10-9521/</guid>
      <description>Ultra-low latency and reliable packet delivery are essential in sectors like financial services, cloud gaming, and media. Delays or packet losses can lead to significant issues, including financial losses and poor user experiences. NVIDIA Rivermax offers a high-performance solution for these challenges. It utilizes GPU-accelerated technologies to ensure high throughput, low latency, and minimal CPU usage, making it ideal for demanding applications. Learn more about how Rivermax is&amp;hellip;</description>
    </item>
    <item>
      <title>How to Connect Distributed Data Centers Into Large AI Factories with Scale-Across Networking</title>
      <link>/articles/article-2025-09-09-9465/</link>
      <pubDate>Tue, 09 Sep 2025 17:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9465/</guid>
      <description>AI scaling faces challenges due to physical limitations in data centers, such as power and cooling capacity. üåê Traditional long-haul Ethernet solutions can lead to high latency and unpredictable data delivery, which is problematic for AI workloads. NVIDIA&amp;rsquo;s Spectrum-XGS Ethernet technology introduces scale-across networking, allowing multiple data centers to function as one large AI factory, enhancing performance for training and inference tasks. üöÄ #ArtificialIntelligence #DataCenters&amp;hellip;</description>
    </item>
    <item>
      <title>NVIDIA Blackwell Ultra Sets New Inference Records in MLPerf Debut</title>
      <link>/articles/article-2025-09-09-9466/</link>
      <pubDate>Tue, 09 Sep 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9466/</guid>
      <description>üöÄ NVIDIA&amp;rsquo;s Blackwell Ultra architecture has made a significant impact in the latest MLPerf Inference v5.1 benchmarks. New models like DeepSeek-R1 and Llama 3.1 have set high performance standards, with impressive token processing speeds. The benchmarks highlight the growing need for advanced compute power as large language models evolve. NVIDIA continues to lead with record-breaking results across all tested scenarios. #NVIDIA #MLPerf #AI #MachineLearning #TechNews</description>
    </item>
    <item>
      <title>NVIDIA Rubin CPX Accelerates Inference Performance and Efficiency for 1M&#43; Token Context Workloads</title>
      <link>/articles/article-2025-09-09-9467/</link>
      <pubDate>Tue, 09 Sep 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9467/</guid>
      <description>NVIDIA is addressing the increasing complexity of AI inference with its new Rubin CPX GPU. This technology supports workloads requiring extensive context, like software development and long-form video generation. The NVIDIA SMART framework optimizes inference across various dimensions, allowing for better resource allocation. This disaggregated approach separates the context and generation phases, improving efficiency and reducing latency. Discover how NVIDIA is redefining AI infrastructure&amp;hellip;.</description>
    </item>
    <item>
      <title>How to Build AI Systems In House with Outerbounds and DGX Cloud Lepton</title>
      <link>/articles/article-2025-09-08-9430/</link>
      <pubDate>Mon, 08 Sep 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-08-9430/</guid>
      <description>Building production-grade AI systems involves managing numerous components. Companies are increasingly opting to develop in-house solutions for better security and compliance. Outerbounds offers a cloud-native platform that simplifies this process, utilizing open-source Metaflow for efficient orchestration. Key to success is leveraging NVIDIA DGX Cloud Lepton for GPU access, enabling scalable AI operations. Explore how to create customized AI products while navigating the complex GPU cloud&amp;hellip;</description>
    </item>
    <item>
      <title>Register for the Global Webinar: How to Prepare for NVIDIA Generative AI Certification</title>
      <link>/articles/article-2025-09-07-8227/</link>
      <pubDate>Sun, 07 Sep 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-07-8227/</guid>
      <description>üåç Join the global webinar on October 7 to learn how to prepare for the NVIDIA Generative AI Certification exams. Get insights into the new professional level certification and tips for success. Don&amp;rsquo;t miss this opportunity to enhance your skills! #NVIDIA #GenerativeAI #Webinar #Certification #ProfessionalDevelopment</description>
    </item>
    <item>
      <title>Just Released: NVIDIA PhysicsNeMo 25.08</title>
      <link>/articles/article-2025-09-05-7789/</link>
      <pubDate>Fri, 05 Sep 2025 17:37:49 +0000</pubDate>
      <guid>/articles/article-2025-09-05-7789/</guid>
      <description>üöÄ Exciting news from NVIDIA! The latest release of PhysicsNeMo 25.08 introduces powerful workflows and recipes specifically designed for CAE application developers. This update aims to enhance simulations and streamline development processes. Explore the new features and boost your CAE projects with NVIDIA&amp;rsquo;s advanced tools! #NVIDIA #PhysicsNeMo #CAE #TechUpdates #Simulation</description>
    </item>
    <item>
      <title>Just Released: NVIDIA PhysicsNeMo 25.08</title>
      <link>/articles/article-2025-09-05-8228/</link>
      <pubDate>Fri, 05 Sep 2025 17:37:49 +0000</pubDate>
      <guid>/articles/article-2025-09-05-8228/</guid>
      <description>üöÄ Exciting news for CAE developers! NVIDIA has just launched PhysicsNeMo 25.08, introducing new workflows and recipes designed to enhance application development. This update aims to streamline processes and improve efficiency in computational physics. Stay tuned for more advancements in simulation technology! #NVIDIA #PhysicsNeMo #CAE #TechUpdate #Simulation</description>
    </item>
    <item>
      <title>Accelerate Large-Scale LLM Inference and KV Cache Offload with CPU-GPU Memory Sharing</title>
      <link>/articles/article-2025-09-05-7790/</link>
      <pubDate>Fri, 05 Sep 2025 17:24:06 +0000</pubDate>
      <guid>/articles/article-2025-09-05-7790/</guid>
      <description>Large Language Models (LLMs) like Llama 3 70B and Llama 4 Scout 109B are pushing AI boundaries but pose memory challenges for inference efficiency. These models can require significant memory, with Llama 3 needing around 140 GB and Llama 4 about 218 GB. The key-value (KV) cache also demands additional memory as context and batch sizes increase. NVIDIA&amp;rsquo;s Grace Hopper and Blackwell architectures use NVLink-C2C, allowing CPU-GPU memory sharing. This innovation enhances data access and&amp;hellip;</description>
    </item>
    <item>
      <title>Accelerate Large-Scale LLM Inference and KV Cache Offload with CPU-GPU Memory Sharing</title>
      <link>/articles/article-2025-09-05-7826/</link>
      <pubDate>Fri, 05 Sep 2025 17:24:06 +0000</pubDate>
      <guid>/articles/article-2025-09-05-7826/</guid>
      <description>Large Language Models (LLMs) like Llama 3 70B and Llama 4 Scout 109B face challenges with inference due to their size. These models can require significant memory, often exceeding GPU limits, especially with large context windows. The NVIDIA Grace architectures address this by utilizing NVLink C2C, allowing CPU and GPU to share memory efficiently. This setup enhances the processing of large datasets and enables quicker access, minimizing the risk of out-of-memory errors during inference&amp;hellip;.</description>
    </item>
    <item>
      <title>Accelerate Large-Scale LLM Inference and KV Cache Offload with CPU-GPU Memory Sharing</title>
      <link>/articles/article-2025-09-05-8229/</link>
      <pubDate>Fri, 05 Sep 2025 17:24:06 +0000</pubDate>
      <guid>/articles/article-2025-09-05-8229/</guid>
      <description>Large Language Models (LLMs) like Llama 3 and Llama 4 are pushing AI boundaries, but their size poses challenges for inference efficiency. These models can require substantial GPU memory, often leading to out-of-memory errors during inference. The NVIDIA Grace architectures address this with NVLink C2C, offering a high-bandwidth connection that shares CPU and GPU memory. This innovation enhances processing capabilities, making it easier to handle large datasets and models. #AI #NVIDIA&amp;hellip;</description>
    </item>
    <item>
      <title>Accelerate Autonomous Vehicle Development with the NVIDIA DRIVE AGX Thor Developer Kit</title>
      <link>/articles/article-2025-09-03-7682/</link>
      <pubDate>Wed, 03 Sep 2025 17:30:00 +0000</pubDate>
      <guid>/articles/article-2025-09-03-7682/</guid>
      <description>üöóüîç The NVIDIA DRIVE AGX Thor Developer Kit is now available, enhancing the development of autonomous vehicle technology. This platform supports advanced AI models for better perception and decision-making, enabling a comprehensive in-vehicle experience. With powerful Blackwell GPUs and next-gen Arm CPUs, it meets high safety and security standards. The DRIVE AGX Thor is designed to empower automotive OEMs and developers in scaling performance and efficiency for future demands. #NVIDIA&amp;hellip;</description>
    </item>
    <item>
      <title>How to Run AI-Powered CAE Simulations</title>
      <link>/articles/article-2025-09-03-7683/</link>
      <pubDate>Wed, 03 Sep 2025 16:09:47 +0000</pubDate>
      <guid>/articles/article-2025-09-03-7683/</guid>
      <description>üöÄ In modern engineering, accelerated simulations are crucial for innovation. Computer-aided engineering (CAE) helps design reliable products by verifying performance and safety. Traditional simulations take time, often hindering exploration of design options. Physics-based AI models serve as surrogates, predicting outcomes in seconds or minutes, thus enhancing the design process. This article outlines a modular workflow for automotive aerodynamics, leveraging NVIDIA technologies. It covers&amp;hellip;</description>
    </item>
    <item>
      <title>North‚ÄìSouth Networks: The Key to Faster Enterprise AI Workloads</title>
      <link>/articles/article-2025-09-03-7684/</link>
      <pubDate>Wed, 03 Sep 2025 15:04:24 +0000</pubDate>
      <guid>/articles/article-2025-09-03-7684/</guid>
      <description>In the realm of AI infrastructure, data movement is crucial for performance. As enterprises adopt advanced AI systems, they face challenges in quickly and reliably moving data. NVIDIA‚Äôs Enterprise Reference Architectures (RAs) provide guidance on optimizing north-south networks, essential for tasks like model loading and inference queries. By utilizing NVIDIA Spectrum-X Ethernet, organizations can enhance data flow, particularly for data-intensive AI applications. Legacy networks often&amp;hellip;</description>
    </item>
    <item>
      <title>Cut Model Deployment Costs While Keeping Performance With GPU Memory Swap</title>
      <link>/articles/article-2025-09-02-7629/</link>
      <pubDate>Tue, 02 Sep 2025 18:44:27 +0000</pubDate>
      <guid>/articles/article-2025-09-02-7629/</guid>
      <description>Deploying large language models (LLMs) at scale involves balancing fast responsiveness and GPU costs. Organizations often face tough choices: over-provisioning GPUs or risking user experience with latency spikes. NVIDIA&amp;rsquo;s GPU memory swap, or model hot-swapping, offers a solution. This innovation allows multiple models to share GPUs, dynamically offloading inactive models to CPU memory, enabling rapid activation when needed. Benchmark tests show promising results with lower costs and improved&amp;hellip;</description>
    </item>
    <item>
      <title>Improving GEMM Kernel Auto-Tuning Efficiency on NVIDIA GPUs with Heuristics and CUTLASS 4.2</title>
      <link>/articles/article-2025-09-02-7630/</link>
      <pubDate>Tue, 02 Sep 2025 17:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-02-7630/</guid>
      <description>üöÄ Selecting the optimal GEMM kernel for specific hardware is challenging due to the many performance-determining parameters. NVIDIA introduces &lt;strong&gt;nvMatmulHeuristics&lt;/strong&gt; to enhance the process. This module identifies a small set of top-performing kernel configurations, simplifying the tuning workflow and saving time. ‚è±Ô∏è With nvMatmulHeuristics and CUTLASS 4.2, users can quickly generate and auto-tune kernels, leading to faster model compilation and better performance. #NVIDIA #GEMM #CUDA&amp;hellip;</description>
    </item>
    <item>
      <title>What‚Äôs New in CUDA Toolkit 13.0 for Jetson Thor: Unified Arm Ecosystem and More</title>
      <link>/articles/article-2025-09-02-7631/</link>
      <pubDate>Tue, 02 Sep 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-02-7631/</guid>
      <description>üöÄ Exciting advancements are on the horizon with CUDA Toolkit 13.0 for Jetson Thor! This release introduces a unified toolkit for Arm platforms, eliminating the need for separate installations. Developers can build applications once and deploy them seamlessly across various systems. Enhanced features like Unified Virtual Memory and improved developer tools streamline workflows and enhance performance for edge AI applications. #NVIDIA #CUDA #JetsonThor #EdgeComputing #AI</description>
    </item>
    <item>
      <title>How Small Language Models Are Key to Scalable Agentic AI</title>
      <link>/articles/article-2025-08-29-7543/</link>
      <pubDate>Fri, 29 Aug 2025 18:00:42 +0000</pubDate>
      <guid>/articles/article-2025-08-29-7543/</guid>
      <description>The rise of agentic AI is transforming how businesses approach automation and productivity. ü§ñ Recent insights highlight the potential of small language models (SLMs) as efficient alternatives to large language models (LLMs) in agentic applications. SLMs can reduce costs and improve operational flexibility while maintaining performance. This shift enables enterprises to utilize SLMs for specific tasks, reserving LLMs for more complex scenarios. Tools like NVIDIA‚Äôs Nemotron demonstrate the&amp;hellip;</description>
    </item>
    <item>
      <title>Fine-Tuning gpt-oss for Accuracy and Performance with Quantization Aware Training</title>
      <link>/articles/article-2025-08-29-7545/</link>
      <pubDate>Fri, 29 Aug 2025 14:47:04 +0000</pubDate>
      <guid>/articles/article-2025-08-29-7545/</guid>
      <description>OpenAI&amp;rsquo;s gpt-oss model has made waves in the AI community with its innovative architecture and performance capabilities. üìàüß† It features a mixture of expert architecture and a 128K context length, competing closely with OpenAI&amp;rsquo;s closed-source models. However, deploying foundational models like gpt-oss in critical fields requires careful fine-tuning. The article discusses employing Supervised Fine-Tuning (SFT) and Quantization-Aware Training (QAT) to enhance model accuracy while maintaining&amp;hellip;</description>
    </item>
    <item>
      <title>Getting Started with NVIDIA Isaac for Healthcare Using the Telesurgery Workflow</title>
      <link>/articles/article-2025-08-28-7474/</link>
      <pubDate>Thu, 28 Aug 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-28-7474/</guid>
      <description>üöÄ Telesurgery is transforming healthcare delivery as the shortage of surgeons rises. With advancements in 5G and AI, experts can now operate remotely, shifting from experimental to essential. üåç NVIDIA Isaac for Healthcare offers a modular workflow that includes video streaming, robot control, and simulation tools. This enables seamless training and clinical deployment. Learn how this technology is paving the way for the next generation of surgical robotics. ü§ñüí° #Telesurgery&amp;hellip;</description>
    </item>
    <item>
      <title>How to Improve CUDA Kernel Performance with Shared Memory Register Spilling</title>
      <link>/articles/article-2025-08-27-7273/</link>
      <pubDate>Wed, 27 Aug 2025 16:30:00 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7273/</guid>
      <description>üöÄ New in CUDA Toolkit 13.0: Shared Memory Register Spilling! This feature helps improve CUDA kernel performance by allowing the compiler to use shared memory for excess variables instead of local memory. This reduces spill latency and L2 pressure for register-heavy kernels. To enable shared memory spilling, use the pragma command in your kernel definition. With this optimization, kernels can perform better, especially in critical regions where registers are heavily used. Learn more about how&amp;hellip;</description>
    </item>
    <item>
      <title>How to Scale Your LangGraph Agents in Production From A Single User to 1,000 Coworkers</title>
      <link>/articles/article-2025-08-27-7274/</link>
      <pubDate>Wed, 27 Aug 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7274/</guid>
      <description>üìà Scaling your AI agent for production use? In a recent article, the deployment of a deep-research agent using the AI-Q NVIDIA Blueprint is explored. This article outlines how NVIDIA tackled the challenges of sharing their AI tools with up to 1,000 coworkers. The focus was on using the NeMo Agent Toolkit to ensure scalability and security while accessing internal data. It details the architecture that supports document processing and web search capabilities. Learn more about the techniques&amp;hellip;</description>
    </item>
    <item>
      <title>How Industry Collaboration Fosters NVIDIA Co-Packaged Optics</title>
      <link>/articles/article-2025-08-26-7202/</link>
      <pubDate>Tue, 26 Aug 2025 17:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-26-7202/</guid>
      <description>NVIDIA is transforming data-center connectivity by merging optical and electrical components through strong industry partnerships. ü§ù Their networking platform integrates advanced technologies from top partners, focusing on scalable and efficient optical systems. Key innovations include the Micro Ring Modulator, allowing high data throughput with a compact design. Collaboration with TSMC has addressed manufacturing challenges, ensuring reliable performance essential for modern data centers&amp;hellip;.</description>
    </item>
    <item>
      <title>NVFP4 Trains with Precision of 16-Bit and Speed and Efficiency of 4-Bit</title>
      <link>/articles/article-2025-08-25-6335/</link>
      <pubDate>Mon, 25 Aug 2025 17:59:23 +0000</pubDate>
      <guid>/articles/article-2025-08-25-6335/</guid>
      <description>üöÄ NVIDIA has introduced NVFP4, a 4-bit format designed to enhance AI workloads during pretraining of large language models (LLMs). This innovation aims to improve training efficiency and throughput while maintaining accuracy. The shift from higher precision formats to 4-bit is set to redefine scalability in AI development. Collaboration with major organizations like Google Cloud and OpenAI is ongoing to explore this technology&amp;rsquo;s full potential. #AI #NVIDIA #MachineLearning #LLMs #Innovation</description>
    </item>
    <item>
      <title>Introducing NVIDIA Jetson Thor, the Ultimate Platform for Physical AI</title>
      <link>/articles/article-2025-08-25-6336/</link>
      <pubDate>Mon, 25 Aug 2025 17:57:00 +0000</pubDate>
      <guid>/articles/article-2025-08-25-6336/</guid>
      <description>üöÄ Robotics is evolving! The shift from specialist machines to adaptable robots marks a new era in generalist robotics. These robots are designed to learn and perform various tasks, enhancing efficiency across industries. With NVIDIA&amp;rsquo;s Jetson Thor platform, developers can create flexible robots that streamline operations without constant reprogramming. Key components include hardware integration, real-time control, perception, and high-level reasoning to facilitate complex interactions&amp;hellip;.</description>
    </item>
    <item>
      <title>How to Spot (and Fix) 5 Common Performance Bottlenecks in pandas Workflows</title>
      <link>/articles/article-2025-08-22-6297/</link>
      <pubDate>Fri, 22 Aug 2025 19:54:44 +0000</pubDate>
      <guid>/articles/article-2025-08-22-6297/</guid>
      <description>Are you facing slow data loads and memory issues in your pandas workflows? üêçüíª This article highlights five common performance bottlenecks in pandas, including slow CSV parsing and memory-intensive joins. It offers practical solutions to improve your workflow efficiency, such as using the PyArrow engine for faster CSV reads and exploring the cudf.pandas library for GPU acceleration. Don&amp;rsquo;t have a GPU? You can use cudf.pandas for free in Google Colab! üöÄüìä #DataScience #Python #Pandas #Performance&amp;hellip;</description>
    </item>
    <item>
      <title>Inside NVIDIA Blackwell Ultra: The Chip Powering the AI Factory Era</title>
      <link>/articles/article-2025-08-22-6299/</link>
      <pubDate>Fri, 22 Aug 2025 17:58:00 +0000</pubDate>
      <guid>/articles/article-2025-08-22-6299/</guid>
      <description>Introducing the NVIDIA Blackwell Ultra GPU, a key advancement in the Blackwell architecture. This GPU enhances AI training and reasoning with innovative technology. Key features include a dual-reticle design, high bandwidth, and energy-efficient performance. It boasts 208 billion transistors and provides significant scalability for AI tasks. With 15 PetaFLOPS performance and improved memory access, the Blackwell Ultra sets a new standard for accelerated computing. #NVIDIA #AI #BlackwellUltra&amp;hellip;</description>
    </item>
    <item>
      <title>NVIDIA Hardware Innovations and Open Source Contributions Are Shaping AI</title>
      <link>/articles/article-2025-08-22-6298/</link>
      <pubDate>Fri, 22 Aug 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-22-6298/</guid>
      <description>NVIDIA is making strides in AI through open source models like Cosmos, DeepSeek, and Llama. üåê These models offer free access to AI methodologies, enabling innovation across the globe. Their new Blackwell GPU architecture enhances AI performance with advanced features like NVFP4 and high-bandwidth interconnects. ‚ö°Ô∏è Additionally, NVIDIA provides a wealth of open source tools and libraries, fostering an environment for developers to build and scale AI efficiently. üíª Discover more about these&amp;hellip;</description>
    </item>
    <item>
      <title>Less Coding, More Science: Simplify Ocean Modeling on GPUs With OpenACC and Unified Memory</title>
      <link>/articles/article-2025-08-21-5038/</link>
      <pubDate>Thu, 21 Aug 2025 16:53:17 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5038/</guid>
      <description>üöÄ Exciting advancements in ocean modeling are here! NVIDIA HPC SDK v25.7 simplifies GPU programming for high-performance computing applications. This update automates data movement between CPU and GPU, reducing manual management and enhancing developer productivity. Notable systems like the NVIDIA GH200 Grace Hopper Superchip are leading the way. With unified memory programming, developers can focus more on science and less on coding complexities. This change is already benefiting projects,&amp;hellip;</description>
    </item>
    <item>
      <title>Improve Data Integrity and Security with Accelerated Hash Functions and Merkle Trees in cuPQC 0.4</title>
      <link>/articles/article-2025-08-21-5039/</link>
      <pubDate>Thu, 21 Aug 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5039/</guid>
      <description>üîí As data sizes grow, ensuring security and integrity is vital. The cuPQC SDK v0.4 offers advanced cryptographic techniques, including inclusion proofs and digital signatures, to enhance data protection. New features include expanded hash function support and efficient Merkle tree calculations, improving performance in data verification. üå≥ Discover how these updates can benefit your cryptographic tasks! #DataIntegrity #Cryptography #cuPQC #MerkleTrees #CyberSecurity</description>
    </item>
    <item>
      <title>Scaling AI Inference Performance and Flexibility with NVIDIA NVLink and NVLink Fusion</title>
      <link>/articles/article-2025-08-21-5040/</link>
      <pubDate>Thu, 21 Aug 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5040/</guid>
      <description>The rise of AI model complexity has increased parameter counts from millions to trillions, demanding more computational power. üåê NVIDIA NVLink and NVLink Fusion are key technologies enhancing AI inference performance. They enable large-scale parallelization strategies, essential for handling advanced AI architectures like mixture-of-experts (MoE). ü§ñ This evolution in AI systems highlights the need for interconnected GPUs acting as a unified pool of compute and memory. #AI #NVIDIA #NVLink&amp;hellip;</description>
    </item>
    <item>
      <title>Reinforcement Learning with NVIDIA NeMo-RL: Megatron-Core Support for Optimized Training Throughput</title>
      <link>/articles/article-2025-08-20-5041/</link>
      <pubDate>Wed, 20 Aug 2025 15:15:16 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5041/</guid>
      <description>üöÄ Exciting updates in reinforcement learning with NVIDIA NeMo-RL! The latest release introduces support for the Megatron-Core library, enhancing training throughput for massive language models. This integration addresses limitations found in the PyTorch DTensor backend, particularly for models with hundreds of billions of parameters. With GPU-optimized techniques and simplified configuration options, NeMo-RL makes it easier for developers to harness the power of Megatron-Core. Explore&amp;hellip;</description>
    </item>
    <item>
      <title>Deploying Your Omniverse Kit Apps at Scale</title>
      <link>/articles/article-2025-08-20-5042/</link>
      <pubDate>Wed, 20 Aug 2025 13:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5042/</guid>
      <description>Unlock the potential of 3D applications with NVIDIA Omniverse Kit App Streaming! üåê This solution simplifies deployment and enables users to stream applications directly from their browsers, reducing the need for complex installations. With flexible options like self-managed deployment or fully-managed infrastructure, developers can easily reach their audience. Explore the straightforward steps to get started and enhance your 3D application experience! üíªüöÄ #NVIDIA #Omniverse #3DStreaming&amp;hellip;</description>
    </item>
    <item>
      <title>New Nemotron Nano 2 Open Reasoning Model Tops Leaderboard and Delivers 6x Higher Throughput</title>
      <link>/articles/article-2025-08-19-5043/</link>
      <pubDate>Tue, 19 Aug 2025 20:50:07 +0000</pubDate>
      <guid>/articles/article-2025-08-19-5043/</guid>
      <description>üöÄ Exciting news in AI! The NVIDIA Nemotron Nano 2 model has topped the leaderboard with impressive accuracy. This open reasoning model offers up to 6x higher throughput compared to its closest competitors, enhancing edge AI capabilities. Stay updated on advancements in technology! üîçüìà #AI #NVIDIA #Innovation #EdgeComputing #Nemotron</description>
    </item>
    <item>
      <title>Announcing the Latest NVIDIA Gaming AI and Neural Rendering Technologies</title>
      <link>/articles/article-2025-08-18-5044/</link>
      <pubDate>Mon, 18 Aug 2025 19:30:00 +0000</pubDate>
      <guid>/articles/article-2025-08-18-5044/</guid>
      <description>üöÄ NVIDIA has made significant announcements at Gamescom 2025, introducing updates to its RTX neural rendering and ACE generative AI technologies. These advancements aim to enhance gaming experiences with expanded integration for DLSS 4, new AI models, and cloud solutions like GeForce NOW inside Discord. üéÆ Upcoming titles, including Resident Evil Requiem and Borderlands 4, will feature these technologies, helping developers optimize graphics even for players with older hardware. For Unreal&amp;hellip;</description>
    </item>
    <item>
      <title>Identify Speakers in Meetings, Calls, and Voice Apps in Real-Time with NVIDIA Streaming Sortformer</title>
      <link>/articles/article-2025-08-18-5045/</link>
      <pubDate>Mon, 18 Aug 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-18-5045/</guid>
      <description>Introducing NVIDIA Streaming Sortformer, a breakthrough in real-time speaker identification for meetings, calls, and voice-enabled apps. üé§ This production-grade diarization model offers low-latency performance, making it ideal for multi-speaker environments. Key features include frame-level diarization, precision timestamps, and efficient GPU inference. üåê Optimized for English and tested with Mandarin and other languages, it promises robust tracking with minimal latency. #NVIDIA #AI&amp;hellip;</description>
    </item>
    <item>
      <title>Scaling AI Factories with Co-Packaged Optics for Better Power Efficiency</title>
      <link>/articles/article-2025-08-18-5046/</link>
      <pubDate>Mon, 18 Aug 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-18-5046/</guid>
      <description>AI is reshaping the computing landscape, with networks becoming essential for future data centers. NVIDIA is leading this evolution with GPU-driven AI factories that require high bandwidth and low latency. Their networking solutions, including Spectrum-X Ethernet and Quantum InfiniBand, support these advanced needs. Co-packaged optics are now crucial for power efficiency and resilience in AI workloads, marking a significant shift from traditional data center designs. #NVIDIA #AI #DataCenters&amp;hellip;</description>
    </item>
    <item>
      <title>Upcoming Livestream: Building Cross-Framework Agent Ecosystems</title>
      <link>/articles/article-2025-08-14-5047/</link>
      <pubDate>Thu, 14 Aug 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-14-5047/</guid>
      <description>üöÄ Join us for an insightful livestream on August 21! Discover how the NVIDIA NeMo Agent Toolkit enhances multi-agent workflows through deep MCP integration. üìÖ Time: 18:00 - 19:00 (CEST) üìç Learn about building optimized agentic systems with NVIDIA NIM. Don&amp;rsquo;t miss this opportunity to expand your knowledge! #NVIDIA #Livestream #NeMoAgent #TechInnovation #AI</description>
    </item>
    <item>
      <title>Streamline CUDA-Accelerated Python Install and Packaging Workflows with Wheel Variants</title>
      <link>/articles/article-2025-08-13-4892/</link>
      <pubDate>Wed, 13 Aug 2025 22:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-13-4892/</guid>
      <description>üöÄ NVIDIA addresses the challenges of installing GPU-accelerated Python packages with the WheelNext initiative. Current wheel formats struggle with hardware diversity, leading to installation complexities. WheelNext aims to improve this by introducing Wheel Variants, allowing precise artifact descriptions for better compatibility. This collaboration with Meta and others enhances user experience in scientific computing and AI. üîó Learn more: [GitHub repo link] #Python #NVIDIA #CUDA #OpenSource #AI</description>
    </item>
    <item>
      <title>Scaling LLM Reinforcement Learning with Prolonged Training Using ProRL v2</title>
      <link>/articles/article-2025-08-13-4893/</link>
      <pubDate>Wed, 13 Aug 2025 21:33:03 +0000</pubDate>
      <guid>/articles/article-2025-08-13-4893/</guid>
      <description>üöÄ Exciting advancements in AI with NVIDIA&amp;rsquo;s ProRL v2! This new framework explores whether large language models (LLMs) can enhance their capabilities through extended reinforcement learning (RL). ProRL v2 incorporates advanced algorithms and rigorous training methods across multiple domains. Key features include over 3,000 RL steps, stability improvements, and fully verifiable rewards. These innovations aim to help models discover new solutions rather than just refining existing ones. #AI&amp;hellip;</description>
    </item>
    <item>
      <title>Streamlining Quantum Error Correction and Application Development with CUDA-QX 0.4</title>
      <link>/articles/article-2025-08-13-4894/</link>
      <pubDate>Wed, 13 Aug 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-13-4894/</guid>
      <description>üöÄ Quantum computing is advancing with the latest release of CUDA-QX 0.4, focusing on quantum error correction (QEC). This update streamlines QEC experiments, enabling researchers to define and simulate codes, configure decoders, and deploy them effectively. Key features include a comprehensive API for user-defined components and the introduction of a detector error model (DEM) for improved circuit simulations. üîó Check out the full release notes on GitHub for ongoing development and&amp;hellip;</description>
    </item>
    <item>
      <title>Dynamo 0.4 Delivers 4x Faster Performance, SLO-Based Autoscaling, and Real-Time Observability</title>
      <link>/articles/article-2025-08-13-4895/</link>
      <pubDate>Wed, 13 Aug 2025 15:30:00 +0000</pubDate>
      <guid>/articles/article-2025-08-13-4895/</guid>
      <description>üöÄ Exciting advancements in AI! Dynamo 0.4 has been released, offering 4x faster performance and SLO-based autoscaling. This update is designed for deploying new open-source models like OpenAI&amp;rsquo;s gpt-oss and Moonshot AI&amp;rsquo;s Kimi K2 efficiently. Key features include enhanced real-time observability and resiliency, making it easier to monitor performance and manage requests. #AI #OpenSource #Dynamo #Innovation #TechUpdates</description>
    </item>
    <item>
      <title>Announcing General Availability for NVIDIA Isaac Sim 5.0 and NVIDIA Isaac Lab 2.2</title>
      <link>/articles/article-2025-08-11-302/</link>
      <pubDate>Mon, 11 Aug 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-11-302/</guid>
      <description>üöÄ NVIDIA has announced the general availability of NVIDIA Isaac Sim 5.0 and NVIDIA Isaac Lab 2.2 at SIGGRAPH 2025. These frameworks are now accessible on GitHub, providing developers with tools for building, training, and testing AI-powered robots in physics-based simulations. Explore the cutting-edge capabilities that these releases bring to robotics development. #NVIDIA #IsaacSim #Robotics #AI #SIGGRAPH2025</description>
    </item>
    <item>
      <title>Developers Build Fast and Reliable Robot Simulations with NVIDIA Omniverse Libraries</title>
      <link>/articles/article-2025-08-11-4832/</link>
      <pubDate>Mon, 11 Aug 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-11-4832/</guid>
      <description>NVIDIA recently unveiled updates to the Omniverse libraries and Cosmos world foundation models at SIGGRAPH. üåê These enhancements, driven by OpenUSD, provide developers with new tools and models to create accurate virtual environments. They focus on building AI agents and simulations that can interact effectively with the real world. ü§ñ This advancement aims to improve the reliability and speed of robotic simulations. #NVIDIA #Omniverse #Robotics #AI #SIGGRAPH</description>
    </item>
    <item>
      <title>How to Instantly Render Real-World Scenes in Interactive Simulation</title>
      <link>/articles/article-2025-08-11-4834/</link>
      <pubDate>Mon, 11 Aug 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-11-4834/</guid>
      <description>Transforming real-world environments into interactive simulations is now faster than ever. With NVIDIA Omniverse NuRec and 3DGUT, users can reconstruct photorealistic 3D scenes from basic sensor data. This process takes mere moments instead of days or weeks. üåç‚ú® These scenes can be deployed in platforms like NVIDIA Isaac Sim or CARLA Simulator, enhancing simulation experiences. #NVIDIA #SimulationTechnology #3DModeling #Omniverse #InteractiveSimulations</description>
    </item>
    <item>
      <title>Maximize Robotics Performance by Post-Training NVIDIA Cosmos Reason</title>
      <link>/articles/article-2025-08-11-4833/</link>
      <pubDate>Mon, 11 Aug 2025 15:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-11-4833/</guid>
      <description>Introducing NVIDIA Cosmos Reason, unveiled at GTC 2025! ü§ñ This innovative reasoning vision language model (VLM) is designed for physical AI and robotics. It allows robots and vision AI agents to utilize prior knowledge, physics, and common sense to interpret and interact with the real world. By processing video and text prompts, Cosmos Reason transforms visual information into actionable insights. #NVIDIA #Robotics #AI #Innovation #GTC2025</description>
    </item>
    <item>
      <title>R¬≤D¬≤: Boost Robot Training with World Foundation Models and Workflows from NVIDIA Research</title>
      <link>/articles/article-2025-08-08-4714/</link>
      <pubDate>Fri, 08 Aug 2025 18:33:16 +0000</pubDate>
      <guid>/articles/article-2025-08-08-4714/</guid>
      <description>üöÄ The latest edition of NVIDIA&amp;rsquo;s R¬≤D¬≤ highlights the role of World Foundation Models (WFMs) in enhancing robot training. WFMs address the growing need for labeled datasets by simulating real-world dynamics. Key components include Cosmos Predict, Transfer, and Reason, each designed for specific applications in robotics and autonomous vehicles. Cosmos Predict generates future world states through various input types. Cosmos Transfer facilitates photorealistic style transfers, while Cosmos&amp;hellip;</description>
    </item>
    <item>
      <title>Efficient Transforms in cuDF Using JIT Compilation</title>
      <link>/articles/article-2025-08-07-4715/</link>
      <pubDate>Thu, 07 Aug 2025 21:06:42 +0000</pubDate>
      <guid>/articles/article-2025-08-07-4715/</guid>
      <description>Unlock efficient data processing with RAPIDS cuDF! üöÄ cuDF offers a wide range of ETL algorithms optimized for GPUs, allowing for seamless integration with pandas. Users can leverage accelerated algorithms without changing their existing code. For advanced developers, the cuDF C++ submodule enhances functionality through non-owning views and kernel fusion, boosting performance and reducing unnecessary GPU memory transfers. Learn how JIT compilation improves throughput and resource utilization&amp;hellip;</description>
    </item>
    <item>
      <title>Train with Terabyte-Scale Datasets on a Single NVIDIA Grace Hopper Superchip Using XGBoost 3.0</title>
      <link>/articles/article-2025-08-07-4716/</link>
      <pubDate>Thu, 07 Aug 2025 18:25:36 +0000</pubDate>
      <guid>/articles/article-2025-08-07-4716/</guid>
      <description>üöÄ Exciting advancements in machine learning with XGBoost 3.0! This version leverages the NVIDIA Grace Hopper Superchip to process datasets up to 1 TB, significantly speeding up training times‚Äîup to 8x faster than traditional CPUs. Key enhancements include a new external-memory engine, simplifying scalability and reducing reliance on complex GPU clusters. Major banks like RBC are already benefiting, reporting 16x speedups and 94% reductions in training costs. #XGBoost #MachineLearning #NVIDIA&amp;hellip;</description>
    </item>
    <item>
      <title>How Hackers Exploit AI‚Äôs Problem-Solving Instincts</title>
      <link>/articles/article-2025-08-07-4717/</link>
      <pubDate>Thu, 07 Aug 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-07-4717/</guid>
      <description>üö® As AI models become more advanced, they face new vulnerabilities. Researchers highlight how hackers exploit these systems by manipulating their problem-solving instincts. üîç The article discusses the evolution of attack techniques from text-based prompt injections to sophisticated multimodal reasoning attacks. These new methods target how AI merges inputs like text, images, and audio. üîí Securing AI requires a shift in focus from just input/output layers to the reasoning architecture itself&amp;hellip;.</description>
    </item>
    <item>
      <title>What‚Äôs New and Important in CUDA Toolkit 13.0</title>
      <link>/articles/article-2025-08-06-4134/</link>
      <pubDate>Wed, 06 Aug 2025 16:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-06-4134/</guid>
      <description>üöÄ Exciting updates in CUDA Toolkit 13.0! This major release enhances computing on NVIDIA CPUs and GPUs, introducing new features like tile-based programming and improved support for Arm platforms. Key updates include: - Enhanced NVIDIA Nsight Developer Tools - Math libraries updates for linear algebra and FFT - Improved NVCC Compiler with better compression - Accelerated Python cuda.core release CUDA 13.0 continues to support Blackwell GPUs and introduces a new programming model to boost&amp;hellip;</description>
    </item>
    <item>
      <title>NVIDIA vGPU 19.0 Enables Graphics and AI Virtualization on NVIDIA Blackwell GPUs</title>
      <link>/articles/article-2025-08-05-210/</link>
      <pubDate>Tue, 05 Aug 2025 18:39:57 +0000</pubDate>
      <guid>/articles/article-2025-08-05-210/</guid>
      <description>NVIDIA has released vGPU 19.0, enhancing virtualization for graphics and AI workloads. üåê The update leverages the NVIDIA RTX PRO 6000 Blackwell GPUs, which support advanced features like Multi-Instance GPU (MIG) for improved scalability and user density in data centers. With 96 GB of GDDR7 memory, these GPUs excel in demanding enterprise tasks, from AI inference to scientific computing. This release aims to significantly boost performance for virtualized workloads. #NVIDIA #Virtualization #AI&amp;hellip;</description>
    </item>
    <item>
      <title>NVIDIA Accelerates OpenAI gpt-oss Models Delivering 1.5 M TPS Inference on NVIDIA GB200 NVL72</title>
      <link>/articles/article-2025-08-05-211/</link>
      <pubDate>Tue, 05 Aug 2025 17:10:00 +0000</pubDate>
      <guid>/articles/article-2025-08-05-211/</guid>
      <description>üöÄ NVIDIA and OpenAI are advancing AI technologies with the launch of the gpt-oss-20b and gpt-oss-120b models. These models, designed for high-performance inference, can achieve 1.5 million tokens per second on the NVIDIA GB200 NVL72 system. üß† The gpt-oss models utilize a mixture of experts architecture and are optimized for NVIDIA&amp;rsquo;s Blackwell system. They support advanced text reasoning capabilities and are trained on NVIDIA H100 Tensor Core GPUs. üîß Developers can access optimized kernels and&amp;hellip;</description>
    </item>
    <item>
      <title>CUDA Pro Tip: Increase Performance with Vectorized Memory Access</title>
      <link>/articles/article-2025-08-04-212/</link>
      <pubDate>Mon, 04 Aug 2025 21:05:00 +0000</pubDate>
      <guid>/articles/article-2025-08-04-212/</guid>
      <description>Boost your CUDA performance by addressing bandwidth limitations! üåê Bandwidth-bound kernels are becoming more common due to the increasing ratio of flops to bandwidth in new hardware. To enhance bandwidth utilization, consider using vector loads and stores in your CUDA C++ code. Check out the provided memory copy kernel example, which uses grid-stride loops to improve efficiency. üìä #CUDA #PerformanceOptimization #ProgrammingTips #TechInsights #NVIDIA</description>
    </item>
    <item>
      <title>Navigating GPU Architecture Support: A Guide for NVIDIA CUDA Developers</title>
      <link>/articles/article-2025-08-04-213/</link>
      <pubDate>Mon, 04 Aug 2025 20:01:47 +0000</pubDate>
      <guid>/articles/article-2025-08-04-213/</guid>
      <description>üöÄ Are you developing with NVIDIA CUDA? You may have seen warnings about offline compilation for architectures prior to &amp;lsquo;_75&amp;rsquo; being phased out. This is a heads-up for developers to update their practices. The NVIDIA software stack consists of two main components: the CUDA Toolkit for building applications and the NVIDIA Driver for running them. The driver interfaces directly with GPU hardware and comes in three branches: New Feature Branch, Production Branch, and Long-Term Support Branch. Each&amp;hellip;</description>
    </item>
    <item>
      <title>NVIDIA CUDA-Q 0.12 Expands Toolset for Developing Hardware-Performant Quantum Applications</title>
      <link>/articles/article-2025-08-04-214/</link>
      <pubDate>Mon, 04 Aug 2025 19:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-04-214/</guid>
      <description>üöÄ NVIDIA CUDA-Q 0.12 has been released, bringing new simulation tools for quantum application development. The update allows researchers to access detailed statistics on individual simulation runs, aiding in areas like noise correlation and circuit benchmarking. New features also enhance the CUDA-Q dynamics backend, improving support for multidiagonal sparse matrices and generic super-operators. This open-source project includes community contributions and Python 3.13 support. For more&amp;hellip;</description>
    </item>
    <item>
      <title>How to Enhance RAG Pipelines with Reasoning Using NVIDIA Llama Nemotron Models</title>
      <link>/articles/article-2025-08-04-215/</link>
      <pubDate>Mon, 04 Aug 2025 17:00:00 +0000</pubDate>
      <guid>/articles/article-2025-08-04-215/</guid>
      <description>Unlocking the potential of retrieval-augmented generation (RAG) systems involves addressing user queries that are vague or carry implicit intent. ü§î The article discusses how NVIDIA&amp;rsquo;s Nemotron LLMs enhance RAG pipelines through advanced query rewriting techniques. This process optimizes user prompts for better information retrieval, improving the relevance of results. üìà Techniques like Q2E, Q2D, and chain-of-thought query rewriting help bridge gaps in understanding, leading to more accurate&amp;hellip;</description>
    </item>
    <item>
      <title>7 Drop-In Replacements to Instantly Speed Up Your Python Data Science Workflows</title>
      <link>/articles/article-2025-08-01-216/</link>
      <pubDate>Fri, 01 Aug 2025 22:45:50 +0000</pubDate>
      <guid>/articles/article-2025-08-01-216/</guid>
      <description>üöÄ Speed up your Python data science workflows with easy drop-in replacements! Many libraries like pandas and scikit-learn can now leverage GPU acceleration with minimal code changes. Using tools like NVIDIA cuDF, you can enhance performance on large datasets without rewriting your scripts. Explore seven options to optimize your data processing today! #DataScience #Python #GPUAcceleration #TechTips #Programming</description>
    </item>
    <item>
      <title>Optimizing LLMs for Performance and Accuracy with Post-Training Quantization</title>
      <link>/articles/article-2025-08-01-217/</link>
      <pubDate>Fri, 01 Aug 2025 21:27:23 +0000</pubDate>
      <guid>/articles/article-2025-08-01-217/</guid>
      <description>üöÄ Quantization is a key method for developers looking to enhance AI model performance with minimal overhead. It allows for significant improvements in latency, throughput, and memory efficiency by reducing model precision without retraining. Models typically use FP16 or BF16, while advancing to FP4 can yield even better efficiency. NVIDIA&amp;rsquo;s TensorRT Model Optimizer offers a flexible framework for post-training quantization, supporting various formats and integrating calibration techniques for&amp;hellip;</description>
    </item>
    <item>
      <title>Just Released: NVIDIA HPC SDK v25.7</title>
      <link>/articles/article-2025-07-31-218/</link>
      <pubDate>Thu, 31 Jul 2025 18:09:45 +0000</pubDate>
      <guid>/articles/article-2025-07-31-218/</guid>
      <description>üöÄ Just announced: NVIDIA HPC SDK v25.7 is now available! This update includes support for CUDA 12.9U1, along with updated library components, bug fixes, and performance improvements. For installation, users can download the SDK for Linux x86_64 and follow the provided instructions for setup. Check it out to enhance your high-performance computing projects! #NVIDIA #HPCSDK #CUDA #TechUpdate #HighPerformanceComputing</description>
    </item>
    <item>
      <title>Just Released: NVIDIA cuPQC v0.4</title>
      <link>/articles/article-2025-07-31-219/</link>
      <pubDate>Thu, 31 Jul 2025 18:07:46 +0000</pubDate>
      <guid>/articles/article-2025-07-31-219/</guid>
      <description>üöÄ Just in: NVIDIA has launched cuPQC v0.4! This update brings Poseidon2 to cuHash and introduces a Merkle Tree API compatible with all cuHash hash functions. For those interested, you can download the SDK for GPU-accelerated Post-Quantum Cryptography. Check the documentation for system requirements and installation instructions. üîó Download cuPQC: &lt;a href=&#34;https://developer.download.nvidia.com/compute/cupqc/redist/cupqc/cupqc-sdk-0.4.0-x86_64.tar.gz&#34;&gt;x86_64&lt;/a&gt; |&amp;hellip;</description>
    </item>
    <item>
      <title>Securing Agentic AI: How Semantic Prompt Injections Bypass AI Guardrails</title>
      <link>/articles/article-2025-07-31-220/</link>
      <pubDate>Thu, 31 Jul 2025 16:58:07 +0000</pubDate>
      <guid>/articles/article-2025-07-31-220/</guid>
      <description>Prompt injection remains a significant threat to AI systems, particularly with the rise of multimodal and agentic AI. üõ°Ô∏è NVIDIA&amp;rsquo;s AI Red Team simulates real-world attacks to identify vulnerabilities in these advanced systems, emphasizing the need for cross-functional solutions. Their recent research introduces a new category of multimodal prompt injection using symbolic visual inputs, like emoji sequences. üîç This shift highlights the importance of adapting security strategies from input&amp;hellip;</description>
    </item>
  </channel>
</rss>
