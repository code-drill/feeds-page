<!DOCTYPE html>
<html lang="en-us">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Nvidia-Developer-Blog | Daily Tech Articles Feed</title>
    <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 24 24'><text y='20' font-size='20'>üì°</text></svg>">
    <style>
        body { 
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif; 
            margin: 0; 
            padding: 0; 
            background: #fff;
            color: #333;
            line-height: 1.5;
            font-size: 14px;
        }
        
         
        .header { 
            background: #f8f9fa; 
            border-bottom: 1px solid #e9ecef; 
            padding: 10px 0;
        }
        .header .container { 
            max-width: 1200px; 
            margin: 0 auto; 
            padding: 0 20px;
        }
        .header h1 { 
            margin: 0; 
            font-size: 24px; 
            color: #333;
        }
        .header h1 a {
            color: #333;
            text-decoration: none;
        }
        .header h1 a:hover {
            color: #337ab7;
        }
        .nav { 
            margin-top: 10px;
        }
        .nav a { 
            color: #666; 
            text-decoration: none; 
            margin-right: 20px;
            font-size: 14px;
        }
        .nav a:hover { 
            color: #333; 
            text-decoration: underline;
        }
        
         
        .container { 
            max-width: 1200px; 
            margin: 0 auto; 
            padding: 20px;
        }
        
         
        .articles-list { 
            margin-top: 20px;
        }
        
         
        .day-label {
            font-size: 18px;
            font-weight: bold;
            color: #333;
            margin: 40px 0 20px 0;
            padding: 12px 16px;
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-left: 4px solid #0066cc;
            border-radius: 4px;
        }
        .day-label:first-child {
            margin-top: 20px;
        }
        
        .article-item { 
            margin-bottom: 30px; 
            border-bottom: 1px solid #f0f0f0;
            padding-bottom: 20px;
        }
        .article-item:last-child { 
            border-bottom: none; 
        }
        .article-item h2 { 
            margin: 0 0 8px 0; 
            font-size: 18px; 
            line-height: 1.3;
        }
        .article-item h2 a { 
            color: #337ab7; 
            text-decoration: none; 
        }
        .article-item h2 a:hover { 
            color: #286090; 
            text-decoration: underline;
        }
        
         
        .publication-date { 
            font-size: 13px; 
            color: #666; 
            margin-bottom: 15px;
        }
        .source { 
            font-size: 13px; 
            color: #337ab7; 
            margin-bottom: 6px;
        }
        .source a {
            color: #337ab7;
            text-decoration: none;
        }
        .source a:hover {
            color: #286090;
        }
        .author { 
            font-size: 13px; 
            color: #666; 
            margin-bottom: 6px;
        }
        .author::before {
            content: "Author: ";
        }
        
         
        .summary { 
            color: #555; 
            line-height: 1.4; 
            margin-bottom: 8px;
        }
        
         
        .categories { 
            margin-bottom: 8px;
        }
        .categories::before {
            content: "Category: ";
            font-size: 13px;
            color: #666;
        }
        .category-text { 
            font-size: 13px; 
            color: #337ab7;
            text-decoration: none;
        }
        .category-text:hover { 
            color: #286090;
        }
        .category { 
            font-size: 13px; 
            color: #337ab7;
            text-decoration: none;
        }
        .category:hover { 
            color: #286090;
        }
        
         
        .pagination-info { 
            text-align: center; 
            margin: 20px 0; 
            color: #666; 
            font-size: 14px;
        }
        .pagination { 
            display: flex; 
            justify-content: center; 
            align-items: center; 
            gap: 10px; 
            margin: 30px 0; 
            flex-wrap: wrap;
        }
        .pagination-numbers { 
              
            gap: 5px;
            margin-bottom: 5px;
        }
        .pagination-link { 
            display: inline-block; 
            padding: 6px 10px; 
            border: 1px solid #ddd; 
            text-decoration: none; 
            color: #333; 
            background: #fff;
            margin-bottom: 5px;
        }
        .pagination-link:hover { 
            background: #f0f0f0; 
            border-color: #ccc;
        }
        .pagination-current { 
            display: inline-block; 
            padding: 6px 10px; 
            background: #333; 
            color: white; 
            font-weight: bold;
        }
        
         
        .filters-container { 
            margin-bottom: 25px; 
            padding: 20px;
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 8px;
        }
        .filter-section { 
            margin-bottom: 18px;
        }
        .filter-section:last-child {
            margin-bottom: 0;
        }
        .filter-section h3 { 
            margin: 0 0 12px 0; 
            color: #333; 
            font-size: 16px;
            padding-bottom: 6px;
            border-bottom: 2px solid #0066cc;
            display: inline-block;
        }
        .filter-options { 
            display: flex; 
            flex-wrap: wrap; 
            gap: 8px;
        }
        .filter-link { 
            display: inline-block; 
            padding: 6px 12px; 
            background: transparent; 
            color: #337ab7; 
            text-decoration: none; 
            font-size: 13px;
            border: none;
            border-radius: 20px;
            transition: all 0.2s ease;
        }
        .filter-link:hover { 
            background: #286090;
            color: white;
        }
        .filter-link.all-link { 
            background: transparent; 
            color: #337ab7;
            font-weight: bold;
        }
        .filter-link.all-link:hover { 
            background: #286090;
            color: white;
        }
        
         
        .filter-header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            cursor: pointer;
            margin-bottom: 12px;
        }
        .filter-toggle {
            background: none;
            border: none;
            font-size: 18px;
            color: #337ab7;
            cursor: pointer;
            padding: 0;
            margin: 0;
            line-height: 1;
            transition: transform 0.2s ease;
        }
        .filter-toggle:hover {
            color: #286090;
        }
        .filter-content {
            overflow: hidden;
            transition: max-height 0.3s ease;
        }
        .filter-content.collapsed {
            max-height: 0;
        }
        .filter-content.expanded {
            max-height: 500px;
        }
        .show-more-btn {
            display: inline-block;
            padding: 4px 8px;
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            color: #337ab7;
            text-decoration: none;
            font-size: 12px;
            border-radius: 4px;
            margin-top: 8px;
            cursor: pointer;
        }
        .show-more-btn:hover {
            background: #e9ecef;
            color: #286090;
        }
        
         
        .filter-input {
            width: 100%;
            padding: 8px 12px;
            border: 1px solid #dee2e6;
            border-radius: 4px;
            font-size: 14px;
            margin-bottom: 12px;
            background: white;
            color: #333;
        }
        .filter-input:focus {
            outline: none;
            border-color: #337ab7;
            box-shadow: 0 0 0 2px rgba(51, 122, 183, 0.1);
        }
        .filter-input::placeholder {
            color: #999;
            font-style: italic;
        }
        
         
        .breadcrumb { margin-bottom: 20px; }
        .breadcrumb a { color: #337ab7; text-decoration: none; }
        .breadcrumb a:hover { color: #286090; }
        
         
        .taxonomy-index { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin-top: 20px; }
        .taxonomy-item { padding: 15px; border: 1px solid #eee; border-radius: 8px; background: #fafafa; }
        .taxonomy-item h3 { margin: 0 0 5px 0; display: flex; align-items: center; gap: 8px; }
        .taxonomy-item .count { color: #666; font-size: 14px; font-weight: normal; }
        .taxonomy-item .taxonomy-description { color: #666; font-size: 14px; margin: 0; }
        .taxonomy-item h3 a { 
            color: #337ab7; 
            text-decoration: none; 
        }
        .taxonomy-item h3 a:hover { 
            color: #286090; 
            text-decoration: underline;
        }
        
         
        .site-footer {
            margin-top: 40px;
            padding: 20px 0;
            border-top: 1px solid #e9ecef;
            background: #f8f9fa;
        }
        .footer-text {
            text-align: center;
            margin: 0;
            font-size: 13px;
            color: #666;
        }
        .author-link {
            color: #337ab7;
            text-decoration: none;
        }
        .author-link:hover {
            color: #286090;
            text-decoration: underline;
        }
        
        @media (max-width: 768px) {
            .container { 
                padding: 15px;
            }
            
             
            .filters-container {
                padding: 15px;
                margin-bottom: 20px;
            }
            .filter-section {
                margin-bottom: 15px;
            }
            .filter-section h3 {
                font-size: 15px;
                margin: 0;
                border: none;
                padding: 0;
            }
            .filter-content {
                margin-top: 8px;
            }
            .filter-content.collapsed {
                max-height: 0;
                margin-top: 0;
            }
            .filter-options { 
                justify-content: flex-start;
                gap: 6px;
            }
            .filter-link {
                padding: 4px 8px;
                font-size: 11px;
                border-radius: 12px;
                min-height: 36px;
                display: flex;
                align-items: center;
                line-height: 1.2;
            }
            
             
            .filter-content {
                max-height: 0;
            }
            .filter-content.expanded {
                max-height: none;
                overflow-y: auto;
                max-height: 60vh;
            }
            
             
            .filter-input {
                font-size: 13px;
                padding: 6px 10px;
                margin-bottom: 10px;
            }
            
            .pagination { 
                flex-direction: column; 
                gap: 10px;
            }
            .pagination-numbers { 
                flex-wrap: wrap; 
                justify-content: center;
            }
        }
    </style>
</head>
<body>
    
<div class="container">
    <h1>Articles from Source: Nvidia-Developer-Blog</h1>
    
    <nav class="breadcrumb">
        <a href="/">‚Üê Back to all articles</a>
    </nav>
    
    
    <div class="articles-list">
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/nvidia-hpc-sdk-259-downloads#new_tab" target="_blank">Just Released: NVIDIA HPC SDK v25.9</a></h2>
            <div class="publication-date">2025-09-25 22:36</div>
            <div class="summary">üöÄ Just announced: NVIDIA has released the HPC SDK v25.9! This update brings support for CUDA 13.0, along with various updated library components, bug fixes, and performance enhancements. Download options are available for different target platforms. Make sure to review the installation instructions carefully! #NVIDIA #HPCSDK #CUDA #TechNews #SoftwareUpdate</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Heidi Poxon</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/r2d2-three-neural-breakthroughs-transforming-robot-learning-from-nvidia-research/" target="_blank">R¬≤D¬≤: Three Neural Breakthroughs Transforming Robot Learning from NVIDIA Research</a></h2>
            <div class="publication-date">2025-09-25 18:47</div>
            <div class="summary">üåê Exciting advancements in robot learning are highlighted in NVIDIA&#39;s R¬≤D¬≤ edition. Today‚Äôs robots excel in controlled environments but face challenges with real-world unpredictability and dexterity. Traditional approaches are limited, struggling with complex dynamics and translating human demonstrations. NVIDIA introduces three neural innovations: 1Ô∏è‚É£ **NeRD**: Enhances simulation with learned dynamics for better task generalization. 2Ô∏è‚É£ **Dexplore**: Achieves human-level dexterity using...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Rishabh Chadha</div>
            
            
            <div class="categories">
                
                <a href="/categories/technical_deep_dives" class="category-text">Technical Deep Dives</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/how-to-integrate-computer-vision-pipelines-with-generative-ai-and-reasoning/" target="_blank">How to Integrate Computer Vision Pipelines with Generative AI and Reasoning</a></h2>
            <div class="publication-date">2025-09-25 16:42</div>
            <div class="summary">üöÄ Generative AI is transforming video analytics, moving beyond simple object counting to real-time insights from video streams. üîç The NVIDIA AI Blueprint for Video Search and Summarization (VSS) integrates advanced technologies, enhancing video understanding for both stored and live content. üìà The recent VSS Blueprint 2.4 update includes major enhancements such as: 1. Improved physical world understanding with NVIDIA Cosmos Reason. 2. Enhanced Q&amp;A capabilities with cross-camera support. 3....</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Samuel Ochoa</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/how-to-gpu-accelerate-model-training-with-cuda-x-data-science/" target="_blank">How to GPU-Accelerate Model Training with CUDA-X Data Science</a></h2>
            <div class="publication-date">2025-09-25 16:30</div>
            <div class="summary">Unlock the potential of machine learning in manufacturing with GPU-accelerated model training! üöÄ This article discusses best practices for training models on structured manufacturing data. Tree-based models, like XGBoost, LightGBM, and CatBoost, are highlighted for their performance and interpretability. üìä Using GPU acceleration can significantly enhance training workflows, allowing for rapid iteration on hyperparameters. Explore how these methods can lead to improved yields and actionable...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Divyansh Jain</div>
            
            
            <div class="categories">
                
                <a href="/categories/educational" class="category-text">Educational</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/nvidia-open-sources-audio2face-animation-model/" target="_blank">NVIDIA Open Sources Audio2Face Animation Model</a></h2>
            <div class="publication-date">2025-09-24 17:00</div>
            <div class="summary">NVIDIA has announced the open sourcing of its Audio2Face technology, aimed at enhancing the creation of lifelike 3D avatars. üéÆü§ñ This innovation utilizes generative AI to animate characters&#39; faces in real-time based on audio input, ensuring realistic lip-sync and emotional expressions. üìäüé§ The technology can be applied in various fields, from gaming to customer service, making interactions more engaging. #NVIDIA #Audio2Face #GenerativeAI #3DAnimation #TechInnovation</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Ike Nnoli</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/deploy-ai-models-faster-with-windows-ml-on-rtx-pcs/" target="_blank">Deploy High-Performance AI Models in Windows Applications on NVIDIA RTX AI PCs</a></h2>
            <div class="publication-date">2025-09-23 19:20</div>
            <div class="summary">üöÄ Microsoft has launched Windows ML for developers, enabling C#, C&#43;&#43;, and Python programmers to efficiently run AI models on PCs. üñ•Ô∏è This tool supports various hardware types, including CPU, NPU, and GPUs. On NVIDIA RTX GPUs, it leverages TensorRT for optimal AI inference performance. üìä Windows ML simplifies dependency management and helps developers build scalable AI applications seamlessly. #Microsoft #WindowsML #AI #NVIDIA #DeveloperTools</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Maximilian M√ºller</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/faster-training-throughput-in-fp8-precision-with-nvidia-nemo/" target="_blank">Faster Training Throughput in FP8 Precision with NVIDIA NeMo</a></h2>
            <div class="publication-date">2025-09-23 16:36</div>
            <div class="summary">Unlocking faster training throughput in FP8 precision with NVIDIA NeMo is the focus of the latest insights. üöÄ The article discusses the benefits of FP8 training, emphasizing real-world speed improvements and potential overheads. It compares various FP8 scaling recipes using NVIDIA GPUs, assessing efficiency, stability, and scalability across large models. Reducing numerical precision to 8 bits enhances computational efficiency, lowers costs, and diminishes communication overhead in...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Karin Sevegnani</div>
            
            
            <div class="categories">
                
                <a href="/categories/technical_deep_dives" class="category-text">Technical Deep Dives</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/how-to-accelerate-community-detection-in-python-using-gpu-powered-leiden/" target="_blank">How to Accelerate Community Detection in Python Using GPU-Powered Leiden</a></h2>
            <div class="publication-date">2025-09-23 16:30</div>
            <div class="summary">üöÄ Community detection algorithms are vital for uncovering hidden relationships in networks. The Leiden algorithm, a popular choice among data scientists, offers improved performance for large-scale graphs in Python. üñ•Ô∏è With GPU acceleration from cuGraph, Leiden can be up to 47x faster than traditional CPU methods, making it suitable for real-world applications across various fields, including social network analysis, recommendation systems, and genomics. üîç This article explores Leiden&#39;s...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Rick Ratzel</div>
            
            
            <div class="categories">
                
                <a href="/categories/educational" class="category-text">Educational</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/build-a-real-time-visual-inspection-pipeline-with-nvidia-tao-6-and-nvidia-deepstream-8/" target="_blank">Build a Real-Time Visual Inspection Pipeline with NVIDIA TAO 6 and NVIDIA DeepStream 8</a></h2>
            <div class="publication-date">2025-09-23 16:00</div>
            <div class="summary">üöÄ Building a visual inspection pipeline for defect detection can be challenging. Manufacturers often struggle with model customization, optimization for edge devices, and real-time deployment. NVIDIA Metropolis offers solutions through its tools like TAO 6 for fine-tuning models and DeepStream 8 for streaming analytics. These resources help streamline the entire process. üìä Learn how to effectively implement these technologies to enhance quality control in your workflows. #NVIDIA #AI...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Varun Praveen</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/reasoning-through-molecular-synthetic-pathways-with-generative-ai/" target="_blank">Reasoning Through Molecular Synthetic Pathways with Generative AI</a></h2>
            <div class="publication-date">2025-09-23 15:30</div>
            <div class="summary">üåç In molecular design, synthesizing viable molecules is a major challenge. Assessing synthesizability often involves mapping complex synthesis pathways. üî¨ NVIDIA&#39;s ReaSyn model addresses this by predicting molecular synthesis pathways using a novel approach that combines chain-of-thought reasoning with test-time search methods. üß™ This framework treats synthetic pathways as sequences of reactions, helping chemists deduce effective routes to valuable target molecules. #MolecularDesign...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Seul Lee</div>
            
            
            <div class="categories">
                
                <a href="/categories/technical_deep_dives" class="category-text">Technical Deep Dives</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/build-a-rag-agent-with-nvidia-nemotron/" target="_blank">Build a Retrieval-Augmented Generation (RAG) Agent with NVIDIA Nemotron</a></h2>
            <div class="publication-date">2025-09-23 15:00</div>
            <div class="summary">Discover how to build a Retrieval-Augmented Generation (RAG) agent using NVIDIA Nemotron! This self-paced workshop covers the principles of agentic RAG, enabling systems to make decisions and adapt effectively. You&#39;ll learn to create your customized RAG system with LangGraph and access a portable development environment. Join the journey towards advanced text generation! üöÄüíª #NVIDIA #RAG #AI #MachineLearning #TechWorkshop</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Edward Li</div>
            
            
            <div class="categories">
                
                <a href="/categories/educational" class="category-text">Educational</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/predict-extreme-weather-events-in-minutes-without-a-supercomputer/" target="_blank">Predict Extreme Weather Events in Minutes Without a Supercomputer</a></h2>
            <div class="publication-date">2025-09-19 19:19</div>
            <div class="summary">üåßÔ∏è Scientists from NVIDIA and Lawrence Berkeley National Laboratory have launched a new machine learning tool called Huge Ensembles (HENS) for predicting extreme weather events. This tool delivers supercomputer-level forecasts with lower computational costs. HENS can predict high-impact weather events, offering forecasts from 6 hours up to 14 days ahead. ‚è±Ô∏è Utilizing 40 years of climate data, HENS can analyze vast amounts of weather patterns quickly, aiming to assist climate scientists and...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Mike Pritchard</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/nvidia-hgx-b200-reduces-embodied-carbon-emissions-intensity/" target="_blank">NVIDIA HGX B200 Reduces Embodied Carbon Emissions Intensity</a></h2>
            <div class="publication-date">2025-09-19 16:30</div>
            <div class="summary">üöÄ NVIDIA has unveiled the HGX B200, a game-changer in accelerated computing. This new platform shows a 24% reduction in embodied carbon emissions compared to its predecessor, the HGX H100. It achieves this through enhanced AI performance and energy efficiency. üå± With upgraded Blackwell B200 GPUs and significant memory improvements, the HGX B200 offers faster throughput and lower energy use for AI workloads. For more insights, check the latest product carbon footprint data! #NVIDIA...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Zoe Kessler</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/" target="_blank">The Kaggle Grandmasters Playbook: 7 Battle-Tested Modeling Techniques for Tabular Data</a></h2>
            <div class="publication-date">2025-09-18 17:29</div>
            <div class="summary">Unlock the secrets of Kaggle competitions with the &#34;Kaggle Grandmasters Playbook&#34;! üìä‚ú® This playbook outlines 7 proven techniques for tackling tabular data challenges, emphasizing fast experimentation and robust validation. By leveraging GPU acceleration, you can enhance your modeling process effectively. Key highlights include: - **Fast Experimentation:** Optimize your pipeline for speed to uncover patterns quickly. - **Local Validation:** Use k-fold cross-validation for reliable performance...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Kazuki Onodera</div>
            
            
            <div class="categories">
                
                <a href="/categories/educational" class="category-text">Educational</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/how-to-reduce-kv-cache-bottlenecks-with-nvidia-dynamo/" target="_blank">How to Reduce KV Cache Bottlenecks with NVIDIA Dynamo</a></h2>
            <div class="publication-date">2025-09-18 16:30</div>
            <div class="summary">As AI models expand, managing inference has become a significant challenge due to the Key-Value (KV) Cache requirements. üß† The KV Cache stores crucial attention data but grows with prompt length, leading to bottlenecks in GPU memory. This can affect performance and increase costs. üí∞ NVIDIA Dynamo&#39;s latest release addresses this by offloading the KV Cache to more affordable storage, enabling faster access without disrupting inference. ‚ö° Explore how these optimizations can enhance user...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Amr Elmeleegy</div>
            
            
            <div class="categories">
                
                <a href="/categories/technical_deep_dives" class="category-text">Technical Deep Dives</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/nvidia-rapids-25-08-adds-new-profiler-for-cuml-updates-to-the-polars-gpu-engine-additional-algorithm-support-and-more/" target="_blank">NVIDIA RAPIDS 25.08 Adds New Profiler for cuML, Updates to the Polars GPU Engine, Additional Algorithm Support, and More</a></h2>
            <div class="publication-date">2025-09-17 22:29</div>
            <div class="summary">üöÄ The latest RAPIDS 25.08 release enhances data science accessibility with several new features. üîç Two profiling tools for cuML have been added to help troubleshoot code performance. Users can now track GPU vs. CPU operations and their execution times. üìä Additionally, the Polars GPU engine now supports larger datasets, and new algorithms have been incorporated into cuML and cuml.accel. Learn more about these updates! #DataScience #NVIDIA #RAPIDS #MachineLearning #GPU</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Brian Tepera</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/an-introduction-to-speculative-decoding-for-reducing-latency-in-ai-inference/" target="_blank">An Introduction to Speculative Decoding for Reducing Latency in AI Inference</a></h2>
            <div class="publication-date">2025-09-17 18:09</div>
            <div class="summary">üöÄ Speculative decoding is a key technique for reducing latency in AI inference with large language models (LLMs). It addresses the bottleneck caused by the sequential nature of autoregressive generation, which can lead to underutilization of GPU power. By predicting multiple tokens at once, it enhances efficiency without sacrificing output quality. This method pairs a target model with a lightweight draft mechanism to speed up text generation, making AI systems more responsive. Explore how...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Jamie Li</div>
            
            
            <div class="categories">
                
                <a href="/categories/technical_deep_dives" class="category-text">Technical Deep Dives</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://github.com/NVIDIA/warp/releases/tag/v1.9.0#new_tab" target="_blank">Just Released: Warp 1.9</a></h2>
            <div class="publication-date">2025-09-16 20:51</div>
            <div class="summary">üöÄ Just released: Warp 1.9! This update brings support for CUDA 13.0, enhancing compatibility and performance. Additionally, new functions for the ahead-of-time compilation module have been introduced, broadening development capabilities. Stay tuned for more updates! üîßüíª #Warp19 #CUDA #NVIDIA #TechUpdate #Programming</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Bhoomi Gadhia</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/reducing-cold-start-latency-for-llm-inference-with-nvidia-runai-model-streamer/" target="_blank">Reducing Cold Start Latency for LLM Inference with NVIDIA Run:ai Model Streamer</a></h2>
            <div class="publication-date">2025-09-16 17:35</div>
            <div class="summary">üöÄ Deploying large language models (LLMs) can be challenging due to cold start delays, which hinder performance and scalability. üñ•Ô∏è The article discusses the NVIDIA Run:ai Model Streamer, an open-source SDK that reduces loading times by concurrently streaming model weights into GPU memory. üìä Benchmark tests show significant improvements in cold start latency, especially in cloud environments, while maintaining compatibility with Safetensor formats. #AI #MachineLearning #NVIDIA #Inference...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Omer Dayan</div>
            
            
            <div class="categories">
                
                <a href="/categories/technical_deep_dives" class="category-text">Technical Deep Dives</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/whats-new-in-pynvvideocodec-2-0-for-python-gpu-accelerated-video-processing/" target="_blank">What‚Äôs New in PyNvVideoCodec 2.0 for Python GPU-Accelerated Video Processing</a></h2>
            <div class="publication-date">2025-09-16 17:32</div>
            <div class="summary">üöÄ Exciting news for video processing developers! PyNvVideoCodec 2.0 is an upgraded NVIDIA library for GPU-accelerated video encoding, decoding, and transcoding using Python. This lightweight, easy-to-install library offers performance on par with the native SDK. It supports projects in video analytics, AI preprocessing, media transcoding, and real-time streaming, combining the speed of C&#43;&#43; with the ease of Python. Discover the enhanced features and performance improvements in this latest...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Abhijit Patait</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/autodesk-research-brings-warp-speed-to-computational-fluid-dynamics-on-nvidia-gh200/" target="_blank">Autodesk Research Brings Warp Speed to Computational Fluid Dynamics on NVIDIA GH200</a></h2>
            <div class="publication-date">2025-09-16 15:00</div>
            <div class="summary">üöÄ Autodesk Research has made strides in computational fluid dynamics (CFD) with its Accelerated Lattice Boltzmann (XLB) library. This open-source solver bridges the gap between traditional CAE and AI/ML ecosystems. By leveraging NVIDIA Warp and the GH200 Superchip, XLB achieves an ~8x speedup in performance, allowing for high-fidelity simulations at scale. This advancement demonstrates the potential of Python in high-performance scenarios. #CFD #AutodeskResearch #NVIDIAWarp...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Mehdi Ataei</div>
            
            
            <div class="categories">
                
                <a href="/categories/technical_deep_dives" class="category-text">Technical Deep Dives</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/build-a-report-generator-ai-agent-with-nvidia-nemotron-on-openrouter/" target="_blank">Build a Report Generator AI Agent with NVIDIA Nemotron on OpenRouter</a></h2>
            <div class="publication-date">2025-09-15 19:31</div>
            <div class="summary">üöÄ Discover how to build an AI report generator with NVIDIA Nemotron! This self-paced workshop covers essential topics including the four core considerations for AI agents, creating a document generation agent, and utilizing LangGraph and OpenRouter. Participants will have access to a portable development environment and can share their customized agents as NVIDIA Launchables. #AI #NVIDIA #MachineLearning #OpenSource #TechWorkshop</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Edward Li</div>
            
            
            <div class="categories">
                
                <a href="/categories/educational" class="category-text">Educational</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/new-open-source-qwen3-next-models-preview-hybrid-moe-architecture-delivering-improved-accuracy-and-accelerated-parallel-processing-across-nvidia-platform/" target="_blank">New Open Source Qwen3-Next Models Preview Hybrid MoE Architecture Delivering Improved Accuracy and Accelerated Parallel Processing across NVIDIA Platform</a></h2>
            <div class="publication-date">2025-09-15 13:00</div>
            <div class="summary">üöÄ Alibaba has unveiled two new open-source models: Qwen3-Next 80B-A3B-Thinking and Qwen3-Next 80B-A3B-Instruct. These models feature a hybrid Mixture of Experts (MoE) architecture designed for improved efficiency and accuracy. üîç The Qwen3-Next-80B-A3B-Thinking model is now available on build.nvidia.com, allowing developers to explore its advanced reasoning capabilities. üí° With 80 billion parameters, only a fraction is activated per token, optimizing processing for longer context lengths. The...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Anu Srivastava</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/modeling-attacks-on-ai-powered-apps-with-the-ai-kill-chain-framework/" target="_blank">Modeling Attacks on AI-Powered Apps with the AI Kill Chain Framework</a></h2>
            <div class="publication-date">2025-09-11 16:00</div>
            <div class="summary">AI-powered applications are facing new security challenges that traditional models may not address. The AI Kill Chain framework, developed by NVIDIA, outlines how adversaries target these systems. This framework emphasizes the stages of an attack: recon, poison, hijack, persist, and impact. It aims to help defenders identify where they can intervene effectively. Learn more about the evolving landscape of AI security! üîêüíªüõ°Ô∏è #AI #CyberSecurity #NVIDIA #AIKillChain #TechTrends</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Rich Harang</div>
            
            
            <div class="categories">
                
                <a href="/categories/security_compliance" class="category-text">Security Compliance</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/how-quantization-aware-training-enables-low-precision-accuracy-recovery/" target="_blank">How Quantization Aware Training Enables Low-Precision Accuracy Recovery</a></h2>
            <div class="publication-date">2025-09-11 15:00</div>
            <div class="summary">Optimizing AI models for deployment involves various compression techniques. Post-training quantization (PTQ) is common, but quantization aware training (QAT) and quantization aware distillation (QAD) provide significant advantages. These methods prepare models for lower precision by simulating quantization effects, enhancing accuracy recovery. Learn more about these techniques and their impact on model performance! üìäü§ñ #AI #Quantization #MachineLearning #ModelOptimization #TechTrends</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Eduardo Alvarez</div>
            
            
            <div class="categories">
                
                <a href="/categories/technical_deep_dives" class="category-text">Technical Deep Dives</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/accelerate-protein-structure-inference-over-100x-with-nvidia-rtx-pro-6000-blackwell-server-edition/" target="_blank">Accelerate Protein Structure Inference Over 100x with NVIDIA RTX PRO 6000 Blackwell Server Edition</a></h2>
            <div class="publication-date">2025-09-10 16:48</div>
            <div class="summary">Unlocking the future of protein structure analysis is now possible with the NVIDIA RTX PRO 6000 Blackwell Server Edition. This new GPU significantly accelerates protein structure inference, enhancing research efficiency and reducing costs for organizations. üß¨üíª With advancements from NVIDIA&#39;s Digital Biology Research labs, researchers can now utilize OpenFold for rapid analysis without sacrificing accuracy compared to AlphaFold2. Discover how this technology can transform large-scale protein...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Kyle Tretina</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/deploy-scalable-ai-inference-with-nvidia-nim-operator-3-0-0/" target="_blank">Deploy Scalable AI Inference with NVIDIA NIM Operator 3.0.0</a></h2>
            <div class="publication-date">2025-09-10 16:30</div>
            <div class="summary">Unlock the potential of AI with NVIDIA NIM Operator 3.0.0! üöÄ This latest release enhances the deployment of NVIDIA NIM and NeMo microservices in Kubernetes environments, making it easier to manage complex AI inference pipelines. Key features include efficient resource utilization and seamless integration with existing infrastructures, including KServe. ü§ñ Collaboration with Red Hat further streamlines NIM deployment, supporting model caching and trusted AI capabilities. #NVIDIA #AI #Kubernetes...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Meenakshi Kaushik</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/developers-can-now-get-cuda-directly-from-their-favorite-third-party-platforms/" target="_blank">Developers Can Now Get CUDA Directly from Their Favorite Third-Party Platforms</a></h2>
            <div class="publication-date">2025-09-10 16:00</div>
            <div class="summary">üöÄ Developers can now access CUDA directly through popular third-party platforms, making application deployment easier. NVIDIA is collaborating with Canonical, CIQ, and others to simplify installation and maintain compatibility across various OS and package managers. This initiative helps streamline the integration of GPU support in applications like PyTorch and OpenCV. Key benefits include consistent CUDA naming, timely updates, and continued free access to CUDA. #NVIDIA #CUDA #DeveloperTools...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Jonathan Bentz</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/maximizing-low-latency-networking-performance-for-financial-services-with-nvidia-rivermax-and-neio-fastsocket/" target="_blank">Maximizing Low-Latency Networking Performance for Financial Services with NVIDIA Rivermax and NEIO FastSocket</a></h2>
            <div class="publication-date">2025-09-10 16:00</div>
            <div class="summary">Ultra-low latency and reliable packet delivery are essential in sectors like financial services, cloud gaming, and media. Delays or packet losses can lead to significant issues, including financial losses and poor user experiences. NVIDIA Rivermax offers a high-performance solution for these challenges. It utilizes GPU-accelerated technologies to ensure high throughput, low latency, and minimal CPU usage, making it ideal for demanding applications. Learn more about how Rivermax is...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Simon Raviv</div>
            
            
            <div class="categories">
                
                <a href="/categories/technical_deep_dives" class="category-text">Technical Deep Dives</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/how-to-connect-distributed-data-centers-into-large-ai-factories-with-scale-across-networking/" target="_blank">How to Connect Distributed Data Centers Into Large AI Factories with Scale-Across Networking</a></h2>
            <div class="publication-date">2025-09-09 17:00</div>
            <div class="summary">AI scaling faces challenges due to physical limitations in data centers, such as power and cooling capacity. üåê Traditional long-haul Ethernet solutions can lead to high latency and unpredictable data delivery, which is problematic for AI workloads. NVIDIA&#39;s Spectrum-XGS Ethernet technology introduces scale-across networking, allowing multiple data centers to function as one large AI factory, enhancing performance for training and inference tasks. üöÄ #ArtificialIntelligence #DataCenters...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Taylor Allison</div>
            
            
            <div class="categories">
                
                <a href="/categories/technical_deep_dives" class="category-text">Technical Deep Dives</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/nvidia-blackwell-ultra-sets-new-inference-records-in-mlperf-debut/" target="_blank">NVIDIA Blackwell Ultra Sets New Inference Records in MLPerf Debut</a></h2>
            <div class="publication-date">2025-09-09 15:00</div>
            <div class="summary">üöÄ NVIDIA&#39;s Blackwell Ultra architecture has made a significant impact in the latest MLPerf Inference v5.1 benchmarks. New models like DeepSeek-R1 and Llama 3.1 have set high performance standards, with impressive token processing speeds. The benchmarks highlight the growing need for advanced compute power as large language models evolve. NVIDIA continues to lead with record-breaking results across all tested scenarios. #NVIDIA #MLPerf #AI #MachineLearning #TechNews</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Ashwin Nanjappa</div>
            
            
            <div class="categories">
                
                <a href="/categories/industry_analysis" class="category-text">Industry Analysis</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/nvidia-rubin-cpx-accelerates-inference-performance-and-efficiency-for-1m-token-context-workloads/" target="_blank">NVIDIA Rubin CPX Accelerates Inference Performance and Efficiency for 1M&#43; Token Context Workloads</a></h2>
            <div class="publication-date">2025-09-09 15:00</div>
            <div class="summary">NVIDIA is addressing the increasing complexity of AI inference with its new Rubin CPX GPU. This technology supports workloads requiring extensive context, like software development and long-form video generation. The NVIDIA SMART framework optimizes inference across various dimensions, allowing for better resource allocation. This disaggregated approach separates the context and generation phases, improving efficiency and reducing latency. Discover how NVIDIA is redefining AI infrastructure....</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Joe DeLaere</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/how-to-build-ai-systems-in-house-with-outerbounds-and-dgx-cloud-lepton/" target="_blank">How to Build AI Systems In House with Outerbounds and DGX Cloud Lepton</a></h2>
            <div class="publication-date">2025-09-08 16:00</div>
            <div class="summary">Building production-grade AI systems involves managing numerous components. Companies are increasingly opting to develop in-house solutions for better security and compliance. Outerbounds offers a cloud-native platform that simplifies this process, utilizing open-source Metaflow for efficient orchestration. Key to success is leveraging NVIDIA DGX Cloud Lepton for GPU access, enabling scalable AI operations. Explore how to create customized AI products while navigating the complex GPU cloud...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Ville Tuulos</div>
            
            
            <div class="categories">
                
                <a href="/categories/educational" class="category-text">Educational</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://nvda.ws/4g1w81S" target="_blank">Register for the Global Webinar: How to Prepare for NVIDIA Generative AI Certification</a></h2>
            <div class="publication-date">2025-09-07 15:00</div>
            <div class="summary">üåç Join the global webinar on October 7 to learn how to prepare for the NVIDIA Generative AI Certification exams. Get insights into the new professional level certification and tips for success. Don&#39;t miss this opportunity to enhance your skills! #NVIDIA #GenerativeAI #Webinar #Certification #ProfessionalDevelopment</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Shara Tibken</div>
            
            
            <div class="categories">
                
                <a href="/categories/event" class="category-text">Event</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://www.nvidia.com/en-us/events/speech-ai-day/?nvid=nv-int-tblg-799133" target="_blank">Just Released: NVIDIA PhysicsNeMo 25.08</a></h2>
            <div class="publication-date">2025-09-05 17:37</div>
            <div class="summary">üöÄ Exciting news from NVIDIA! The latest release of PhysicsNeMo 25.08 introduces powerful workflows and recipes specifically designed for CAE application developers. This update aims to enhance simulations and streamline development processes. Explore the new features and boost your CAE projects with NVIDIA&#39;s advanced tools! #NVIDIA #PhysicsNeMo #CAE #TechUpdates #Simulation</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Bhoomi Gadhia</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://www.nvidia.com/en-us/events/speech-ai-day/?nvid=nv-int-tblg-799133" target="_blank">Just Released: NVIDIA PhysicsNeMo 25.08</a></h2>
            <div class="publication-date">2025-09-05 17:37</div>
            <div class="summary">üöÄ Exciting news for CAE developers! NVIDIA has just launched PhysicsNeMo 25.08, introducing new workflows and recipes designed to enhance application development. This update aims to streamline processes and improve efficiency in computational physics. Stay tuned for more advancements in simulation technology! #NVIDIA #PhysicsNeMo #CAE #TechUpdate #Simulation</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Bhoomi Gadhia</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/accelerate-large-scale-llm-inference-and-kv-cache-offload-with-cpu-gpu-memory-sharing/" target="_blank">Accelerate Large-Scale LLM Inference and KV Cache Offload with CPU-GPU Memory Sharing</a></h2>
            <div class="publication-date">2025-09-05 17:24</div>
            <div class="summary">Large Language Models (LLMs) like Llama 3 70B and Llama 4 Scout 109B are pushing AI boundaries but pose memory challenges for inference efficiency. These models can require significant memory, with Llama 3 needing around 140 GB and Llama 4 about 218 GB. The key-value (KV) cache also demands additional memory as context and batch sizes increase. NVIDIA&#39;s Grace Hopper and Blackwell architectures use NVLink-C2C, allowing CPU-GPU memory sharing. This innovation enhances data access and...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Afroze Syed</div>
            
            
            <div class="categories">
                
                <a href="/categories/technical_deep_dives" class="category-text">Technical Deep Dives</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/accelerate-large-scale-llm-inference-and-kv-cache-offload-with-cpu-gpu-memory-sharing/" target="_blank">Accelerate Large-Scale LLM Inference and KV Cache Offload with CPU-GPU Memory Sharing</a></h2>
            <div class="publication-date">2025-09-05 17:24</div>
            <div class="summary">Large Language Models (LLMs) like Llama 3 70B and Llama 4 Scout 109B face challenges with inference due to their size. These models can require significant memory, often exceeding GPU limits, especially with large context windows. The NVIDIA Grace architectures address this by utilizing NVLink C2C, allowing CPU and GPU to share memory efficiently. This setup enhances the processing of large datasets and enables quicker access, minimizing the risk of out-of-memory errors during inference....</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Afroze Syed</div>
            
            
            <div class="categories">
                
                <a href="/categories/technical_deep_dives" class="category-text">Technical Deep Dives</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/accelerate-large-scale-llm-inference-and-kv-cache-offload-with-cpu-gpu-memory-sharing/" target="_blank">Accelerate Large-Scale LLM Inference and KV Cache Offload with CPU-GPU Memory Sharing</a></h2>
            <div class="publication-date">2025-09-05 17:24</div>
            <div class="summary">Large Language Models (LLMs) like Llama 3 and Llama 4 are pushing AI boundaries, but their size poses challenges for inference efficiency. These models can require substantial GPU memory, often leading to out-of-memory errors during inference. The NVIDIA Grace architectures address this with NVLink C2C, offering a high-bandwidth connection that shares CPU and GPU memory. This innovation enhances processing capabilities, making it easier to handle large datasets and models. #AI #NVIDIA...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Afroze Syed</div>
            
            
            <div class="categories">
                
                <a href="/categories/technical_deep_dives" class="category-text">Technical Deep Dives</a>
                
            </div>
            
        </article>
        
        <article class="article-item">
            <h2><a href="https://developer.nvidia.com/blog/accelerate-autonomous-vehicle-development-with-the-nvidia-drive-agx-thor-developer-kit/" target="_blank">Accelerate Autonomous Vehicle Development with the NVIDIA DRIVE AGX Thor Developer Kit</a></h2>
            <div class="publication-date">2025-09-03 17:30</div>
            <div class="summary">üöóüîç The NVIDIA DRIVE AGX Thor Developer Kit is now available, enhancing the development of autonomous vehicle technology. This platform supports advanced AI models for better perception and decision-making, enabling a comprehensive in-vehicle experience. With powerful Blackwell GPUs and next-gen Arm CPUs, it meets high safety and security standards. The DRIVE AGX Thor is designed to empower automotive OEMs and developers in scaling performance and efficiency for future demands. #NVIDIA...</div>
            <div class="source">Source: Nvidia Developer Blog</div>
            
            <div class="author">Abhinaw Priyadershi</div>
            
            
            <div class="categories">
                
                <a href="/categories/product_announcements" class="category-text">Product Announcements</a>
                
            </div>
            
        </article>
        
    </div>
    
    
    <nav class="pagination">
        
        <a href="/sources/nvidia-developer-blog/page/3/" class="pagination-link">&laquo; Previous</a>
        
        
        <div class="pagination-numbers">
            
            
            <a href="/sources/nvidia-developer-blog/" class="pagination-link">1</a>
            
            
            
            <a href="/sources/nvidia-developer-blog/page/2/" class="pagination-link">2</a>
            
            
            
            <a href="/sources/nvidia-developer-blog/page/3/" class="pagination-link">3</a>
            
            
            
            <span class="pagination-current">4</span>
            
            
            
            <a href="/sources/nvidia-developer-blog/page/5/" class="pagination-link">5</a>
            
            
            
            <a href="/sources/nvidia-developer-blog/page/6/" class="pagination-link">6</a>
            
            
        </div>
        
        
        <a href="/sources/nvidia-developer-blog/page/5/" class="pagination-link">Next &raquo;</a>
        
    </nav>
    
</div>

    
    <footer class="site-footer">
        <div class="container">
            <p class="footer-text">
                Contents ¬© 2025 <a href="#" id="author-email" class="author-link">Micha≈Ç Rutkowski</a>
            </p>
        </div>
    </footer>
    <script>
        
        document.addEventListener('DOMContentLoaded', function() {
            function fixEmojiEncoding(text) {
                
                var fixed = text
                    
                    .replace(/√∞ÔøΩÔøΩÔøΩ/g, 'üöÄ')  
                    .replace(/√∞ÔøΩÔøΩ¬ª/g, 'üë®‚Äçüíª')  
                    .replace(/√∞ÔøΩÔøΩÔøΩ/g, 'üéØ')  
                    .replace(/√∞ÔøΩÔøΩ¬ß/g, 'üîß')  
                    .replace(/√∞ÔøΩÔøΩ¬°/g, 'üí°')  
                    .replace(/√∞ÔøΩÔøΩÔøΩ/g, 'üîí')  
                    .replace(/√∞ÔøΩÔøΩ¬°√Ø¬∏ÔøΩ/g, 'üõ°Ô∏è')  
                    .replace(/√∞ÔøΩÔøΩÔøΩ√Ø¬∏ÔøΩ/g, '‚öóÔ∏è')  
                    .replace(/√∞ÔøΩÔøΩ¬¨/g, 'üöÄ')  
                    .replace(/√∞ÔøΩÔøΩÔøΩ/g, 'üìä')  
                    .replace(/√∞ÔøΩÔøΩ/g, 'üìà')  
                    .replace(/√∞ÔøΩ¬§ÔøΩ/g, 'ü§ñ')  
                    
                    
                    .replace(/√∞/g, 'üöÄ')     
                    
                    
                    .replace(/ÔøΩ/g, '');     
                
                return fixed;
            }
            
            
            function fixAllText(element) {
                if (element.nodeType === Node.TEXT_NODE) {
                    var original = element.textContent;
                    
                    if (original.includes('√∞') || original.includes('ÔøΩ')) {
                        var fixed = fixEmojiEncoding(original);
                        if (fixed !== original) {
                            element.textContent = fixed;
                        }
                    }
                } else {
                    for (var i = 0; i < element.childNodes.length; i++) {
                        fixAllText(element.childNodes[i]);
                    }
                }
            }
            
            
            fixAllText(document.body);
        });
        
        
        function toggleFilter(sectionId) {
            const content = document.getElementById(sectionId + '-content');
            const toggle = document.getElementById(sectionId + '-toggle');
            
            if (content.classList.contains('collapsed')) {
                content.classList.remove('collapsed');
                content.classList.add('expanded');
                toggle.textContent = '‚ñ≤';
                toggle.style.transform = 'rotate(180deg)';
            } else {
                content.classList.remove('expanded');
                content.classList.add('collapsed');
                toggle.textContent = '‚ñº';
                toggle.style.transform = 'rotate(0deg)';
            }
        }
        
        
        document.addEventListener('DOMContentLoaded', function() {
            function checkScreenSize() {
                const isMobile = window.innerWidth <= 768;
                const categoriesContent = document.getElementById('categories-content');
                const sourcesContent = document.getElementById('sources-content');
                const categoriesToggle = document.getElementById('categories-toggle');
                const sourcesToggle = document.getElementById('sources-toggle');
                
                if (categoriesContent && sourcesContent) {
                    if (isMobile) {
                        
                        categoriesContent.classList.add('collapsed');
                        categoriesContent.classList.remove('expanded');
                        sourcesContent.classList.add('collapsed');
                        sourcesContent.classList.remove('expanded');
                        categoriesToggle.textContent = '‚ñº';
                        sourcesToggle.textContent = '‚ñº';
                    } else {
                        
                        categoriesContent.classList.remove('collapsed');
                        categoriesContent.classList.add('expanded');
                        sourcesContent.classList.remove('collapsed');
                        sourcesContent.classList.add('expanded');
                        categoriesToggle.textContent = '‚ñ≤';
                        sourcesToggle.textContent = '‚ñ≤';
                    }
                }
            }
            
            
            checkScreenSize();
            window.addEventListener('resize', checkScreenSize);
            
            
            function cleanSourceNames() {
                const sourceLinks = document.querySelectorAll('.filter-options a[href*="/sources/"]');
                sourceLinks.forEach(link => {
                    if (link.textContent.includes('-Blog')) {
                        link.textContent = link.textContent.replace(/-Blog(\s*\(\d+\))?/g, '$1');
                    }
                });
            }
            
            
            cleanSourceNames();
            
            
            clearSourcesFilter();
            
            
            setupEmailLink();
        });
        
        
        function clearSourcesFilter() {
            const sourcesInput = document.getElementById('sources-filter');
            if (sourcesInput) {
                sourcesInput.value = '';
                
                filterSources();
            }
        }
        
        
        window.addEventListener('pageshow', function(event) {
            clearSourcesFilter();
        });
        
        
        function filterSources() {
            const input = document.getElementById('sources-filter');
            const filter = input.value.toLowerCase();
            const sourcesList = document.getElementById('sources-list');
            const links = sourcesList.getElementsByTagName('a');
            
            for (let i = 0; i < links.length; i++) {
                const link = links[i];
                const sourceName = link.getAttribute('data-source-name') || link.textContent;
                
                
                if (link.classList.contains('all-link')) {
                    continue;
                }
                
                if (sourceName.toLowerCase().indexOf(filter) > -1) {
                    link.style.display = '';
                } else {
                    link.style.display = 'none';
                }
            }
        }
        
        
        function setupEmailLink() {
            const emailLink = document.getElementById('author-email');
            if (emailLink) {
                
                const encodedEmail = 'aG9tZWVuZEB3cC5wbA==';
                
                
                const decodedEmail = atob(encodedEmail);
                const mailtoLink = 'mailto:' + decodedEmail;
                
                emailLink.href = mailtoLink;
                
                
                emailLink.addEventListener('click', function(e) {
                    
                });
            }
        }
    </script>
</body>
</html>
