<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Red-Hat-Developer-Blog on Daily Tech Articles Feed</title>
    <link>/sources/red-hat-developer-blog/</link>
    <description>Recent content in Red-Hat-Developer-Blog on Daily Tech Articles Feed</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 23 Dec 2025 08:01:03 +0000</lastBuildDate>
    <atom:link href="/sources/red-hat-developer-blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How in-place pod resizing boosts efficiency in OpenShift</title>
      <link>/articles/article-2025-12-23-14124/</link>
      <pubDate>Tue, 23 Dec 2025 08:01:03 +0000</pubDate>
      <guid>/articles/article-2025-12-23-14124/</guid>
      <description>üöÄ Red Hat OpenShift introduces in-place resource resizing, allowing users to adjust CPU and memory of running pods without recreating them. This feature enhances resource management, reducing downtime and operational complexity. üí° Available by default in OpenShift 4.20, it supports dynamic resource allocation based on real-time needs, leading to efficient usage and potential cost savings. üîß While beneficial, users should monitor for resource contention and ensure compatibility with container&amp;hellip;</description>
    </item>
    <item>
      <title>Automate Oracle 19c deployments on OpenShift Virtualization</title>
      <link>/articles/article-2025-12-22-14096/</link>
      <pubDate>Mon, 22 Dec 2025 07:16:13 +0000</pubDate>
      <guid>/articles/article-2025-12-22-14096/</guid>
      <description>üöÄ Automate your Oracle Database 19c deployments on OpenShift Virtualization! Installing Oracle can be complex, involving many manual steps and potential misconfigurations. However, with Red Hat Ansible Automation Platform, you can streamline the process. üñ•Ô∏è This automation reduces setup time, ensures consistent environments, and allows developers to manage their testing environments independently. For optimal results, use essential playbooks like &lt;code&gt;prepare_os.yml&lt;/code&gt; for VM provisioning and&amp;hellip;</description>
    </item>
    <item>
      <title>Monitoring OpenShift Gateway API and Service Mesh with Kiali</title>
      <link>/articles/article-2025-12-19-14041/</link>
      <pubDate>Fri, 19 Dec 2025 08:01:00 +0000</pubDate>
      <guid>/articles/article-2025-12-19-14041/</guid>
      <description>üöÄ In the latest article, we explore monitoring OpenShift Gateway API and Service Mesh using Kiali. üîß The guide covers how to configure Kiali for visibility into both OpenShift Gateway API components and service mesh workloads, providing a unified view of traffic flow. ‚ö†Ô∏è It highlights two main challenges: namespace discovery and GatewayClass validation, which can limit Kiali‚Äôs observability in dual-mesh environments. üìä Solutions are provided for proper configuration, enhancing monitoring&amp;hellip;</description>
    </item>
    <item>
      <title>Improve efficiency with OpenStack Services on OpenShift</title>
      <link>/articles/article-2025-12-19-14042/</link>
      <pubDate>Fri, 19 Dec 2025 08:00:57 +0000</pubDate>
      <guid>/articles/article-2025-12-19-14042/</guid>
      <description>üöÄ Enhance your cloud efficiency with the Red Hat OpenStack Services on OpenShift! This new workload optimization operator offers improved workload distribution, reducing hotspots and operational costs. It helps balance resources, leading to lower hardware needs and better performance. The OpenStack Workload Optimization (OWO) framework simplifies managing workloads, ensuring seamless operations. For installation details and more, explore the official documentation. #OpenStack #CloudComputing&amp;hellip;</description>
    </item>
    <item>
      <title>Quantum-secure gateways in Red Hat OpenShift Service Mesh 3.2</title>
      <link>/articles/article-2025-12-18-13990/</link>
      <pubDate>Thu, 18 Dec 2025 07:01:22 +0000</pubDate>
      <guid>/articles/article-2025-12-18-13990/</guid>
      <description>üåê The advancement of quantum computing poses risks to traditional cryptography. Red Hat OpenShift Service Mesh 3.2 introduces post-quantum cryptography (PQC) to enhance security against these threats. üîë Key algorithms like lattice-based and code-based cryptography are designed to resist both classical and quantum attacks. Migrating to AES-256 is recommended to safeguard symmetric encryption. üöÄ Organizations are urged to prepare now, as large-scale quantum computers may emerge in the next&amp;hellip;</description>
    </item>
    <item>
      <title>Deploy and customize JBoss Web Server on Red Hat OpenShift</title>
      <link>/articles/article-2025-12-18-13991/</link>
      <pubDate>Thu, 18 Dec 2025 07:01:19 +0000</pubDate>
      <guid>/articles/article-2025-12-18-13991/</guid>
      <description>üöÄ Learn how to deploy and customize the Red Hat JBoss Web Server (JWS) on OpenShift! This article covers installation, default settings, and customization options for JWS containers. üîç It also explains the JWS Operator, enabling easy deployment of JWS images. Key customization features include JVM options and garbage collection settings. üîß To explore more about JWS capabilities and configurations, check out the full article. #RedHat #OpenShift #JBoss #WebServer #CloudComputing</description>
    </item>
    <item>
      <title>What&#39;s new in network observability 1.10</title>
      <link>/articles/article-2025-12-17-13926/</link>
      <pubDate>Wed, 17 Dec 2025 08:16:07 +0000</pubDate>
      <guid>/articles/article-2025-12-17-13926/</guid>
      <description>üöÄ Exciting updates in network observability with version 1.10! This release is compatible with all supported OpenShift versions and introduces a simplified 4-step wizard for setting up FlowCollector and FlowMetric instances. It enhances visibility into network traffic through eBPF technology and provides tools for troubleshooting issues like packet drops and DNS errors. New features include technology previews for custom alerts and a network health dashboard, which helps monitor overall&amp;hellip;</description>
    </item>
    <item>
      <title>Fine-tune a RAG model with Feast and Kubeflow Trainer</title>
      <link>/articles/article-2025-12-17-13924/</link>
      <pubDate>Wed, 17 Dec 2025 07:15:57 +0000</pubDate>
      <guid>/articles/article-2025-12-17-13924/</guid>
      <description>üöÄ Learn how to enhance a RAG model with Feast and Kubeflow Trainer! This guide covers preprocessing the Natural Questions dataset, fine-tuning a RAG model with a custom Feast retriever, and scaling training on Red Hat OpenShift AI. Key steps include dual tokenization, validation checks, and joint training strategies for better performance. üîç Optimize your retrieval and generation components together for improved results! #RAGModel #MachineLearning #Feast #Kubeflow #AI</description>
    </item>
    <item>
      <title>Modern Kubernetes monitoring: Metrics, tools, and AIOps</title>
      <link>/articles/article-2025-12-17-13925/</link>
      <pubDate>Wed, 17 Dec 2025 07:15:54 +0000</pubDate>
      <guid>/articles/article-2025-12-17-13925/</guid>
      <description>Kubernetes monitoring is essential for managing today&amp;rsquo;s complex environments. Effective strategies enhance performance, reliability, and cost control. Key aspects include tracking various metrics like API server latency and container restart rates. AIOps integration aids in anomaly detection and proactive management. Open-source tools like Prometheus and Grafana are foundational for effective monitoring. Understanding cardinality and granularity in data management is crucial for cost&amp;hellip;</description>
    </item>
    <item>
      <title>Manage credentials with Tekton and OpenShift on IBM Cloud</title>
      <link>/articles/article-2025-12-16-13611/</link>
      <pubDate>Tue, 16 Dec 2025 15:03:39 +0000</pubDate>
      <guid>/articles/article-2025-12-16-13611/</guid>
      <description>üîí Securing CI/CD workflows is essential in cloud-native environments. This article discusses how to protect credentials and enforce compliance using Tekton Pipelines on Red Hat OpenShift on IBM Cloud. Key highlights include managing Kubernetes Secrets, integrating IBM Cloud Key Protect, and utilizing Tekton Chains for integrity. Effective security measures ensure secrets are injected only when needed, images are scanned, and unsafe deployments are blocked. Learn more about building a trusted&amp;hellip;</description>
    </item>
    <item>
      <title>Improve RAG retrieval and training with Feast and Kubeflow Trainer</title>
      <link>/articles/article-2025-12-16-13612/</link>
      <pubDate>Tue, 16 Dec 2025 07:01:17 +0000</pubDate>
      <guid>/articles/article-2025-12-16-13612/</guid>
      <description>üöÄ Retrieval Augmented Generation (RAG) enhances AI language models by combining them with external knowledge bases, improving accuracy and context. üîß The integration of Feast, an open-source feature store, with RAG optimizes feature management, ensuring consistent training and inference. üõ†Ô∏è Introducing the FeastRAGRetriever, which supports various search methods for better information retrieval and seamless integration with Hugging Face Transformers. #AIML #MLOps #DataScience #FeatureStore #RAG</description>
    </item>
    <item>
      <title>How to reduce false positives in security scans</title>
      <link>/articles/article-2025-12-15-13613/</link>
      <pubDate>Mon, 15 Dec 2025 08:00:59 +0000</pubDate>
      <guid>/articles/article-2025-12-15-13613/</guid>
      <description>üîç Running security scans on Python applications in Fedora or RHEL can lead to false positives. Scanners often flag backported, patched versions of setuptools or pip as vulnerable due to outdated version numbers. üöÄ To address this, Fedora Rawhide is now incorporating Software Bill of Materials (SBOM) information directly into Python wheels. This helps scanners identify the actual patched version, reducing false alerts. üì¢ Feedback from the developer community is welcomed to refine this feature&amp;hellip;.</description>
    </item>
    <item>
      <title>Set up FSx for NetApp ONTAP on Red Hat OpenShift Service on AWS</title>
      <link>/articles/article-2025-12-15-13614/</link>
      <pubDate>Mon, 15 Dec 2025 07:15:54 +0000</pubDate>
      <guid>/articles/article-2025-12-15-13614/</guid>
      <description>üöÄ Ready to deploy a high-availability storage backend on Red Hat OpenShift Service using Amazon FSx for NetApp ONTAP? This guide walks you through the setup process, covering both iSCSI and NFS configurations. Key prerequisites include administrative access to your ROSA cluster and the AWS Management Console. Follow the steps to create your FSx file system, configure security groups, and install the NetApp Trident Operator. For detailed instructions, check out the full article! üìñüîß #RedHat&amp;hellip;</description>
    </item>
    <item>
      <title>Optimizing cloud development environment storage: FSx for ONTAP</title>
      <link>/articles/article-2025-12-15-13615/</link>
      <pubDate>Mon, 15 Dec 2025 07:00:56 +0000</pubDate>
      <guid>/articles/article-2025-12-15-13615/</guid>
      <description>Optimizing storage for cloud development environments (CDE) is crucial for enhancing developer productivity and application resilience. This guide discusses key factors like volumeMode, Persistent Volume Claim (PVC) strategies, and storage protocols (iSCSI vs. NFS). It highlights how these choices impact performance and resiliency in setups like Red Hat OpenShift on AWS using FSx for NetApp ONTAP. By understanding these elements, teams can select the best configuration for their needs. üìäüíª&amp;hellip;</description>
    </item>
    <item>
      <title>JBoss EAP XP 6 is here</title>
      <link>/articles/article-2025-12-08-13545/</link>
      <pubDate>Mon, 08 Dec 2025 14:47:13 +0000</pubDate>
      <guid>/articles/article-2025-12-08-13545/</guid>
      <description>üöÄ Red Hat announces the general availability of JBoss EAP XP 6! This release enhances resilience across platforms and environments. Key features include upgrades to MicroProfile 7, support for MicroProfile LRA, and multi-app deployment capabilities. Developers can benefit from improved observability through integrated OpenTelemetry and standardized metrics collection with Prometheus. Start exploring these features today! #JBossEAP #Microservices #RedHat #DevOps #SoftwareDevelopment</description>
    </item>
    <item>
      <title>Manage your Camel fleet on OpenShift</title>
      <link>/articles/article-2025-12-08-13532/</link>
      <pubDate>Mon, 08 Dec 2025 08:16:13 +0000</pubDate>
      <guid>/articles/article-2025-12-08-13532/</guid>
      <description>üöÄ Manage your Camel fleet effortlessly on OpenShift! Apache Camel, a robust integration framework, now offers a dashboard to visualize all Camel workloads in a microservices architecture. This tool simplifies monitoring and provides immediate alerts for any issues. The dashboard enhances observability with minimal setup, allowing operators to track application health and performance metrics effectively. Learn more about setting up and managing your Camel applications today! #ApacheCamel&amp;hellip;</description>
    </item>
    <item>
      <title>Disconnected experiences for Red Hat Lightspeed are now available in Red Hat Satellite 6.18</title>
      <link>/articles/article-2025-12-08-13531/</link>
      <pubDate>Mon, 08 Dec 2025 07:16:13 +0000</pubDate>
      <guid>/articles/article-2025-12-08-13531/</guid>
      <description>üöÄ Red Hat Satellite 6.18 introduces Red Hat Lightspeed capabilities for disconnected environments. The advisor service offers assessments of RHEL infrastructure in key areas such as availability and security. Meanwhile, the vulnerability service helps identify at-risk systems using the CVE database. For efficient setup in air-gapped environments, installation involves container images from the Satellite ISO. For more information, check out the official documentation. #RedHat #Satellite&amp;hellip;</description>
    </item>
    <item>
      <title>Right-sizing recommendations for OpenShift Virtualization</title>
      <link>/articles/article-2025-12-05-13484/</link>
      <pubDate>Fri, 05 Dec 2025 08:01:22 +0000</pubDate>
      <guid>/articles/article-2025-12-05-13484/</guid>
      <description>üöÄ Red Hat has introduced right-sizing recommendations in a technology preview as part of the Advanced Cluster Management for Kubernetes 2.15 release. This feature helps users optimize CPU and memory allocation for improved performance and cost efficiency. In multicluster environments, managing resource efficiency is challenging. The right-sizing capability offers end-to-end observability across Cluster, Namespace, and Virtual Machine layers, integrated with OpenShift and Prometheus telemetry&amp;hellip;.</description>
    </item>
    <item>
      <title>OpenJDK 25 now available in Red Hat Enterprise Linux 10.1</title>
      <link>/articles/article-2025-12-04-13432/</link>
      <pubDate>Thu, 04 Dec 2025 16:07:16 +0000</pubDate>
      <guid>/articles/article-2025-12-04-13432/</guid>
      <description>üöÄ Red Hat Enterprise Linux (RHEL) 10.1 now features OpenJDK 25 LTS, enhancing startup performance, memory efficiency, and developer ergonomics. üîß This update supports developers until December 2030, offering a robust foundation for applications. Key improvements include better garbage collection and concurrency features. üì¶ To install, use: &lt;code&gt;sudo yum install java-25-openjdk&lt;/code&gt; #OpenJDK #RHEL #JavaDevelopment #RedHat #SoftwareUpdates</description>
    </item>
    <item>
      <title>Migrating Red Hat Ansible Automation Platform: From RPM to container on Red Hat Enterprise Linux</title>
      <link>/articles/article-2025-12-04-13433/</link>
      <pubDate>Thu, 04 Dec 2025 14:06:35 +0000</pubDate>
      <guid>/articles/article-2025-12-04-13433/</guid>
      <description>üöÄ Exciting changes are coming for Ansible Automation users! The migration from Red Hat Ansible Automation Platform 2.5 RPM on RHEL 9 to the containerized version on RHEL 10 is underway. This shift is essential as the RPM installation will be deprecated with the release of version 2.7. Key steps include preparing your current environment, creating backups, and setting up new VMs. For detailed guidance, refer to the release notes and ensure your components are ready for a seamless transition&amp;hellip;.</description>
    </item>
    <item>
      <title>Python 3.9 reaches end of life: What it means for RHEL users</title>
      <link>/articles/article-2025-12-04-13420/</link>
      <pubDate>Thu, 04 Dec 2025 08:01:22 +0000</pubDate>
      <guid>/articles/article-2025-12-04-13420/</guid>
      <description>üìÖ Python 3.9 has officially reached its end-of-life phase after five years of maintenance. üîç For RHEL users, Python 3.9 will continue to be supported on RHEL 9 throughout its lifecycle, providing critical patches and security updates. üìå Users on RHEL 8 will see support for Python 3.9 end in November 2025, with newer versions like Python 3.11 and 3.12 available for those needing upgrades. üíª Consider RHEL 9-based container images for ongoing Python 3.9 workloads. #Python #RHEL #EndOfLife&amp;hellip;</description>
    </item>
    <item>
      <title>Upgrade air-gapped OpenShift with self-signed certificates</title>
      <link>/articles/article-2025-12-03-13299/</link>
      <pubDate>Wed, 03 Dec 2025 08:00:58 +0000</pubDate>
      <guid>/articles/article-2025-12-03-13299/</guid>
      <description>Upgrading a disconnected Red Hat OpenShift cluster involves unique challenges, particularly in certificate management. This guide details a step-by-step process to upgrade using self-signed certificates, ensuring your cluster trusts these certificates during the upgrade. Key steps include installing the Cincinnati operator, applying mirrored release signatures, and configuring access to your private registry. For a smooth upgrade experience, establish a complete chain of trust within your&amp;hellip;</description>
    </item>
    <item>
      <title>Tame Ray workloads on OpenShift AI with KubeRay and Kueue</title>
      <link>/articles/article-2025-12-03-13298/</link>
      <pubDate>Wed, 03 Dec 2025 07:15:59 +0000</pubDate>
      <guid>/articles/article-2025-12-03-13298/</guid>
      <description>üöÄ Managing AI workloads on Kubernetes just got easier! Red Hat OpenShift AI 3 introduces KubeRay and Kueue to tackle resource management issues. This integration allows for priority-driven scheduling and efficient resource control for Ray workloads. Key workflows include: - Long-running RayClusters for interactive development - Quick-iteration jobs for rapid testing - Ephemeral clusters for automated job management Data scientists can now manage resources seamlessly with the CodeFlare SDK&amp;hellip;.</description>
    </item>
    <item>
      <title>Run Mistral Large 3 &amp; Ministral 3 on vLLM with Red Hat AI on Day 0: A step-by-step guide</title>
      <link>/articles/article-2025-12-02-13262/</link>
      <pubDate>Tue, 02 Dec 2025 19:03:40 +0000</pubDate>
      <guid>/articles/article-2025-12-02-13262/</guid>
      <description>üöÄ Mistral has launched Mistral Large 3 and the Ministral 3 family under Apache 2, offering open-source checkpoints for developers. üîç Mistral Large 3 features sparse MoE with optimized low precision variants. The Ministral 3 models come in 3B, 8B, and 14B sizes, supporting multilingual and multimodal inputs. üîß With vLLM and Red Hat AI, users can access these models on Day 0 for immediate deployment without custom integrations. #MistralAI #OpenSource #AIModels #RedHatAI #vLLM</description>
    </item>
    <item>
      <title>Run cost-effective AI workloads on OpenShift with AWS Neuron Operator</title>
      <link>/articles/article-2025-12-02-13220/</link>
      <pubDate>Tue, 02 Dec 2025 16:30:23 +0000</pubDate>
      <guid>/articles/article-2025-12-02-13220/</guid>
      <description>üöÄ Enhance your AI workloads with the AWS Neuron Operator on Red Hat OpenShift! This collaboration allows enterprises to run LLM inference and training with AWS Inferentia and Trainium chips, offering up to 70% lower costs per inference. The AWS Neuron Operator simplifies deployment and management of AI devices, optimizing performance and cost efficiency. Key features include automated scheduling, device management, and telemetry collection. Gain flexibility and significant savings while&amp;hellip;</description>
    </item>
    <item>
      <title>Automate unique compliance checks with OpenShift and CustomRule</title>
      <link>/articles/article-2025-12-02-13212/</link>
      <pubDate>Tue, 02 Dec 2025 08:00:55 +0000</pubDate>
      <guid>/articles/article-2025-12-02-13212/</guid>
      <description>Unlock enhanced compliance for Red Hat OpenShift with the new CustomRule feature! üöÄ This article reveals how security teams can automate unique compliance checks, transforming specific security rules into code. It offers practical examples on writing and integrating CustomRules into existing workflows, streamlining the auditing process. Currently in Tech Preview, this feature is designed to help organizations maintain compliance efficiently. Explore more about CustomRules and their potential!&amp;hellip;</description>
    </item>
    <item>
      <title>Build custom OS images for IBM Power systems (ppc64le) with bootc</title>
      <link>/articles/article-2025-12-02-13209/</link>
      <pubDate>Tue, 02 Dec 2025 07:01:17 +0000</pubDate>
      <guid>/articles/article-2025-12-02-13209/</guid>
      <description>üöÄ Developers and system admins can now streamline OS image creation for IBM Power systems using bootc! This guide explains how to build reproducible, container-native OS images efficiently. Bootc allows you to convert OCI container images into bootable OS images, enhancing speed and consistency. Key steps include setting up your ppc64le builder machine, installing necessary tools, and defining your custom image. For detailed instructions, check the full article! üñ•Ô∏èüîß #IBMCloud #PowerSystems&amp;hellip;</description>
    </item>
    <item>
      <title>Generate synthetic data for your AI models with SDG Hub</title>
      <link>/articles/article-2025-12-02-13210/</link>
      <pubDate>Tue, 02 Dec 2025 07:01:14 +0000</pubDate>
      <guid>/articles/article-2025-12-02-13210/</guid>
      <description>Unlock the potential of your AI models with SDG Hub! üöÄ This open-source framework transforms minimal quality data into extensive synthetic datasets. It utilizes modular blocks to create automated pipelines that generate, validate, and scale data while keeping sensitive information secure. üîí Developers can enhance model training efficiency with tailored synthetic data, making the process faster and more cost-effective. Explore the step-by-step guide to get started with SDG Hub and create high-&amp;hellip;</description>
    </item>
    <item>
      <title>What you need to know about Red Hat&#39;s .NET container images</title>
      <link>/articles/article-2025-12-01-13155/</link>
      <pubDate>Mon, 01 Dec 2025 15:30:16 +0000</pubDate>
      <guid>/articles/article-2025-12-01-13155/</guid>
      <description>üöÄ Red Hat offers .NET container images under the Universal Base Image (UBI) license, allowing free use and redistribution without a subscription. üîí These images feature strong security practices, including CVE monitoring and detailed software bill of materials (SBOMs). Enterprise support is available on Red Hat platforms, with community support for others. üñ•Ô∏è Images cater to various architectures, including IBM Z and Power Systems, and include separate repositories for the .NET SDK, ASP.NET&amp;hellip;</description>
    </item>
    <item>
      <title>How to set up Red Hat Lightspeed Model Context Protocol</title>
      <link>/articles/article-2025-12-01-13150/</link>
      <pubDate>Mon, 01 Dec 2025 08:00:55 +0000</pubDate>
      <guid>/articles/article-2025-12-01-13150/</guid>
      <description>üîç Red Hat Lightspeed (formerly Red Hat Insights) enhances operational efficiency with proactive analytics. The new Model Context Protocol (MCP) allows AI to interact with services using natural language. This feature simplifies incident response by providing immediate answers to queries about alerts, such as CVEs. The article provides a step-by-step guide on setting up the insights-mcp service, including creating service accounts, assigning roles, and deploying the server. For more details,&amp;hellip;</description>
    </item>
    <item>
      <title>Lift and shift a .NET application to OpenShift</title>
      <link>/articles/article-2025-12-01-13148/</link>
      <pubDate>Mon, 01 Dec 2025 07:15:56 +0000</pubDate>
      <guid>/articles/article-2025-12-01-13148/</guid>
      <description>üöÄ Looking to migrate a .NET application? Consider the lift-and-shift approach on Red Hat OpenShift. This method allows you to move applications with minimal code changes, making it a practical first step towards modernization. The article details the process of containerizing an e-commerce app using a Containerfile and highlights key considerations for deployment. Key points include using the Red Hat .NET 9.0 SDK image and setting up security best practices for non-root users. For those&amp;hellip;</description>
    </item>
    <item>
      <title>Run Ruby applications in FIPS mode on Red Hat Enterprise Linux</title>
      <link>/articles/article-2025-11-28-13116/</link>
      <pubDate>Fri, 28 Nov 2025 07:15:53 +0000</pubDate>
      <guid>/articles/article-2025-11-28-13116/</guid>
      <description>üîí Interested in running Ruby applications in FIPS mode on Red Hat Enterprise Linux? This article provides clear guidance on how to achieve this. It explains the necessary versions of RHEL and Ruby, with a focus on Ruby OpenSSL support. Learn how to confirm your FIPS environment and handle cryptographic algorithms properly. For more details, check out the full article! #Ruby #FIPS #RedHat #Cybersecurity #OpenSSL</description>
    </item>
    <item>
      <title>Use NetApp to run SAP on OpenShift Virtualization with a dual boot on bare metal</title>
      <link>/articles/article-2025-11-27-13083/</link>
      <pubDate>Thu, 27 Nov 2025 07:01:03 +0000</pubDate>
      <guid>/articles/article-2025-11-27-13083/</guid>
      <description>üöÄ In complex enterprise environments, migrating virtual workloads to physical hardware can be challenging. This article highlights how Red Hat OpenShift Virtualization, NetApp Trident, and FlexClone tech can streamline this process. üîß It explains configuring OpenShift, installing NetApp Trident, and creating bootable LUNs for physical servers. This enables rapid migration and testing for applications like SAP HANA, ensuring consistent performance across platforms. For detailed steps on&amp;hellip;</description>
    </item>
    <item>
      <title>How does cgroups v2 impact Java and Node.js in OpenShift 4?</title>
      <link>/articles/article-2025-11-27-13084/</link>
      <pubDate>Thu, 27 Nov 2025 07:01:02 +0000</pubDate>
      <guid>/articles/article-2025-11-27-13084/</guid>
      <description>Understanding the impact of cgroups v2 on Java and Node.js in OpenShift 4 is essential for developers. This article outlines compatibility concerns and solutions associated with cgroups v2, a Linux kernel feature for resource management in containers. It details how different OpenShift versions handle cgroups, emphasizing the importance of using the latest images for Node.js and OpenJDK. For those using Java, cgroups v2 compatibility was introduced in OpenJDK 8u372 and later versions. Node.js&amp;hellip;</description>
    </item>
    <item>
      <title>How to enable NVIDIA GPU acceleration in OpenShift Local</title>
      <link>/articles/article-2025-11-27-13085/</link>
      <pubDate>Thu, 27 Nov 2025 07:00:58 +0000</pubDate>
      <guid>/articles/article-2025-11-27-13085/</guid>
      <description>Unlock the power of NVIDIA GPU acceleration in OpenShift Local! üñ•Ô∏è‚ú® This article details the steps to share an NVIDIA GPU with OpenShift Local for AI and ML workloads, enhancing your local development experience. Key topics include GPU passthrough configuration, BIOS adjustments, and validating your setup. Explore how to optimize your environment to run intensive applications without needing a dedicated server. #OpenShift #NVIDIA #GPU #AI #MachineLearning</description>
    </item>
    <item>
      <title>Trusted execution clusters operator: Design and flow overview</title>
      <link>/articles/article-2025-11-26-13062/</link>
      <pubDate>Wed, 26 Nov 2025 08:01:19 +0000</pubDate>
      <guid>/articles/article-2025-11-26-13062/</guid>
      <description>üîí Confidential computing enhances cloud-native security by protecting data in use, which is traditionally vulnerable. The trusted execution cluster operator, a Kubernetes-native tool, manages clusters with hardware-based security features like secure enclaves and memory encryption. This ensures that sensitive workloads are accessed only by verified software. Key components include the Trustee for attestation and key management, and the operator automates the configuration of security&amp;hellip;</description>
    </item>
    <item>
      <title>Autoscaling vLLM with OpenShift AI model serving: Performance validation</title>
      <link>/articles/article-2025-11-26-13061/</link>
      <pubDate>Wed, 26 Nov 2025 07:01:11 +0000</pubDate>
      <guid>/articles/article-2025-11-26-13061/</guid>
      <description>üöÄ Exciting insights on autoscaling with vLLM in OpenShift AI! This article compares KServe&amp;rsquo;s KEDA-based autoscaling to Knative&amp;rsquo;s concurrency-based approach. Key findings show KEDA&amp;rsquo;s ability to scale effectively under both homogeneous and heterogeneous workloads, maintaining service-level objectives (SLO) better than Knative. üîç KEDA adapts to real-time metrics, ensuring efficient resource use and improved request success rates. Dive deeper into the performance results and implications for AI&amp;hellip;</description>
    </item>
    <item>
      <title>Introducing Models-as-a-Service in OpenShift AI</title>
      <link>/articles/article-2025-11-25-13027/</link>
      <pubDate>Tue, 25 Nov 2025 07:00:59 +0000</pubDate>
      <guid>/articles/article-2025-11-25-13027/</guid>
      <description>üöÄ Exciting news for AI enthusiasts! Red Hat has introduced Models-as-a-Service (MaaS) in OpenShift, currently in developer preview. MaaS allows organizations to deploy and manage AI models as shared resources, enhancing accessibility and scalability. This new feature offers standardized API endpoints for efficient model sharing. üîß Setup is straightforward with a single deployment script. Users can also test sample models and experience rate limiting to ensure quality of service. For detailed&amp;hellip;</description>
    </item>
    <item>
      <title>Building domain-specific LLMs with synthetic data and SDG Hub</title>
      <link>/articles/article-2025-11-25-13028/</link>
      <pubDate>Tue, 25 Nov 2025 07:00:57 +0000</pubDate>
      <guid>/articles/article-2025-11-25-13028/</guid>
      <description>üåê Synthetic data generation is transforming how we build large language models (LLMs). By using one model to create training examples for another, teams can fill domain-specific gaps without relying on scarce human data. üîß Enter SDG Hub, an open-source toolkit that simplifies synthetic data workflows. It allows users to mix LLM components with traditional data tools, enhancing efficiency and scalability. üìà The process includes generating synthetic data, fine-tuning models, and deploying&amp;hellip;</description>
    </item>
    <item>
      <title>External IP visibility in Red Hat Advanced Cluster Security</title>
      <link>/articles/article-2025-11-24-12977/</link>
      <pubDate>Mon, 24 Nov 2025 08:01:02 +0000</pubDate>
      <guid>/articles/article-2025-11-24-12977/</guid>
      <description>üîç Red Hat Advanced Cluster Security for Kubernetes 4.8 has launched with new features, including external IP visibility. This capability helps security teams identify external IP addresses used by their deployments, improving awareness of network connections. üåê The update also includes OpenShift infrastructure compliance and enhanced vulnerability advisories. These tools aid in detecting and managing threats, particularly from potential malware and command-and-control activities. üîß For setup,&amp;hellip;</description>
    </item>
    <item>
      <title>How I used Red Hat Lightspeed image builder to create CIS (and more) compliant images</title>
      <link>/articles/article-2025-11-24-12975/</link>
      <pubDate>Mon, 24 Nov 2025 07:00:57 +0000</pubDate>
      <guid>/articles/article-2025-11-24-12975/</guid>
      <description>Creating compliant images just got easier with Red Hat Lightspeed! üöÄ As a Technical Marketing Manager, I discovered that building RHEL systems for regulatory compliance was time-consuming. After switching to Red Hat Lightspeed image builder, I streamlined the process significantly. Now, I can create CIS-compliant images quickly through an intuitive wizard. This tool simplifies compliance with various regulatory policies and frameworks, cutting down hours of work to just minutes. ‚è±Ô∏è Interested&amp;hellip;</description>
    </item>
    <item>
      <title>Building a oversaturation detector with iterative error analysis</title>
      <link>/articles/article-2025-11-24-12976/</link>
      <pubDate>Mon, 24 Nov 2025 07:00:54 +0000</pubDate>
      <guid>/articles/article-2025-11-24-12976/</guid>
      <description>üöÄ Excited to share insights from our recent work on building an oversaturation detector (OSD) using iterative error analysis! We began with a baseline algorithm that struggled with false alerts due to erratic initial data. By ignoring the first 25% of requests, we significantly reduced these errors. Next, we added a 30-second grace period to differentiate good runs from bad ones during the early shoot-up phase. Finally, we established a rule to alert only when both response time and request&amp;hellip;</description>
    </item>
    <item>
      <title>Introduction to distributed inference with llm-d</title>
      <link>/articles/article-2025-11-21-12930/</link>
      <pubDate>Fri, 21 Nov 2025 07:01:01 +0000</pubDate>
      <guid>/articles/article-2025-11-21-12930/</guid>
      <description>üöÄ Distributed inference is revolutionizing the deployment of large language models (LLMs). This approach enhances efficiency across diverse infrastructures by utilizing Kubernetes and Red Hat OpenShift. üîç The article highlights the evolution of distributed inference and introduces the open-source project, llm-d, which optimizes LLM performance through disaggregated inference and intelligent scheduling. üìä Key innovations include separating model execution components, prompt-aware routing, and&amp;hellip;</description>
    </item>
    <item>
      <title>How to build your dynamic plug-ins for Developer Hub</title>
      <link>/articles/article-2025-11-20-12884/</link>
      <pubDate>Thu, 20 Nov 2025 08:01:03 +0000</pubDate>
      <guid>/articles/article-2025-11-20-12884/</guid>
      <description>üöÄ Red Hat Developer Hub supports dynamic plug-ins, allowing you to enhance your portal without recompiling the core application. This system offers key benefits: - Immutable design for better security - Easy plug-in management - Flexible customization options - Faster feature innovation Learn how to bundle and install your own plug-ins with Developer Hub! #RedHat #DeveloperHub #DynamicPlugins #Backstage #SoftwareDevelopment</description>
    </item>
    <item>
      <title>Defining success: Evaluation metrics and data augmentation for oversaturation detection</title>
      <link>/articles/article-2025-11-20-12879/</link>
      <pubDate>Thu, 20 Nov 2025 07:01:00 +0000</pubDate>
      <guid>/articles/article-2025-11-20-12879/</guid>
      <description>Oversaturation in benchmarking large language models (LLMs) can waste time and resources. To tackle this issue, we developed an algorithm that accurately detects oversaturation while preserving valid tests. Our new metric, the Soft-C-Index, prioritizes not just the order of alerts but also the time saved, ensuring efficiency. Next, we will explore algorithm improvements and error analysis. #DataScience #MachineLearning #LLM #Oversaturation #Innovation üöÄüìäüí°</description>
    </item>
    <item>
      <title>Deploying OpenShift hosted clusters on bare metal</title>
      <link>/articles/article-2025-11-19-12830/</link>
      <pubDate>Wed, 19 Nov 2025 08:17:40 +0000</pubDate>
      <guid>/articles/article-2025-11-19-12830/</guid>
      <description>Deploying Red Hat OpenShift hosted clusters on bare metal offers significant infrastructure efficiency. Here are five key lessons learned from practical experience: 1Ô∏è‚É£ &lt;strong&gt;Network Setup is Crucial&lt;/strong&gt;: Proper network configuration is essential for stability. Pay attention to link aggregation protocols for optimal performance. 2Ô∏è‚É£ &lt;strong&gt;API Access via IP&lt;/strong&gt;: Access the Kube API using a raw IP address instead of a domain name to avoid certificate errors. 3Ô∏è‚É£ &lt;strong&gt;Manual Ingress Setup&lt;/strong&gt;: Unlike traditional&amp;hellip;</description>
    </item>
    <item>
      <title>Get started with language model post-training using Training Hub</title>
      <link>/articles/article-2025-11-19-12824/</link>
      <pubDate>Wed, 19 Nov 2025 07:15:56 +0000</pubDate>
      <guid>/articles/article-2025-11-19-12824/</guid>
      <description>Unlock the potential of open-source language models with Training Hub! üöÄ This library simplifies post-training by providing a unified Python interface for various algorithms, making it easier to customize models for specific tasks. Training Hub supports a variety of methods, allowing seamless integration and exploration of different libraries without the hassle of complex setups. Get started today and enhance your language model capabilities! üìàüíª #LanguageModels #OpenSource #AI&amp;hellip;</description>
    </item>
    <item>
      <title>Speculators: Standardized, production-ready speculative decoding</title>
      <link>/articles/article-2025-11-19-12825/</link>
      <pubDate>Wed, 19 Nov 2025 07:15:51 +0000</pubDate>
      <guid>/articles/article-2025-11-19-12825/</guid>
      <description>üöÄ Speculative decoding is changing the game for large language models (LLMs) by improving inference speed! A small speculator model predicts multiple tokens efficiently, while a larger verifier model confirms them in one pass. This can lead to speed improvements of 1.5 to 2.5 times, especially under low request rates. Challenges remain, including a lack of standard formats and production-ready algorithms. The newly released Speculators v0.2.0 aims to address these issues with a standardized&amp;hellip;</description>
    </item>
    <item>
      <title>The strategic choice: Making sense of LLM customization</title>
      <link>/articles/article-2025-11-18-12761/</link>
      <pubDate>Tue, 18 Nov 2025 14:16:22 +0000</pubDate>
      <guid>/articles/article-2025-11-18-12761/</guid>
      <description>Unlocking the potential of Large Language Models (LLMs) starts with effective prompting. ü§ñ Out-of-the-box models may provide accurate responses, but they often lack your brand‚Äôs voice and tone. Customization, particularly through prompt engineering, is crucial for aligning the model with your organization&amp;rsquo;s needs. Prompting shapes conversations and helps refine the model&amp;rsquo;s reasoning. By structuring prompts effectively, you can transform these models into proactive collaborators. Learn more&amp;hellip;</description>
    </item>
    <item>
      <title>Building the digital substation: Exploring the LF Energy SEAPATH architecture on Red Hat Enterprise Linux</title>
      <link>/articles/article-2025-11-18-12747/</link>
      <pubDate>Tue, 18 Nov 2025 08:01:39 +0000</pubDate>
      <guid>/articles/article-2025-11-18-12747/</guid>
      <description>üåê The LF Energy SEAPATH project on Red Hat Enterprise Linux is revolutionizing electrical substation automation. By utilizing open source technologies, SEAPATH aims to enhance the integration of IT and OT for improved system reliability and cybersecurity. üîß Key components include a real-time Linux kernel, KVM for virtualization, and Ceph for distributed storage. This architecture supports software-defined protection, automation, and control in digital substations. üìà With a focus on open&amp;hellip;</description>
    </item>
    <item>
      <title>How to run performance tests using benchmark-runner</title>
      <link>/articles/article-2025-11-18-12748/</link>
      <pubDate>Tue, 18 Nov 2025 08:01:36 +0000</pubDate>
      <guid>/articles/article-2025-11-18-12748/</guid>
      <description>üåê Performance testing is essential for Kubernetes and Red Hat OpenShift clusters, especially when scaling applications across pods or VMs. üîç The benchmark-runner framework allows users to execute various performance tests to assess scalability in hardware, network, storage, and more. It simplifies testing with just a single command and supports both functional and performance-oriented run types. üìä Results are stored in ElasticSearch and visualized in Grafana, making it easier for cluster&amp;hellip;</description>
    </item>
    <item>
      <title>Reduce LLM benchmarking costs with oversaturation detection</title>
      <link>/articles/article-2025-11-18-12741/</link>
      <pubDate>Tue, 18 Nov 2025 07:01:10 +0000</pubDate>
      <guid>/articles/article-2025-11-18-12741/</guid>
      <description>Exploring large language model (LLM) performance is complex and costly. A recent article highlights the challenges faced by a team at Red Hat in benchmarking 7,488 combinations of models and hardware. They encountered a significant issue known as oversaturation, which invalidated over half of their tests. This led to the development of an oversaturation detection (OSD) strategy to improve efficiency. Their testing relied on a three-part stack: vLLM for inference, GuideLLM for real-world load&amp;hellip;</description>
    </item>
    <item>
      <title>.NET 10 is now available for RHEL and OpenShift</title>
      <link>/articles/article-2025-11-17-12206/</link>
      <pubDate>Mon, 17 Nov 2025 15:20:33 +0000</pubDate>
      <guid>/articles/article-2025-11-17-12206/</guid>
      <description>üöÄ .NET 10 is now available for Red Hat Enterprise Linux (RHEL) and OpenShift! This release includes support for C# 14 and F# 10, improved performance in the base library, and new Post-Quantum Cryptography APIs. Developers can install .NET 10 using the command: &lt;code&gt;dnf install dotnet-sdk-10.0&lt;/code&gt;. It offers long-term support until November 2028. #DotNet10 #RHEL #OpenShift #SoftwareDevelopment #RedHat</description>
    </item>
    <item>
      <title>Image mode for RHEL 10: Updates in seconds with soft reboot</title>
      <link>/articles/article-2025-11-17-12197/</link>
      <pubDate>Mon, 17 Nov 2025 08:00:59 +0000</pubDate>
      <guid>/articles/article-2025-11-17-12197/</guid>
      <description>üöÄ Exciting news for RHEL 10 users! The new image mode feature introduces a soft reboot capability, allowing for faster updates without the need for a full system reboot. This method improves OS management, reducing downtime from minutes to seconds for userspace updates. The soft reboot skips lengthy hardware initialization steps, making it ideal for critical infrastructure. However, it&amp;rsquo;s important to note that kernel updates still require a full reboot. Explore this advancement to enhance&amp;hellip;</description>
    </item>
    <item>
      <title>What‚Äôs new in Red Hat build of Apache Camel 4.14</title>
      <link>/articles/article-2025-11-14-12175/</link>
      <pubDate>Fri, 14 Nov 2025 16:56:38 +0000</pubDate>
      <guid>/articles/article-2025-11-14-12175/</guid>
      <description>üöÄ The Red Hat build of Apache Camel 4.14 introduces an enhanced integration toolkit for hybrid environments. Key updates include support for OpenSearch, Azure Data Lake Storage, and Mail Microsoft OAuth. üîç Developers will benefit from productivity boosts with the Kaoto integration designer, which now supports visual data mapping for JSON and XML. üìä Additionally, a new Camel dashboard provides real-time insights into integration health on Red Hat OpenShift, while the HawtIO Artemis Plugin&amp;hellip;</description>
    </item>
    <item>
      <title>Red Hat Enterprise Linux 9.7: Top features for developers</title>
      <link>/articles/article-2025-11-12-12008/</link>
      <pubDate>Wed, 12 Nov 2025 20:02:15 +0000</pubDate>
      <guid>/articles/article-2025-11-12-12008/</guid>
      <description>üöÄ Red Hat Enterprise Linux (RHEL) 9.7 is now available, bringing many enhancements for developers! Key updates include the latest versions of Rust, GCC Toolset, LLVM, and Go compilers, all aimed at improving development speed and efficiency. Notable features are the new Rust 2024 Edition and improved performance in Go 1.24. RHEL 9.7 also introduces post-quantum cryptography for enhanced security, a locally available AI command-line assistant, and reproducible container image builds. Explore&amp;hellip;</description>
    </item>
    <item>
      <title>Red Hat Enterprise Linux 10.1: Top features for developers</title>
      <link>/articles/article-2025-11-12-12009/</link>
      <pubDate>Wed, 12 Nov 2025 19:19:53 +0000</pubDate>
      <guid>/articles/article-2025-11-12-12009/</guid>
      <description>üöÄ Red Hat Enterprise Linux (RHEL) 10.1 is now available! This release enhances developer tools and introduces new features for efficient application development. Key updates include: - Vendor-validated AI accelerator drivers for better AI integration. - Soft-reboot capability to reduce downtime during updates. - Reproducible builds for container tools, ensuring identical images. Developers can also access the latest versions of Rust, GCC, LLVM, and Go compilers for improved performance&amp;hellip;.</description>
    </item>
    <item>
      <title>New in MicroShift 4.20: The generic device plug-in</title>
      <link>/articles/article-2025-11-12-12010/</link>
      <pubDate>Wed, 12 Nov 2025 14:00:59 +0000</pubDate>
      <guid>/articles/article-2025-11-12-12010/</guid>
      <description>üöÄ Exciting news for edge computing! MicroShift 4.20 introduces a generic device plug-in, enhancing access to devices like serial ports and cameras from Kubernetes pods. This feature simplifies secure connections without granting full host access, reducing security risks. Devices are defined in the configuration, allowing for flexible resource management. For detailed steps on implementation, check the product documentation! üñ•Ô∏èüîå #MicroShift #Kubernetes #EdgeComputing #RedHat #DevOps</description>
    </item>
    <item>
      <title>Exhaustive profiling toolkit: elfutils and libdwfl_stacktrace</title>
      <link>/articles/article-2025-11-12-12011/</link>
      <pubDate>Wed, 12 Nov 2025 08:01:04 +0000</pubDate>
      <guid>/articles/article-2025-11-12-12011/</guid>
      <description>The article explores advancements in Linux stack profiling through elfutils and the new libdwfl_stacktrace initiative. It highlights how these tools aim to provide exhaustive profiling solutions, focusing on system-wide stack sample profiling without needing frame pointers. The libdwfl_stacktrace interface offers improved functionality for interacting with various profiling tools. Additionally, the article discusses the SFrame project as a lightweight alternative, although it faces challenges&amp;hellip;</description>
    </item>
    <item>
      <title>What‚Äôs new for developers in Red Hat OpenShift 4.20</title>
      <link>/articles/article-2025-11-11-12012/</link>
      <pubDate>Tue, 11 Nov 2025 14:01:05 +0000</pubDate>
      <guid>/articles/article-2025-11-11-12012/</guid>
      <description>üöÄ Red Hat OpenShift 4.20 is now available! This release features enhancements for developers, including multicluster support and improved AI capabilities. üîß Key updates include a streamlined Red Hat Developer Hub, new tools in Podman Desktop, and expanded support in OpenShift Dev Spaces. Developers can now efficiently manage multiple clusters and access the latest AI models. üìä New observability tools and infrastructure optimizations are also part of this update, enhancing overall performance&amp;hellip;.</description>
    </item>
    <item>
      <title>Introducing the external secrets operator for OpenShift</title>
      <link>/articles/article-2025-11-11-12013/</link>
      <pubDate>Tue, 11 Nov 2025 08:00:58 +0000</pubDate>
      <guid>/articles/article-2025-11-11-12013/</guid>
      <description>üöÄ The external secrets operator (ESO) for Red Hat OpenShift is now generally available. This operator enhances secrets management, complementing tools like cert-manager and secrets store CSI operator. üîê ESO automates the management of Kubernetes secrets, improving security by allowing DevSecOps teams to manage credentials from a centralized source. üìö For more insights on secrets management in OpenShift, check out Red Hat&amp;rsquo;s learning path. #RedHat #OpenShift #SecretsManagement #DevSecOps&amp;hellip;</description>
    </item>
    <item>
      <title>OpenShift AI connector for Red Hat Developer Hub (Developer Preview)</title>
      <link>/articles/article-2025-11-10-12014/</link>
      <pubDate>Mon, 10 Nov 2025 12:15:57 +0000</pubDate>
      <guid>/articles/article-2025-11-10-12014/</guid>
      <description>üöÄ Exciting updates for developers! The new OpenShift AI connector for Red Hat Developer Hub allows seamless integration, automatically transferring AI model metadata into the Software Catalog. This enhancement streamlines the development process by providing a unified view of AI infrastructure and resources. Key features include dynamic plug-ins and sidecar containers that help manage AI model metadata directly from OpenShift AI. Explore the details in the latest article. #OpenShift #RedHat&amp;hellip;</description>
    </item>
    <item>
      <title>MCP in Red Hat Developer Hub: Chat with your catalog</title>
      <link>/articles/article-2025-11-10-12015/</link>
      <pubDate>Mon, 10 Nov 2025 12:15:55 +0000</pubDate>
      <guid>/articles/article-2025-11-10-12015/</guid>
      <description>üöÄ Exciting updates for Red Hat Developer Hub! New plug-ins for Model Context Protocol (MCP) are now available starting with version 1.8. These tools enable MCP clients to interact with the software catalog and retrieve TechDocs documentation. üîç The Red Hat Developer Hub centralizes development resources, enhancing productivity. The MCP server allows for seamless connection between AI models and external tools. For installation and configuration details, check out the article! #RedHat&amp;hellip;</description>
    </item>
    <item>
      <title>How to develop Red Hat Enterprise Linux applications on other Linux distributions or Microsoft Windows</title>
      <link>/articles/article-2025-11-10-12016/</link>
      <pubDate>Mon, 10 Nov 2025 07:00:57 +0000</pubDate>
      <guid>/articles/article-2025-11-10-12016/</guid>
      <description>Developing applications for Red Hat Enterprise Linux (RHEL) can be done effectively on various platforms, including other Linux distributions and Microsoft Windows. One approach is using Toolbx on Linux, which creates a native command-line environment within a container. This allows developers to run RHEL applications seamlessly across different Linux versions. Alternatively, on Windows, the Windows Subsystem for Linux (WSL) enables a full Linux experience, integrating tools from both&amp;hellip;</description>
    </item>
    <item>
      <title>Automate VM golden image builds for OpenShift with Packer</title>
      <link>/articles/article-2025-11-07-11890/</link>
      <pubDate>Fri, 07 Nov 2025 08:15:53 +0000</pubDate>
      <guid>/articles/article-2025-11-07-11890/</guid>
      <description>Automating VM golden image builds for OpenShift is made easy with Packer! üñ•Ô∏è‚ú® This tool helps create consistent, pre-configured VM templates, ensuring every image has the right OS settings and security patches. The article covers how to use Packer with the KVM plugin for Red Hat OpenShift Virtualization. Key benefits include: - Automation of image creation üì¶ - Easy customization of software and settings - Reduced risk of errors Explore how Packer streamlines your VM image management!&amp;hellip;</description>
    </item>
    <item>
      <title>Setting up Intel TDX VMs with Trustee on OpenShift</title>
      <link>/articles/article-2025-11-05-11845/</link>
      <pubDate>Wed, 05 Nov 2025 08:16:08 +0000</pubDate>
      <guid>/articles/article-2025-11-05-11845/</guid>
      <description>üì¢ Protecting sensitive data is crucial. The latest article discusses setting up confidential VMs on Red Hat OpenShift using Intel TDX technology. üîë This setup ensures data privacy, complying with regulations like DORA. It highlights how to use Trustee for secure attestation during VM boot-up. üõ†Ô∏è This proof of concept (PoC) involves configuring KubeVirt and verifying TDX support through the Linux kernel. Learn more about enhancing your cloud security! #CloudComputing #OpenShift #DataPrivacy&amp;hellip;</description>
    </item>
    <item>
      <title>Building and running Request Tracker as a quadlet container</title>
      <link>/articles/article-2025-11-05-11846/</link>
      <pubDate>Wed, 05 Nov 2025 07:16:50 +0000</pubDate>
      <guid>/articles/article-2025-11-05-11846/</guid>
      <description>üöÄ Dive into containerization with Request Tracker (RT)! This article guides you through the process of running RT as a quadlet container, utilizing MariaDB and httpd images. Learn about the setup, including persistent storage, configuration, and email routing. Key commands and examples are provided for a smooth deployment. üì¶ Explore the benefits of using containers to simplify maintenance and enhance security. #RequestTracker #Containerization #Podman #DevOps #OpenSource</description>
    </item>
    <item>
      <title>Use OpenShift Lightspeed with locally served LLMs to drive security-focused, cost-efficient enterprise solutions for Red Hat products</title>
      <link>/articles/article-2025-11-05-11847/</link>
      <pubDate>Wed, 05 Nov 2025 07:16:47 +0000</pubDate>
      <guid>/articles/article-2025-11-05-11847/</guid>
      <description>üöÄ Red Hat OpenShift Lightspeed is enhancing user efficiency by integrating with locally served large language models (LLMs) through OpenShift AI. This setup boosts data security, reduces costs, and allows for better performance control. The article outlines steps to connect OpenShift Lightspeed with an LLM, from prerequisites to model deployment. Key steps include setting up S3-compatible storage and configuring model connections. For detailed instructions, check the full article! #RedHat&amp;hellip;</description>
    </item>
    <item>
      <title>3 MCP servers you should be using (safely)</title>
      <link>/articles/article-2025-11-04-11712/</link>
      <pubDate>Tue, 04 Nov 2025 15:37:39 +0000</pubDate>
      <guid>/articles/article-2025-11-04-11712/</guid>
      <description>Unlock the potential of Large Language Models (LLMs) with Model Context Protocol (MCP) servers! üõ†Ô∏è MCP enables AI models to interact with tools and resources effectively. Here are three recommended MCP servers: 1Ô∏è‚É£ &lt;strong&gt;Kubernetes MCP Server&lt;/strong&gt; - Allows direct communication with your cluster for resource management. 2Ô∏è‚É£ &lt;strong&gt;Context7 MCP Server&lt;/strong&gt; - Provides real-time access to updated technical documentation for development support. 3Ô∏è‚É£ &lt;strong&gt;GitHub MCP Server&lt;/strong&gt; - Facilitates natural language&amp;hellip;</description>
    </item>
    <item>
      <title>Announcing resource optimization for Red Hat OpenShift GA</title>
      <link>/articles/article-2025-11-04-11691/</link>
      <pubDate>Tue, 04 Nov 2025 10:00:00 +0000</pubDate>
      <guid>/articles/article-2025-11-04-11691/</guid>
      <description>üöÄ Exciting news for Red Hat OpenShift users! Resource optimization is now generally available as part of Red Hat Lightspeed cost management. This feature simplifies resource allocation for containers, deployments, and more. Key features include: - Recommendations for various workloads - Profile-based insights - Visual explanations for recommendations Get started by labeling your namespaces, installing the Cost Management Metrics Operator, and connecting your cloud accounts. For more details,&amp;hellip;</description>
    </item>
    <item>
      <title>Convert CentOS Linux to RHEL using Red Hat Lightspeed</title>
      <link>/articles/article-2025-11-04-11696/</link>
      <pubDate>Tue, 04 Nov 2025 10:00:00 +0000</pubDate>
      <guid>/articles/article-2025-11-04-11696/</guid>
      <description>üö® CentOS Linux 7 will reach its end-of-life on June 30, 2024, leaving users without official support. A recommended solution is migrating to Red Hat Enterprise Linux (RHEL) for ongoing security updates and support. The transition can be facilitated using Red Hat Lightspeed, which provides tools for analysis and conversion. üîß Steps include validating your CentOS version, updating the system, installing client tools, and running pre-conversion analyses. For detailed guidance, check out the full&amp;hellip;</description>
    </item>
    <item>
      <title>Detect network issues in Open vSwitch using Red Hat Lightspeed</title>
      <link>/articles/article-2025-11-04-11695/</link>
      <pubDate>Tue, 04 Nov 2025 10:00:00 +0000</pubDate>
      <guid>/articles/article-2025-11-04-11695/</guid>
      <description>üöÄ Red Hat Lightspeed accelerates the detection of network issues in Open vSwitch (OVS). Support engineers can now quickly address problems like packet drops or latency, reducing lengthy communication with developers. The tool allows for easy monitoring of OVS coverage metrics and logs, streamlining the troubleshooting process. With extendable rules, it adapts to evolving needs in network management. #RedHat #OpenvSwitch #Networking #TechSupport #Troubleshooting</description>
    </item>
    <item>
      <title>Extend Red Hat Lightspeed client to execute custom automation</title>
      <link>/articles/article-2025-11-04-11692/</link>
      <pubDate>Tue, 04 Nov 2025 10:00:00 +0000</pubDate>
      <guid>/articles/article-2025-11-04-11692/</guid>
      <description>Red Hat Lightspeed enhances operational efficiency by providing actionable intelligence for Red Hat Enterprise Linux environments. The insights client, running daily, can trigger custom automation using a shell script. This automation can assign systems to inventory groups, aiding in organized management and access control. Both inventory groups and system tags assist in filtering and managing systems effectively. A detailed guide on extending the insights client for automation is available&amp;hellip;</description>
    </item>
    <item>
      <title>How Red Hat Lightspeed events enhance system life cycle management</title>
      <link>/articles/article-2025-11-04-11687/</link>
      <pubDate>Tue, 04 Nov 2025 10:00:00 +0000</pubDate>
      <guid>/articles/article-2025-11-04-11687/</guid>
      <description>üöÄ Red Hat Lightspeed enhances system life cycle management through proactive monitoring and analytics. With new inventory events, IT teams gain deeper visibility, automating responses to system changes. Key events include new system registrations, stale system detection, and deletions, allowing for timely actions like opening ServiceNow tickets or initiating security checks. Integrating these events into workflows can lead to self-healing systems and optimized operations. Learn more about&amp;hellip;</description>
    </item>
    <item>
      <title>How to use content templates in Red Hat Lightspeed</title>
      <link>/articles/article-2025-11-04-11688/</link>
      <pubDate>Tue, 04 Nov 2025 10:00:00 +0000</pubDate>
      <guid>/articles/article-2025-11-04-11688/</guid>
      <description>Manage your patching cycle effectively with content templates in Red Hat Lightspeed! üõ†Ô∏è These templates use snapshots of Red Hat and third-party repositories, allowing admins to control software availability at the dnf/yum level. Snapshots are updated every 24 hours, ensuring stability. Learn how to create and assign templates for smooth updates, including adding custom content. üì¶ Explore the process for better system management today! #RedHat #SystemManagement #ContentTemplates #DevOps&amp;hellip;</description>
    </item>
    <item>
      <title>InterSystems IRIS operations made easy with Red Hat Lightspeed</title>
      <link>/articles/article-2025-11-04-11689/</link>
      <pubDate>Tue, 04 Nov 2025 10:00:00 +0000</pubDate>
      <guid>/articles/article-2025-11-04-11689/</guid>
      <description>üöÄ Red Hat Lightspeed, formerly Red Hat Insights, now enhances operations for InterSystems IRIS users. This service provides timely alerts and recommendations for Red Hat Enterprise Linux (RHEL) administrators, ensuring optimal system performance. Key features include performance tuning suggestions and high-availability enhancements to prevent failover issues. Connect your RHEL machine to Red Hat Lightspeed easily and access valuable insights through the new &amp;ldquo;InterSystems&amp;rdquo; topic in the Advisor&amp;hellip;</description>
    </item>
    <item>
      <title>Leverage Red Hat Satellite for Red Hat Lightspeed reporting and automation</title>
      <link>/articles/article-2025-11-04-11690/</link>
      <pubDate>Tue, 04 Nov 2025 10:00:00 +0000</pubDate>
      <guid>/articles/article-2025-11-04-11690/</guid>
      <description>Unlock efficient reporting with Red Hat Satellite! üöÄ This article highlights how to automate data retrieval from Red Hat Lightspeed using Ansible integration. System administrators can schedule tasks to generate CSV reports on system health, vulnerabilities, and more, directly to their inbox. Learn how to set up a service account, configure job templates, and receive timely updates on your infrastructure. üìä Check out the step-by-step guide and start automating today! #RedHat #Automation&amp;hellip;</description>
    </item>
    <item>
      <title>Synchronize instance tags from Amazon EC2 and Microsoft Azure with Red Hat Lightspeed</title>
      <link>/articles/article-2025-11-04-11694/</link>
      <pubDate>Tue, 04 Nov 2025 10:00:00 +0000</pubDate>
      <guid>/articles/article-2025-11-04-11694/</guid>
      <description>üîÑ Red Hat Lightspeed now synchronizes system tags from Amazon EC2 and Microsoft Azure, enhancing operational efficiency. Tagging allows organizations to manage and filter their resources effectively. üåê This article outlines how Lightspeed ingests existing tags from cloud providers to streamline management. Users can leverage these tags for better reporting and automation across platforms. For detailed insights, explore the full article! #RedHat #CloudManagement #EC2 #MicrosoftAzure #DevOps</description>
    </item>
    <item>
      <title>Testing frameworks for images built via Red Hat Lightspeed image builder</title>
      <link>/articles/article-2025-11-04-11693/</link>
      <pubDate>Tue, 04 Nov 2025 10:00:00 +0000</pubDate>
      <guid>/articles/article-2025-11-04-11693/</guid>
      <description>Building images for cloud and on-premises servers poses challenges like reducing attack surfaces and ensuring compliance. üåê Red Hat Lightspeed simplifies image hardening by using OpenSCAP remediations at build time, allowing for pre-hardened images. Users can build images via an API or a user interface on sandbox.redhat.com. üõ†Ô∏è The article details steps for selecting the PCI-DSS profile and customizing images, ensuring compliance throughout the process. For compliance monitoring, Red Hat&amp;hellip;</description>
    </item>
    <item>
      <title>Post-training methods for language models</title>
      <link>/articles/article-2025-11-04-11683/</link>
      <pubDate>Tue, 04 Nov 2025 07:01:25 +0000</pubDate>
      <guid>/articles/article-2025-11-04-11683/</guid>
      <description>Post-training methods are crucial for enhancing large language models (LLMs) beyond their initial pre-training phase. üåê These methods include supervised fine-tuning, continual learning, and reinforcement learning, each aimed at making models more useful and aligned with specific tasks. Techniques like Orthogonal Subspace Fine-Tuning and Parameter-Efficient Fine-Tuning optimize memory and performance. üìà Developers can explore these approaches using the open-source Training Hub library, which&amp;hellip;</description>
    </item>
    <item>
      <title>Using eBPF to attribute packet drops to netfilter rules</title>
      <link>/articles/article-2025-11-03-11637/</link>
      <pubDate>Mon, 03 Nov 2025 08:01:25 +0000</pubDate>
      <guid>/articles/article-2025-11-03-11637/</guid>
      <description>Unlock the power of eBPF in Linux! üöÄ This article explores how eBPF can help attribute packet drops to specific netfilter rules in the Linux kernel. It dives into the netfilter subsystem, illustrating how to pinpoint which firewall rule caused a packet drop and how to hook into kernel processing for detailed insights. Learn how to create a simple nftables ruleset and utilize eBPF tools for effective troubleshooting. üîçüíª #eBPF #LinuxKernel #Netfilter #Firewall #PacketDrops</description>
    </item>
    <item>
      <title>Reduce bootc system update size</title>
      <link>/articles/article-2025-11-03-11638/</link>
      <pubDate>Mon, 03 Nov 2025 08:01:22 +0000</pubDate>
      <guid>/articles/article-2025-11-03-11638/</guid>
      <description>Minimizing bandwidth during system updates is crucial. The article discusses how the &lt;strong&gt;rpm-ostree build-chunked-oci tool&lt;/strong&gt; helps by isolating related rpm packages into separate layers. This means that changes to one configuration file won&amp;rsquo;t require downloading large amounts of data. A new feature allows specific files to be assigned to particular layers, improving efficiency, especially for large embedded images. Setting up a test environment and using this tool can significantly speed up&amp;hellip;</description>
    </item>
    <item>
      <title>Deploy an LLM inference service on OpenShift AI</title>
      <link>/articles/article-2025-11-03-11639/</link>
      <pubDate>Mon, 03 Nov 2025 07:01:14 +0000</pubDate>
      <guid>/articles/article-2025-11-03-11639/</guid>
      <description>üöÄ Deploying large language models (LLMs) on Red Hat OpenShift AI enhances on-premise inference for the Ansible Lightspeed intelligent assistant. You can containerize, scale, and integrate LLM workloads. This ensures better data control and compliance with organizational policies. Key components include model storage, a serving runtime, and GPU infrastructure. Performance is evaluated using Time to First Token (TTFT) and Inter-Token Latency (ITL) to maintain a responsive user experience. üîó&amp;hellip;</description>
    </item>
    <item>
      <title>Why vLLM is the best choice for AI inference today</title>
      <link>/articles/article-2025-10-30-11488/</link>
      <pubDate>Thu, 30 Oct 2025 13:02:11 +0000</pubDate>
      <guid>/articles/article-2025-10-30-11488/</guid>
      <description>Organizations transitioning to AI production face critical decisions on inference platforms. vLLM, a library of open-source code, optimizes large language model (LLM) performance through efficient GPU memory use. Its architecture, including advanced KV-Cache management and parallelization strategies, supports diverse hardware and enhances scalability. As an open-source project under the PyTorch Foundation, vLLM ensures sustainable innovation and flexibility, making it a strong choice for&amp;hellip;</description>
    </item>
    <item>
      <title>Happy birthday, Repo! A look back on our mascot‚Äôs first year</title>
      <link>/articles/article-2025-10-30-11489/</link>
      <pubDate>Thu, 30 Oct 2025 12:46:10 +0000</pubDate>
      <guid>/articles/article-2025-10-30-11489/</guid>
      <description>üéâ Happy 1st Birthday, Repo! üéâ This year marked the debut of Repo, our helpful &amp;ldquo;reponaut,&amp;rdquo; who assists developers in managing complex coding challenges. Key events included advancements in Red Hat OpenShift AI and the successful growth of the Quarkus project, highlighting the focus on developer productivity. In 2025, major releases such as Red Hat Enterprise Linux 10 and the Red Hat OpenShift Lightspeed assistant enhanced the developer experience. The community continues to embrace AI and&amp;hellip;</description>
    </item>
    <item>
      <title>A guide to the oc adm upgrade recommend command</title>
      <link>/articles/article-2025-10-30-11481/</link>
      <pubDate>Thu, 30 Oct 2025 07:01:26 +0000</pubDate>
      <guid>/articles/article-2025-10-30-11481/</guid>
      <description>üîß Red Hat OpenShift 4.20 introduces the &lt;code&gt;oc adm upgrade recommend&lt;/code&gt; command, aimed at simplifying the update process. This tool offers tailored version recommendations to enhance your update planning. üìã The precheck feature actively identifies alerts that may hinder updates, like the critical &lt;code&gt;ClusterOperatorDown&lt;/code&gt; alert, ensuring you have the necessary information before proceeding. ‚úÖ This command helps manage risks effectively, allowing for a more confident upgrade experience. Explore the new&amp;hellip;</description>
    </item>
    <item>
      <title>ActiveMQ Artemis or Apache Kafka? What you need to know</title>
      <link>/articles/article-2025-10-29-11392/</link>
      <pubDate>Wed, 29 Oct 2025 07:01:08 +0000</pubDate>
      <guid>/articles/article-2025-10-29-11392/</guid>
      <description>üìä As AI applications grow, understanding messaging systems like ActiveMQ Artemis and Apache Kafka is essential. ActiveMQ Artemis focuses on transactional reliability and supports various messaging protocols. It&amp;rsquo;s ideal for point-to-point and batch processing. In contrast, Apache Kafka excels in real-time data streaming, offering high throughput and the ability to replay messages for analytics. Choosing between them depends on your specific use case needs. #MessagingSystems #ActiveMQ&amp;hellip;</description>
    </item>
    <item>
      <title>Multimodal AI at the edge: Deploy vision language models with RamaLama</title>
      <link>/articles/article-2025-10-27-11286/</link>
      <pubDate>Mon, 27 Oct 2025 07:01:14 +0000</pubDate>
      <guid>/articles/article-2025-10-27-11286/</guid>
      <description>Explore the future of AI with RamaLama! üåê This open-source CLI simplifies the deployment of vision language models (VLMs) on edge devices. By leveraging container technology, it eliminates complex dependencies, making it easier for developers to implement AI in real-world scenarios. From real-time object recognition to identifying hazards, VLMs are set to revolutionize industries. Learn how to effectively deploy and manage these models with RamaLama. #AI #MachineLearning #EdgeComputing&amp;hellip;</description>
    </item>
    <item>
      <title>SDG Hub: Building synthetic data pipelines with modular blocks</title>
      <link>/articles/article-2025-10-27-11287/</link>
      <pubDate>Mon, 27 Oct 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-10-27-11287/</guid>
      <description>üåê The SDG Hub is transforming how we build synthetic data pipelines for large language models (LLMs). It offers an open framework that enables users to create, compose, and scale data generation with reusable blocks. This modular approach replaces one-off scripts, enhancing reproducibility and innovation. Key features include asynchronous execution, monitoring, and custom block extensions. The SDG Hub supports diverse applications, from knowledge tuning to multilingual data generation&amp;hellip;.</description>
    </item>
    <item>
      <title>AI accelerator selection for inference: A stage-based framework</title>
      <link>/articles/article-2025-10-27-11288/</link>
      <pubDate>Mon, 27 Oct 2025 07:01:09 +0000</pubDate>
      <guid>/articles/article-2025-10-27-11288/</guid>
      <description>üöÄ As enterprises advance AI from experimentation to production, selecting the right hardware accelerators is essential. This article outlines a stage-based framework for choosing AI accelerators throughout the inference lifecycle, covering five key stages: 1Ô∏è‚É£ Initial Setup 2Ô∏è‚É£ Performance Tuning 3Ô∏è‚É£ Production Deployment 4Ô∏è‚É£ Large Model Serving 5Ô∏è‚É£ Edge Deployment Each stage has unique requirements and challenges that influence hardware choices. Understanding these can help organizations&amp;hellip;</description>
    </item>
    <item>
      <title>How to modify system-reserved parameters on OpenShift nodes</title>
      <link>/articles/article-2025-10-24-11247/</link>
      <pubDate>Fri, 24 Oct 2025 07:00:51 +0000</pubDate>
      <guid>/articles/article-2025-10-24-11247/</guid>
      <description>Optimize your OpenShift nodes with effective system-reserved parameters! üöÄ This article outlines the steps to calculate and configure CPU and memory resources for underlying components. Proper reservation enhances scheduling and prevents resource overcommitment. Key steps include reserving resources, verifying configurations, and adjusting values for better performance. For more details on implementation, check out the full article! üìäüíª #OpenShift #RedHat #CloudComputing #ContainerManagement&amp;hellip;</description>
    </item>
    <item>
      <title>The odo CLI is deprecated: What developers need to know</title>
      <link>/articles/article-2025-10-23-11184/</link>
      <pubDate>Thu, 23 Oct 2025 07:01:14 +0000</pubDate>
      <guid>/articles/article-2025-10-23-11184/</guid>
      <description>üö® Important Update for Developers! üö® The odo CLI is officially deprecated. The immediate deprecation date is October 23, 2025, with an end of life on March 31, 2026. After this date, no maintenance or support will be provided. For a smoother transition, explore Red Hat OpenShift Dev Spaces for inner-loop development, and consider using Podman and oc CLI for your outer-loop tasks. Stay informed and plan your migration! #RedHat #OpenShift #DevOps #CloudNative #DeveloperTools</description>
    </item>
    <item>
      <title>Exposing OpenShift networks using BGP</title>
      <link>/articles/article-2025-10-23-11185/</link>
      <pubDate>Thu, 23 Oct 2025 07:01:09 +0000</pubDate>
      <guid>/articles/article-2025-10-23-11185/</guid>
      <description>üöÄ OpenShift users can now enhance their networking capabilities using BGP! This article details how to expose OpenShift networks, providing dynamic routing and advanced features for VMs. Key benefits include automated route configurations, improved performance, and high availability with BFD support. Learn how to export network routes efficiently from OpenShift to a BGP router, ensuring seamless VM migration and connectivity. #OpenShift #BGP #Virtualization #CloudNetworking #FRRouting</description>
    </item>
    <item>
      <title>How to run I/O workloads on OpenShift Virtualization VMs</title>
      <link>/articles/article-2025-10-22-11137/</link>
      <pubDate>Wed, 22 Oct 2025 07:01:14 +0000</pubDate>
      <guid>/articles/article-2025-10-22-11137/</guid>
      <description>Learn how to effectively run I/O workloads on OpenShift Virtualization VMs! üöÄ This article outlines the steps needed to test I/O performance at scale using a generic FIO workload. It covers prerequisites, such as a functional OpenShift environment and SSH access to virtual machines. Step-by-step instructions detail how to create virtual machines, set up testing parameters, and analyze results, ensuring accurate performance assessments. üìä Explore the testing process and improve your&amp;hellip;</description>
    </item>
    <item>
      <title>How spec-driven development improves AI coding quality</title>
      <link>/articles/article-2025-10-22-11138/</link>
      <pubDate>Wed, 22 Oct 2025 07:01:11 +0000</pubDate>
      <guid>/articles/article-2025-10-22-11138/</guid>
      <description>Unlock the potential of AI coding with spec-driven development! üé∂ This approach enhances collaboration between humans and AI by establishing clear specifications. Unlike &amp;ldquo;vibe coding,&amp;rdquo; which can lead to fragile code, spec coding ensures robust results through detailed planning. Stakeholders benefit from early involvement, improving productivity and ROI. By defining the &amp;ldquo;what&amp;rdquo; and &amp;ldquo;how,&amp;rdquo; teams create error-free, scalable code while empowering AI with context. ü§ñ Explore how to start with spec&amp;hellip;</description>
    </item>
    <item>
      <title>Krkn-AI: A feedback-driven approach to chaos engineering</title>
      <link>/articles/article-2025-10-21-11095/</link>
      <pubDate>Tue, 21 Oct 2025 07:01:41 +0000</pubDate>
      <guid>/articles/article-2025-10-21-11095/</guid>
      <description>Introducing &lt;strong&gt;Krkn-AI&lt;/strong&gt;: a new framework for AI-assisted chaos engineering. It addresses the challenges of testing modern systems, especially in dynamic environments like Kubernetes. Chaos engineering helps identify weaknesses by simulating failures, but traditional methods can be manual and static. Krkn-AI automates experiment discovery and execution, allowing teams to focus on insights rather than manual setups. Key features include cluster-aware discoverability, enhanced test coverage, and&amp;hellip;</description>
    </item>
    <item>
      <title>How to import provider network routes to OpenShift via BGP</title>
      <link>/articles/article-2025-10-21-11096/</link>
      <pubDate>Tue, 21 Oct 2025 07:01:39 +0000</pubDate>
      <guid>/articles/article-2025-10-21-11096/</guid>
      <description>Importing provider network routes into Red Hat OpenShift Virtualization via BGP enhances network capabilities. üåê This integration allows for dynamic routing and automates configurations, improving VM migration and overall performance. BGP&amp;rsquo;s features like bidirectional forwarding detection (BFD) ensure high availability and rapid failover. To implement this, ensure your OpenShift cluster meets the prerequisites and follow the detailed configuration steps provided. #OpenShift #BGP #CloudNative&amp;hellip;</description>
    </item>
    <item>
      <title>A case study in Kubelet regression in OpenShift</title>
      <link>/articles/article-2025-10-20-11059/</link>
      <pubDate>Mon, 20 Oct 2025 07:01:19 +0000</pubDate>
      <guid>/articles/article-2025-10-20-11059/</guid>
      <description>In the latest analysis of Red Hat OpenShift, a kubelet regression was detected that increased CPU usage by 30% and pod readiness latency by 50%. Our performance engineering team utilized the changepoint detection tool, Orion, to identify these issues during automated scale tests. The regression was linked to kubelet 1.33, which was resolved by reverting to version 1.32.6, restoring normal performance metrics. This case highlights the importance of continuous testing and collaboration to&amp;hellip;</description>
    </item>
    <item>
      <title>Profiling vLLM Inference Server with GPU acceleration on RHEL</title>
      <link>/articles/article-2025-10-16-10998/</link>
      <pubDate>Thu, 16 Oct 2025 15:44:40 +0000</pubDate>
      <guid>/articles/article-2025-10-16-10998/</guid>
      <description>üöÄ Profiling large language models (LLMs) is essential for optimization. This guide details how to set up and profile a vLLM inference server on RHEL with NVIDIA GPUs. üîß It covers three main stages: 1Ô∏è‚É£ Environment setup: Install NVIDIA drivers and the Container Toolkit. 2Ô∏è‚É£ Basic profiling: Use the PyTorch profiler to trace inference requests. 3Ô∏è‚É£ Advanced profiling: Leverage NVIDIA Nsight Systems for deeper insights. For a comprehensive understanding, check the full guide! #LLM #GPU #vLLM&amp;hellip;</description>
    </item>
    <item>
      <title>Network performance in distributed training: Maximizing GPU utilization on OpenShift</title>
      <link>/articles/article-2025-10-16-10999/</link>
      <pubDate>Thu, 16 Oct 2025 15:07:18 +0000</pubDate>
      <guid>/articles/article-2025-10-16-10999/</guid>
      <description>üöÄ Key findings from a recent study on GPU clusters for distributed training highlight the importance of network architecture. Using IBM Cloud, tests showed that the standard OpenShift pod network creates bottlenecks. For L40S GPUs, secondary vNICs increased performance by up to 132% at scale. For H100 GPUs, switching to SR-IOV led to a 3x increase in throughput. Recommendations emphasize investing in high-performance networks to maximize GPU utilization. #DistributedTraining #GPUPerformance&amp;hellip;</description>
    </item>
    <item>
      <title>Clang bytecode interpreter update</title>
      <link>/articles/article-2025-10-15-10924/</link>
      <pubDate>Wed, 15 Oct 2025 07:16:20 +0000</pubDate>
      <guid>/articles/article-2025-10-15-10924/</guid>
      <description>üöÄ This October, an update on the Clang bytecode interpreter reveals significant progress! With about 500 commits since last year, the implementation has become more robust. Test failures in the clang suite have decreased from 155 to 90. A working version of &lt;code&gt;builtin_constant_p&lt;/code&gt; is now available, supporting real-world use cases. Key enhancements include optimizations for constant expressions, improving performance in certain scenarios. The inclusion of libc++ testing has also led to better&amp;hellip;</description>
    </item>
    <item>
      <title>How Red Hat has redefined continuous performance testing</title>
      <link>/articles/article-2025-10-15-10925/</link>
      <pubDate>Wed, 15 Oct 2025 07:16:15 +0000</pubDate>
      <guid>/articles/article-2025-10-15-10925/</guid>
      <description>üöÄ Continuous performance testing (CPT) is crucial for software development, especially for Red Hat OpenShift. The article highlights its importance in preventing performance bottlenecks and improving user experience. Challenges include OpenShift&amp;rsquo;s complexity and the need for flexible testing solutions. The team shifted-left, integrating performance tests into their CI/CD pipeline, increasing development velocity and collaboration. Stay tuned for best practices and insights on CPT! üìàüîç #RedHat&amp;hellip;</description>
    </item>
    <item>
      <title>Simplify OpenShift installation in air-gapped environments</title>
      <link>/articles/article-2025-10-14-10900/</link>
      <pubDate>Tue, 14 Oct 2025 17:27:33 +0000</pubDate>
      <guid>/articles/article-2025-10-14-10900/</guid>
      <description>Deploying OpenShift in air-gapped environments can be challenging due to complex setup requirements. The article introduces &amp;ldquo;aba,&amp;rdquo; a new tool that simplifies this process. Aba provides a pre-tested install bundle that includes all necessary components, automating the setup of registries and mirroring images. This tool aims to reduce installation time and manual troubleshooting. Aba&amp;rsquo;s key features include end-to-end automation, built-in best practices, and support for various installation&amp;hellip;</description>
    </item>
    <item>
      <title>Dynamic GPU slicing with Red Hat OpenShift and NVIDIA MIG</title>
      <link>/articles/article-2025-10-14-10884/</link>
      <pubDate>Tue, 14 Oct 2025 07:01:10 +0000</pubDate>
      <guid>/articles/article-2025-10-14-10884/</guid>
      <description>Unlock the potential of your GPU with NVIDIA&amp;rsquo;s Multi-Instance GPU (MIG) and Red Hat OpenShift! üöÄ This powerful combination allows you to dynamically allocate GPU resources, enabling diverse workloads‚Äîfrom running seven small models to a single large one‚Äîwithout idle time. Discover how the dynamic accelerator slicer operates, facilitating efficient resource management and isolation for teams. üíª Read more about the setup and see live demos of this innovative technology in action! #NVIDIA&amp;hellip;</description>
    </item>
    <item>
      <title>Protecting virtual machines from storage and secondary network node failures</title>
      <link>/articles/article-2025-10-13-10865/</link>
      <pubDate>Mon, 13 Oct 2025 07:01:04 +0000</pubDate>
      <guid>/articles/article-2025-10-13-10865/</guid>
      <description>Kubernetes provides basic health monitoring for nodes but lacks adequate support for storage and secondary network failures, crucial for virtual machines and telco deployments. The kubelet detects node issues, focusing mainly on resource availability and control plane connectivity. However, it does not monitor storage or network health directly, leading to potential inconsistencies and downtime. To address this, the Node Problem Detector (NPD) operator can be implemented, allowing for&amp;hellip;</description>
    </item>
    <item>
      <title>How to use OCI for GitOps in OpenShift</title>
      <link>/articles/article-2025-10-13-10866/</link>
      <pubDate>Mon, 13 Oct 2025 07:01:02 +0000</pubDate>
      <guid>/articles/article-2025-10-13-10866/</guid>
      <description>üöÄ Exploring GitOps with OCI in OpenShift! Organizations transitioning to GitOps often think they need Git-based systems. However, GitOps principles allow for other compliant storage options like OCI, which can store various content types beyond container images. OpenShift GitOps 1.18 now supports OCI as a source of truth, simplifying management and enhancing security. This approach streamlines operations and integrates well with CI pipelines. To get started, ensure you have the oras CLI and&amp;hellip;</description>
    </item>
    <item>
      <title>Using AI agents with Red Hat Insights</title>
      <link>/articles/article-2025-10-13-10867/</link>
      <pubDate>Mon, 13 Oct 2025 07:00:59 +0000</pubDate>
      <guid>/articles/article-2025-10-13-10867/</guid>
      <description>Unlock the potential of AI with insights-mcp by Red Hat! üåê This self-hosted server allows seamless interaction with key Red Hat Insights features like vulnerability management and inventory tracking, all through the Model Context Protocol (MCP). To get started, set up a service account and install VS Code. You can then connect LLM agents to enhance your workflows, from daily security checks to compliance monitoring. Explore the developer preview today and share your feedback! üõ†Ô∏èüíª #RedHat #AI&amp;hellip;</description>
    </item>
    <item>
      <title>Splitting OpenShift machine config pool without node reboots</title>
      <link>/articles/article-2025-10-10-10616/</link>
      <pubDate>Fri, 10 Oct 2025 07:00:58 +0000</pubDate>
      <guid>/articles/article-2025-10-10-10616/</guid>
      <description>üöÄ Splitting an OpenShift Machine Config Pool (MCP) without node reboots is now possible! This guide details how to create two separate MCPs while maintaining identical configurations. This method is especially beneficial for large clusters with over 100 worker nodes, simplifying upgrades and management. Key steps include identifying the current MCP and machine configurations, creating a new MCP, and labeling nodes for the transition. For detailed commands and procedures, refer to the full&amp;hellip;</description>
    </item>
    <item>
      <title>Node.js 20&#43; memory management in containers</title>
      <link>/articles/article-2025-10-10-10617/</link>
      <pubDate>Fri, 10 Oct 2025 07:00:55 +0000</pubDate>
      <guid>/articles/article-2025-10-10-10617/</guid>
      <description>Node.js 20 enhances memory management in containers by being container-aware, limiting heap size based on cgroup limits. This adaptation helps prevent memory overflow issues on platforms like OpenShift. The maximum heap size is 50% of the container size, capping at 2 GiB for larger containers. Developers can also set specific limits using the &lt;code&gt;--max-old-space-size&lt;/code&gt; flag. For efficient CPU allocation, combining &lt;code&gt;worker_threads&lt;/code&gt; with multiple CPU limits can improve performance, but balance is&amp;hellip;</description>
    </item>
    <item>
      <title>Integrate incident detection with OpenShift Lightspeed via MCP</title>
      <link>/articles/article-2025-10-09-10576/</link>
      <pubDate>Thu, 09 Oct 2025 07:00:51 +0000</pubDate>
      <guid>/articles/article-2025-10-09-10576/</guid>
      <description>Red Hat OpenShift now integrates incident detection with OpenShift Lightspeed, enhancing how users analyze and resolve cluster issues. This integration allows for natural language interaction, helping to group related alerts and reduce alert fatigue. Users can easily inquire about incidents, symptoms, and event chains. To set up, ensure you have OpenShift 4.19 and an API key for an LLM provider. Installation steps are available for the Cluster Health MCP server. Explore these new capabilities&amp;hellip;</description>
    </item>
    <item>
      <title>One model is not enough, too many models is hard: Technical deep dive</title>
      <link>/articles/article-2025-10-08-10542/</link>
      <pubDate>Wed, 08 Oct 2025 14:16:08 +0000</pubDate>
      <guid>/articles/article-2025-10-08-10542/</guid>
      <description>üöÄ Discover how to efficiently manage hundreds to thousands of machine learning models with a systematic approach! This guide outlines a model lifecycle assembly line, focusing on configuration-driven pipelines, version control, and GitOps promotion. Key features include: - Continuous training and versioned pipelines - Data lineage for reproducibility - Safe, automated deployments Learn how to implement these practices in your environment! üîó Check out the full details and demo on YouTube!&amp;hellip;</description>
    </item>
    <item>
      <title>What&#39;s new in Ansible Automation Platform 2.6</title>
      <link>/articles/article-2025-10-08-10532/</link>
      <pubDate>Wed, 08 Oct 2025 13:01:32 +0000</pubDate>
      <guid>/articles/article-2025-10-08-10532/</guid>
      <description>üöÄ Red Hat Ansible Automation Platform 2.6 is now available! This release enhances automation accessibility with new features. Key updates include a self-service automation portal, the Ansible Lightspeed intelligent assistant, and an on-premise automation dashboard for tracking metrics. Developers can now provide teams with a simple interface to launch automation jobs, visualize their impact, and streamline development environments. Explore the latest version today! #Ansible #Automation&amp;hellip;</description>
    </item>
    <item>
      <title>Quantum computing 101 for developers</title>
      <link>/articles/article-2025-10-08-10526/</link>
      <pubDate>Wed, 08 Oct 2025 07:16:06 +0000</pubDate>
      <guid>/articles/article-2025-10-08-10526/</guid>
      <description>üåê Quantum computing is emerging as a transformative technology for developers and businesses. Unlike classical computing, which uses bits (0s and 1s), quantum computing employs qubits, allowing for superposition and entanglement. üîç These concepts enable quantum computers to tackle complex problems that classical systems struggle with, such as optimizing financial portfolios or drug design. üîó Red Hat is adapting its platforms to integrate quantum capabilities, ensuring developers are prepared&amp;hellip;</description>
    </item>
    <item>
      <title>LLM Compressor 0.8.0: Extended support for Qwen3 and more</title>
      <link>/articles/article-2025-10-07-10506/</link>
      <pubDate>Tue, 07 Oct 2025 18:07:28 +0000</pubDate>
      <guid>/articles/article-2025-10-07-10506/</guid>
      <description>üöÄ The LLM Compressor 0.8.0 release enhances quantization workflows and extends support for Qwen3 models. Key updates include: 1Ô∏è‚É£ Support for multiple modifiers during a single oneshot compression run, allowing for non-uniform quantization. 2Ô∏è‚É£ Configurable transforms with variable rotation sizes for improved efficiency. 3Ô∏è‚É£ R4 support for SpinQuant-style transforms. 4Ô∏è‚É£ Added quantization for Qwen3 models, including FP8 support. 5Ô∏è‚É£ Improved accuracy for GPTQ W4A16 schemes. Explore the&amp;hellip;</description>
    </item>
    <item>
      <title>Master KV cache aware routing with llm-d for efficient AI inference</title>
      <link>/articles/article-2025-10-07-10481/</link>
      <pubDate>Tue, 07 Oct 2025 07:00:56 +0000</pubDate>
      <guid>/articles/article-2025-10-07-10481/</guid>
      <description>Unlock efficient AI inference with llm-d! üöÄ This Kubernetes-native framework introduces KV cache aware routing, reducing latency and improving throughput by directing requests to pods with relevant context in GPU memory. Key features include an External Processing Pod and intelligent routing. With a recent test showing an impressive 87.4% cache hit rate, llm-d enhances performance and optimizes resource use. Learn more about maximizing AI infrastructure efficiency! üìäüí° #AIInference #Kubernetes&amp;hellip;</description>
    </item>
    <item>
      <title>Deploying OpenShift hosted clusters with Hypershift</title>
      <link>/articles/article-2025-10-07-10482/</link>
      <pubDate>Tue, 07 Oct 2025 07:00:55 +0000</pubDate>
      <guid>/articles/article-2025-10-07-10482/</guid>
      <description>üöÄ HyperShift revolutionizes Kubernetes management with hosted control planes in Red Hat OpenShift. This innovative feature reduces costs and complexity while enhancing scalability. It allows for faster cluster creation and upgrades, making it easier to manage large fleets. HyperShift‚Äôs architecture enables hosted control planes to run on a management cluster, optimizing resource usage. Key considerations include configuring networking, storage, and certificate management for security. Explore&amp;hellip;</description>
    </item>
    <item>
      <title>Signing RPM packages using quantum-resistant cryptography</title>
      <link>/articles/article-2025-10-07-10483/</link>
      <pubDate>Tue, 07 Oct 2025 07:00:52 +0000</pubDate>
      <guid>/articles/article-2025-10-07-10483/</guid>
      <description>üîí Learn how to sign RPM packages in Red Hat Enterprise Linux 10.1 using quantum-resistant cryptography. This article details the process for developers and vendors to enhance software security through strong signatures. It covers generating OpenPGP keys, configuring RPM, and integrating these steps into existing workflows. Post-quantum cryptography (PQC) aims to protect against future quantum attacks by using hybrid keys and signatures. RPM 6 supports multiple signatures, ensuring both&amp;hellip;</description>
    </item>
    <item>
      <title>Optimize and deploy LLMs for production with OpenShift AI</title>
      <link>/articles/article-2025-10-06-10436/</link>
      <pubDate>Mon, 06 Oct 2025 07:00:48 +0000</pubDate>
      <guid>/articles/article-2025-10-06-10436/</guid>
      <description>üöÄ Organizations face challenges in running large language models (LLMs) on their infrastructure, especially regarding GPU availability and cost. The Qwen3-Coder-30B-A3B-Instruct model offers strong code-generation capabilities but requires significant GPU resources. To enhance efficiency, quantization is employed to reduce the model&amp;rsquo;s memory footprint while maintaining accuracy. The article outlines a workflow for optimizing and deploying LLMs using Red Hat OpenShift AI, including model&amp;hellip;</description>
    </item>
    <item>
      <title>DeepSeek-V3.2-Exp on vLLM, Day 0: Sparse Attention for long-context inference, ready for experimentation today with Red Hat AI</title>
      <link>/articles/article-2025-10-03-10410/</link>
      <pubDate>Fri, 03 Oct 2025 13:14:44 +0000</pubDate>
      <guid>/articles/article-2025-10-03-10410/</guid>
      <description>üöÄ Exciting news in AI! DeepSeek-V3.2-Exp has launched, introducing Sparse Attention for efficient long-context inference. This two-stage process aims to lower costs by up to 50% for API calls. Supported by vLLM from Day 0, it runs on NVIDIA Hopper and Blackwell architectures, enabling immediate experimentation. Red Hat AI users can deploy it seamlessly on their platforms. Learn more about optimizing your long-context tasks! #AI #MachineLearning #DeepLearning #RedHatAI #NVIDIA</description>
    </item>
    <item>
      <title>How to deploy the Offline Knowledge Portal on OpenShift</title>
      <link>/articles/article-2025-10-03-10406/</link>
      <pubDate>Fri, 03 Oct 2025 07:00:48 +0000</pubDate>
      <guid>/articles/article-2025-10-03-10406/</guid>
      <description>üöÄ Discover the Red Hat Offline Knowledge Portal, designed for users in low-bandwidth or disconnected environments. This tool consolidates essential Red Hat information, including documentation and security data, into a portable container image. üõ†Ô∏è The article provides a step-by-step guide for deploying the portal on an OpenShift cluster, including prerequisites like OpenShift cluster access and Podman installation. üì• Key steps involve downloading the image, transferring it, and deploying it&amp;hellip;</description>
    </item>
    <item>
      <title>Autoscaling vLLM with OpenShift AI</title>
      <link>/articles/article-2025-10-02-10358/</link>
      <pubDate>Thu, 02 Oct 2025 07:00:57 +0000</pubDate>
      <guid>/articles/article-2025-10-02-10358/</guid>
      <description>Unlock the power of efficient LLM serving with OpenShift AI! üöÄ This article discusses how vLLM and KServe enable autoscaling of model servers, optimizing GPU resource utilization. It highlights the Serverless deployment mode, allowing scaling based on concurrent requests, and the future potential for RawDeployments using KEDA. Key prerequisites for setup include the NVIDIA GPU Operator and OpenShift Serverless. The article also provides a step-by-step guide on deploying models and configuring&amp;hellip;</description>
    </item>
    <item>
      <title>Filtering packets from anywhere in the networking stack</title>
      <link>/articles/article-2025-10-02-10359/</link>
      <pubDate>Thu, 02 Oct 2025 07:00:56 +0000</pubDate>
      <guid>/articles/article-2025-10-02-10359/</guid>
      <description>Discover the potential of packet filtering with Retis! üåê This article explores how Retis allows packet dumps from anywhere in the networking stack. It highlights its unique filtering methods: packet filtering and metadata filtering, which help manage data, ensuring accurate captures and reducing overhead. Learn how Retis compares to tools like tcpdump and tshark, emphasizing the importance of precise filtering for effective network debugging. #NetworkEngineering #PacketFiltering #Retis&amp;hellip;</description>
    </item>
    <item>
      <title>PostGIS: A powerful geospatial extension for PostgreSQL</title>
      <link>/articles/article-2025-10-02-10360/</link>
      <pubDate>Thu, 02 Oct 2025 07:00:52 +0000</pubDate>
      <guid>/articles/article-2025-10-02-10360/</guid>
      <description>üöÄ PostGIS is a geospatial extension for PostgreSQL, enhancing the database&amp;rsquo;s ability to manage geographic data. It supports operations like distance calculations and spatial joins, making it ideal for GIS applications. üîß Installation requires compatible PostgreSQL versions, currently supporting PostgreSQL 16 on RHEL 9 and 10. üìä Users can create tables with various geometric types and utilize raster data analysis through PostGIS. For detailed setup instructions, refer to the full article!&amp;hellip;</description>
    </item>
    <item>
      <title>The secure way to handle secrets in OpenShift</title>
      <link>/articles/article-2025-10-01-10306/</link>
      <pubDate>Wed, 01 Oct 2025 07:01:07 +0000</pubDate>
      <guid>/articles/article-2025-10-01-10306/</guid>
      <description>Managing sensitive information in cloud-native platforms like OpenShift is essential for security. üåê This article discusses two methods for accessing secrets: environment variables and volume mounts. While both are supported, volume mounts are recommended for better security and control. üîí Volume mounts automatically update sensitive data and limit exposure, ensuring only necessary credentials are accessed by applications. In contrast, environment variables carry risks of accidental exposure&amp;hellip;</description>
    </item>
    <item>
      <title>How to deploy MCP servers on OpenShift using ToolHive</title>
      <link>/articles/article-2025-10-01-10307/</link>
      <pubDate>Wed, 01 Oct 2025 07:01:03 +0000</pubDate>
      <guid>/articles/article-2025-10-01-10307/</guid>
      <description>üöÄ The Model Context Protocol (MCP), introduced by Anthropic in November 2024, standardizes AI interactions with large language models. Its rapid adoption has led to a surge in MCP servers for local development. üõ†Ô∏è ToolHive, developed by Stacklok, facilitates the deployment and management of these servers on Kubernetes and OpenShift. It includes a GUI for local developers and an operator for Kubernetes orchestration. üîß To get started, ensure you have Helm and access to an OpenShift-based&amp;hellip;</description>
    </item>
    <item>
      <title>How to change the meaning of python and python3 on RHEL</title>
      <link>/articles/article-2025-09-30-10240/</link>
      <pubDate>Tue, 30 Sep 2025 07:00:55 +0000</pubDate>
      <guid>/articles/article-2025-09-30-10240/</guid>
      <description>Changing the default Python interpreter on RHEL requires caution. The alternatives command, previously used, is unsupported in RHEL 9 and later due to potential system risks. Modifying the system Python can disrupt core components like dnf, affecting system management. A safer approach is to create a symbolic link to your desired Python version without altering the system Python. This method is easy to reverse and maintains system integrity. For script portability, use `#!/usr/bin/env&amp;hellip;</description>
    </item>
    <item>
      <title>vLLM or llama.cpp: Choosing the right LLM inference engine for your use case</title>
      <link>/articles/article-2025-09-30-10241/</link>
      <pubDate>Tue, 30 Sep 2025 07:00:52 +0000</pubDate>
      <guid>/articles/article-2025-09-30-10241/</guid>
      <description>üîç Exploring LLM Inference Engines: vLLM vs. llama.cpp This article compares two powerful inference engines, highlighting their distinct features. vLLM is built for high-throughput, multi-user scenarios, excelling in scalability and responsiveness. It delivers rapid responses even under heavy loads. In contrast, llama.cpp focuses on efficiency and portability, ideal for single-user tasks and consumer-grade hardware. Its C++ architecture allows for quick loading and minimal dependencies. For&amp;hellip;</description>
    </item>
    <item>
      <title>How to implement and monitor circuit breakers in OpenShift Service Mesh 3</title>
      <link>/articles/article-2025-09-29-10192/</link>
      <pubDate>Mon, 29 Sep 2025 07:00:58 +0000</pubDate>
      <guid>/articles/article-2025-09-29-10192/</guid>
      <description>Learn how to implement and monitor circuit breakers in OpenShift Service Mesh 3.0 to enhance your application&amp;rsquo;s resilience! ‚ö° This guide outlines the steps to configure, trigger, and monitor a circuit breaker that isolates unhealthy services, helping prevent system-wide failures. Key prerequisites include having an OpenShift cluster and the Bookinfo application set up. The tutorial also covers using Kiali for monitoring. üìä For detailed instructions, check out the full guide! #OpenShift&amp;hellip;</description>
    </item>
    <item>
      <title>Analysis of OpenShift node-system-admin-client lifespan</title>
      <link>/articles/article-2025-09-29-10193/</link>
      <pubDate>Mon, 29 Sep 2025 07:00:55 +0000</pubDate>
      <guid>/articles/article-2025-09-29-10193/</guid>
      <description>In the Red Hat OpenShift Container Platform, the node-system-admin-client certificate plays a vital role in securing internal communication. This article analyzes its lifecycle, revealing a mismatch between its intended two-year validity and the actual one-year expiration due to constraints from its signing Certificate Authority (CA). It also highlights the manual rotation of certificates and the steps needed to renew them effectively. üîÑüîç #OpenShift #PKI #Certificates #RedHat #ContainerSecurity</description>
    </item>
    <item>
      <title>Beyond a single cluster with OpenShift Service Mesh 3</title>
      <link>/articles/article-2025-09-26-10120/</link>
      <pubDate>Fri, 26 Sep 2025 07:01:07 +0000</pubDate>
      <guid>/articles/article-2025-09-26-10120/</guid>
      <description>Explore the advancements of Red Hat OpenShift Service Mesh 3! üöÄ This article highlights its robust support for multi-cluster topologies, transforming independent clusters into a unified application network. It emphasizes secure inter-cluster communication through dedicated gateways. Learn about the benefits of enhanced scalability, fault tolerance, and seamless failover patterns. A step-by-step guide is provided for creating a multi-cluster architecture. #OpenShift #ServiceMesh #MultiCluster&amp;hellip;</description>
    </item>
    <item>
      <title>Kubernetes MCP server: AI-powered cluster management</title>
      <link>/articles/article-2025-09-25-10046/</link>
      <pubDate>Thu, 25 Sep 2025 07:00:56 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10046/</guid>
      <description>üöÄ Explore the Kubernetes MCP server, an AI-powered extension for Kubernetes and OpenShift! This tool allows AI assistants like VS Code and Microsoft Copilot to interact safely with your clusters. It simplifies cluster management through natural language commands and supports secure access via least-privilege ServiceAccounts. Key features include no external dependencies, support for generic Kubernetes resources, and advanced pod operations. Currently in developer preview, it encourages&amp;hellip;</description>
    </item>
    <item>
      <title>Unlocking the power of OpenShift Service Mesh 3</title>
      <link>/articles/article-2025-09-25-10047/</link>
      <pubDate>Thu, 25 Sep 2025 07:00:54 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10047/</guid>
      <description>üöÄ Red Hat OpenShift Service Mesh 3 enhances traffic management, observability, and security for microservices. As applications grow, so do the complexities of routing and securing communications. OSSM 3 introduces Envoy proxies to streamline these processes, ensuring secure service interactions and better traffic control. With features like mutual TLS for security, canary deployments for testing, and enhanced observability tools, teams can manage their microservices more effectively&amp;hellip;.</description>
    </item>
    <item>
      <title>Run DialoGPT-small on OpenShift AI for internal model testing</title>
      <link>/articles/article-2025-09-25-10048/</link>
      <pubDate>Thu, 25 Sep 2025 07:00:51 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10048/</guid>
      <description>Explore the deployment of the DialoGPT-small language model on OpenShift AI for internal testing. This guide details setting up your environment, configuring ServingRuntime, and deploying an inference service, all within a secure, cloud-native environment. Key steps include verifying components, managing model storage with PVCs, and running tests without exposing external endpoints. This workflow is intended for internal evaluation only. For production use, refer to official documentation&amp;hellip;.</description>
    </item>
    <item>
      <title>Skopeo: The unsung hero of Linux container-tools</title>
      <link>/articles/article-2025-09-24-9963/</link>
      <pubDate>Wed, 24 Sep 2025 07:00:54 +0000</pubDate>
      <guid>/articles/article-2025-09-24-9963/</guid>
      <description>Discover the power of Skopeo, an essential tool in the Linux container-tools ecosystem. üåü Skopeo allows you to inspect and copy container images efficiently without downloading them first. This is especially useful for developers using Kubernetes clusters. It simplifies many tasks typically done with Podman, making workflows smoother. From inspecting remote images to syncing multiple registries, Skopeo enhances your container management experience. üåêüîß #Linux #ContainerTools #Skopeo #DevOps&amp;hellip;</description>
    </item>
    <item>
      <title>Automate certificate management in OpenShift</title>
      <link>/articles/article-2025-09-24-9964/</link>
      <pubDate>Wed, 24 Sep 2025 07:00:51 +0000</pubDate>
      <guid>/articles/article-2025-09-24-9964/</guid>
      <description>Managing certificates in IT can be challenging. Many DevOps engineers and IT managers face time-consuming manual tasks, risking governance and security. This article discusses automating the certificate lifecycle in Red Hat OpenShift using the cert-manager operator with Venafi. It offers a solution that enhances efficiency and security. By transitioning from traditional to modern certificate management, teams can minimize errors and focus on innovation. The cert-manager operator simplifies&amp;hellip;</description>
    </item>
    <item>
      <title>Customize RHEL CoreOS at scale: On-cluster image mode in OpenShift</title>
      <link>/articles/article-2025-09-23-9903/</link>
      <pubDate>Tue, 23 Sep 2025 07:01:38 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9903/</guid>
      <description>üöÄ Exciting news for OpenShift users! Red Hat introduces &amp;ldquo;on-cluster&amp;rdquo; image mode for Red Hat Enterprise Linux CoreOS, allowing seamless customization at scale. This cloud-native approach treats your OS like a container image, enabling you to define configurations as code. You can now add drivers, deploy hotfixes, and maintain customizations during upgrades directly from your cluster. OpenShift 4.19 and EUS users on 4.18.21 can fully utilize this capability. The streamlined build process&amp;hellip;</description>
    </item>
    <item>
      <title>How to set up KServe autoscaling for vLLM with KEDA</title>
      <link>/articles/article-2025-09-23-9904/</link>
      <pubDate>Tue, 23 Sep 2025 07:01:36 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9904/</guid>
      <description>Deploying machine learning models poses unique challenges, especially with fluctuating traffic levels. Traditional autoscaling methods often fall short, leading to inefficiencies. This article discusses setting up KServe autoscaling using vLLM and KEDA. This approach focuses on application-specific metrics, enabling efficient scaling tailored to AI workload demands. Learn about the process, including exposing metrics to Prometheus and configuring KEDA for optimal performance. üåêüìà&amp;hellip;</description>
    </item>
    <item>
      <title>How I used Cursor AI to migrate a Bash test suite to Python</title>
      <link>/articles/article-2025-09-23-9905/</link>
      <pubDate>Tue, 23 Sep 2025 07:01:33 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9905/</guid>
      <description>üöÄ Migrating code can be tough, but Cursor AI simplifies the process! Our team transitioned a Bash test suite to Python using the Cursor AI code editor. After installing and logging in, we enabled specific AI models to assist with the migration. Cursor helped analyze the Bash scripts, generated a Python library, and created basic tests automatically. The result? A significant time-saving of about 1.5 months! For a detailed look at the process, check our documentation. #CodeMigration #CursorAI&amp;hellip;</description>
    </item>
    <item>
      <title>Install Python 3.13 on Red Hat Enterprise Linux from EPEL</title>
      <link>/articles/article-2025-09-22-9860/</link>
      <pubDate>Mon, 22 Sep 2025 07:01:15 +0000</pubDate>
      <guid>/articles/article-2025-09-22-9860/</guid>
      <description>üì£ Exciting news for developers! Python 3.13 is now available in the EPEL repository for Red Hat Enterprise Linux (RHEL) 9 and 10. This allows users to access the latest Python features seamlessly. To install, ensure the EPEL repository is enabled and run: &lt;code&gt;sudo dnf install python3.13&lt;/code&gt; Verify the installation with: &lt;code&gt;python3.13 --version&lt;/code&gt; For project management, consider using virtual environments to isolate dependencies. Learn more about how EPEL supports software availability while&amp;hellip;</description>
    </item>
    <item>
      <title>Zero trust automation on AWS with Ansible and Terraform</title>
      <link>/articles/article-2025-09-22-9861/</link>
      <pubDate>Mon, 22 Sep 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-09-22-9861/</guid>
      <description>üöÄ Exciting advancements in cloud automation! The latest blog post discusses the Red Hat Ansible Certified Content Collection for amazon.aws 10.0.0. It highlights the amazon.aws.aws_ssm connection plug-in that enhances security by eliminating SSH access and public IPs. Key features include: - Secure provisioning of EC2 instances using Terraform - Management of tasks via Ansible over SSM - Dynamic inventory for automated resource discovery This approach supports zero trust networking and&amp;hellip;</description>
    </item>
    <item>
      <title>Cloud bursting with confidential containers on OpenShift</title>
      <link>/articles/article-2025-09-18-9763/</link>
      <pubDate>Thu, 18 Sep 2025 07:00:58 +0000</pubDate>
      <guid>/articles/article-2025-09-18-9763/</guid>
      <description>üöÄ Cloud bursting enhances on-premises applications by extending them to the cloud during peak demand. üîí Secure connectivity ensures that cloud resources can access on-premises data seamlessly. Confidential computing adds a layer of security, protecting sensitive information even in untrusted environments. üõ†Ô∏è This article details how to set up a cloud-bursting scenario from an OpenShift cluster to Azure using confidential containers and OpenVPN. #CloudBursting #OpenShift #ConfidentialComputing&amp;hellip;</description>
    </item>
    <item>
      <title>Reach native speed with MacOS llama.cpp container inference</title>
      <link>/articles/article-2025-09-18-9764/</link>
      <pubDate>Thu, 18 Sep 2025 07:00:55 +0000</pubDate>
      <guid>/articles/article-2025-09-18-9764/</guid>
      <description>üöÄ New advancements in GPU acceleration for AI inference on macOS! Recent developments showcase how llama.cpp now achieves native speed performance in most use cases. By leveraging a thin virtualization layer, containers can run efficiently on macOS. This enhancement utilizes the API remoting architecture, allowing optimized GPU access in virtualized environments. Key components include ggml-remoting and libkrun&amp;rsquo;s virtio-gpu, which enable seamless communication between the virtual machine and&amp;hellip;</description>
    </item>
    <item>
      <title>A deep dive into Apache Kafka&#39;s KRaft protocol</title>
      <link>/articles/article-2025-09-17-9720/</link>
      <pubDate>Wed, 17 Sep 2025 12:33:25 +0000</pubDate>
      <guid>/articles/article-2025-09-17-9720/</guid>
      <description>üöÄ Dive into the KRaft protocol of Apache Kafka! This article explores the key concepts and implementation of KRaft in version 4.1.0. It highlights how KRaft simplifies Kafka operations by eliminating the need for ZooKeeper and addressing scalability and consistency issues. The guide covers important elements like consensus algorithms, leader election, log replication, and safety rules essential for distributed systems. Developers and engineers looking to enhance their understanding will find&amp;hellip;</description>
    </item>
    <item>
      <title>Staying ahead of artificial intelligence threats</title>
      <link>/articles/article-2025-09-17-9715/</link>
      <pubDate>Wed, 17 Sep 2025 07:01:06 +0000</pubDate>
      <guid>/articles/article-2025-09-17-9715/</guid>
      <description>üöÄ In 2024, over 40,000 Common Vulnerabilities and Exposures (CVEs) were reported, marking a 38% rise from 2023. The trend of increasing CVEs is expected to continue into 2025, with projections of up to 58,956 new CVEs. üîí Kernel live patching has emerged as a crucial practice for applying security updates without downtime. This allows OpenStack Services on OpenShift users to maintain system integrity while minimizing interruptions. üñ•Ô∏è For more details, check out the article on kernel live&amp;hellip;</description>
    </item>
    <item>
      <title>Strengthen privacy and security with encrypted DNS in RHEL</title>
      <link>/articles/article-2025-09-17-9716/</link>
      <pubDate>Wed, 17 Sep 2025 07:01:03 +0000</pubDate>
      <guid>/articles/article-2025-09-17-9716/</guid>
      <description>üîí In today&amp;rsquo;s digital world, securing DNS traffic is crucial. Unencrypted DNS queries can expose sensitive information to eavesdroppers, leading to potential data breaches. üîç Encrypted DNS, particularly DNS over TLS (DoT), is now available in Red Hat Enterprise Linux 10 and 9.6. This advancement strengthens network security by ensuring that DNS queries are kept private and verifiable. üõ†Ô∏è The article provides a step-by-step guide for implementing encrypted DNS to improve system security during&amp;hellip;</description>
    </item>
    <item>
      <title>How to enable Ansible Lightspeed intelligent assistant</title>
      <link>/articles/article-2025-09-16-9674/</link>
      <pubDate>Tue, 16 Sep 2025 07:00:56 +0000</pubDate>
      <guid>/articles/article-2025-09-16-9674/</guid>
      <description>üöÄ Discover the Red Hat Ansible Lightspeed intelligent assistant in the latest Red Hat Ansible Automation Platform 2.6! This integrated chatbot utilizes various inference backends and can be deployed with Red Hat OpenShift AI. The article provides a step-by-step guide for installing OpenShift AI and setting up an inference service on the same cluster. Key topics include: - Installing OpenShift AI - Deploying an Inference Service - Configuring Ansible Lightspeed Stay tuned for more insights in&amp;hellip;</description>
    </item>
    <item>
      <title>Why some agentic AI developers are moving code from Python to Rust</title>
      <link>/articles/article-2025-09-15-9636/</link>
      <pubDate>Mon, 15 Sep 2025 07:00:53 +0000</pubDate>
      <guid>/articles/article-2025-09-15-9636/</guid>
      <description>AI developers are exploring a shift from Python to Rust for agentic AI solutions. While Python is popular for its simplicity and rich libraries, its Global Interpreter Lock (GIL) limits performance in CPU-bound tasks, especially as systems scale from 5 to 500 agents. Rust offers a solution with better concurrency and scalability, allowing more efficient handling of multiple agents and CPU-intensive tasks. Developers are finding that a hybrid approach‚Äîprototyping in Python and optimizing with&amp;hellip;</description>
    </item>
    <item>
      <title>Confidential VMs: The core of confidential containers</title>
      <link>/articles/article-2025-09-15-9637/</link>
      <pubDate>Mon, 15 Sep 2025 07:00:51 +0000</pubDate>
      <guid>/articles/article-2025-09-15-9637/</guid>
      <description>üîç Discover the essentials of Confidential Virtual Machines (CVMs) and their role in enhancing the security of confidential containers (CoCo). CVMs utilize hardware and software to ensure data confidentiality, isolating workloads from the host environment. This integration with Red Hat Enterprise Linux (RHEL) and OpenShift boosts security standards for data in use. üõ°Ô∏è Learn about features like Unified Kernel Images (UKI) and remote attestation that enhance the protection of workloads&amp;hellip;.</description>
    </item>
    <item>
      <title>Benchmarking with GuideLLM in air-gapped OpenShift clusters</title>
      <link>/articles/article-2025-09-15-9638/</link>
      <pubDate>Mon, 15 Sep 2025 07:00:48 +0000</pubDate>
      <guid>/articles/article-2025-09-15-9638/</guid>
      <description>Deploying and benchmarking large language models (LLMs) in air-gapped environments is vital for regulated enterprises. This article details the process of using the Red Hat AI Inference Server with vLLM and GuideLLM for performance evaluation within a disconnected OpenShift cluster. Key components include prebuilt container images, Persistent Volume Claims (PVCs), and OpenShift-native Job resources. GuideLLM, an open-source tool, provides metrics like token throughput and latency, ensuring&amp;hellip;</description>
    </item>
    <item>
      <title>Run Qwen3-Next on vLLM with Red Hat AI: A step-by-step guide</title>
      <link>/articles/article-2025-09-12-9624/</link>
      <pubDate>Fri, 12 Sep 2025 22:59:57 +0000</pubDate>
      <guid>/articles/article-2025-09-12-9624/</guid>
      <description>üöÄ Exciting news in AI! The Qwen3-Next model features a new hybrid attention and sparse MoE architecture, enhancing training efficiency and inference speed. üîß With Day 0 support from vLLM, organizations can deploy it immediately using Red Hat AI for secure and scalable solutions. üìä Key improvements include multi-token prediction and optimized training stability. For a step-by-step guide on deployment, check the latest blog! #AI #RedHat #OpenSource #MachineLearning #Qwen3Next</description>
    </item>
    <item>
      <title>How to implement observability with Python and Llama Stack</title>
      <link>/articles/article-2025-09-12-9602/</link>
      <pubDate>Fri, 12 Sep 2025 07:01:14 +0000</pubDate>
      <guid>/articles/article-2025-09-12-9602/</guid>
      <description>Discover how to enhance AI application observability using Python and Llama Stack! üöÄ This article highlights the importance of observability in production, focusing on logging, metrics, and distributed tracing. It introduces OpenTelemetry as a key tool for instrumenting applications and discusses setting up Jaeger for trace visualization. Explore the detailed steps for implementing observability, including configuring your Llama Stack instance to capture and visualize traces effectively&amp;hellip;.</description>
    </item>
    <item>
      <title>Deploy a lightweight AI model with AI Inference Server containerization</title>
      <link>/articles/article-2025-09-12-9603/</link>
      <pubDate>Fri, 12 Sep 2025 07:01:11 +0000</pubDate>
      <guid>/articles/article-2025-09-12-9603/</guid>
      <description>üöÄ Ready to explore AI? This tutorial provides a step-by-step guide to deploy a lightweight AI model, Llama-3.2-1B, using the Red Hat AI Inference Server. It‚Äôs designed for quick testing on personal machines with local GPUs. üîß You&amp;rsquo;ll need a valid Red Hat account and a compatible GPU. The tutorial covers everything from logging in to the Red Hat container registry to running the model with minimal setup. For more details, check out the tutorial! #AI #RedHat #MachineLearning #Containerization&amp;hellip;</description>
    </item>
    <item>
      <title>vLLM Semantic Router: Improving efficiency in AI reasoning</title>
      <link>/articles/article-2025-09-11-9544/</link>
      <pubDate>Thu, 11 Sep 2025 07:01:00 +0000</pubDate>
      <guid>/articles/article-2025-09-11-9544/</guid>
      <description>Introducing the vLLM Semantic Router, an open-source solution for enhancing efficiency in AI reasoning. üéâ This system intelligently routes queries based on their complexity, ensuring that resources are used wisely. It utilizes a ModernBERT-based classifier for semantic classification, sending simpler requests to faster models and more complex ones to stronger models. Key benefits include improved accuracy (+10.2%), reduced latency (‚Äì47.1%), and decreased token usage (‚Äì48.5%). This approach&amp;hellip;</description>
    </item>
    <item>
      <title>Declaratively assigning DNS records to virtual machines</title>
      <link>/articles/article-2025-09-11-9545/</link>
      <pubDate>Thu, 11 Sep 2025 07:00:57 +0000</pubDate>
      <guid>/articles/article-2025-09-11-9545/</guid>
      <description>üîç Virtual machines often require DNS records to maintain unique identities. This article discusses how to declaratively assign these records using Red Hat OpenShift Virtualization. üìä It highlights the importance of naming conventions and provides methods to automate DNS record assignments via labels and annotations. üîß Key considerations include network exposure, IP assignment, and managing multiple DNS records for diverse network interfaces. #VirtualMachines #DNSManagement #OpenShift #GitOps&amp;hellip;</description>
    </item>
    <item>
      <title>How to deploy language models with Red Hat OpenShift AI</title>
      <link>/articles/article-2025-09-10-9507/</link>
      <pubDate>Wed, 10 Sep 2025 07:00:55 +0000</pubDate>
      <guid>/articles/article-2025-09-10-9507/</guid>
      <description>üöÄ Red Hat OpenShift AI is transforming the deployment of language models! This guide explores the OpenShift AI console, your hub for managing data science projects. You can easily deploy models like Llama, leveraging GPU acceleration and resource scaling. Key features include project dashboards, model tracking, and multiple storage options. Check out the step-by-step deployment process for Llama, from GPU setup to testing both internal and external access. üîó Watch the full video demo for a&amp;hellip;</description>
    </item>
    <item>
      <title>AI search with style: Fashion on OpenShift AI with EDB</title>
      <link>/articles/article-2025-09-10-9508/</link>
      <pubDate>Wed, 10 Sep 2025 07:00:53 +0000</pubDate>
      <guid>/articles/article-2025-09-10-9508/</guid>
      <description>Unlocking fashion e-commerce with AI! üõçÔ∏è‚ú® Traditional keyword searches often miss the mark in understanding customers&amp;rsquo; true intent. This article highlights a solution using semantic search, which captures meaning and intent in fashion searches. EDB Postgres AI and Red Hat OpenShift AI work together to process AI data, enabling seamless visual and text searches. Users can upload images or describe items without needing exact terms. This innovative approach not only enhances search accuracy but&amp;hellip;</description>
    </item>
    <item>
      <title>What qualifies for Red Hat Developer Subscription for Teams?</title>
      <link>/articles/article-2025-09-09-9464/</link>
      <pubDate>Tue, 09 Sep 2025 14:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9464/</guid>
      <description>Unlock development potential with the Red Hat Developer Subscription for Teams! üöÄ This program provides organizations using Red Hat technologies free access to Red Hat Enterprise Linux for development activities. It&amp;rsquo;s available via Red Hat representatives or self-service at developers.redhat.com. Key activities covered include software design, coding, building, testing, and pre-production setups. The subscription supports efficient application development and deployment. For more details,&amp;hellip;</description>
    </item>
    <item>
      <title>How to run OpenAI&#39;s gpt-oss models locally with RamaLama</title>
      <link>/articles/article-2025-09-09-9444/</link>
      <pubDate>Tue, 09 Sep 2025 07:01:03 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9444/</guid>
      <description>Unlock the power of OpenAI&amp;rsquo;s gpt-oss models locally with RamaLama! üñ•Ô∏è These models, available in 20B and 120B variants, enable advanced AI capabilities right on your machine. RamaLama simplifies the setup process using containerization for security and ease. üöÄ Key features include zero trust security and automatic GPU optimization. Get started easily with just a single command. Explore more about running AI models in a secure, efficient manner! üîí‚ú® #OpenAI #AIModels #RamaLama #MachineLearning&amp;hellip;</description>
    </item>
    <item>
      <title>Using DNS over TLS in OpenShift to secure communications</title>
      <link>/articles/article-2025-09-09-9445/</link>
      <pubDate>Tue, 09 Sep 2025 07:01:00 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9445/</guid>
      <description>üîí Secure your DNS traffic in Red Hat OpenShift with DNS over TLS (DoT). This feature enhances security by ensuring all DNS communications are encrypted, aligning with zero trust architecture principles. üõ†Ô∏è The recent RHEL 10 release introduces encrypted DNS, allowing DoT during installation and runtime. While currently a Technology Preview in Identity Management (IdM), it lays the groundwork for secure operations. üîç Explore installation steps for IdM and OpenShift, including configuring DNS&amp;hellip;</description>
    </item>
    <item>
      <title>Scaling DeepSeek and Sparse MoE models in vLLM with llm-d</title>
      <link>/articles/article-2025-09-08-9429/</link>
      <pubDate>Mon, 08 Sep 2025 14:02:38 +0000</pubDate>
      <guid>/articles/article-2025-09-08-9429/</guid>
      <description>üöÄ Exciting advancements in scaling Mixture of Experts (MoE) models with vLLM and the llm-d project are transforming open-source LLM capabilities. üåê This article discusses innovations like multi-head latent attention and sparse configurations, enabling efficient deployment in Kubernetes. Learn how vLLM enhances expert parallelism and communication for large models. For detailed insights, check the full article! üìä #MachineLearning #AI #Kubernetes #DeepLearning #OpenSource</description>
    </item>
    <item>
      <title>Scaling DeepSeek-style MoEs with vLLM and llm-d using Wide EP</title>
      <link>/articles/article-2025-09-08-9551/</link>
      <pubDate>Mon, 08 Sep 2025 14:02:38 +0000</pubDate>
      <guid>/articles/article-2025-09-08-9551/</guid>
      <description>üîç Exciting advancements in serving large-scale Mixture of Experts (MoE) language models are discussed in a recent article on vLLM and llm-d. The article covers the architectural changes in vLLM that enhance the efficiency of DeepSeek-style models. Key innovations include multi-head latent attention and sparse configurations with hundreds of experts. llm-d enables high-performance deployments in Kubernetes, offering intelligent scheduling and expert parallelism for efficient scaling. Learn&amp;hellip;</description>
    </item>
    <item>
      <title>Multicluster authentication with Ansible Automation Platform</title>
      <link>/articles/article-2025-09-08-9394/</link>
      <pubDate>Mon, 08 Sep 2025 07:00:54 +0000</pubDate>
      <guid>/articles/article-2025-09-08-9394/</guid>
      <description>Implementing multicluster authentication between Red Hat Ansible Automation Platform and Red Hat Advanced Cluster Management can enhance security and streamline operations. This integration allows for centralized authentication, reducing credential proliferation. Key features include dynamic token management and network security via Cluster Proxy. For successful implementation, ensure both ManagedServiceAccount and Cluster Proxy are enabled in your setup. Access detailed steps and best&amp;hellip;</description>
    </item>
    <item>
      <title>Verify Cosign bring-your-own PKI signature on OpenShift</title>
      <link>/articles/article-2025-09-08-9395/</link>
      <pubDate>Mon, 08 Sep 2025 07:00:51 +0000</pubDate>
      <guid>/articles/article-2025-09-08-9395/</guid>
      <description>üöÄ Red Hat OpenShift 4.16 introduces ClusterImagePolicy and ImagePolicy for sigstore verification. These tech preview features support Fulcio CA and public key policies. üîç The bring-your-own PKI (BYO-PKI) feature, available from OpenShift 4.19, allows validation of container images using existing X.509 certificates. üîß The article outlines how to sign images with Cosign and configure OpenShift for signature verification using ClusterImagePolicy. #OpenShift #Cosign #BYOPKI #ContainerSecurity&amp;hellip;</description>
    </item>
    <item>
      <title>What&#39;s new in network observability 1.9</title>
      <link>/articles/article-2025-09-05-7761/</link>
      <pubDate>Fri, 05 Sep 2025 07:01:17 +0000</pubDate>
      <guid>/articles/article-2025-09-05-7761/</guid>
      <description>üöÄ Exciting updates in Network Observability 1.9! This version enhances insights into network traffic with features like IPsec tracking, flowlogs-pipeline filter queries, and UDN mapping. It is compatible with Red Hat OpenShift Container Platform 4.19 and older releases. Learn how to enable IPsec and explore the new CLI enhancements for capturing flows, metrics, and packets. For detailed installation instructions, refer to the OpenShift documentation. üìäüîç #NetworkObservability #RedHat&amp;hellip;</description>
    </item>
    <item>
      <title>Customize your deployments with the Red Hat Developer Hub Operator</title>
      <link>/articles/article-2025-09-04-7736/</link>
      <pubDate>Thu, 04 Sep 2025 16:53:23 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7736/</guid>
      <description>üöÄ The Red Hat Developer Hub enhances internal developer portals when paired with Red Hat OpenShift. Key updates in version 1.2 include: - A new Argo CD front-end plug-in for better UX. - Enhanced orchestration capabilities for software templates. - Improved provenance tracking through ScaffoldedFrom metadata. Deployment is streamlined using the Red Hat Developer Hub Operator. Access your Backstage instance easily with the provided route. For detailed customization, a Backstage custom resource&amp;hellip;</description>
    </item>
    <item>
      <title>How to migrate from Fluentd to Vector in OpenShift 4</title>
      <link>/articles/article-2025-09-04-7703/</link>
      <pubDate>Thu, 04 Sep 2025 07:01:18 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7703/</guid>
      <description>üîÑ &lt;strong&gt;Migrating from Fluentd to Vector in OpenShift 4&lt;/strong&gt; üîÑ This article provides a comprehensive guide for migrating the default log collector in OpenShift 4 from Fluentd to Vector. With Fluentd being deprecated in Logging 5.X, this transition is essential to access the new features in Logging 6.0. Vector serves as a log collector and analyzer, simplifying the processing of logs for real-time analysis. It allows logs to be sent to destinations like Amazon CloudWatch and supports JSON formatted&amp;hellip;</description>
    </item>
    <item>
      <title>How platform engineering accelerates enterprise AI adoption</title>
      <link>/articles/article-2025-09-04-7704/</link>
      <pubDate>Thu, 04 Sep 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7704/</guid>
      <description>üöÄ Platform engineering is reshaping enterprise AI adoption. By integrating technologies like Kafka and service mesh, organizations can enhance AI deployments. üîç Key challenges include reproducibility and compliance. Platform engineering addresses these by providing self-service access and standardized environments, enabling developers and data scientists to innovate efficiently. üíª Red Hat OpenShift and Developer Hub are pivotal in making AI resources accessible while ensuring governance. #AI&amp;hellip;</description>
    </item>
    <item>
      <title>How to deploy Azure Red Hat OpenShift using Terraform</title>
      <link>/articles/article-2025-09-04-7705/</link>
      <pubDate>Thu, 04 Sep 2025 07:01:13 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7705/</guid>
      <description>üöÄ Learn how to deploy Azure Red Hat OpenShift using Terraform! This article covers the steps to set up and configure your Azure infrastructure with Terraform, ensuring compliance using Azure policies. It emphasizes the importance of governance rules and the use of policy-as-code for better resource management. Key prerequisites include Terraform CLI, Azure CLI, and proper role assignments. The setup involves creating a network, configuring security, and deploying the OpenShift cluster with&amp;hellip;</description>
    </item>
    <item>
      <title>Effective observability with Red Hat build of OpenTelemetry</title>
      <link>/articles/article-2025-09-03-7652/</link>
      <pubDate>Wed, 03 Sep 2025 07:01:17 +0000</pubDate>
      <guid>/articles/article-2025-09-03-7652/</guid>
      <description>üöÄ Discover the power of observability with the Red Hat build of OpenTelemetry! This framework enables comprehensive metrics and logs reporting, crucial for monitoring your applications and infrastructure. It simplifies data collection and management while providing scalability and flexibility. Key features include: - Unified data collection - Seamless integration with monitoring tools - Enterprise-grade support from Red Hat Explore how to get started and enhance your observability practices!&amp;hellip;</description>
    </item>
    <item>
      <title>vLLM with torch.compile: Efficient LLM inference on PyTorch</title>
      <link>/articles/article-2025-09-03-7653/</link>
      <pubDate>Wed, 03 Sep 2025 07:01:11 +0000</pubDate>
      <guid>/articles/article-2025-09-03-7653/</guid>
      <description>üöÄ Efficient LLM inference is crucial in today‚Äôs diverse tech landscape. The article discusses how &lt;strong&gt;torch.compile&lt;/strong&gt;, PyTorch&amp;rsquo;s JIT compiler, streamlines performance by automatically optimizing kernels. This reduces the burden on developers, allowing them to focus on model design rather than manual tuning. Incorporated into &lt;strong&gt;vLLM&lt;/strong&gt;, torch.compile enhances usability and performance through custom compiler passes. It supports dynamic batch sizes and improves startup times with caching&amp;hellip;</description>
    </item>
    <item>
      <title>Your LLM is too large: How I generate production-ready failure analysis on a toaster</title>
      <link>/articles/article-2025-09-02-7602/</link>
      <pubDate>Tue, 02 Sep 2025 07:00:53 +0000</pubDate>
      <guid>/articles/article-2025-09-02-7602/</guid>
      <description>Running production-grade Kubernetes failure analysis on a cost-effective edge device can streamline troubleshooting. Using Llama 3.2:3B with 4-bit quantization, root cause analysis is achieved in just 70 seconds. This method incorporates pattern preprocessing to efficiently identify known failures without overwhelming the system with raw logs. Real-world results show a significant cost reduction, from $0.30-3.00 per analysis to less than $0.001, while providing actionable insights. Explore&amp;hellip;</description>
    </item>
    <item>
      <title>Migrate your OpenShift logging stack from Elasticsearch to Loki</title>
      <link>/articles/article-2025-09-01-7578/</link>
      <pubDate>Mon, 01 Sep 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-09-01-7578/</guid>
      <description>üöÄ To leverage the latest logging features in Red Hat OpenShift 6.0, migrating from Elasticsearch to Loki is essential. This guide details how to test changes in development and plan for production implementations. Loki, a scalable log aggregation system, offers improved performance by using log labels. It allows multiple tenants, which simplifies resource management. üîÑ The migration process involves running both stacks in parallel, ensuring old logs remain accessible via Elasticsearch while&amp;hellip;</description>
    </item>
    <item>
      <title>Migrating Ansible Automation Platform 2.4 to 2.5</title>
      <link>/articles/article-2025-08-29-7509/</link>
      <pubDate>Fri, 29 Aug 2025 07:01:20 +0000</pubDate>
      <guid>/articles/article-2025-08-29-7509/</guid>
      <description>üöÄ Migrating from Ansible Automation Platform 2.4 to 2.5 involves careful steps to ensure a smooth transition. This article outlines the preparation, export, and import process using the configify.aapconfig collection. Key points include: - Ensure Ansible Automation Platform 2.5 is deployed separately. - Follow similar steps as migrating from AWX 25. - Focus on user roles and authentication changes in the new version. For detailed steps, refer to the article! üìú #Ansible #Automation #DevOps&amp;hellip;</description>
    </item>
    <item>
      <title>Multicluster resiliency with global load balancing and mesh federation</title>
      <link>/articles/article-2025-08-28-7451/</link>
      <pubDate>Thu, 28 Aug 2025 07:01:21 +0000</pubDate>
      <guid>/articles/article-2025-08-28-7451/</guid>
      <description>Explore the new architecture for multicluster resiliency using global load balancing and mesh federation! üåê This approach combines a global load balancer and a federated service mesh to enhance service availability and disaster recovery, particularly for stateless workloads. New capabilities in Red Hat OpenShift Service Mesh 3.0 and Red Hat Connectivity Link now allow for more robust deployments. Learn how to configure these tools for optimal performance! #Multicluster #RedHat #CloudComputing&amp;hellip;</description>
    </item>
    <item>
      <title>Simplify local prototyping with Camel JBang infrastructure</title>
      <link>/articles/article-2025-08-28-7452/</link>
      <pubDate>Thu, 28 Aug 2025 07:01:18 +0000</pubDate>
      <guid>/articles/article-2025-08-28-7452/</guid>
      <description>üöÄ Apache Camel simplifies integration with systems like databases and APIs through minimal coding. üåü Camel JBang, a command-line interface, enhances prototyping by allowing rapid creation and testing of integration flows without complex setups. üîß Its infra command quickly launches backends like Kafka or ActiveMQ, streamlining the development process and reducing setup time. For more details, check out the full article! #ApacheCamel #CamelJBang #Integration #Development #Prototyping</description>
    </item>
    <item>
      <title>Smart deployments at scale: Leveraging ApplicationSets and Helm with cluster labels in Red Hat Advanced Cluster Management for Kubernetes</title>
      <link>/articles/article-2025-08-27-7203/</link>
      <pubDate>Wed, 27 Aug 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7203/</guid>
      <description>Managing multiple Kubernetes clusters can be complex, but Red Hat Advanced Cluster Management simplifies this process. üåê It offers a centralized platform to oversee the entire lifecycle of Kubernetes clusters, ensuring consistent health monitoring and policy enforcement across environments. Combining ApplicationSets and Helm with cluster labels allows for tailored deployments, adapting configurations based on specific cluster characteristics. This integration streamlines operations and&amp;hellip;</description>
    </item>
    <item>
      <title>How to verify container signatures in disconnected OpenShift</title>
      <link>/articles/article-2025-08-27-7204/</link>
      <pubDate>Wed, 27 Aug 2025 07:01:15 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7204/</guid>
      <description>üîç Discover how to verify container signatures in disconnected OpenShift environments using the latest tools from sigstore! The article explores the use of oc-mirror v2 in Red Hat OpenShift 4.19, allowing mirroring of container images and their cryptographic signatures. It provides a proof of concept and detailed configuration steps for enabling signature verification with CoSign. Check it out for practical insights! üõ†Ô∏èüîí #OpenShift #ContainerSecurity #Sigstore #RedHat #DevOps</description>
    </item>
    <item>
      <title>Event-driven ingestion of Keycloak entities</title>
      <link>/articles/article-2025-08-27-7205/</link>
      <pubDate>Wed, 27 Aug 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7205/</guid>
      <description>üöÄ Discover a solution to delayed updates in entity information with the Backstage Events System! This article details a Proof of Concept (PoC) that enables near real-time synchronization of Keycloak entities into Red Hat Developer Hub (RHDH). Key benefits include immediate updates and efficient, incremental syncing, reducing API calls and CPU usage. Learn how to set up the PoC and optimize your developer catalog! üîó Check out the PoC code: [GitHub Link] #Keycloak #RedHat #EventDriven&amp;hellip;</description>
    </item>
    <item>
      <title>BGP dynamic routing with Fast Data Path on RHOSO 18</title>
      <link>/articles/article-2025-08-27-7206/</link>
      <pubDate>Wed, 27 Aug 2025 07:01:08 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7206/</guid>
      <description>Exploring the performance of dynamic routing with OVN-BGP-Agent and Fast Data Path on RHOSO 18 has yielded insightful findings. üöÄ A recent Proof of Concept assessed throughput, packet loss, stability, and resource utilization using Trex and BIRD. The results show high throughput, especially with large frames, and stable performance over extended periods. üìà However, there are limitations, including bottlenecks for small packets and some manual configuration challenges. Insights from this study&amp;hellip;</description>
    </item>
    <item>
      <title>A VM tuning case study: Balancing power and performance on AMD processors</title>
      <link>/articles/article-2025-08-26-7173/</link>
      <pubDate>Tue, 26 Aug 2025 07:01:25 +0000</pubDate>
      <guid>/articles/article-2025-08-26-7173/</guid>
      <description>During a server deployment, a significant performance gap was found between bare metal and virtual machine (VM) workloads. Optimizations, including adjusting system profiles and enabling CPU scaling drivers, were implemented. These changes resulted in notable improvements in VM performance, with the tuned VM even surpassing the original bare-metal completion times. The study highlights how targeted adjustments can lead to substantial gains in efficiency. üîßüíª‚ö°Ô∏è #VMTuning&amp;hellip;</description>
    </item>
    <item>
      <title>Optimize GPU utilization with Kueue and KEDA</title>
      <link>/articles/article-2025-08-26-7174/</link>
      <pubDate>Tue, 26 Aug 2025 07:01:23 +0000</pubDate>
      <guid>/articles/article-2025-08-26-7174/</guid>
      <description>Explore how integrating Kueue and KEDA can optimize GPU utilization in AI workloads! üöÄ This proof of concept showcases a method to enhance resource efficiency on OpenShift AI. The combination allows scaling long-running workloads to zero when idle, reducing costs significantly. Learn how to implement this strategy with a focus on resource management and effective workload scheduling. üìäüíª #AI #GPUUtilization #OpenShift #Kubernetes #CloudComputing</description>
    </item>
    <item>
      <title>Implement AI safeguards with Python and Llama Stack</title>
      <link>/articles/article-2025-08-26-7175/</link>
      <pubDate>Tue, 26 Aug 2025 07:01:20 +0000</pubDate>
      <guid>/articles/article-2025-08-26-7175/</guid>
      <description>üöÄ Exploring AI safety with Llama Stack! This article highlights how to implement guardrails in AI applications using Python and Llama Stack. It introduces two main built-in guardrails: Llama Guard, which filters unsafe content, and Prompt Guard, designed to prevent circumvention of safety measures. The post provides insights into setting up Llama Stack and utilizing these guardrails effectively in Python. #AI #LlamaStack #Python #MachineLearning #AIsafety</description>
    </item>
    <item>
      <title>LLM Compressor 0.7.0 release recap</title>
      <link>/articles/article-2025-08-25-6534/</link>
      <pubDate>Mon, 25 Aug 2025 16:09:49 +0000</pubDate>
      <guid>/articles/article-2025-08-25-6534/</guid>
      <description>üöÄ LLM Compressor has released version 0.7.0, enhancing performance for quantizing large language models. Key updates include: 1Ô∏è‚É£ New QuIP and SpinQuant-style transforms for improved accuracy. 2Ô∏è‚É£ Mixed-precision support with FP4 enhancements for better layer quantization. 3Ô∏è‚É£ DeepSeek v3-style block quantization for efficient compression without calibration data. Explore more about these features! #LLMCompressor #AI #MachineLearning #Quantization #TechUpdate</description>
    </item>
    <item>
      <title>What is an image mode 3-way merge?</title>
      <link>/articles/article-2025-08-25-6331/</link>
      <pubDate>Mon, 25 Aug 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-08-25-6331/</guid>
      <description>üîç Curious about the 3-way merge in Red Hat Enterprise Linux (RHEL)? In image mode, a new filesystem image is created to manage updates. This process includes a third version, older than the current and new images, to reduce conflicts. The merge prioritizes local changes, ensuring personalized settings remain intact. Utilizing OSTree, RHEL manages multiple OS installations effectively, making the merging process smoother. üñ•Ô∏è‚ú® #RedHat #Linux #3WayMerge #OSTree #TechUpdates</description>
    </item>
    <item>
      <title>Least-privilege installation of OpenShift IPI on AWS</title>
      <link>/articles/article-2025-08-22-6295/</link>
      <pubDate>Fri, 22 Aug 2025 07:16:18 +0000</pubDate>
      <guid>/articles/article-2025-08-22-6295/</guid>
      <description>üîí The latest guide on installing OpenShift IPI on AWS emphasizes a secure, least-privilege approach. By using the cloud credential operator utility (ccoctl) and setting credentials mode to manual, users can create narrowly-defined IAM roles. üõ†Ô∏è This method eliminates long-lived AWS access keys, relying instead on short-term AWS STS credentials. The ccoctl &amp;ndash;dry-run feature allows for auditing IAM policies before applying them, enhancing security. üìä Key points include understanding the IAM&amp;hellip;</description>
    </item>
    <item>
      <title>Integrate Azure DevOps into Red Hat Developer Hub workflows</title>
      <link>/articles/article-2025-08-22-6296/</link>
      <pubDate>Fri, 22 Aug 2025 07:16:13 +0000</pubDate>
      <guid>/articles/article-2025-08-22-6296/</guid>
      <description>üöÄ Exciting news for developers! Integrating Azure DevOps with Red Hat Developer Hub creates a seamless CI/CD experience. Azure DevOps enhances source control and deployment, while Red Hat Developer Hub centralizes tools and documentation. Key plug-ins include Azure Scaffolder and Azure DevOps, enabling improved collaboration and faster delivery. For setup, ensure Azure Entra ID is configured and follow the detailed steps for integration. Learn more about optimizing your workflows!&amp;hellip;</description>
    </item>
    <item>
      <title>How to auto-register Red Hat Edge Manager with MicroShift</title>
      <link>/articles/article-2025-08-21-5016/</link>
      <pubDate>Thu, 21 Aug 2025 07:01:31 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5016/</guid>
      <description>üöÄ Red Hat Edge Manager, in Technology Preview, offers a fleet management solution for edge devices. It ensures security, simplifies management, and provides real-time visibility. üîß The article details how to auto-register Edge Manager with Red Hat MicroShift using Red Hat Advanced Cluster Management for Kubernetes 2.13. üìã Key steps include enabling Edge Manager, setting up the flightctl command, and configuring auto-registration. Explore how these tools can enhance your edge device&amp;hellip;</description>
    </item>
    <item>
      <title>The hidden pitfalls of Kafka tiered storage</title>
      <link>/articles/article-2025-08-21-5019/</link>
      <pubDate>Thu, 21 Aug 2025 07:01:29 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5019/</guid>
      <description>üöÄ Apache Kafka 3.9.0 introduces tiered storage for improved long-term data retention and cost efficiency. This feature allows independent scaling of compute and storage resources, leading to better client isolation. However, challenges remain in reading remote data. The article outlines two key problems and offers solutions, emphasizing important configurations like &lt;code&gt;fetch.max.bytes&lt;/code&gt; and &lt;code&gt;max.partition.fetch.bytes&lt;/code&gt;. Kafka 4.2.0 promises improvements to address these issues, enhancing&amp;hellip;</description>
    </item>
    <item>
      <title>Unleash controlled chaos with krknctl</title>
      <link>/articles/article-2025-08-21-5020/</link>
      <pubDate>Thu, 21 Aug 2025 07:01:25 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5020/</guid>
      <description>Unleash the power of chaos engineering with &lt;strong&gt;krknctl&lt;/strong&gt;! üéâ This command-line interface simplifies testing system resilience by orchestrating chaos scenarios using container images from krkn-hub. Key features include instant autocompletion, dynamic graph orchestration, and versatile container support with Podman or Docker. With pre-compiled binaries available, you can start your chaos engineering journey in minutes. Discover more and elevate your systems today! üîçüíª #ChaosEngineering #DevOps&amp;hellip;</description>
    </item>
    <item>
      <title>Your agent, your rules: A deep dive into the Responses API with Llama Stack</title>
      <link>/articles/article-2025-08-20-5021/</link>
      <pubDate>Wed, 20 Aug 2025 07:01:24 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5021/</guid>
      <description>üîç The OpenAI Responses API simplifies AI application development by managing complex orchestration. However, it is tied to specific models and a proprietary cloud service. Enter Llama Stack, an open-source server that offers a compatible Responses API and lets you deploy on your hardware with your chosen models. It supports advanced features like Retrieval-augmented Generation (RAG) for accurate answers without compromising document privacy. Explore how Llama Stack can transform your AI&amp;hellip;</description>
    </item>
    <item>
      <title>Build a container image for a Quarkus project using Buildpacks</title>
      <link>/articles/article-2025-08-20-5024/</link>
      <pubDate>Wed, 20 Aug 2025 07:01:22 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5024/</guid>
      <description>üöÄ Learn how to build container images for your Quarkus projects using the Container Image Buildpack extension! This method eliminates the need for a Dockerfile, streamlining your CI/CD workflow. üîß The extension leverages the Java Buildpack Client to simplify application deployment in Kubernetes. Ensure you have Podman/Docker, JDK 21+, and Maven 3.9+ to get started. üì¶ With just a few Maven commands, you can create, build, and push your images to container registries effortlessly. #Quarkus&amp;hellip;</description>
    </item>
    <item>
      <title>How I built an agentic application for Docling with MCP</title>
      <link>/articles/article-2025-08-20-5025/</link>
      <pubDate>Wed, 20 Aug 2025 07:01:20 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5025/</guid>
      <description>üåê Exciting developments in AI with the Model Context Protocol (MCP) from Anthropic! Released in November 2024, MCP enables large language models to communicate seamlessly with various tools. üõ†Ô∏è With thousands of open-source MCP servers available, many developers are now creating agentic applications. However, there&amp;rsquo;s still untapped potential in fully utilizing MCP‚Äôs capabilities. üìÑ My journey began during my internship at Red Hat, where I worked with Docling, an open-source data preprocessor&amp;hellip;.</description>
    </item>
    <item>
      <title>Building trustworthy AI: A developer&#39;s guide to production-ready systems</title>
      <link>/articles/article-2025-08-20-5028/</link>
      <pubDate>Wed, 20 Aug 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5028/</guid>
      <description>üåê Building trustworthy AI is essential in today&amp;rsquo;s development landscape. As AI engineers and developers, focusing on trust, safety, and transparency is crucial for creating reliable applications. üîç AI systems should be assessed based on their potential impact, categorized into high, moderate, and minimal tiers. This impacts design choices and operational guardrails. üí° Best practices include documenting training data, testing for bias, ensuring explainability, and providing human&amp;hellip;</description>
    </item>
    <item>
      <title>Build on multi-arch clusters with builds for Red Hat OpenShift</title>
      <link>/articles/article-2025-08-19-5030/</link>
      <pubDate>Tue, 19 Aug 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-08-19-5030/</guid>
      <description>üöÄ Discover how to streamline multi-arch builds with Red Hat OpenShift! This article explains the builds for Red Hat OpenShift operator, allowing you to create a single build object for mixed architecture clusters. Key steps include installing the oc client, configuring the ClusterBuildStrategy, and verifying image builds for different architectures. Learn more about simplifying your build process! #RedHat #OpenShift #MultiArch #CloudComputing #DevOps</description>
    </item>
    <item>
      <title>How to enhance Agent2Agent (A2A) security</title>
      <link>/articles/article-2025-08-19-5032/</link>
      <pubDate>Tue, 19 Aug 2025 07:01:14 +0000</pubDate>
      <guid>/articles/article-2025-08-19-5032/</guid>
      <description>üîí The Agent2Agent (A2A) protocol by Google facilitates communication between AI agents, allowing seamless interaction across different vendors. Each agent can serve as a client or remote agent depending on the context. üåê Communication involves retrieving an Agent Card, which contains essential details for task execution. Security measures such as HTTPS and authentication protocols are crucial for protecting these interactions. üõ°Ô∏è Developers implementing A2A should remain vigilant about&amp;hellip;</description>
    </item>
    <item>
      <title>Getting started with llm-d for distributed AI inference</title>
      <link>/articles/article-2025-08-19-5035/</link>
      <pubDate>Tue, 19 Aug 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-08-19-5035/</guid>
      <description>üåê As large language models (LLMs) evolve, so must their infrastructure. Introducing &lt;strong&gt;llm-d&lt;/strong&gt;, a Kubernetes-native distributed inference stack designed to enhance AI applications. It optimizes for complex reasoning, long-running prompts, and modular scaling. Key features include smart load balancing, split-phase inference, and disaggregated caching for efficiency. This innovation addresses the unique challenges of LLM inference, making it more cost-effective and performant. Join the growing&amp;hellip;</description>
    </item>
    <item>
      <title>Manage Advanced Cluster Management policies using Ansible</title>
      <link>/articles/article-2025-08-14-4991/</link>
      <pubDate>Thu, 14 Aug 2025 07:01:15 +0000</pubDate>
      <guid>/articles/article-2025-08-14-4991/</guid>
      <description>Managing multiple Kubernetes clusters can be complex, especially with the need for consistent security and compliance. This article discusses how Red Hat Advanced Cluster Management simplifies this process through centralized management. Ansible automation enhances policy management by ensuring consistency, repeatability, and compliance across clusters. It also covers the use of the external secrets operator for secure credential management with AWS Secrets Manager. For more details, check&amp;hellip;</description>
    </item>
    <item>
      <title>Integrate vLLM inference on macOS/iOS with Alamofire and Apple Foundation</title>
      <link>/articles/article-2025-08-14-4992/</link>
      <pubDate>Thu, 14 Aug 2025 07:01:13 +0000</pubDate>
      <guid>/articles/article-2025-08-14-4992/</guid>
      <description>Unlock the potential of vLLM inference in your macOS/iOS apps! üì±üíª This article explores how to use Apple Foundation and Alamofire for seamless communication with vLLM via an OpenAI-compatible Chat Completions endpoint. It covers essential topics such as data encoding, error handling, and processing streaming results. For hands-on experience, grab the sample code from GitHub and start building! üöÄüîó #vLLM #macOS #iOSDevelopment #OpenAI #Alamofire</description>
    </item>
    <item>
      <title>Enhancing system resilience with Krkn chaos dashboard</title>
      <link>/articles/article-2025-08-14-4993/</link>
      <pubDate>Thu, 14 Aug 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-08-14-4993/</guid>
      <description>üîß In today&amp;rsquo;s digital landscape, system resilience is crucial for businesses. The Krkn chaos dashboard is an open-source tool designed to enhance Kubernetes environments by simulating failures to identify vulnerabilities. üìä The dashboard allows teams to easily design and monitor chaos experiments, providing real-time updates on system health and generating detailed reports on failures. üíª With user-friendly features, it encourages regular chaos testing, helping teams improve their system&amp;rsquo;s&amp;hellip;</description>
    </item>
    <item>
      <title>How to secure your Jenkins pipeline with Red Hat Advanced Developer Suite</title>
      <link>/articles/article-2025-08-14-4994/</link>
      <pubDate>Thu, 14 Aug 2025 07:01:08 +0000</pubDate>
      <guid>/articles/article-2025-08-14-4994/</guid>
      <description>Enhance your Jenkins pipeline security with Red Hat Advanced Developer Suite! üîí This suite integrates cryptographic signing, SBOM validation, and runtime enforcement to ensure a secure CI/CD process. Each stage‚Äîfrom commit to deployment‚Äînow includes proof of compliance. Key features include: - Trusted Artifact Signer for image signing. - Profile Analyzer for risk assessment. - Advanced Cluster Security for policy enforcement. Learn how to keep your deployment velocity while lowering risks! üöÄüîß&amp;hellip;</description>
    </item>
    <item>
      <title>How to deploy an image mode update in offline and air-gapped environments</title>
      <link>/articles/article-2025-08-13-4884/</link>
      <pubDate>Wed, 13 Aug 2025 07:01:07 +0000</pubDate>
      <guid>/articles/article-2025-08-13-4884/</guid>
      <description>Need to deploy image mode updates in offline or air-gapped environments? Red Hat Enterprise Linux offers a flexible solution that doesn&amp;rsquo;t rely on network connections. This method is ideal for security or hardware limitations. üåêüîí Key steps include preparing an external storage device, copying the necessary images, and applying updates directly to the offline system. While effective, this approach can be time-consuming and requires on-site deployment. If your system can connect online, consider&amp;hellip;</description>
    </item>
    <item>
      <title>How to install Offline Knowledge Portal on a local system</title>
      <link>/articles/article-2025-08-13-4885/</link>
      <pubDate>Wed, 13 Aug 2025 07:01:05 +0000</pubDate>
      <guid>/articles/article-2025-08-13-4885/</guid>
      <description>Unlock the Red Hat Offline Knowledge Portal for easy access to documentation and guides without an internet connection! üìöüíª To install, ensure you have a Red Hat Satellite subscription, a web browser, and enough disk space. Follow these steps: 1Ô∏è‚É£ Generate your access key. 2Ô∏è‚É£ Log in to the registry and pull the image. 3Ô∏è‚É£ Run the podman image to verify. 4Ô∏è‚É£ Access the portal at http://localhost:8080. Explore valuable resources anytime, anywhere! üåê‚ú® #RedHat #KnowledgePortal #OfflineAccess&amp;hellip;</description>
    </item>
    <item>
      <title>New features in Bunsen</title>
      <link>/articles/article-2025-08-13-4886/</link>
      <pubDate>Wed, 13 Aug 2025 07:01:02 +0000</pubDate>
      <guid>/articles/article-2025-08-13-4886/</guid>
      <description>üöÄ Bunsen has rolled out new features to enhance user experience! The updated web interface now includes a simplified project chooser, making it easier to select projects and modify search criteria. A cookie support feature allows users to save search settings for future use, streamlining the process. üç™ Additionally, the testrun overview section is customizable, letting users sort results by various columns. The new &amp;ldquo;filter by testcase&amp;rdquo; feature helps identify regressions in test results more&amp;hellip;</description>
    </item>
    <item>
      <title>Windows image-building service for OpenShift Virtualization</title>
      <link>/articles/article-2025-08-12-4887/</link>
      <pubDate>Tue, 12 Aug 2025 15:16:06 +0000</pubDate>
      <guid>/articles/article-2025-08-12-4887/</guid>
      <description>üöÄ Red Hat OpenShift Pipelines now allows for seamless management of virtual machines (VMs) in your CI/CD process. By integrating OpenShift Pipelines with OpenShift Virtualization, developers can automate the creation of standardized Windows golden images, enhancing VM provisioning. Key features include: - Management of pipelines as Kubernetes Custom Resources (CRs). - Simplified collaboration through source control management (SCM). - Streamlined operations by treating VMs as native objects&amp;hellip;</description>
    </item>
    <item>
      <title>Build your first Software Template for Backstage</title>
      <link>/articles/article-2025-08-12-4888/</link>
      <pubDate>Tue, 12 Aug 2025 12:31:14 +0000</pubDate>
      <guid>/articles/article-2025-08-12-4888/</guid>
      <description>üöÄ More organizations are adopting platform engineering and internal developer portals (IDPs) to enhance onboarding and self-service capabilities. This article details how to create a Software Template for Backstage using Red Hat Developer Hub. The template automates developer tasks, enabling faster application repository creation on GitHub with a CI pipeline. Prerequisites include admin access to Red Hat Developer Hub and GitHub integration setup. The guide offers step-by-step instructions&amp;hellip;</description>
    </item>
    <item>
      <title>How to build a simple agentic AI server with MCP</title>
      <link>/articles/article-2025-08-12-4889/</link>
      <pubDate>Tue, 12 Aug 2025 07:16:11 +0000</pubDate>
      <guid>/articles/article-2025-08-12-4889/</guid>
      <description>üåê As AI agents evolve, the need for reliable connections to real-world data grows. The Model Context Protocol (MCP) offers a standardized way to connect AI systems securely and efficiently. In a recent article, a simple MCP server was built to fetch weather data from the Open-Meteo API. This server allows AI models to interact with external tools and data, enhancing their functionality. To explore MCP, developers can set up their environment and create tools to access data easily. The article&amp;hellip;</description>
    </item>
    <item>
      <title>Boost AI efficiency with GPU autoscaling on OpenShift</title>
      <link>/articles/article-2025-08-12-4890/</link>
      <pubDate>Tue, 12 Aug 2025 07:16:07 +0000</pubDate>
      <guid>/articles/article-2025-08-12-4890/</guid>
      <description>Unlock AI potential with GPU autoscaling on OpenShift! üöÄ Dynamic autoscaling is essential for maintaining efficiency and availability in modern applications. Red Hat OpenShift offers features like horizontal pod autoscaling (HPA) and custom metrics autoscaler (KEDA) to optimize resource allocation and manage workloads effectively. KEDA enhances traditional scaling methods by utilizing external metrics, enabling better performance for GPU-accelerated applications. üìà Learn how to implement&amp;hellip;</description>
    </item>
    <item>
      <title>Disaster recovery approaches for Red Hat OpenShift Virtualization, part 2</title>
      <link>/articles/article-2025-08-11-4857/</link>
      <pubDate>Mon, 11 Aug 2025 15:31:15 +0000</pubDate>
      <guid>/articles/article-2025-08-11-4857/</guid>
      <description>üåê Discover effective disaster recovery strategies for Red Hat OpenShift Virtualization! This follow-up article explores orchestrating application failover using Kubernetes-native constructs and GitOps workflows. It emphasizes how to manage workloads during disruptions, focusing on redeployment and prioritization. Key practices include using Node Selectors and automation tools like Ansible and Helm for seamless transitions between primary and DR sites. Regular DR rehearsals and clear&amp;hellip;</description>
    </item>
    <item>
      <title>How to migrate smart inventories to constructed inventories</title>
      <link>/articles/article-2025-08-11-4858/</link>
      <pubDate>Mon, 11 Aug 2025 07:01:11 +0000</pubDate>
      <guid>/articles/article-2025-08-11-4858/</guid>
      <description>üöÄ Red Hat is set to discontinue support for smart inventories in favor of constructed inventories. This shift aims to address the limitations and challenges smart inventories present. üîÑ Migrating to constructed inventories can be complex, especially for large organizations. This article outlines a semi-automated process to simplify the transition, requiring human review to ensure accuracy. üìã Key migration steps include converting filtering conditions, reviewing configurations, and applying&amp;hellip;</description>
    </item>
    <item>
      <title>How to use Minio for Ansible automation hub</title>
      <link>/articles/article-2025-08-11-4859/</link>
      <pubDate>Mon, 11 Aug 2025 07:01:07 +0000</pubDate>
      <guid>/articles/article-2025-08-11-4859/</guid>
      <description>Learn how to configure MinIO as a backend for the Ansible Automation Hub in Red Hat environments. This setup provides a self-hosted, cost-effective alternative to cloud storage solutions like AWS S3. The article covers: 1Ô∏è‚É£ Setting up MinIO on an OpenShift cluster. 2Ô∏è‚É£ Integrating it with the Ansible Automation Platform. This method is ideal for air-gapped or on-premise deployments. #Ansible #MinIO #OpenShift #CloudStorage #DevOps</description>
    </item>
    <item>
      <title>Ollama vs. vLLM: A deep dive into performance benchmarking</title>
      <link>/articles/article-2025-08-08-4711/</link>
      <pubDate>Fri, 08 Aug 2025 07:16:15 +0000</pubDate>
      <guid>/articles/article-2025-08-08-4711/</guid>
      <description>Ollama and vLLM serve distinct roles in the AI landscape. Ollama is designed for local development and prototyping, while vLLM excels in high-performance production environments. In benchmarks, vLLM outperformed Ollama with a peak throughput of 793 TPS compared to Ollama&amp;rsquo;s 41 TPS and lower latency across all concurrency levels. Ollama prioritizes ease of use, making it suitable for individual developers, whereas vLLM is built for scalability, catering to enterprise applications. For detailed&amp;hellip;</description>
    </item>
    <item>
      <title>Upgrade from RHEL 9 to RHEL 10 with Red Hat Satellite 6.17</title>
      <link>/articles/article-2025-08-08-4712/</link>
      <pubDate>Fri, 08 Aug 2025 07:16:11 +0000</pubDate>
      <guid>/articles/article-2025-08-08-4712/</guid>
      <description>üöÄ Red Hat Enterprise Linux (RHEL) 10 is now available! For system admins managing large environments, upgrading from RHEL 9 to RHEL 10 can be simplified using Red Hat Satellite 6.17 and Leapp. These tools help ensure consistency, compliance, and minimal downtime during the upgrade process. Leapp automates checks and resolves compatibility issues, while Satellite manages repository synchronization and system tracking. Before upgrading, ensure your Satellite is properly configured and&amp;hellip;</description>
    </item>
    <item>
      <title>Batch inference on OpenShift AI with Ray Data, vLLM, and CodeFlare</title>
      <link>/articles/article-2025-08-07-4690/</link>
      <pubDate>Thu, 07 Aug 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-08-07-4690/</guid>
      <description>Explore how to run batch inference at scale with OpenShift AI using the CodeFlare SDK, Ray Data, and vLLM. This approach helps bridge the gap between local development and production execution, enabling data scientists to efficiently process large datasets without needing deep infrastructure knowledge. The article outlines the differences between online and offline inference, focusing on the latter for large-scale tasks. It provides a step-by-step guide on connecting to a Ray cluster and&amp;hellip;</description>
    </item>
    <item>
      <title>Build trust in your CI/CD pipelines with OpenShift Pipelines</title>
      <link>/articles/article-2025-08-07-4691/</link>
      <pubDate>Thu, 07 Aug 2025 07:01:13 +0000</pubDate>
      <guid>/articles/article-2025-08-07-4691/</guid>
      <description>üîí Red Hat OpenShift Pipelines provide a cloud-native CI/CD solution using Tekton. This article highlights the use of OpenShift sandboxed containers, which isolate workloads in virtual machines, enhancing security for tasks needing elevated privileges. üåê For untrusted environments, OpenShift confidential containers (CoCo) further protect pipeline data by running containers in isolated hardware enclaves, safeguarding against admin access. üí° The integration of these technologies ensures secure,&amp;hellip;</description>
    </item>
    <item>
      <title>Simplify access management for Red Hat Insights for Red Hat Enterprise Linux with new system roles</title>
      <link>/articles/article-2025-08-06-4103/</link>
      <pubDate>Wed, 06 Aug 2025 07:16:10 +0000</pubDate>
      <guid>/articles/article-2025-08-06-4103/</guid>
      <description>Managing user access for Red Hat Enterprise Linux (RHEL) just became simpler! üöÄ Red Hat has introduced three new system roles in the User Access service of the Hybrid Cloud Console: 1Ô∏è‚É£ &lt;strong&gt;RHEL Administrator&lt;/strong&gt;: Full privileges for managing configurations and vulnerabilities. 2Ô∏è‚É£ &lt;strong&gt;RHEL Operator&lt;/strong&gt;: Broad capabilities for editing configurations, but with some restrictions. 3Ô∏è‚É£ &lt;strong&gt;RHEL Viewer&lt;/strong&gt;: Read-only access for viewing system data. These roles enhance security and streamline user management&amp;hellip;</description>
    </item>
    <item>
      <title>Intro to Redis and PostgreSQL in Red Hat SAP environments</title>
      <link>/articles/article-2025-08-06-4104/</link>
      <pubDate>Wed, 06 Aug 2025 07:16:07 +0000</pubDate>
      <guid>/articles/article-2025-08-06-4104/</guid>
      <description>üöÄ Discover how Redis and PostgreSQL can enhance SQL query performance in SAP environments! This article guides SAP and Red Hat admins in leveraging these technologies for better caching. üîç Key points include: - PostgreSQL and Redis can be deployed alongside SAP applications. - Redis offers granular control over caching, improving performance. - A Python program example showcases data caching. For more insights, check the full article! #Redis #PostgreSQL #SAP #Caching #DataManagement</description>
    </item>
    <item>
      <title>Getting started with managed clusters migration</title>
      <link>/articles/article-2025-08-05-90/</link>
      <pubDate>Tue, 05 Aug 2025 07:01:14 +0000</pubDate>
      <guid>/articles/article-2025-08-05-90/</guid>
      <description>üöÄ Red Hat Advanced Cluster Management 2.13 introduces a new developer preview feature: Managed Cluster Migration. This feature is beneficial when you need to migrate managed clusters due to instability, excess clusters, or selective transfers to another hub cluster. To get started, ensure both hub clusters are imported, running the same version, and have the managed-service account add-on enabled. You can then create a ManagedClusterMigration custom resource to facilitate the migration. For&amp;hellip;</description>
    </item>
    <item>
      <title>Retrieval-augmented generation with Llama Stack and Python</title>
      <link>/articles/article-2025-08-05-91/</link>
      <pubDate>Tue, 05 Aug 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-08-05-91/</guid>
      <description>üöÄ Learn how to implement retrieval-augmented generation (RAG) using Python and Llama Stack! This article explores how RAG enhances AI responses by providing relevant context from documents, like Node.js reference architecture. By transforming data into vectors, the application retrieves pertinent document chunks to improve answer quality. The setup process involves running a Llama Stack instance and managing vector databases for efficient data handling. For developers interested in leveraging&amp;hellip;</description>
    </item>
    <item>
      <title>Introducing incident detection in Red Hat Advanced Cluster Management for Kubernetes 2.14</title>
      <link>/articles/article-2025-08-05-92/</link>
      <pubDate>Tue, 05 Aug 2025 07:01:10 +0000</pubDate>
      <guid>/articles/article-2025-08-05-92/</guid>
      <description>üöÄ Red Hat Advanced Cluster Management for Kubernetes 2.14 introduces incident detection, helping teams manage alert storms more effectively. This feature groups related alerts into manageable incidents, allowing for better root cause analysis and prioritization. To utilize this, install the Cluster Observability Operator on each cluster. It simplifies navigation between incidents within managed clusters. For installation details and to explore this feature, check the latest documentation&amp;hellip;.</description>
    </item>
    <item>
      <title>How to deploy multiple OpenStack environments on OpenShift</title>
      <link>/articles/article-2025-08-05-93/</link>
      <pubDate>Tue, 05 Aug 2025 07:01:07 +0000</pubDate>
      <guid>/articles/article-2025-08-05-93/</guid>
      <description>Red Hat OpenStack Services on OpenShift introduces a new deployment architecture that enhances Infrastructure-as-a-Service (IaaS) environments. This architecture utilizes distributed control plane services in pods, which significantly reduces resource consumption compared to previous versions. A key feature of the latest release is the ability to run multiple OpenStack Services across different namespaces within the same OpenShift infrastructure, supporting development, staging, testing, and&amp;hellip;</description>
    </item>
    <item>
      <title>Optimize workloads with right-sizing recommendations</title>
      <link>/articles/article-2025-08-04-94/</link>
      <pubDate>Mon, 04 Aug 2025 13:46:13 +0000</pubDate>
      <guid>/articles/article-2025-08-04-94/</guid>
      <description>üöÄ Introducing the Right-Sizing Recommendations in Red Hat Advanced Cluster Management for Kubernetes! This new capability helps users identify over-provisioned and under-utilized resources across clusters, promoting efficient infrastructure use and cost savings. By analyzing real-time CPU and memory consumption, it offers actionable recommendations for workload optimization. Key features include a Grafana dashboard for resource metrics, customizable data filtering, and policy-driven&amp;hellip;</description>
    </item>
    <item>
      <title>How to use Red Hat Quay as a proxy cache</title>
      <link>/articles/article-2025-08-04-95/</link>
      <pubDate>Mon, 04 Aug 2025 07:01:06 +0000</pubDate>
      <guid>/articles/article-2025-08-04-95/</guid>
      <description>Unlock the potential of Red Hat Quay as a proxy cache for container images! üåê This guide details how to set up a Red Hat OpenShift cluster and enable proxy caching in Red Hat Quay. Start by configuring the FEATURE_PROXY_CACHE flag in the config.yaml file, then create an organization for remote image proxying. Learn how to pull images from external sources like Docker Hub and deploy applications seamlessly. üöÄ For more insights, check out the full article! #RedHat #ContainerRegistry #OpenShift&amp;hellip;</description>
    </item>
    <item>
      <title>.NET container troubleshooting in OpenShift 4</title>
      <link>/articles/article-2025-08-04-96/</link>
      <pubDate>Mon, 04 Aug 2025 07:01:03 +0000</pubDate>
      <guid>/articles/article-2025-08-04-96/</guid>
      <description>üöÄ The .NET framework is a robust tool for deploying applications across platforms like Windows, Linux, and macOS. Red Hat offers a containerized version specifically for OpenShift. üîç The article by Tom Deseyn outlines steps for creating .NET container images and troubleshooting common issues. It highlights methods for memory analysis using tools like &lt;code&gt;dotnet dump&lt;/code&gt;. üìä For developers looking to optimize their .NET applications in OpenShift, this is a valuable resource. #DotNet #OpenShift&amp;hellip;</description>
    </item>
    <item>
      <title>Automatic certificate provisioning with cert-manager and DNS challenge</title>
      <link>/articles/article-2025-08-01-97/</link>
      <pubDate>Fri, 01 Aug 2025 07:01:18 +0000</pubDate>
      <guid>/articles/article-2025-08-01-97/</guid>
      <description>Learn how to automate certificate management in OpenShift using the cert-manager operator. üîê This article outlines the use of the ACME protocol with Identity Management (IdM) to streamline certificate issuance and renewal through a DNS challenge. It highlights the setup process with Red Hat Enterprise Linux (RHEL) 10 and OpenShift 4.14. Discover the benefits of reducing manual certificate management, which can lead to inefficiencies and errors. Read more to enhance your OpenShift&amp;hellip;</description>
    </item>
    <item>
      <title>5 steps to consistently patch RHEL and Windows systems</title>
      <link>/articles/article-2025-08-01-98/</link>
      <pubDate>Fri, 01 Aug 2025 07:01:15 +0000</pubDate>
      <guid>/articles/article-2025-08-01-98/</guid>
      <description>Staying updated on patching RHEL and Windows systems is crucial for security and operational efficiency. üõ°Ô∏è Using Red Hat Ansible Automation Platform can streamline this process by automating patch management for both systems. This reduces friction between teams and ensures compliance. Key steps include building a centralized inventory, creating job templates, applying patches with safety checks, validating success, and leveraging event-driven automation for proactive patching. üìä Explore more&amp;hellip;</description>
    </item>
    <item>
      <title>IBM Hyper Protect with OpenShift sandboxed containers</title>
      <link>/articles/article-2025-07-31-99/</link>
      <pubDate>Thu, 31 Jul 2025 07:01:17 +0000</pubDate>
      <guid>/articles/article-2025-07-31-99/</guid>
      <description>IBM is advancing data security with Hyper Protect Confidential Containers (HPCC) for Red Hat OpenShift. This solution protects sensitive workloads in untrusted environments, essential for industries like finance and healthcare. Using OpenShift sandboxed containers, HPCC ensures VM-level isolation for confidential computing. It addresses vulnerabilities of traditional containers by employing hardware-based trusted execution environments. Learn how HPCC enhances data protection and supports&amp;hellip;</description>
    </item>
  </channel>
</rss>
