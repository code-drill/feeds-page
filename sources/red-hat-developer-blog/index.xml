<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Red-Hat-Developer-Blog on Daily Tech Articles Feed</title>
    <link>/sources/red-hat-developer-blog/</link>
    <description>Recent content in Red-Hat-Developer-Blog on Daily Tech Articles Feed</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 15 Sep 2025 07:00:53 +0000</lastBuildDate>
    <atom:link href="/sources/red-hat-developer-blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Why some agentic AI developers are moving code from Python to Rust</title>
      <link>/articles/article-2025-09-15-9636/</link>
      <pubDate>Mon, 15 Sep 2025 07:00:53 +0000</pubDate>
      <guid>/articles/article-2025-09-15-9636/</guid>
      <description>AI developers are exploring a shift from Python to Rust for agentic AI solutions. While Python is popular for its simplicity and rich libraries, its Global Interpreter Lock (GIL) limits performance in CPU-bound tasks, especially as systems scale from 5 to 500 agents. Rust offers a solution with better concurrency and scalability, allowing more efficient handling of multiple agents and CPU-intensive tasks. Developers are finding that a hybrid approach‚Äîprototyping in Python and optimizing with&amp;hellip;</description>
    </item>
    <item>
      <title>Confidential VMs: The core of confidential containers</title>
      <link>/articles/article-2025-09-15-9637/</link>
      <pubDate>Mon, 15 Sep 2025 07:00:51 +0000</pubDate>
      <guid>/articles/article-2025-09-15-9637/</guid>
      <description>üîç Discover the essentials of Confidential Virtual Machines (CVMs) and their role in enhancing the security of confidential containers (CoCo). CVMs utilize hardware and software to ensure data confidentiality, isolating workloads from the host environment. This integration with Red Hat Enterprise Linux (RHEL) and OpenShift boosts security standards for data in use. üõ°Ô∏è Learn about features like Unified Kernel Images (UKI) and remote attestation that enhance the protection of workloads&amp;hellip;.</description>
    </item>
    <item>
      <title>Benchmarking with GuideLLM in air-gapped OpenShift clusters</title>
      <link>/articles/article-2025-09-15-9638/</link>
      <pubDate>Mon, 15 Sep 2025 07:00:48 +0000</pubDate>
      <guid>/articles/article-2025-09-15-9638/</guid>
      <description>Deploying and benchmarking large language models (LLMs) in air-gapped environments is vital for regulated enterprises. This article details the process of using the Red Hat AI Inference Server with vLLM and GuideLLM for performance evaluation within a disconnected OpenShift cluster. Key components include prebuilt container images, Persistent Volume Claims (PVCs), and OpenShift-native Job resources. GuideLLM, an open-source tool, provides metrics like token throughput and latency, ensuring&amp;hellip;</description>
    </item>
    <item>
      <title>Run Qwen3-Next on vLLM with Red Hat AI: A step-by-step guide</title>
      <link>/articles/article-2025-09-12-9624/</link>
      <pubDate>Fri, 12 Sep 2025 22:59:57 +0000</pubDate>
      <guid>/articles/article-2025-09-12-9624/</guid>
      <description>üöÄ Exciting news in AI! The Qwen3-Next model features a new hybrid attention and sparse MoE architecture, enhancing training efficiency and inference speed. üîß With Day 0 support from vLLM, organizations can deploy it immediately using Red Hat AI for secure and scalable solutions. üìä Key improvements include multi-token prediction and optimized training stability. For a step-by-step guide on deployment, check the latest blog! #AI #RedHat #OpenSource #MachineLearning #Qwen3Next</description>
    </item>
    <item>
      <title>How to implement observability with Python and Llama Stack</title>
      <link>/articles/article-2025-09-12-9602/</link>
      <pubDate>Fri, 12 Sep 2025 07:01:14 +0000</pubDate>
      <guid>/articles/article-2025-09-12-9602/</guid>
      <description>Discover how to enhance AI application observability using Python and Llama Stack! üöÄ This article highlights the importance of observability in production, focusing on logging, metrics, and distributed tracing. It introduces OpenTelemetry as a key tool for instrumenting applications and discusses setting up Jaeger for trace visualization. Explore the detailed steps for implementing observability, including configuring your Llama Stack instance to capture and visualize traces effectively&amp;hellip;.</description>
    </item>
    <item>
      <title>Deploy a lightweight AI model with AI Inference Server containerization</title>
      <link>/articles/article-2025-09-12-9603/</link>
      <pubDate>Fri, 12 Sep 2025 07:01:11 +0000</pubDate>
      <guid>/articles/article-2025-09-12-9603/</guid>
      <description>üöÄ Ready to explore AI? This tutorial provides a step-by-step guide to deploy a lightweight AI model, Llama-3.2-1B, using the Red Hat AI Inference Server. It‚Äôs designed for quick testing on personal machines with local GPUs. üîß You&amp;rsquo;ll need a valid Red Hat account and a compatible GPU. The tutorial covers everything from logging in to the Red Hat container registry to running the model with minimal setup. For more details, check out the tutorial! #AI #RedHat #MachineLearning #Containerization&amp;hellip;</description>
    </item>
    <item>
      <title>vLLM Semantic Router: Improving efficiency in AI reasoning</title>
      <link>/articles/article-2025-09-11-9544/</link>
      <pubDate>Thu, 11 Sep 2025 07:01:00 +0000</pubDate>
      <guid>/articles/article-2025-09-11-9544/</guid>
      <description>Introducing the vLLM Semantic Router, an open-source solution for enhancing efficiency in AI reasoning. üéâ This system intelligently routes queries based on their complexity, ensuring that resources are used wisely. It utilizes a ModernBERT-based classifier for semantic classification, sending simpler requests to faster models and more complex ones to stronger models. Key benefits include improved accuracy (+10.2%), reduced latency (‚Äì47.1%), and decreased token usage (‚Äì48.5%). This approach&amp;hellip;</description>
    </item>
    <item>
      <title>Declaratively assigning DNS records to virtual machines</title>
      <link>/articles/article-2025-09-11-9545/</link>
      <pubDate>Thu, 11 Sep 2025 07:00:57 +0000</pubDate>
      <guid>/articles/article-2025-09-11-9545/</guid>
      <description>üîç Virtual machines often require DNS records to maintain unique identities. This article discusses how to declaratively assign these records using Red Hat OpenShift Virtualization. üìä It highlights the importance of naming conventions and provides methods to automate DNS record assignments via labels and annotations. üîß Key considerations include network exposure, IP assignment, and managing multiple DNS records for diverse network interfaces. #VirtualMachines #DNSManagement #OpenShift #GitOps&amp;hellip;</description>
    </item>
    <item>
      <title>How to deploy language models with Red Hat OpenShift AI</title>
      <link>/articles/article-2025-09-10-9507/</link>
      <pubDate>Wed, 10 Sep 2025 07:00:55 +0000</pubDate>
      <guid>/articles/article-2025-09-10-9507/</guid>
      <description>üöÄ Red Hat OpenShift AI is transforming the deployment of language models! This guide explores the OpenShift AI console, your hub for managing data science projects. You can easily deploy models like Llama, leveraging GPU acceleration and resource scaling. Key features include project dashboards, model tracking, and multiple storage options. Check out the step-by-step deployment process for Llama, from GPU setup to testing both internal and external access. üîó Watch the full video demo for a&amp;hellip;</description>
    </item>
    <item>
      <title>AI search with style: Fashion on OpenShift AI with EDB</title>
      <link>/articles/article-2025-09-10-9508/</link>
      <pubDate>Wed, 10 Sep 2025 07:00:53 +0000</pubDate>
      <guid>/articles/article-2025-09-10-9508/</guid>
      <description>Unlocking fashion e-commerce with AI! üõçÔ∏è‚ú® Traditional keyword searches often miss the mark in understanding customers&amp;rsquo; true intent. This article highlights a solution using semantic search, which captures meaning and intent in fashion searches. EDB Postgres AI and Red Hat OpenShift AI work together to process AI data, enabling seamless visual and text searches. Users can upload images or describe items without needing exact terms. This innovative approach not only enhances search accuracy but&amp;hellip;</description>
    </item>
    <item>
      <title>What qualifies for Red Hat Developer Subscription for Teams?</title>
      <link>/articles/article-2025-09-09-9464/</link>
      <pubDate>Tue, 09 Sep 2025 14:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9464/</guid>
      <description>Unlock development potential with the Red Hat Developer Subscription for Teams! üöÄ This program provides organizations using Red Hat technologies free access to Red Hat Enterprise Linux for development activities. It&amp;rsquo;s available via Red Hat representatives or self-service at developers.redhat.com. Key activities covered include software design, coding, building, testing, and pre-production setups. The subscription supports efficient application development and deployment. For more details,&amp;hellip;</description>
    </item>
    <item>
      <title>How to run OpenAI&#39;s gpt-oss models locally with RamaLama</title>
      <link>/articles/article-2025-09-09-9444/</link>
      <pubDate>Tue, 09 Sep 2025 07:01:03 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9444/</guid>
      <description>Unlock the power of OpenAI&amp;rsquo;s gpt-oss models locally with RamaLama! üñ•Ô∏è These models, available in 20B and 120B variants, enable advanced AI capabilities right on your machine. RamaLama simplifies the setup process using containerization for security and ease. üöÄ Key features include zero trust security and automatic GPU optimization. Get started easily with just a single command. Explore more about running AI models in a secure, efficient manner! üîí‚ú® #OpenAI #AIModels #RamaLama #MachineLearning&amp;hellip;</description>
    </item>
    <item>
      <title>Using DNS over TLS in OpenShift to secure communications</title>
      <link>/articles/article-2025-09-09-9445/</link>
      <pubDate>Tue, 09 Sep 2025 07:01:00 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9445/</guid>
      <description>üîí Secure your DNS traffic in Red Hat OpenShift with DNS over TLS (DoT). This feature enhances security by ensuring all DNS communications are encrypted, aligning with zero trust architecture principles. üõ†Ô∏è The recent RHEL 10 release introduces encrypted DNS, allowing DoT during installation and runtime. While currently a Technology Preview in Identity Management (IdM), it lays the groundwork for secure operations. üîç Explore installation steps for IdM and OpenShift, including configuring DNS&amp;hellip;</description>
    </item>
    <item>
      <title>Scaling DeepSeek and Sparse MoE models in vLLM with llm-d</title>
      <link>/articles/article-2025-09-08-9429/</link>
      <pubDate>Mon, 08 Sep 2025 14:02:38 +0000</pubDate>
      <guid>/articles/article-2025-09-08-9429/</guid>
      <description>üöÄ Exciting advancements in scaling Mixture of Experts (MoE) models with vLLM and the llm-d project are transforming open-source LLM capabilities. üåê This article discusses innovations like multi-head latent attention and sparse configurations, enabling efficient deployment in Kubernetes. Learn how vLLM enhances expert parallelism and communication for large models. For detailed insights, check the full article! üìä #MachineLearning #AI #Kubernetes #DeepLearning #OpenSource</description>
    </item>
    <item>
      <title>Scaling DeepSeek-style MoEs with vLLM and llm-d using Wide EP</title>
      <link>/articles/article-2025-09-08-9551/</link>
      <pubDate>Mon, 08 Sep 2025 14:02:38 +0000</pubDate>
      <guid>/articles/article-2025-09-08-9551/</guid>
      <description>üîç Exciting advancements in serving large-scale Mixture of Experts (MoE) language models are discussed in a recent article on vLLM and llm-d. The article covers the architectural changes in vLLM that enhance the efficiency of DeepSeek-style models. Key innovations include multi-head latent attention and sparse configurations with hundreds of experts. llm-d enables high-performance deployments in Kubernetes, offering intelligent scheduling and expert parallelism for efficient scaling. Learn&amp;hellip;</description>
    </item>
    <item>
      <title>Multicluster authentication with Ansible Automation Platform</title>
      <link>/articles/article-2025-09-08-9394/</link>
      <pubDate>Mon, 08 Sep 2025 07:00:54 +0000</pubDate>
      <guid>/articles/article-2025-09-08-9394/</guid>
      <description>Implementing multicluster authentication between Red Hat Ansible Automation Platform and Red Hat Advanced Cluster Management can enhance security and streamline operations. This integration allows for centralized authentication, reducing credential proliferation. Key features include dynamic token management and network security via Cluster Proxy. For successful implementation, ensure both ManagedServiceAccount and Cluster Proxy are enabled in your setup. Access detailed steps and best&amp;hellip;</description>
    </item>
    <item>
      <title>Verify Cosign bring-your-own PKI signature on OpenShift</title>
      <link>/articles/article-2025-09-08-9395/</link>
      <pubDate>Mon, 08 Sep 2025 07:00:51 +0000</pubDate>
      <guid>/articles/article-2025-09-08-9395/</guid>
      <description>üöÄ Red Hat OpenShift 4.16 introduces ClusterImagePolicy and ImagePolicy for sigstore verification. These tech preview features support Fulcio CA and public key policies. üîç The bring-your-own PKI (BYO-PKI) feature, available from OpenShift 4.19, allows validation of container images using existing X.509 certificates. üîß The article outlines how to sign images with Cosign and configure OpenShift for signature verification using ClusterImagePolicy. #OpenShift #Cosign #BYOPKI #ContainerSecurity&amp;hellip;</description>
    </item>
    <item>
      <title>What&#39;s new in network observability 1.9</title>
      <link>/articles/article-2025-09-05-7761/</link>
      <pubDate>Fri, 05 Sep 2025 07:01:17 +0000</pubDate>
      <guid>/articles/article-2025-09-05-7761/</guid>
      <description>üöÄ Exciting updates in Network Observability 1.9! This version enhances insights into network traffic with features like IPsec tracking, flowlogs-pipeline filter queries, and UDN mapping. It is compatible with Red Hat OpenShift Container Platform 4.19 and older releases. Learn how to enable IPsec and explore the new CLI enhancements for capturing flows, metrics, and packets. For detailed installation instructions, refer to the OpenShift documentation. üìäüîç #NetworkObservability #RedHat&amp;hellip;</description>
    </item>
    <item>
      <title>Customize your deployments with the Red Hat Developer Hub Operator</title>
      <link>/articles/article-2025-09-04-7736/</link>
      <pubDate>Thu, 04 Sep 2025 16:53:23 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7736/</guid>
      <description>üöÄ The Red Hat Developer Hub enhances internal developer portals when paired with Red Hat OpenShift. Key updates in version 1.2 include: - A new Argo CD front-end plug-in for better UX. - Enhanced orchestration capabilities for software templates. - Improved provenance tracking through ScaffoldedFrom metadata. Deployment is streamlined using the Red Hat Developer Hub Operator. Access your Backstage instance easily with the provided route. For detailed customization, a Backstage custom resource&amp;hellip;</description>
    </item>
    <item>
      <title>How to migrate from Fluentd to Vector in OpenShift 4</title>
      <link>/articles/article-2025-09-04-7703/</link>
      <pubDate>Thu, 04 Sep 2025 07:01:18 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7703/</guid>
      <description>üîÑ &lt;strong&gt;Migrating from Fluentd to Vector in OpenShift 4&lt;/strong&gt; üîÑ This article provides a comprehensive guide for migrating the default log collector in OpenShift 4 from Fluentd to Vector. With Fluentd being deprecated in Logging 5.X, this transition is essential to access the new features in Logging 6.0. Vector serves as a log collector and analyzer, simplifying the processing of logs for real-time analysis. It allows logs to be sent to destinations like Amazon CloudWatch and supports JSON formatted&amp;hellip;</description>
    </item>
    <item>
      <title>How platform engineering accelerates enterprise AI adoption</title>
      <link>/articles/article-2025-09-04-7704/</link>
      <pubDate>Thu, 04 Sep 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7704/</guid>
      <description>üöÄ Platform engineering is reshaping enterprise AI adoption. By integrating technologies like Kafka and service mesh, organizations can enhance AI deployments. üîç Key challenges include reproducibility and compliance. Platform engineering addresses these by providing self-service access and standardized environments, enabling developers and data scientists to innovate efficiently. üíª Red Hat OpenShift and Developer Hub are pivotal in making AI resources accessible while ensuring governance. #AI&amp;hellip;</description>
    </item>
    <item>
      <title>How to deploy Azure Red Hat OpenShift using Terraform</title>
      <link>/articles/article-2025-09-04-7705/</link>
      <pubDate>Thu, 04 Sep 2025 07:01:13 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7705/</guid>
      <description>üöÄ Learn how to deploy Azure Red Hat OpenShift using Terraform! This article covers the steps to set up and configure your Azure infrastructure with Terraform, ensuring compliance using Azure policies. It emphasizes the importance of governance rules and the use of policy-as-code for better resource management. Key prerequisites include Terraform CLI, Azure CLI, and proper role assignments. The setup involves creating a network, configuring security, and deploying the OpenShift cluster with&amp;hellip;</description>
    </item>
    <item>
      <title>Effective observability with Red Hat build of OpenTelemetry</title>
      <link>/articles/article-2025-09-03-7652/</link>
      <pubDate>Wed, 03 Sep 2025 07:01:17 +0000</pubDate>
      <guid>/articles/article-2025-09-03-7652/</guid>
      <description>üöÄ Discover the power of observability with the Red Hat build of OpenTelemetry! This framework enables comprehensive metrics and logs reporting, crucial for monitoring your applications and infrastructure. It simplifies data collection and management while providing scalability and flexibility. Key features include: - Unified data collection - Seamless integration with monitoring tools - Enterprise-grade support from Red Hat Explore how to get started and enhance your observability practices!&amp;hellip;</description>
    </item>
    <item>
      <title>vLLM with torch.compile: Efficient LLM inference on PyTorch</title>
      <link>/articles/article-2025-09-03-7653/</link>
      <pubDate>Wed, 03 Sep 2025 07:01:11 +0000</pubDate>
      <guid>/articles/article-2025-09-03-7653/</guid>
      <description>üöÄ Efficient LLM inference is crucial in today‚Äôs diverse tech landscape. The article discusses how &lt;strong&gt;torch.compile&lt;/strong&gt;, PyTorch&amp;rsquo;s JIT compiler, streamlines performance by automatically optimizing kernels. This reduces the burden on developers, allowing them to focus on model design rather than manual tuning. Incorporated into &lt;strong&gt;vLLM&lt;/strong&gt;, torch.compile enhances usability and performance through custom compiler passes. It supports dynamic batch sizes and improves startup times with caching&amp;hellip;</description>
    </item>
    <item>
      <title>Your LLM is too large: How I generate production-ready failure analysis on a toaster</title>
      <link>/articles/article-2025-09-02-7602/</link>
      <pubDate>Tue, 02 Sep 2025 07:00:53 +0000</pubDate>
      <guid>/articles/article-2025-09-02-7602/</guid>
      <description>Running production-grade Kubernetes failure analysis on a cost-effective edge device can streamline troubleshooting. Using Llama 3.2:3B with 4-bit quantization, root cause analysis is achieved in just 70 seconds. This method incorporates pattern preprocessing to efficiently identify known failures without overwhelming the system with raw logs. Real-world results show a significant cost reduction, from $0.30-3.00 per analysis to less than $0.001, while providing actionable insights. Explore&amp;hellip;</description>
    </item>
    <item>
      <title>Migrate your OpenShift logging stack from Elasticsearch to Loki</title>
      <link>/articles/article-2025-09-01-7578/</link>
      <pubDate>Mon, 01 Sep 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-09-01-7578/</guid>
      <description>üöÄ To leverage the latest logging features in Red Hat OpenShift 6.0, migrating from Elasticsearch to Loki is essential. This guide details how to test changes in development and plan for production implementations. Loki, a scalable log aggregation system, offers improved performance by using log labels. It allows multiple tenants, which simplifies resource management. üîÑ The migration process involves running both stacks in parallel, ensuring old logs remain accessible via Elasticsearch while&amp;hellip;</description>
    </item>
    <item>
      <title>Migrating Ansible Automation Platform 2.4 to 2.5</title>
      <link>/articles/article-2025-08-29-7509/</link>
      <pubDate>Fri, 29 Aug 2025 07:01:20 +0000</pubDate>
      <guid>/articles/article-2025-08-29-7509/</guid>
      <description>üöÄ Migrating from Ansible Automation Platform 2.4 to 2.5 involves careful steps to ensure a smooth transition. This article outlines the preparation, export, and import process using the configify.aapconfig collection. Key points include: - Ensure Ansible Automation Platform 2.5 is deployed separately. - Follow similar steps as migrating from AWX 25. - Focus on user roles and authentication changes in the new version. For detailed steps, refer to the article! üìú #Ansible #Automation #DevOps&amp;hellip;</description>
    </item>
    <item>
      <title>Multicluster resiliency with global load balancing and mesh federation</title>
      <link>/articles/article-2025-08-28-7451/</link>
      <pubDate>Thu, 28 Aug 2025 07:01:21 +0000</pubDate>
      <guid>/articles/article-2025-08-28-7451/</guid>
      <description>Explore the new architecture for multicluster resiliency using global load balancing and mesh federation! üåê This approach combines a global load balancer and a federated service mesh to enhance service availability and disaster recovery, particularly for stateless workloads. New capabilities in Red Hat OpenShift Service Mesh 3.0 and Red Hat Connectivity Link now allow for more robust deployments. Learn how to configure these tools for optimal performance! #Multicluster #RedHat #CloudComputing&amp;hellip;</description>
    </item>
    <item>
      <title>Simplify local prototyping with Camel JBang infrastructure</title>
      <link>/articles/article-2025-08-28-7452/</link>
      <pubDate>Thu, 28 Aug 2025 07:01:18 +0000</pubDate>
      <guid>/articles/article-2025-08-28-7452/</guid>
      <description>üöÄ Apache Camel simplifies integration with systems like databases and APIs through minimal coding. üåü Camel JBang, a command-line interface, enhances prototyping by allowing rapid creation and testing of integration flows without complex setups. üîß Its infra command quickly launches backends like Kafka or ActiveMQ, streamlining the development process and reducing setup time. For more details, check out the full article! #ApacheCamel #CamelJBang #Integration #Development #Prototyping</description>
    </item>
    <item>
      <title>Smart deployments at scale: Leveraging ApplicationSets and Helm with cluster labels in Red Hat Advanced Cluster Management for Kubernetes</title>
      <link>/articles/article-2025-08-27-7203/</link>
      <pubDate>Wed, 27 Aug 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7203/</guid>
      <description>Managing multiple Kubernetes clusters can be complex, but Red Hat Advanced Cluster Management simplifies this process. üåê It offers a centralized platform to oversee the entire lifecycle of Kubernetes clusters, ensuring consistent health monitoring and policy enforcement across environments. Combining ApplicationSets and Helm with cluster labels allows for tailored deployments, adapting configurations based on specific cluster characteristics. This integration streamlines operations and&amp;hellip;</description>
    </item>
    <item>
      <title>How to verify container signatures in disconnected OpenShift</title>
      <link>/articles/article-2025-08-27-7204/</link>
      <pubDate>Wed, 27 Aug 2025 07:01:15 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7204/</guid>
      <description>üîç Discover how to verify container signatures in disconnected OpenShift environments using the latest tools from sigstore! The article explores the use of oc-mirror v2 in Red Hat OpenShift 4.19, allowing mirroring of container images and their cryptographic signatures. It provides a proof of concept and detailed configuration steps for enabling signature verification with CoSign. Check it out for practical insights! üõ†Ô∏èüîí #OpenShift #ContainerSecurity #Sigstore #RedHat #DevOps</description>
    </item>
    <item>
      <title>Event-driven ingestion of Keycloak entities</title>
      <link>/articles/article-2025-08-27-7205/</link>
      <pubDate>Wed, 27 Aug 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7205/</guid>
      <description>üöÄ Discover a solution to delayed updates in entity information with the Backstage Events System! This article details a Proof of Concept (PoC) that enables near real-time synchronization of Keycloak entities into Red Hat Developer Hub (RHDH). Key benefits include immediate updates and efficient, incremental syncing, reducing API calls and CPU usage. Learn how to set up the PoC and optimize your developer catalog! üîó Check out the PoC code: [GitHub Link] #Keycloak #RedHat #EventDriven&amp;hellip;</description>
    </item>
    <item>
      <title>BGP dynamic routing with Fast Data Path on RHOSO 18</title>
      <link>/articles/article-2025-08-27-7206/</link>
      <pubDate>Wed, 27 Aug 2025 07:01:08 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7206/</guid>
      <description>Exploring the performance of dynamic routing with OVN-BGP-Agent and Fast Data Path on RHOSO 18 has yielded insightful findings. üöÄ A recent Proof of Concept assessed throughput, packet loss, stability, and resource utilization using Trex and BIRD. The results show high throughput, especially with large frames, and stable performance over extended periods. üìà However, there are limitations, including bottlenecks for small packets and some manual configuration challenges. Insights from this study&amp;hellip;</description>
    </item>
    <item>
      <title>A VM tuning case study: Balancing power and performance on AMD processors</title>
      <link>/articles/article-2025-08-26-7173/</link>
      <pubDate>Tue, 26 Aug 2025 07:01:25 +0000</pubDate>
      <guid>/articles/article-2025-08-26-7173/</guid>
      <description>During a server deployment, a significant performance gap was found between bare metal and virtual machine (VM) workloads. Optimizations, including adjusting system profiles and enabling CPU scaling drivers, were implemented. These changes resulted in notable improvements in VM performance, with the tuned VM even surpassing the original bare-metal completion times. The study highlights how targeted adjustments can lead to substantial gains in efficiency. üîßüíª‚ö°Ô∏è #VMTuning&amp;hellip;</description>
    </item>
    <item>
      <title>Optimize GPU utilization with Kueue and KEDA</title>
      <link>/articles/article-2025-08-26-7174/</link>
      <pubDate>Tue, 26 Aug 2025 07:01:23 +0000</pubDate>
      <guid>/articles/article-2025-08-26-7174/</guid>
      <description>Explore how integrating Kueue and KEDA can optimize GPU utilization in AI workloads! üöÄ This proof of concept showcases a method to enhance resource efficiency on OpenShift AI. The combination allows scaling long-running workloads to zero when idle, reducing costs significantly. Learn how to implement this strategy with a focus on resource management and effective workload scheduling. üìäüíª #AI #GPUUtilization #OpenShift #Kubernetes #CloudComputing</description>
    </item>
    <item>
      <title>Implement AI safeguards with Python and Llama Stack</title>
      <link>/articles/article-2025-08-26-7175/</link>
      <pubDate>Tue, 26 Aug 2025 07:01:20 +0000</pubDate>
      <guid>/articles/article-2025-08-26-7175/</guid>
      <description>üöÄ Exploring AI safety with Llama Stack! This article highlights how to implement guardrails in AI applications using Python and Llama Stack. It introduces two main built-in guardrails: Llama Guard, which filters unsafe content, and Prompt Guard, designed to prevent circumvention of safety measures. The post provides insights into setting up Llama Stack and utilizing these guardrails effectively in Python. #AI #LlamaStack #Python #MachineLearning #AIsafety</description>
    </item>
    <item>
      <title>LLM Compressor 0.7.0 release recap</title>
      <link>/articles/article-2025-08-25-6534/</link>
      <pubDate>Mon, 25 Aug 2025 16:09:49 +0000</pubDate>
      <guid>/articles/article-2025-08-25-6534/</guid>
      <description>üöÄ LLM Compressor has released version 0.7.0, enhancing performance for quantizing large language models. Key updates include: 1Ô∏è‚É£ New QuIP and SpinQuant-style transforms for improved accuracy. 2Ô∏è‚É£ Mixed-precision support with FP4 enhancements for better layer quantization. 3Ô∏è‚É£ DeepSeek v3-style block quantization for efficient compression without calibration data. Explore more about these features! #LLMCompressor #AI #MachineLearning #Quantization #TechUpdate</description>
    </item>
    <item>
      <title>What is an image mode 3-way merge?</title>
      <link>/articles/article-2025-08-25-6331/</link>
      <pubDate>Mon, 25 Aug 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-08-25-6331/</guid>
      <description>üîç Curious about the 3-way merge in Red Hat Enterprise Linux (RHEL)? In image mode, a new filesystem image is created to manage updates. This process includes a third version, older than the current and new images, to reduce conflicts. The merge prioritizes local changes, ensuring personalized settings remain intact. Utilizing OSTree, RHEL manages multiple OS installations effectively, making the merging process smoother. üñ•Ô∏è‚ú® #RedHat #Linux #3WayMerge #OSTree #TechUpdates</description>
    </item>
    <item>
      <title>Least-privilege installation of OpenShift IPI on AWS</title>
      <link>/articles/article-2025-08-22-6295/</link>
      <pubDate>Fri, 22 Aug 2025 07:16:18 +0000</pubDate>
      <guid>/articles/article-2025-08-22-6295/</guid>
      <description>üîí The latest guide on installing OpenShift IPI on AWS emphasizes a secure, least-privilege approach. By using the cloud credential operator utility (ccoctl) and setting credentials mode to manual, users can create narrowly-defined IAM roles. üõ†Ô∏è This method eliminates long-lived AWS access keys, relying instead on short-term AWS STS credentials. The ccoctl &amp;ndash;dry-run feature allows for auditing IAM policies before applying them, enhancing security. üìä Key points include understanding the IAM&amp;hellip;</description>
    </item>
    <item>
      <title>Integrate Azure DevOps into Red Hat Developer Hub workflows</title>
      <link>/articles/article-2025-08-22-6296/</link>
      <pubDate>Fri, 22 Aug 2025 07:16:13 +0000</pubDate>
      <guid>/articles/article-2025-08-22-6296/</guid>
      <description>üöÄ Exciting news for developers! Integrating Azure DevOps with Red Hat Developer Hub creates a seamless CI/CD experience. Azure DevOps enhances source control and deployment, while Red Hat Developer Hub centralizes tools and documentation. Key plug-ins include Azure Scaffolder and Azure DevOps, enabling improved collaboration and faster delivery. For setup, ensure Azure Entra ID is configured and follow the detailed steps for integration. Learn more about optimizing your workflows!&amp;hellip;</description>
    </item>
    <item>
      <title>How to auto-register Red Hat Edge Manager with MicroShift</title>
      <link>/articles/article-2025-08-21-5016/</link>
      <pubDate>Thu, 21 Aug 2025 07:01:31 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5016/</guid>
      <description>üöÄ Red Hat Edge Manager, in Technology Preview, offers a fleet management solution for edge devices. It ensures security, simplifies management, and provides real-time visibility. üîß The article details how to auto-register Edge Manager with Red Hat MicroShift using Red Hat Advanced Cluster Management for Kubernetes 2.13. üìã Key steps include enabling Edge Manager, setting up the flightctl command, and configuring auto-registration. Explore how these tools can enhance your edge device&amp;hellip;</description>
    </item>
    <item>
      <title>The hidden pitfalls of Kafka tiered storage</title>
      <link>/articles/article-2025-08-21-5019/</link>
      <pubDate>Thu, 21 Aug 2025 07:01:29 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5019/</guid>
      <description>üöÄ Apache Kafka 3.9.0 introduces tiered storage for improved long-term data retention and cost efficiency. This feature allows independent scaling of compute and storage resources, leading to better client isolation. However, challenges remain in reading remote data. The article outlines two key problems and offers solutions, emphasizing important configurations like &lt;code&gt;fetch.max.bytes&lt;/code&gt; and &lt;code&gt;max.partition.fetch.bytes&lt;/code&gt;. Kafka 4.2.0 promises improvements to address these issues, enhancing&amp;hellip;</description>
    </item>
    <item>
      <title>Unleash controlled chaos with krknctl</title>
      <link>/articles/article-2025-08-21-5020/</link>
      <pubDate>Thu, 21 Aug 2025 07:01:25 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5020/</guid>
      <description>Unleash the power of chaos engineering with &lt;strong&gt;krknctl&lt;/strong&gt;! üéâ This command-line interface simplifies testing system resilience by orchestrating chaos scenarios using container images from krkn-hub. Key features include instant autocompletion, dynamic graph orchestration, and versatile container support with Podman or Docker. With pre-compiled binaries available, you can start your chaos engineering journey in minutes. Discover more and elevate your systems today! üîçüíª #ChaosEngineering #DevOps&amp;hellip;</description>
    </item>
    <item>
      <title>Your agent, your rules: A deep dive into the Responses API with Llama Stack</title>
      <link>/articles/article-2025-08-20-5021/</link>
      <pubDate>Wed, 20 Aug 2025 07:01:24 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5021/</guid>
      <description>üîç The OpenAI Responses API simplifies AI application development by managing complex orchestration. However, it is tied to specific models and a proprietary cloud service. Enter Llama Stack, an open-source server that offers a compatible Responses API and lets you deploy on your hardware with your chosen models. It supports advanced features like Retrieval-augmented Generation (RAG) for accurate answers without compromising document privacy. Explore how Llama Stack can transform your AI&amp;hellip;</description>
    </item>
    <item>
      <title>Build a container image for a Quarkus project using Buildpacks</title>
      <link>/articles/article-2025-08-20-5024/</link>
      <pubDate>Wed, 20 Aug 2025 07:01:22 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5024/</guid>
      <description>üöÄ Learn how to build container images for your Quarkus projects using the Container Image Buildpack extension! This method eliminates the need for a Dockerfile, streamlining your CI/CD workflow. üîß The extension leverages the Java Buildpack Client to simplify application deployment in Kubernetes. Ensure you have Podman/Docker, JDK 21+, and Maven 3.9+ to get started. üì¶ With just a few Maven commands, you can create, build, and push your images to container registries effortlessly. #Quarkus&amp;hellip;</description>
    </item>
    <item>
      <title>How I built an agentic application for Docling with MCP</title>
      <link>/articles/article-2025-08-20-5025/</link>
      <pubDate>Wed, 20 Aug 2025 07:01:20 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5025/</guid>
      <description>üåê Exciting developments in AI with the Model Context Protocol (MCP) from Anthropic! Released in November 2024, MCP enables large language models to communicate seamlessly with various tools. üõ†Ô∏è With thousands of open-source MCP servers available, many developers are now creating agentic applications. However, there&amp;rsquo;s still untapped potential in fully utilizing MCP‚Äôs capabilities. üìÑ My journey began during my internship at Red Hat, where I worked with Docling, an open-source data preprocessor&amp;hellip;.</description>
    </item>
    <item>
      <title>Building trustworthy AI: A developer&#39;s guide to production-ready systems</title>
      <link>/articles/article-2025-08-20-5028/</link>
      <pubDate>Wed, 20 Aug 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5028/</guid>
      <description>üåê Building trustworthy AI is essential in today&amp;rsquo;s development landscape. As AI engineers and developers, focusing on trust, safety, and transparency is crucial for creating reliable applications. üîç AI systems should be assessed based on their potential impact, categorized into high, moderate, and minimal tiers. This impacts design choices and operational guardrails. üí° Best practices include documenting training data, testing for bias, ensuring explainability, and providing human&amp;hellip;</description>
    </item>
    <item>
      <title>Build on multi-arch clusters with builds for Red Hat OpenShift</title>
      <link>/articles/article-2025-08-19-5030/</link>
      <pubDate>Tue, 19 Aug 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-08-19-5030/</guid>
      <description>üöÄ Discover how to streamline multi-arch builds with Red Hat OpenShift! This article explains the builds for Red Hat OpenShift operator, allowing you to create a single build object for mixed architecture clusters. Key steps include installing the oc client, configuring the ClusterBuildStrategy, and verifying image builds for different architectures. Learn more about simplifying your build process! #RedHat #OpenShift #MultiArch #CloudComputing #DevOps</description>
    </item>
    <item>
      <title>How to enhance Agent2Agent (A2A) security</title>
      <link>/articles/article-2025-08-19-5032/</link>
      <pubDate>Tue, 19 Aug 2025 07:01:14 +0000</pubDate>
      <guid>/articles/article-2025-08-19-5032/</guid>
      <description>üîí The Agent2Agent (A2A) protocol by Google facilitates communication between AI agents, allowing seamless interaction across different vendors. Each agent can serve as a client or remote agent depending on the context. üåê Communication involves retrieving an Agent Card, which contains essential details for task execution. Security measures such as HTTPS and authentication protocols are crucial for protecting these interactions. üõ°Ô∏è Developers implementing A2A should remain vigilant about&amp;hellip;</description>
    </item>
    <item>
      <title>Getting started with llm-d for distributed AI inference</title>
      <link>/articles/article-2025-08-19-5035/</link>
      <pubDate>Tue, 19 Aug 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-08-19-5035/</guid>
      <description>üåê As large language models (LLMs) evolve, so must their infrastructure. Introducing &lt;strong&gt;llm-d&lt;/strong&gt;, a Kubernetes-native distributed inference stack designed to enhance AI applications. It optimizes for complex reasoning, long-running prompts, and modular scaling. Key features include smart load balancing, split-phase inference, and disaggregated caching for efficiency. This innovation addresses the unique challenges of LLM inference, making it more cost-effective and performant. Join the growing&amp;hellip;</description>
    </item>
    <item>
      <title>Manage Advanced Cluster Management policies using Ansible</title>
      <link>/articles/article-2025-08-14-4991/</link>
      <pubDate>Thu, 14 Aug 2025 07:01:15 +0000</pubDate>
      <guid>/articles/article-2025-08-14-4991/</guid>
      <description>Managing multiple Kubernetes clusters can be complex, especially with the need for consistent security and compliance. This article discusses how Red Hat Advanced Cluster Management simplifies this process through centralized management. Ansible automation enhances policy management by ensuring consistency, repeatability, and compliance across clusters. It also covers the use of the external secrets operator for secure credential management with AWS Secrets Manager. For more details, check&amp;hellip;</description>
    </item>
    <item>
      <title>Integrate vLLM inference on macOS/iOS with Alamofire and Apple Foundation</title>
      <link>/articles/article-2025-08-14-4992/</link>
      <pubDate>Thu, 14 Aug 2025 07:01:13 +0000</pubDate>
      <guid>/articles/article-2025-08-14-4992/</guid>
      <description>Unlock the potential of vLLM inference in your macOS/iOS apps! üì±üíª This article explores how to use Apple Foundation and Alamofire for seamless communication with vLLM via an OpenAI-compatible Chat Completions endpoint. It covers essential topics such as data encoding, error handling, and processing streaming results. For hands-on experience, grab the sample code from GitHub and start building! üöÄüîó #vLLM #macOS #iOSDevelopment #OpenAI #Alamofire</description>
    </item>
    <item>
      <title>Enhancing system resilience with Krkn chaos dashboard</title>
      <link>/articles/article-2025-08-14-4993/</link>
      <pubDate>Thu, 14 Aug 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-08-14-4993/</guid>
      <description>üîß In today&amp;rsquo;s digital landscape, system resilience is crucial for businesses. The Krkn chaos dashboard is an open-source tool designed to enhance Kubernetes environments by simulating failures to identify vulnerabilities. üìä The dashboard allows teams to easily design and monitor chaos experiments, providing real-time updates on system health and generating detailed reports on failures. üíª With user-friendly features, it encourages regular chaos testing, helping teams improve their system&amp;rsquo;s&amp;hellip;</description>
    </item>
    <item>
      <title>How to secure your Jenkins pipeline with Red Hat Advanced Developer Suite</title>
      <link>/articles/article-2025-08-14-4994/</link>
      <pubDate>Thu, 14 Aug 2025 07:01:08 +0000</pubDate>
      <guid>/articles/article-2025-08-14-4994/</guid>
      <description>Enhance your Jenkins pipeline security with Red Hat Advanced Developer Suite! üîí This suite integrates cryptographic signing, SBOM validation, and runtime enforcement to ensure a secure CI/CD process. Each stage‚Äîfrom commit to deployment‚Äînow includes proof of compliance. Key features include: - Trusted Artifact Signer for image signing. - Profile Analyzer for risk assessment. - Advanced Cluster Security for policy enforcement. Learn how to keep your deployment velocity while lowering risks! üöÄüîß&amp;hellip;</description>
    </item>
    <item>
      <title>How to deploy an image mode update in offline and air-gapped environments</title>
      <link>/articles/article-2025-08-13-4884/</link>
      <pubDate>Wed, 13 Aug 2025 07:01:07 +0000</pubDate>
      <guid>/articles/article-2025-08-13-4884/</guid>
      <description>Need to deploy image mode updates in offline or air-gapped environments? Red Hat Enterprise Linux offers a flexible solution that doesn&amp;rsquo;t rely on network connections. This method is ideal for security or hardware limitations. üåêüîí Key steps include preparing an external storage device, copying the necessary images, and applying updates directly to the offline system. While effective, this approach can be time-consuming and requires on-site deployment. If your system can connect online, consider&amp;hellip;</description>
    </item>
    <item>
      <title>How to install Offline Knowledge Portal on a local system</title>
      <link>/articles/article-2025-08-13-4885/</link>
      <pubDate>Wed, 13 Aug 2025 07:01:05 +0000</pubDate>
      <guid>/articles/article-2025-08-13-4885/</guid>
      <description>Unlock the Red Hat Offline Knowledge Portal for easy access to documentation and guides without an internet connection! üìöüíª To install, ensure you have a Red Hat Satellite subscription, a web browser, and enough disk space. Follow these steps: 1Ô∏è‚É£ Generate your access key. 2Ô∏è‚É£ Log in to the registry and pull the image. 3Ô∏è‚É£ Run the podman image to verify. 4Ô∏è‚É£ Access the portal at http://localhost:8080. Explore valuable resources anytime, anywhere! üåê‚ú® #RedHat #KnowledgePortal #OfflineAccess&amp;hellip;</description>
    </item>
    <item>
      <title>New features in Bunsen</title>
      <link>/articles/article-2025-08-13-4886/</link>
      <pubDate>Wed, 13 Aug 2025 07:01:02 +0000</pubDate>
      <guid>/articles/article-2025-08-13-4886/</guid>
      <description>üöÄ Bunsen has rolled out new features to enhance user experience! The updated web interface now includes a simplified project chooser, making it easier to select projects and modify search criteria. A cookie support feature allows users to save search settings for future use, streamlining the process. üç™ Additionally, the testrun overview section is customizable, letting users sort results by various columns. The new &amp;ldquo;filter by testcase&amp;rdquo; feature helps identify regressions in test results more&amp;hellip;</description>
    </item>
    <item>
      <title>Windows image-building service for OpenShift Virtualization</title>
      <link>/articles/article-2025-08-12-4887/</link>
      <pubDate>Tue, 12 Aug 2025 15:16:06 +0000</pubDate>
      <guid>/articles/article-2025-08-12-4887/</guid>
      <description>üöÄ Red Hat OpenShift Pipelines now allows for seamless management of virtual machines (VMs) in your CI/CD process. By integrating OpenShift Pipelines with OpenShift Virtualization, developers can automate the creation of standardized Windows golden images, enhancing VM provisioning. Key features include: - Management of pipelines as Kubernetes Custom Resources (CRs). - Simplified collaboration through source control management (SCM). - Streamlined operations by treating VMs as native objects&amp;hellip;</description>
    </item>
    <item>
      <title>Build your first Software Template for Backstage</title>
      <link>/articles/article-2025-08-12-4888/</link>
      <pubDate>Tue, 12 Aug 2025 12:31:14 +0000</pubDate>
      <guid>/articles/article-2025-08-12-4888/</guid>
      <description>üöÄ More organizations are adopting platform engineering and internal developer portals (IDPs) to enhance onboarding and self-service capabilities. This article details how to create a Software Template for Backstage using Red Hat Developer Hub. The template automates developer tasks, enabling faster application repository creation on GitHub with a CI pipeline. Prerequisites include admin access to Red Hat Developer Hub and GitHub integration setup. The guide offers step-by-step instructions&amp;hellip;</description>
    </item>
    <item>
      <title>How to build a simple agentic AI server with MCP</title>
      <link>/articles/article-2025-08-12-4889/</link>
      <pubDate>Tue, 12 Aug 2025 07:16:11 +0000</pubDate>
      <guid>/articles/article-2025-08-12-4889/</guid>
      <description>üåê As AI agents evolve, the need for reliable connections to real-world data grows. The Model Context Protocol (MCP) offers a standardized way to connect AI systems securely and efficiently. In a recent article, a simple MCP server was built to fetch weather data from the Open-Meteo API. This server allows AI models to interact with external tools and data, enhancing their functionality. To explore MCP, developers can set up their environment and create tools to access data easily. The article&amp;hellip;</description>
    </item>
    <item>
      <title>Boost AI efficiency with GPU autoscaling on OpenShift</title>
      <link>/articles/article-2025-08-12-4890/</link>
      <pubDate>Tue, 12 Aug 2025 07:16:07 +0000</pubDate>
      <guid>/articles/article-2025-08-12-4890/</guid>
      <description>Unlock AI potential with GPU autoscaling on OpenShift! üöÄ Dynamic autoscaling is essential for maintaining efficiency and availability in modern applications. Red Hat OpenShift offers features like horizontal pod autoscaling (HPA) and custom metrics autoscaler (KEDA) to optimize resource allocation and manage workloads effectively. KEDA enhances traditional scaling methods by utilizing external metrics, enabling better performance for GPU-accelerated applications. üìà Learn how to implement&amp;hellip;</description>
    </item>
    <item>
      <title>Disaster recovery approaches for Red Hat OpenShift Virtualization, part 2</title>
      <link>/articles/article-2025-08-11-4857/</link>
      <pubDate>Mon, 11 Aug 2025 15:31:15 +0000</pubDate>
      <guid>/articles/article-2025-08-11-4857/</guid>
      <description>üåê Discover effective disaster recovery strategies for Red Hat OpenShift Virtualization! This follow-up article explores orchestrating application failover using Kubernetes-native constructs and GitOps workflows. It emphasizes how to manage workloads during disruptions, focusing on redeployment and prioritization. Key practices include using Node Selectors and automation tools like Ansible and Helm for seamless transitions between primary and DR sites. Regular DR rehearsals and clear&amp;hellip;</description>
    </item>
    <item>
      <title>How to migrate smart inventories to constructed inventories</title>
      <link>/articles/article-2025-08-11-4858/</link>
      <pubDate>Mon, 11 Aug 2025 07:01:11 +0000</pubDate>
      <guid>/articles/article-2025-08-11-4858/</guid>
      <description>üöÄ Red Hat is set to discontinue support for smart inventories in favor of constructed inventories. This shift aims to address the limitations and challenges smart inventories present. üîÑ Migrating to constructed inventories can be complex, especially for large organizations. This article outlines a semi-automated process to simplify the transition, requiring human review to ensure accuracy. üìã Key migration steps include converting filtering conditions, reviewing configurations, and applying&amp;hellip;</description>
    </item>
    <item>
      <title>How to use Minio for Ansible automation hub</title>
      <link>/articles/article-2025-08-11-4859/</link>
      <pubDate>Mon, 11 Aug 2025 07:01:07 +0000</pubDate>
      <guid>/articles/article-2025-08-11-4859/</guid>
      <description>Learn how to configure MinIO as a backend for the Ansible Automation Hub in Red Hat environments. This setup provides a self-hosted, cost-effective alternative to cloud storage solutions like AWS S3. The article covers: 1Ô∏è‚É£ Setting up MinIO on an OpenShift cluster. 2Ô∏è‚É£ Integrating it with the Ansible Automation Platform. This method is ideal for air-gapped or on-premise deployments. #Ansible #MinIO #OpenShift #CloudStorage #DevOps</description>
    </item>
    <item>
      <title>Ollama vs. vLLM: A deep dive into performance benchmarking</title>
      <link>/articles/article-2025-08-08-4711/</link>
      <pubDate>Fri, 08 Aug 2025 07:16:15 +0000</pubDate>
      <guid>/articles/article-2025-08-08-4711/</guid>
      <description>Ollama and vLLM serve distinct roles in the AI landscape. Ollama is designed for local development and prototyping, while vLLM excels in high-performance production environments. In benchmarks, vLLM outperformed Ollama with a peak throughput of 793 TPS compared to Ollama&amp;rsquo;s 41 TPS and lower latency across all concurrency levels. Ollama prioritizes ease of use, making it suitable for individual developers, whereas vLLM is built for scalability, catering to enterprise applications. For detailed&amp;hellip;</description>
    </item>
    <item>
      <title>Upgrade from RHEL 9 to RHEL 10 with Red Hat Satellite 6.17</title>
      <link>/articles/article-2025-08-08-4712/</link>
      <pubDate>Fri, 08 Aug 2025 07:16:11 +0000</pubDate>
      <guid>/articles/article-2025-08-08-4712/</guid>
      <description>üöÄ Red Hat Enterprise Linux (RHEL) 10 is now available! For system admins managing large environments, upgrading from RHEL 9 to RHEL 10 can be simplified using Red Hat Satellite 6.17 and Leapp. These tools help ensure consistency, compliance, and minimal downtime during the upgrade process. Leapp automates checks and resolves compatibility issues, while Satellite manages repository synchronization and system tracking. Before upgrading, ensure your Satellite is properly configured and&amp;hellip;</description>
    </item>
    <item>
      <title>Batch inference on OpenShift AI with Ray Data, vLLM, and CodeFlare</title>
      <link>/articles/article-2025-08-07-4690/</link>
      <pubDate>Thu, 07 Aug 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-08-07-4690/</guid>
      <description>Explore how to run batch inference at scale with OpenShift AI using the CodeFlare SDK, Ray Data, and vLLM. This approach helps bridge the gap between local development and production execution, enabling data scientists to efficiently process large datasets without needing deep infrastructure knowledge. The article outlines the differences between online and offline inference, focusing on the latter for large-scale tasks. It provides a step-by-step guide on connecting to a Ray cluster and&amp;hellip;</description>
    </item>
    <item>
      <title>Build trust in your CI/CD pipelines with OpenShift Pipelines</title>
      <link>/articles/article-2025-08-07-4691/</link>
      <pubDate>Thu, 07 Aug 2025 07:01:13 +0000</pubDate>
      <guid>/articles/article-2025-08-07-4691/</guid>
      <description>üîí Red Hat OpenShift Pipelines provide a cloud-native CI/CD solution using Tekton. This article highlights the use of OpenShift sandboxed containers, which isolate workloads in virtual machines, enhancing security for tasks needing elevated privileges. üåê For untrusted environments, OpenShift confidential containers (CoCo) further protect pipeline data by running containers in isolated hardware enclaves, safeguarding against admin access. üí° The integration of these technologies ensures secure,&amp;hellip;</description>
    </item>
    <item>
      <title>Simplify access management for Red Hat Insights for Red Hat Enterprise Linux with new system roles</title>
      <link>/articles/article-2025-08-06-4103/</link>
      <pubDate>Wed, 06 Aug 2025 07:16:10 +0000</pubDate>
      <guid>/articles/article-2025-08-06-4103/</guid>
      <description>Managing user access for Red Hat Enterprise Linux (RHEL) just became simpler! üöÄ Red Hat has introduced three new system roles in the User Access service of the Hybrid Cloud Console: 1Ô∏è‚É£ &lt;strong&gt;RHEL Administrator&lt;/strong&gt;: Full privileges for managing configurations and vulnerabilities. 2Ô∏è‚É£ &lt;strong&gt;RHEL Operator&lt;/strong&gt;: Broad capabilities for editing configurations, but with some restrictions. 3Ô∏è‚É£ &lt;strong&gt;RHEL Viewer&lt;/strong&gt;: Read-only access for viewing system data. These roles enhance security and streamline user management&amp;hellip;</description>
    </item>
    <item>
      <title>Intro to Redis and PostgreSQL in Red Hat SAP environments</title>
      <link>/articles/article-2025-08-06-4104/</link>
      <pubDate>Wed, 06 Aug 2025 07:16:07 +0000</pubDate>
      <guid>/articles/article-2025-08-06-4104/</guid>
      <description>üöÄ Discover how Redis and PostgreSQL can enhance SQL query performance in SAP environments! This article guides SAP and Red Hat admins in leveraging these technologies for better caching. üîç Key points include: - PostgreSQL and Redis can be deployed alongside SAP applications. - Redis offers granular control over caching, improving performance. - A Python program example showcases data caching. For more insights, check the full article! #Redis #PostgreSQL #SAP #Caching #DataManagement</description>
    </item>
    <item>
      <title>Getting started with managed clusters migration</title>
      <link>/articles/article-2025-08-05-90/</link>
      <pubDate>Tue, 05 Aug 2025 07:01:14 +0000</pubDate>
      <guid>/articles/article-2025-08-05-90/</guid>
      <description>üöÄ Red Hat Advanced Cluster Management 2.13 introduces a new developer preview feature: Managed Cluster Migration. This feature is beneficial when you need to migrate managed clusters due to instability, excess clusters, or selective transfers to another hub cluster. To get started, ensure both hub clusters are imported, running the same version, and have the managed-service account add-on enabled. You can then create a ManagedClusterMigration custom resource to facilitate the migration. For&amp;hellip;</description>
    </item>
    <item>
      <title>Retrieval-augmented generation with Llama Stack and Python</title>
      <link>/articles/article-2025-08-05-91/</link>
      <pubDate>Tue, 05 Aug 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-08-05-91/</guid>
      <description>üöÄ Learn how to implement retrieval-augmented generation (RAG) using Python and Llama Stack! This article explores how RAG enhances AI responses by providing relevant context from documents, like Node.js reference architecture. By transforming data into vectors, the application retrieves pertinent document chunks to improve answer quality. The setup process involves running a Llama Stack instance and managing vector databases for efficient data handling. For developers interested in leveraging&amp;hellip;</description>
    </item>
    <item>
      <title>Introducing incident detection in Red Hat Advanced Cluster Management for Kubernetes 2.14</title>
      <link>/articles/article-2025-08-05-92/</link>
      <pubDate>Tue, 05 Aug 2025 07:01:10 +0000</pubDate>
      <guid>/articles/article-2025-08-05-92/</guid>
      <description>üöÄ Red Hat Advanced Cluster Management for Kubernetes 2.14 introduces incident detection, helping teams manage alert storms more effectively. This feature groups related alerts into manageable incidents, allowing for better root cause analysis and prioritization. To utilize this, install the Cluster Observability Operator on each cluster. It simplifies navigation between incidents within managed clusters. For installation details and to explore this feature, check the latest documentation&amp;hellip;.</description>
    </item>
    <item>
      <title>How to deploy multiple OpenStack environments on OpenShift</title>
      <link>/articles/article-2025-08-05-93/</link>
      <pubDate>Tue, 05 Aug 2025 07:01:07 +0000</pubDate>
      <guid>/articles/article-2025-08-05-93/</guid>
      <description>Red Hat OpenStack Services on OpenShift introduces a new deployment architecture that enhances Infrastructure-as-a-Service (IaaS) environments. This architecture utilizes distributed control plane services in pods, which significantly reduces resource consumption compared to previous versions. A key feature of the latest release is the ability to run multiple OpenStack Services across different namespaces within the same OpenShift infrastructure, supporting development, staging, testing, and&amp;hellip;</description>
    </item>
    <item>
      <title>Optimize workloads with right-sizing recommendations</title>
      <link>/articles/article-2025-08-04-94/</link>
      <pubDate>Mon, 04 Aug 2025 13:46:13 +0000</pubDate>
      <guid>/articles/article-2025-08-04-94/</guid>
      <description>üöÄ Introducing the Right-Sizing Recommendations in Red Hat Advanced Cluster Management for Kubernetes! This new capability helps users identify over-provisioned and under-utilized resources across clusters, promoting efficient infrastructure use and cost savings. By analyzing real-time CPU and memory consumption, it offers actionable recommendations for workload optimization. Key features include a Grafana dashboard for resource metrics, customizable data filtering, and policy-driven&amp;hellip;</description>
    </item>
    <item>
      <title>How to use Red Hat Quay as a proxy cache</title>
      <link>/articles/article-2025-08-04-95/</link>
      <pubDate>Mon, 04 Aug 2025 07:01:06 +0000</pubDate>
      <guid>/articles/article-2025-08-04-95/</guid>
      <description>Unlock the potential of Red Hat Quay as a proxy cache for container images! üåê This guide details how to set up a Red Hat OpenShift cluster and enable proxy caching in Red Hat Quay. Start by configuring the FEATURE_PROXY_CACHE flag in the config.yaml file, then create an organization for remote image proxying. Learn how to pull images from external sources like Docker Hub and deploy applications seamlessly. üöÄ For more insights, check out the full article! #RedHat #ContainerRegistry #OpenShift&amp;hellip;</description>
    </item>
    <item>
      <title>.NET container troubleshooting in OpenShift 4</title>
      <link>/articles/article-2025-08-04-96/</link>
      <pubDate>Mon, 04 Aug 2025 07:01:03 +0000</pubDate>
      <guid>/articles/article-2025-08-04-96/</guid>
      <description>üöÄ The .NET framework is a robust tool for deploying applications across platforms like Windows, Linux, and macOS. Red Hat offers a containerized version specifically for OpenShift. üîç The article by Tom Deseyn outlines steps for creating .NET container images and troubleshooting common issues. It highlights methods for memory analysis using tools like &lt;code&gt;dotnet dump&lt;/code&gt;. üìä For developers looking to optimize their .NET applications in OpenShift, this is a valuable resource. #DotNet #OpenShift&amp;hellip;</description>
    </item>
    <item>
      <title>Automatic certificate provisioning with cert-manager and DNS challenge</title>
      <link>/articles/article-2025-08-01-97/</link>
      <pubDate>Fri, 01 Aug 2025 07:01:18 +0000</pubDate>
      <guid>/articles/article-2025-08-01-97/</guid>
      <description>Learn how to automate certificate management in OpenShift using the cert-manager operator. üîê This article outlines the use of the ACME protocol with Identity Management (IdM) to streamline certificate issuance and renewal through a DNS challenge. It highlights the setup process with Red Hat Enterprise Linux (RHEL) 10 and OpenShift 4.14. Discover the benefits of reducing manual certificate management, which can lead to inefficiencies and errors. Read more to enhance your OpenShift&amp;hellip;</description>
    </item>
    <item>
      <title>5 steps to consistently patch RHEL and Windows systems</title>
      <link>/articles/article-2025-08-01-98/</link>
      <pubDate>Fri, 01 Aug 2025 07:01:15 +0000</pubDate>
      <guid>/articles/article-2025-08-01-98/</guid>
      <description>Staying updated on patching RHEL and Windows systems is crucial for security and operational efficiency. üõ°Ô∏è Using Red Hat Ansible Automation Platform can streamline this process by automating patch management for both systems. This reduces friction between teams and ensures compliance. Key steps include building a centralized inventory, creating job templates, applying patches with safety checks, validating success, and leveraging event-driven automation for proactive patching. üìä Explore more&amp;hellip;</description>
    </item>
    <item>
      <title>IBM Hyper Protect with OpenShift sandboxed containers</title>
      <link>/articles/article-2025-07-31-99/</link>
      <pubDate>Thu, 31 Jul 2025 07:01:17 +0000</pubDate>
      <guid>/articles/article-2025-07-31-99/</guid>
      <description>IBM is advancing data security with Hyper Protect Confidential Containers (HPCC) for Red Hat OpenShift. This solution protects sensitive workloads in untrusted environments, essential for industries like finance and healthcare. Using OpenShift sandboxed containers, HPCC ensures VM-level isolation for confidential computing. It addresses vulnerabilities of traditional containers by employing hardware-based trusted execution environments. Learn how HPCC enhances data protection and supports&amp;hellip;</description>
    </item>
  </channel>
</rss>
