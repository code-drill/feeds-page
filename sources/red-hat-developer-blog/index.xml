<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Red-Hat-Developer-Blog on Daily Tech Articles Feed</title>
    <link>/sources/red-hat-developer-blog/</link>
    <description>Recent content in Red-Hat-Developer-Blog on Daily Tech Articles Feed</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 21 Oct 2025 07:01:41 +0000</lastBuildDate>
    <atom:link href="/sources/red-hat-developer-blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Krkn-AI: A feedback-driven approach to chaos engineering</title>
      <link>/articles/article-2025-10-21-11095/</link>
      <pubDate>Tue, 21 Oct 2025 07:01:41 +0000</pubDate>
      <guid>/articles/article-2025-10-21-11095/</guid>
      <description>Introducing &lt;strong&gt;Krkn-AI&lt;/strong&gt;: a new framework for AI-assisted chaos engineering. It addresses the challenges of testing modern systems, especially in dynamic environments like Kubernetes. Chaos engineering helps identify weaknesses by simulating failures, but traditional methods can be manual and static. Krkn-AI automates experiment discovery and execution, allowing teams to focus on insights rather than manual setups. Key features include cluster-aware discoverability, enhanced test coverage, and&amp;hellip;</description>
    </item>
    <item>
      <title>How to import provider network routes to OpenShift via BGP</title>
      <link>/articles/article-2025-10-21-11096/</link>
      <pubDate>Tue, 21 Oct 2025 07:01:39 +0000</pubDate>
      <guid>/articles/article-2025-10-21-11096/</guid>
      <description>Importing provider network routes into Red Hat OpenShift Virtualization via BGP enhances network capabilities. üåê This integration allows for dynamic routing and automates configurations, improving VM migration and overall performance. BGP&amp;rsquo;s features like bidirectional forwarding detection (BFD) ensure high availability and rapid failover. To implement this, ensure your OpenShift cluster meets the prerequisites and follow the detailed configuration steps provided. #OpenShift #BGP #CloudNative&amp;hellip;</description>
    </item>
    <item>
      <title>A case study in Kubelet regression in OpenShift</title>
      <link>/articles/article-2025-10-20-11059/</link>
      <pubDate>Mon, 20 Oct 2025 07:01:19 +0000</pubDate>
      <guid>/articles/article-2025-10-20-11059/</guid>
      <description>In the latest analysis of Red Hat OpenShift, a kubelet regression was detected that increased CPU usage by 30% and pod readiness latency by 50%. Our performance engineering team utilized the changepoint detection tool, Orion, to identify these issues during automated scale tests. The regression was linked to kubelet 1.33, which was resolved by reverting to version 1.32.6, restoring normal performance metrics. This case highlights the importance of continuous testing and collaboration to&amp;hellip;</description>
    </item>
    <item>
      <title>Profiling vLLM Inference Server with GPU acceleration on RHEL</title>
      <link>/articles/article-2025-10-16-10998/</link>
      <pubDate>Thu, 16 Oct 2025 15:44:40 +0000</pubDate>
      <guid>/articles/article-2025-10-16-10998/</guid>
      <description>üöÄ Profiling large language models (LLMs) is essential for optimization. This guide details how to set up and profile a vLLM inference server on RHEL with NVIDIA GPUs. üîß It covers three main stages: 1Ô∏è‚É£ Environment setup: Install NVIDIA drivers and the Container Toolkit. 2Ô∏è‚É£ Basic profiling: Use the PyTorch profiler to trace inference requests. 3Ô∏è‚É£ Advanced profiling: Leverage NVIDIA Nsight Systems for deeper insights. For a comprehensive understanding, check the full guide! #LLM #GPU #vLLM&amp;hellip;</description>
    </item>
    <item>
      <title>Network performance in distributed training: Maximizing GPU utilization on OpenShift</title>
      <link>/articles/article-2025-10-16-10999/</link>
      <pubDate>Thu, 16 Oct 2025 15:07:18 +0000</pubDate>
      <guid>/articles/article-2025-10-16-10999/</guid>
      <description>üöÄ Key findings from a recent study on GPU clusters for distributed training highlight the importance of network architecture. Using IBM Cloud, tests showed that the standard OpenShift pod network creates bottlenecks. For L40S GPUs, secondary vNICs increased performance by up to 132% at scale. For H100 GPUs, switching to SR-IOV led to a 3x increase in throughput. Recommendations emphasize investing in high-performance networks to maximize GPU utilization. #DistributedTraining #GPUPerformance&amp;hellip;</description>
    </item>
    <item>
      <title>Clang bytecode interpreter update</title>
      <link>/articles/article-2025-10-15-10924/</link>
      <pubDate>Wed, 15 Oct 2025 07:16:20 +0000</pubDate>
      <guid>/articles/article-2025-10-15-10924/</guid>
      <description>üöÄ This October, an update on the Clang bytecode interpreter reveals significant progress! With about 500 commits since last year, the implementation has become more robust. Test failures in the clang suite have decreased from 155 to 90. A working version of &lt;code&gt;builtin_constant_p&lt;/code&gt; is now available, supporting real-world use cases. Key enhancements include optimizations for constant expressions, improving performance in certain scenarios. The inclusion of libc++ testing has also led to better&amp;hellip;</description>
    </item>
    <item>
      <title>How Red Hat has redefined continuous performance testing</title>
      <link>/articles/article-2025-10-15-10925/</link>
      <pubDate>Wed, 15 Oct 2025 07:16:15 +0000</pubDate>
      <guid>/articles/article-2025-10-15-10925/</guid>
      <description>üöÄ Continuous performance testing (CPT) is crucial for software development, especially for Red Hat OpenShift. The article highlights its importance in preventing performance bottlenecks and improving user experience. Challenges include OpenShift&amp;rsquo;s complexity and the need for flexible testing solutions. The team shifted-left, integrating performance tests into their CI/CD pipeline, increasing development velocity and collaboration. Stay tuned for best practices and insights on CPT! üìàüîç #RedHat&amp;hellip;</description>
    </item>
    <item>
      <title>Simplify OpenShift installation in air-gapped environments</title>
      <link>/articles/article-2025-10-14-10900/</link>
      <pubDate>Tue, 14 Oct 2025 17:27:33 +0000</pubDate>
      <guid>/articles/article-2025-10-14-10900/</guid>
      <description>Deploying OpenShift in air-gapped environments can be challenging due to complex setup requirements. The article introduces &amp;ldquo;aba,&amp;rdquo; a new tool that simplifies this process. Aba provides a pre-tested install bundle that includes all necessary components, automating the setup of registries and mirroring images. This tool aims to reduce installation time and manual troubleshooting. Aba&amp;rsquo;s key features include end-to-end automation, built-in best practices, and support for various installation&amp;hellip;</description>
    </item>
    <item>
      <title>Dynamic GPU slicing with Red Hat OpenShift and NVIDIA MIG</title>
      <link>/articles/article-2025-10-14-10884/</link>
      <pubDate>Tue, 14 Oct 2025 07:01:10 +0000</pubDate>
      <guid>/articles/article-2025-10-14-10884/</guid>
      <description>Unlock the potential of your GPU with NVIDIA&amp;rsquo;s Multi-Instance GPU (MIG) and Red Hat OpenShift! üöÄ This powerful combination allows you to dynamically allocate GPU resources, enabling diverse workloads‚Äîfrom running seven small models to a single large one‚Äîwithout idle time. Discover how the dynamic accelerator slicer operates, facilitating efficient resource management and isolation for teams. üíª Read more about the setup and see live demos of this innovative technology in action! #NVIDIA&amp;hellip;</description>
    </item>
    <item>
      <title>Protecting virtual machines from storage and secondary network node failures</title>
      <link>/articles/article-2025-10-13-10865/</link>
      <pubDate>Mon, 13 Oct 2025 07:01:04 +0000</pubDate>
      <guid>/articles/article-2025-10-13-10865/</guid>
      <description>Kubernetes provides basic health monitoring for nodes but lacks adequate support for storage and secondary network failures, crucial for virtual machines and telco deployments. The kubelet detects node issues, focusing mainly on resource availability and control plane connectivity. However, it does not monitor storage or network health directly, leading to potential inconsistencies and downtime. To address this, the Node Problem Detector (NPD) operator can be implemented, allowing for&amp;hellip;</description>
    </item>
    <item>
      <title>How to use OCI for GitOps in OpenShift</title>
      <link>/articles/article-2025-10-13-10866/</link>
      <pubDate>Mon, 13 Oct 2025 07:01:02 +0000</pubDate>
      <guid>/articles/article-2025-10-13-10866/</guid>
      <description>üöÄ Exploring GitOps with OCI in OpenShift! Organizations transitioning to GitOps often think they need Git-based systems. However, GitOps principles allow for other compliant storage options like OCI, which can store various content types beyond container images. OpenShift GitOps 1.18 now supports OCI as a source of truth, simplifying management and enhancing security. This approach streamlines operations and integrates well with CI pipelines. To get started, ensure you have the oras CLI and&amp;hellip;</description>
    </item>
    <item>
      <title>Using AI agents with Red Hat Insights</title>
      <link>/articles/article-2025-10-13-10867/</link>
      <pubDate>Mon, 13 Oct 2025 07:00:59 +0000</pubDate>
      <guid>/articles/article-2025-10-13-10867/</guid>
      <description>Unlock the potential of AI with insights-mcp by Red Hat! üåê This self-hosted server allows seamless interaction with key Red Hat Insights features like vulnerability management and inventory tracking, all through the Model Context Protocol (MCP). To get started, set up a service account and install VS Code. You can then connect LLM agents to enhance your workflows, from daily security checks to compliance monitoring. Explore the developer preview today and share your feedback! üõ†Ô∏èüíª #RedHat #AI&amp;hellip;</description>
    </item>
    <item>
      <title>Splitting OpenShift machine config pool without node reboots</title>
      <link>/articles/article-2025-10-10-10616/</link>
      <pubDate>Fri, 10 Oct 2025 07:00:58 +0000</pubDate>
      <guid>/articles/article-2025-10-10-10616/</guid>
      <description>üöÄ Splitting an OpenShift Machine Config Pool (MCP) without node reboots is now possible! This guide details how to create two separate MCPs while maintaining identical configurations. This method is especially beneficial for large clusters with over 100 worker nodes, simplifying upgrades and management. Key steps include identifying the current MCP and machine configurations, creating a new MCP, and labeling nodes for the transition. For detailed commands and procedures, refer to the full&amp;hellip;</description>
    </item>
    <item>
      <title>Node.js 20&#43; memory management in containers</title>
      <link>/articles/article-2025-10-10-10617/</link>
      <pubDate>Fri, 10 Oct 2025 07:00:55 +0000</pubDate>
      <guid>/articles/article-2025-10-10-10617/</guid>
      <description>Node.js 20 enhances memory management in containers by being container-aware, limiting heap size based on cgroup limits. This adaptation helps prevent memory overflow issues on platforms like OpenShift. The maximum heap size is 50% of the container size, capping at 2 GiB for larger containers. Developers can also set specific limits using the &lt;code&gt;--max-old-space-size&lt;/code&gt; flag. For efficient CPU allocation, combining &lt;code&gt;worker_threads&lt;/code&gt; with multiple CPU limits can improve performance, but balance is&amp;hellip;</description>
    </item>
    <item>
      <title>Integrate incident detection with OpenShift Lightspeed via MCP</title>
      <link>/articles/article-2025-10-09-10576/</link>
      <pubDate>Thu, 09 Oct 2025 07:00:51 +0000</pubDate>
      <guid>/articles/article-2025-10-09-10576/</guid>
      <description>Red Hat OpenShift now integrates incident detection with OpenShift Lightspeed, enhancing how users analyze and resolve cluster issues. This integration allows for natural language interaction, helping to group related alerts and reduce alert fatigue. Users can easily inquire about incidents, symptoms, and event chains. To set up, ensure you have OpenShift 4.19 and an API key for an LLM provider. Installation steps are available for the Cluster Health MCP server. Explore these new capabilities&amp;hellip;</description>
    </item>
    <item>
      <title>One model is not enough, too many models is hard: Technical deep dive</title>
      <link>/articles/article-2025-10-08-10542/</link>
      <pubDate>Wed, 08 Oct 2025 14:16:08 +0000</pubDate>
      <guid>/articles/article-2025-10-08-10542/</guid>
      <description>üöÄ Discover how to efficiently manage hundreds to thousands of machine learning models with a systematic approach! This guide outlines a model lifecycle assembly line, focusing on configuration-driven pipelines, version control, and GitOps promotion. Key features include: - Continuous training and versioned pipelines - Data lineage for reproducibility - Safe, automated deployments Learn how to implement these practices in your environment! üîó Check out the full details and demo on YouTube!&amp;hellip;</description>
    </item>
    <item>
      <title>What&#39;s new in Ansible Automation Platform 2.6</title>
      <link>/articles/article-2025-10-08-10532/</link>
      <pubDate>Wed, 08 Oct 2025 13:01:32 +0000</pubDate>
      <guid>/articles/article-2025-10-08-10532/</guid>
      <description>üöÄ Red Hat Ansible Automation Platform 2.6 is now available! This release enhances automation accessibility with new features. Key updates include a self-service automation portal, the Ansible Lightspeed intelligent assistant, and an on-premise automation dashboard for tracking metrics. Developers can now provide teams with a simple interface to launch automation jobs, visualize their impact, and streamline development environments. Explore the latest version today! #Ansible #Automation&amp;hellip;</description>
    </item>
    <item>
      <title>Quantum computing 101 for developers</title>
      <link>/articles/article-2025-10-08-10526/</link>
      <pubDate>Wed, 08 Oct 2025 07:16:06 +0000</pubDate>
      <guid>/articles/article-2025-10-08-10526/</guid>
      <description>üåê Quantum computing is emerging as a transformative technology for developers and businesses. Unlike classical computing, which uses bits (0s and 1s), quantum computing employs qubits, allowing for superposition and entanglement. üîç These concepts enable quantum computers to tackle complex problems that classical systems struggle with, such as optimizing financial portfolios or drug design. üîó Red Hat is adapting its platforms to integrate quantum capabilities, ensuring developers are prepared&amp;hellip;</description>
    </item>
    <item>
      <title>LLM Compressor 0.8.0: Extended support for Qwen3 and more</title>
      <link>/articles/article-2025-10-07-10506/</link>
      <pubDate>Tue, 07 Oct 2025 18:07:28 +0000</pubDate>
      <guid>/articles/article-2025-10-07-10506/</guid>
      <description>üöÄ The LLM Compressor 0.8.0 release enhances quantization workflows and extends support for Qwen3 models. Key updates include: 1Ô∏è‚É£ Support for multiple modifiers during a single oneshot compression run, allowing for non-uniform quantization. 2Ô∏è‚É£ Configurable transforms with variable rotation sizes for improved efficiency. 3Ô∏è‚É£ R4 support for SpinQuant-style transforms. 4Ô∏è‚É£ Added quantization for Qwen3 models, including FP8 support. 5Ô∏è‚É£ Improved accuracy for GPTQ W4A16 schemes. Explore the&amp;hellip;</description>
    </item>
    <item>
      <title>Master KV cache aware routing with llm-d for efficient AI inference</title>
      <link>/articles/article-2025-10-07-10481/</link>
      <pubDate>Tue, 07 Oct 2025 07:00:56 +0000</pubDate>
      <guid>/articles/article-2025-10-07-10481/</guid>
      <description>Unlock efficient AI inference with llm-d! üöÄ This Kubernetes-native framework introduces KV cache aware routing, reducing latency and improving throughput by directing requests to pods with relevant context in GPU memory. Key features include an External Processing Pod and intelligent routing. With a recent test showing an impressive 87.4% cache hit rate, llm-d enhances performance and optimizes resource use. Learn more about maximizing AI infrastructure efficiency! üìäüí° #AIInference #Kubernetes&amp;hellip;</description>
    </item>
    <item>
      <title>Deploying OpenShift hosted clusters with Hypershift</title>
      <link>/articles/article-2025-10-07-10482/</link>
      <pubDate>Tue, 07 Oct 2025 07:00:55 +0000</pubDate>
      <guid>/articles/article-2025-10-07-10482/</guid>
      <description>üöÄ HyperShift revolutionizes Kubernetes management with hosted control planes in Red Hat OpenShift. This innovative feature reduces costs and complexity while enhancing scalability. It allows for faster cluster creation and upgrades, making it easier to manage large fleets. HyperShift‚Äôs architecture enables hosted control planes to run on a management cluster, optimizing resource usage. Key considerations include configuring networking, storage, and certificate management for security. Explore&amp;hellip;</description>
    </item>
    <item>
      <title>Signing RPM packages using quantum-resistant cryptography</title>
      <link>/articles/article-2025-10-07-10483/</link>
      <pubDate>Tue, 07 Oct 2025 07:00:52 +0000</pubDate>
      <guid>/articles/article-2025-10-07-10483/</guid>
      <description>üîí Learn how to sign RPM packages in Red Hat Enterprise Linux 10.1 using quantum-resistant cryptography. This article details the process for developers and vendors to enhance software security through strong signatures. It covers generating OpenPGP keys, configuring RPM, and integrating these steps into existing workflows. Post-quantum cryptography (PQC) aims to protect against future quantum attacks by using hybrid keys and signatures. RPM 6 supports multiple signatures, ensuring both&amp;hellip;</description>
    </item>
    <item>
      <title>Optimize and deploy LLMs for production with OpenShift AI</title>
      <link>/articles/article-2025-10-06-10436/</link>
      <pubDate>Mon, 06 Oct 2025 07:00:48 +0000</pubDate>
      <guid>/articles/article-2025-10-06-10436/</guid>
      <description>üöÄ Organizations face challenges in running large language models (LLMs) on their infrastructure, especially regarding GPU availability and cost. The Qwen3-Coder-30B-A3B-Instruct model offers strong code-generation capabilities but requires significant GPU resources. To enhance efficiency, quantization is employed to reduce the model&amp;rsquo;s memory footprint while maintaining accuracy. The article outlines a workflow for optimizing and deploying LLMs using Red Hat OpenShift AI, including model&amp;hellip;</description>
    </item>
    <item>
      <title>DeepSeek-V3.2-Exp on vLLM, Day 0: Sparse Attention for long-context inference, ready for experimentation today with Red Hat AI</title>
      <link>/articles/article-2025-10-03-10410/</link>
      <pubDate>Fri, 03 Oct 2025 13:14:44 +0000</pubDate>
      <guid>/articles/article-2025-10-03-10410/</guid>
      <description>üöÄ Exciting news in AI! DeepSeek-V3.2-Exp has launched, introducing Sparse Attention for efficient long-context inference. This two-stage process aims to lower costs by up to 50% for API calls. Supported by vLLM from Day 0, it runs on NVIDIA Hopper and Blackwell architectures, enabling immediate experimentation. Red Hat AI users can deploy it seamlessly on their platforms. Learn more about optimizing your long-context tasks! #AI #MachineLearning #DeepLearning #RedHatAI #NVIDIA</description>
    </item>
    <item>
      <title>How to deploy the Offline Knowledge Portal on OpenShift</title>
      <link>/articles/article-2025-10-03-10406/</link>
      <pubDate>Fri, 03 Oct 2025 07:00:48 +0000</pubDate>
      <guid>/articles/article-2025-10-03-10406/</guid>
      <description>üöÄ Discover the Red Hat Offline Knowledge Portal, designed for users in low-bandwidth or disconnected environments. This tool consolidates essential Red Hat information, including documentation and security data, into a portable container image. üõ†Ô∏è The article provides a step-by-step guide for deploying the portal on an OpenShift cluster, including prerequisites like OpenShift cluster access and Podman installation. üì• Key steps involve downloading the image, transferring it, and deploying it&amp;hellip;</description>
    </item>
    <item>
      <title>Autoscaling vLLM with OpenShift AI</title>
      <link>/articles/article-2025-10-02-10358/</link>
      <pubDate>Thu, 02 Oct 2025 07:00:57 +0000</pubDate>
      <guid>/articles/article-2025-10-02-10358/</guid>
      <description>Unlock the power of efficient LLM serving with OpenShift AI! üöÄ This article discusses how vLLM and KServe enable autoscaling of model servers, optimizing GPU resource utilization. It highlights the Serverless deployment mode, allowing scaling based on concurrent requests, and the future potential for RawDeployments using KEDA. Key prerequisites for setup include the NVIDIA GPU Operator and OpenShift Serverless. The article also provides a step-by-step guide on deploying models and configuring&amp;hellip;</description>
    </item>
    <item>
      <title>Filtering packets from anywhere in the networking stack</title>
      <link>/articles/article-2025-10-02-10359/</link>
      <pubDate>Thu, 02 Oct 2025 07:00:56 +0000</pubDate>
      <guid>/articles/article-2025-10-02-10359/</guid>
      <description>Discover the potential of packet filtering with Retis! üåê This article explores how Retis allows packet dumps from anywhere in the networking stack. It highlights its unique filtering methods: packet filtering and metadata filtering, which help manage data, ensuring accurate captures and reducing overhead. Learn how Retis compares to tools like tcpdump and tshark, emphasizing the importance of precise filtering for effective network debugging. #NetworkEngineering #PacketFiltering #Retis&amp;hellip;</description>
    </item>
    <item>
      <title>PostGIS: A powerful geospatial extension for PostgreSQL</title>
      <link>/articles/article-2025-10-02-10360/</link>
      <pubDate>Thu, 02 Oct 2025 07:00:52 +0000</pubDate>
      <guid>/articles/article-2025-10-02-10360/</guid>
      <description>üöÄ PostGIS is a geospatial extension for PostgreSQL, enhancing the database&amp;rsquo;s ability to manage geographic data. It supports operations like distance calculations and spatial joins, making it ideal for GIS applications. üîß Installation requires compatible PostgreSQL versions, currently supporting PostgreSQL 16 on RHEL 9 and 10. üìä Users can create tables with various geometric types and utilize raster data analysis through PostGIS. For detailed setup instructions, refer to the full article!&amp;hellip;</description>
    </item>
    <item>
      <title>The secure way to handle secrets in OpenShift</title>
      <link>/articles/article-2025-10-01-10306/</link>
      <pubDate>Wed, 01 Oct 2025 07:01:07 +0000</pubDate>
      <guid>/articles/article-2025-10-01-10306/</guid>
      <description>Managing sensitive information in cloud-native platforms like OpenShift is essential for security. üåê This article discusses two methods for accessing secrets: environment variables and volume mounts. While both are supported, volume mounts are recommended for better security and control. üîí Volume mounts automatically update sensitive data and limit exposure, ensuring only necessary credentials are accessed by applications. In contrast, environment variables carry risks of accidental exposure&amp;hellip;</description>
    </item>
    <item>
      <title>How to deploy MCP servers on OpenShift using ToolHive</title>
      <link>/articles/article-2025-10-01-10307/</link>
      <pubDate>Wed, 01 Oct 2025 07:01:03 +0000</pubDate>
      <guid>/articles/article-2025-10-01-10307/</guid>
      <description>üöÄ The Model Context Protocol (MCP), introduced by Anthropic in November 2024, standardizes AI interactions with large language models. Its rapid adoption has led to a surge in MCP servers for local development. üõ†Ô∏è ToolHive, developed by Stacklok, facilitates the deployment and management of these servers on Kubernetes and OpenShift. It includes a GUI for local developers and an operator for Kubernetes orchestration. üîß To get started, ensure you have Helm and access to an OpenShift-based&amp;hellip;</description>
    </item>
    <item>
      <title>How to change the meaning of python and python3 on RHEL</title>
      <link>/articles/article-2025-09-30-10240/</link>
      <pubDate>Tue, 30 Sep 2025 07:00:55 +0000</pubDate>
      <guid>/articles/article-2025-09-30-10240/</guid>
      <description>Changing the default Python interpreter on RHEL requires caution. The alternatives command, previously used, is unsupported in RHEL 9 and later due to potential system risks. Modifying the system Python can disrupt core components like dnf, affecting system management. A safer approach is to create a symbolic link to your desired Python version without altering the system Python. This method is easy to reverse and maintains system integrity. For script portability, use `#!/usr/bin/env&amp;hellip;</description>
    </item>
    <item>
      <title>vLLM or llama.cpp: Choosing the right LLM inference engine for your use case</title>
      <link>/articles/article-2025-09-30-10241/</link>
      <pubDate>Tue, 30 Sep 2025 07:00:52 +0000</pubDate>
      <guid>/articles/article-2025-09-30-10241/</guid>
      <description>üîç Exploring LLM Inference Engines: vLLM vs. llama.cpp This article compares two powerful inference engines, highlighting their distinct features. vLLM is built for high-throughput, multi-user scenarios, excelling in scalability and responsiveness. It delivers rapid responses even under heavy loads. In contrast, llama.cpp focuses on efficiency and portability, ideal for single-user tasks and consumer-grade hardware. Its C++ architecture allows for quick loading and minimal dependencies. For&amp;hellip;</description>
    </item>
    <item>
      <title>How to implement and monitor circuit breakers in OpenShift Service Mesh 3</title>
      <link>/articles/article-2025-09-29-10192/</link>
      <pubDate>Mon, 29 Sep 2025 07:00:58 +0000</pubDate>
      <guid>/articles/article-2025-09-29-10192/</guid>
      <description>Learn how to implement and monitor circuit breakers in OpenShift Service Mesh 3.0 to enhance your application&amp;rsquo;s resilience! ‚ö° This guide outlines the steps to configure, trigger, and monitor a circuit breaker that isolates unhealthy services, helping prevent system-wide failures. Key prerequisites include having an OpenShift cluster and the Bookinfo application set up. The tutorial also covers using Kiali for monitoring. üìä For detailed instructions, check out the full guide! #OpenShift&amp;hellip;</description>
    </item>
    <item>
      <title>Analysis of OpenShift node-system-admin-client lifespan</title>
      <link>/articles/article-2025-09-29-10193/</link>
      <pubDate>Mon, 29 Sep 2025 07:00:55 +0000</pubDate>
      <guid>/articles/article-2025-09-29-10193/</guid>
      <description>In the Red Hat OpenShift Container Platform, the node-system-admin-client certificate plays a vital role in securing internal communication. This article analyzes its lifecycle, revealing a mismatch between its intended two-year validity and the actual one-year expiration due to constraints from its signing Certificate Authority (CA). It also highlights the manual rotation of certificates and the steps needed to renew them effectively. üîÑüîç #OpenShift #PKI #Certificates #RedHat #ContainerSecurity</description>
    </item>
    <item>
      <title>Beyond a single cluster with OpenShift Service Mesh 3</title>
      <link>/articles/article-2025-09-26-10120/</link>
      <pubDate>Fri, 26 Sep 2025 07:01:07 +0000</pubDate>
      <guid>/articles/article-2025-09-26-10120/</guid>
      <description>Explore the advancements of Red Hat OpenShift Service Mesh 3! üöÄ This article highlights its robust support for multi-cluster topologies, transforming independent clusters into a unified application network. It emphasizes secure inter-cluster communication through dedicated gateways. Learn about the benefits of enhanced scalability, fault tolerance, and seamless failover patterns. A step-by-step guide is provided for creating a multi-cluster architecture. #OpenShift #ServiceMesh #MultiCluster&amp;hellip;</description>
    </item>
    <item>
      <title>Kubernetes MCP server: AI-powered cluster management</title>
      <link>/articles/article-2025-09-25-10046/</link>
      <pubDate>Thu, 25 Sep 2025 07:00:56 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10046/</guid>
      <description>üöÄ Explore the Kubernetes MCP server, an AI-powered extension for Kubernetes and OpenShift! This tool allows AI assistants like VS Code and Microsoft Copilot to interact safely with your clusters. It simplifies cluster management through natural language commands and supports secure access via least-privilege ServiceAccounts. Key features include no external dependencies, support for generic Kubernetes resources, and advanced pod operations. Currently in developer preview, it encourages&amp;hellip;</description>
    </item>
    <item>
      <title>Unlocking the power of OpenShift Service Mesh 3</title>
      <link>/articles/article-2025-09-25-10047/</link>
      <pubDate>Thu, 25 Sep 2025 07:00:54 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10047/</guid>
      <description>üöÄ Red Hat OpenShift Service Mesh 3 enhances traffic management, observability, and security for microservices. As applications grow, so do the complexities of routing and securing communications. OSSM 3 introduces Envoy proxies to streamline these processes, ensuring secure service interactions and better traffic control. With features like mutual TLS for security, canary deployments for testing, and enhanced observability tools, teams can manage their microservices more effectively&amp;hellip;.</description>
    </item>
    <item>
      <title>Run DialoGPT-small on OpenShift AI for internal model testing</title>
      <link>/articles/article-2025-09-25-10048/</link>
      <pubDate>Thu, 25 Sep 2025 07:00:51 +0000</pubDate>
      <guid>/articles/article-2025-09-25-10048/</guid>
      <description>Explore the deployment of the DialoGPT-small language model on OpenShift AI for internal testing. This guide details setting up your environment, configuring ServingRuntime, and deploying an inference service, all within a secure, cloud-native environment. Key steps include verifying components, managing model storage with PVCs, and running tests without exposing external endpoints. This workflow is intended for internal evaluation only. For production use, refer to official documentation&amp;hellip;.</description>
    </item>
    <item>
      <title>Skopeo: The unsung hero of Linux container-tools</title>
      <link>/articles/article-2025-09-24-9963/</link>
      <pubDate>Wed, 24 Sep 2025 07:00:54 +0000</pubDate>
      <guid>/articles/article-2025-09-24-9963/</guid>
      <description>Discover the power of Skopeo, an essential tool in the Linux container-tools ecosystem. üåü Skopeo allows you to inspect and copy container images efficiently without downloading them first. This is especially useful for developers using Kubernetes clusters. It simplifies many tasks typically done with Podman, making workflows smoother. From inspecting remote images to syncing multiple registries, Skopeo enhances your container management experience. üåêüîß #Linux #ContainerTools #Skopeo #DevOps&amp;hellip;</description>
    </item>
    <item>
      <title>Automate certificate management in OpenShift</title>
      <link>/articles/article-2025-09-24-9964/</link>
      <pubDate>Wed, 24 Sep 2025 07:00:51 +0000</pubDate>
      <guid>/articles/article-2025-09-24-9964/</guid>
      <description>Managing certificates in IT can be challenging. Many DevOps engineers and IT managers face time-consuming manual tasks, risking governance and security. This article discusses automating the certificate lifecycle in Red Hat OpenShift using the cert-manager operator with Venafi. It offers a solution that enhances efficiency and security. By transitioning from traditional to modern certificate management, teams can minimize errors and focus on innovation. The cert-manager operator simplifies&amp;hellip;</description>
    </item>
    <item>
      <title>Customize RHEL CoreOS at scale: On-cluster image mode in OpenShift</title>
      <link>/articles/article-2025-09-23-9903/</link>
      <pubDate>Tue, 23 Sep 2025 07:01:38 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9903/</guid>
      <description>üöÄ Exciting news for OpenShift users! Red Hat introduces &amp;ldquo;on-cluster&amp;rdquo; image mode for Red Hat Enterprise Linux CoreOS, allowing seamless customization at scale. This cloud-native approach treats your OS like a container image, enabling you to define configurations as code. You can now add drivers, deploy hotfixes, and maintain customizations during upgrades directly from your cluster. OpenShift 4.19 and EUS users on 4.18.21 can fully utilize this capability. The streamlined build process&amp;hellip;</description>
    </item>
    <item>
      <title>How to set up KServe autoscaling for vLLM with KEDA</title>
      <link>/articles/article-2025-09-23-9904/</link>
      <pubDate>Tue, 23 Sep 2025 07:01:36 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9904/</guid>
      <description>Deploying machine learning models poses unique challenges, especially with fluctuating traffic levels. Traditional autoscaling methods often fall short, leading to inefficiencies. This article discusses setting up KServe autoscaling using vLLM and KEDA. This approach focuses on application-specific metrics, enabling efficient scaling tailored to AI workload demands. Learn about the process, including exposing metrics to Prometheus and configuring KEDA for optimal performance. üåêüìà&amp;hellip;</description>
    </item>
    <item>
      <title>How I used Cursor AI to migrate a Bash test suite to Python</title>
      <link>/articles/article-2025-09-23-9905/</link>
      <pubDate>Tue, 23 Sep 2025 07:01:33 +0000</pubDate>
      <guid>/articles/article-2025-09-23-9905/</guid>
      <description>üöÄ Migrating code can be tough, but Cursor AI simplifies the process! Our team transitioned a Bash test suite to Python using the Cursor AI code editor. After installing and logging in, we enabled specific AI models to assist with the migration. Cursor helped analyze the Bash scripts, generated a Python library, and created basic tests automatically. The result? A significant time-saving of about 1.5 months! For a detailed look at the process, check our documentation. #CodeMigration #CursorAI&amp;hellip;</description>
    </item>
    <item>
      <title>Install Python 3.13 on Red Hat Enterprise Linux from EPEL</title>
      <link>/articles/article-2025-09-22-9860/</link>
      <pubDate>Mon, 22 Sep 2025 07:01:15 +0000</pubDate>
      <guid>/articles/article-2025-09-22-9860/</guid>
      <description>üì£ Exciting news for developers! Python 3.13 is now available in the EPEL repository for Red Hat Enterprise Linux (RHEL) 9 and 10. This allows users to access the latest Python features seamlessly. To install, ensure the EPEL repository is enabled and run: &lt;code&gt;sudo dnf install python3.13&lt;/code&gt; Verify the installation with: &lt;code&gt;python3.13 --version&lt;/code&gt; For project management, consider using virtual environments to isolate dependencies. Learn more about how EPEL supports software availability while&amp;hellip;</description>
    </item>
    <item>
      <title>Zero trust automation on AWS with Ansible and Terraform</title>
      <link>/articles/article-2025-09-22-9861/</link>
      <pubDate>Mon, 22 Sep 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-09-22-9861/</guid>
      <description>üöÄ Exciting advancements in cloud automation! The latest blog post discusses the Red Hat Ansible Certified Content Collection for amazon.aws 10.0.0. It highlights the amazon.aws.aws_ssm connection plug-in that enhances security by eliminating SSH access and public IPs. Key features include: - Secure provisioning of EC2 instances using Terraform - Management of tasks via Ansible over SSM - Dynamic inventory for automated resource discovery This approach supports zero trust networking and&amp;hellip;</description>
    </item>
    <item>
      <title>Cloud bursting with confidential containers on OpenShift</title>
      <link>/articles/article-2025-09-18-9763/</link>
      <pubDate>Thu, 18 Sep 2025 07:00:58 +0000</pubDate>
      <guid>/articles/article-2025-09-18-9763/</guid>
      <description>üöÄ Cloud bursting enhances on-premises applications by extending them to the cloud during peak demand. üîí Secure connectivity ensures that cloud resources can access on-premises data seamlessly. Confidential computing adds a layer of security, protecting sensitive information even in untrusted environments. üõ†Ô∏è This article details how to set up a cloud-bursting scenario from an OpenShift cluster to Azure using confidential containers and OpenVPN. #CloudBursting #OpenShift #ConfidentialComputing&amp;hellip;</description>
    </item>
    <item>
      <title>Reach native speed with MacOS llama.cpp container inference</title>
      <link>/articles/article-2025-09-18-9764/</link>
      <pubDate>Thu, 18 Sep 2025 07:00:55 +0000</pubDate>
      <guid>/articles/article-2025-09-18-9764/</guid>
      <description>üöÄ New advancements in GPU acceleration for AI inference on macOS! Recent developments showcase how llama.cpp now achieves native speed performance in most use cases. By leveraging a thin virtualization layer, containers can run efficiently on macOS. This enhancement utilizes the API remoting architecture, allowing optimized GPU access in virtualized environments. Key components include ggml-remoting and libkrun&amp;rsquo;s virtio-gpu, which enable seamless communication between the virtual machine and&amp;hellip;</description>
    </item>
    <item>
      <title>A deep dive into Apache Kafka&#39;s KRaft protocol</title>
      <link>/articles/article-2025-09-17-9720/</link>
      <pubDate>Wed, 17 Sep 2025 12:33:25 +0000</pubDate>
      <guid>/articles/article-2025-09-17-9720/</guid>
      <description>üöÄ Dive into the KRaft protocol of Apache Kafka! This article explores the key concepts and implementation of KRaft in version 4.1.0. It highlights how KRaft simplifies Kafka operations by eliminating the need for ZooKeeper and addressing scalability and consistency issues. The guide covers important elements like consensus algorithms, leader election, log replication, and safety rules essential for distributed systems. Developers and engineers looking to enhance their understanding will find&amp;hellip;</description>
    </item>
    <item>
      <title>Staying ahead of artificial intelligence threats</title>
      <link>/articles/article-2025-09-17-9715/</link>
      <pubDate>Wed, 17 Sep 2025 07:01:06 +0000</pubDate>
      <guid>/articles/article-2025-09-17-9715/</guid>
      <description>üöÄ In 2024, over 40,000 Common Vulnerabilities and Exposures (CVEs) were reported, marking a 38% rise from 2023. The trend of increasing CVEs is expected to continue into 2025, with projections of up to 58,956 new CVEs. üîí Kernel live patching has emerged as a crucial practice for applying security updates without downtime. This allows OpenStack Services on OpenShift users to maintain system integrity while minimizing interruptions. üñ•Ô∏è For more details, check out the article on kernel live&amp;hellip;</description>
    </item>
    <item>
      <title>Strengthen privacy and security with encrypted DNS in RHEL</title>
      <link>/articles/article-2025-09-17-9716/</link>
      <pubDate>Wed, 17 Sep 2025 07:01:03 +0000</pubDate>
      <guid>/articles/article-2025-09-17-9716/</guid>
      <description>üîí In today&amp;rsquo;s digital world, securing DNS traffic is crucial. Unencrypted DNS queries can expose sensitive information to eavesdroppers, leading to potential data breaches. üîç Encrypted DNS, particularly DNS over TLS (DoT), is now available in Red Hat Enterprise Linux 10 and 9.6. This advancement strengthens network security by ensuring that DNS queries are kept private and verifiable. üõ†Ô∏è The article provides a step-by-step guide for implementing encrypted DNS to improve system security during&amp;hellip;</description>
    </item>
    <item>
      <title>How to enable Ansible Lightspeed intelligent assistant</title>
      <link>/articles/article-2025-09-16-9674/</link>
      <pubDate>Tue, 16 Sep 2025 07:00:56 +0000</pubDate>
      <guid>/articles/article-2025-09-16-9674/</guid>
      <description>üöÄ Discover the Red Hat Ansible Lightspeed intelligent assistant in the latest Red Hat Ansible Automation Platform 2.6! This integrated chatbot utilizes various inference backends and can be deployed with Red Hat OpenShift AI. The article provides a step-by-step guide for installing OpenShift AI and setting up an inference service on the same cluster. Key topics include: - Installing OpenShift AI - Deploying an Inference Service - Configuring Ansible Lightspeed Stay tuned for more insights in&amp;hellip;</description>
    </item>
    <item>
      <title>Why some agentic AI developers are moving code from Python to Rust</title>
      <link>/articles/article-2025-09-15-9636/</link>
      <pubDate>Mon, 15 Sep 2025 07:00:53 +0000</pubDate>
      <guid>/articles/article-2025-09-15-9636/</guid>
      <description>AI developers are exploring a shift from Python to Rust for agentic AI solutions. While Python is popular for its simplicity and rich libraries, its Global Interpreter Lock (GIL) limits performance in CPU-bound tasks, especially as systems scale from 5 to 500 agents. Rust offers a solution with better concurrency and scalability, allowing more efficient handling of multiple agents and CPU-intensive tasks. Developers are finding that a hybrid approach‚Äîprototyping in Python and optimizing with&amp;hellip;</description>
    </item>
    <item>
      <title>Confidential VMs: The core of confidential containers</title>
      <link>/articles/article-2025-09-15-9637/</link>
      <pubDate>Mon, 15 Sep 2025 07:00:51 +0000</pubDate>
      <guid>/articles/article-2025-09-15-9637/</guid>
      <description>üîç Discover the essentials of Confidential Virtual Machines (CVMs) and their role in enhancing the security of confidential containers (CoCo). CVMs utilize hardware and software to ensure data confidentiality, isolating workloads from the host environment. This integration with Red Hat Enterprise Linux (RHEL) and OpenShift boosts security standards for data in use. üõ°Ô∏è Learn about features like Unified Kernel Images (UKI) and remote attestation that enhance the protection of workloads&amp;hellip;.</description>
    </item>
    <item>
      <title>Benchmarking with GuideLLM in air-gapped OpenShift clusters</title>
      <link>/articles/article-2025-09-15-9638/</link>
      <pubDate>Mon, 15 Sep 2025 07:00:48 +0000</pubDate>
      <guid>/articles/article-2025-09-15-9638/</guid>
      <description>Deploying and benchmarking large language models (LLMs) in air-gapped environments is vital for regulated enterprises. This article details the process of using the Red Hat AI Inference Server with vLLM and GuideLLM for performance evaluation within a disconnected OpenShift cluster. Key components include prebuilt container images, Persistent Volume Claims (PVCs), and OpenShift-native Job resources. GuideLLM, an open-source tool, provides metrics like token throughput and latency, ensuring&amp;hellip;</description>
    </item>
    <item>
      <title>Run Qwen3-Next on vLLM with Red Hat AI: A step-by-step guide</title>
      <link>/articles/article-2025-09-12-9624/</link>
      <pubDate>Fri, 12 Sep 2025 22:59:57 +0000</pubDate>
      <guid>/articles/article-2025-09-12-9624/</guid>
      <description>üöÄ Exciting news in AI! The Qwen3-Next model features a new hybrid attention and sparse MoE architecture, enhancing training efficiency and inference speed. üîß With Day 0 support from vLLM, organizations can deploy it immediately using Red Hat AI for secure and scalable solutions. üìä Key improvements include multi-token prediction and optimized training stability. For a step-by-step guide on deployment, check the latest blog! #AI #RedHat #OpenSource #MachineLearning #Qwen3Next</description>
    </item>
    <item>
      <title>How to implement observability with Python and Llama Stack</title>
      <link>/articles/article-2025-09-12-9602/</link>
      <pubDate>Fri, 12 Sep 2025 07:01:14 +0000</pubDate>
      <guid>/articles/article-2025-09-12-9602/</guid>
      <description>Discover how to enhance AI application observability using Python and Llama Stack! üöÄ This article highlights the importance of observability in production, focusing on logging, metrics, and distributed tracing. It introduces OpenTelemetry as a key tool for instrumenting applications and discusses setting up Jaeger for trace visualization. Explore the detailed steps for implementing observability, including configuring your Llama Stack instance to capture and visualize traces effectively&amp;hellip;.</description>
    </item>
    <item>
      <title>Deploy a lightweight AI model with AI Inference Server containerization</title>
      <link>/articles/article-2025-09-12-9603/</link>
      <pubDate>Fri, 12 Sep 2025 07:01:11 +0000</pubDate>
      <guid>/articles/article-2025-09-12-9603/</guid>
      <description>üöÄ Ready to explore AI? This tutorial provides a step-by-step guide to deploy a lightweight AI model, Llama-3.2-1B, using the Red Hat AI Inference Server. It‚Äôs designed for quick testing on personal machines with local GPUs. üîß You&amp;rsquo;ll need a valid Red Hat account and a compatible GPU. The tutorial covers everything from logging in to the Red Hat container registry to running the model with minimal setup. For more details, check out the tutorial! #AI #RedHat #MachineLearning #Containerization&amp;hellip;</description>
    </item>
    <item>
      <title>vLLM Semantic Router: Improving efficiency in AI reasoning</title>
      <link>/articles/article-2025-09-11-9544/</link>
      <pubDate>Thu, 11 Sep 2025 07:01:00 +0000</pubDate>
      <guid>/articles/article-2025-09-11-9544/</guid>
      <description>Introducing the vLLM Semantic Router, an open-source solution for enhancing efficiency in AI reasoning. üéâ This system intelligently routes queries based on their complexity, ensuring that resources are used wisely. It utilizes a ModernBERT-based classifier for semantic classification, sending simpler requests to faster models and more complex ones to stronger models. Key benefits include improved accuracy (+10.2%), reduced latency (‚Äì47.1%), and decreased token usage (‚Äì48.5%). This approach&amp;hellip;</description>
    </item>
    <item>
      <title>Declaratively assigning DNS records to virtual machines</title>
      <link>/articles/article-2025-09-11-9545/</link>
      <pubDate>Thu, 11 Sep 2025 07:00:57 +0000</pubDate>
      <guid>/articles/article-2025-09-11-9545/</guid>
      <description>üîç Virtual machines often require DNS records to maintain unique identities. This article discusses how to declaratively assign these records using Red Hat OpenShift Virtualization. üìä It highlights the importance of naming conventions and provides methods to automate DNS record assignments via labels and annotations. üîß Key considerations include network exposure, IP assignment, and managing multiple DNS records for diverse network interfaces. #VirtualMachines #DNSManagement #OpenShift #GitOps&amp;hellip;</description>
    </item>
    <item>
      <title>How to deploy language models with Red Hat OpenShift AI</title>
      <link>/articles/article-2025-09-10-9507/</link>
      <pubDate>Wed, 10 Sep 2025 07:00:55 +0000</pubDate>
      <guid>/articles/article-2025-09-10-9507/</guid>
      <description>üöÄ Red Hat OpenShift AI is transforming the deployment of language models! This guide explores the OpenShift AI console, your hub for managing data science projects. You can easily deploy models like Llama, leveraging GPU acceleration and resource scaling. Key features include project dashboards, model tracking, and multiple storage options. Check out the step-by-step deployment process for Llama, from GPU setup to testing both internal and external access. üîó Watch the full video demo for a&amp;hellip;</description>
    </item>
    <item>
      <title>AI search with style: Fashion on OpenShift AI with EDB</title>
      <link>/articles/article-2025-09-10-9508/</link>
      <pubDate>Wed, 10 Sep 2025 07:00:53 +0000</pubDate>
      <guid>/articles/article-2025-09-10-9508/</guid>
      <description>Unlocking fashion e-commerce with AI! üõçÔ∏è‚ú® Traditional keyword searches often miss the mark in understanding customers&amp;rsquo; true intent. This article highlights a solution using semantic search, which captures meaning and intent in fashion searches. EDB Postgres AI and Red Hat OpenShift AI work together to process AI data, enabling seamless visual and text searches. Users can upload images or describe items without needing exact terms. This innovative approach not only enhances search accuracy but&amp;hellip;</description>
    </item>
    <item>
      <title>What qualifies for Red Hat Developer Subscription for Teams?</title>
      <link>/articles/article-2025-09-09-9464/</link>
      <pubDate>Tue, 09 Sep 2025 14:00:00 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9464/</guid>
      <description>Unlock development potential with the Red Hat Developer Subscription for Teams! üöÄ This program provides organizations using Red Hat technologies free access to Red Hat Enterprise Linux for development activities. It&amp;rsquo;s available via Red Hat representatives or self-service at developers.redhat.com. Key activities covered include software design, coding, building, testing, and pre-production setups. The subscription supports efficient application development and deployment. For more details,&amp;hellip;</description>
    </item>
    <item>
      <title>How to run OpenAI&#39;s gpt-oss models locally with RamaLama</title>
      <link>/articles/article-2025-09-09-9444/</link>
      <pubDate>Tue, 09 Sep 2025 07:01:03 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9444/</guid>
      <description>Unlock the power of OpenAI&amp;rsquo;s gpt-oss models locally with RamaLama! üñ•Ô∏è These models, available in 20B and 120B variants, enable advanced AI capabilities right on your machine. RamaLama simplifies the setup process using containerization for security and ease. üöÄ Key features include zero trust security and automatic GPU optimization. Get started easily with just a single command. Explore more about running AI models in a secure, efficient manner! üîí‚ú® #OpenAI #AIModels #RamaLama #MachineLearning&amp;hellip;</description>
    </item>
    <item>
      <title>Using DNS over TLS in OpenShift to secure communications</title>
      <link>/articles/article-2025-09-09-9445/</link>
      <pubDate>Tue, 09 Sep 2025 07:01:00 +0000</pubDate>
      <guid>/articles/article-2025-09-09-9445/</guid>
      <description>üîí Secure your DNS traffic in Red Hat OpenShift with DNS over TLS (DoT). This feature enhances security by ensuring all DNS communications are encrypted, aligning with zero trust architecture principles. üõ†Ô∏è The recent RHEL 10 release introduces encrypted DNS, allowing DoT during installation and runtime. While currently a Technology Preview in Identity Management (IdM), it lays the groundwork for secure operations. üîç Explore installation steps for IdM and OpenShift, including configuring DNS&amp;hellip;</description>
    </item>
    <item>
      <title>Scaling DeepSeek and Sparse MoE models in vLLM with llm-d</title>
      <link>/articles/article-2025-09-08-9429/</link>
      <pubDate>Mon, 08 Sep 2025 14:02:38 +0000</pubDate>
      <guid>/articles/article-2025-09-08-9429/</guid>
      <description>üöÄ Exciting advancements in scaling Mixture of Experts (MoE) models with vLLM and the llm-d project are transforming open-source LLM capabilities. üåê This article discusses innovations like multi-head latent attention and sparse configurations, enabling efficient deployment in Kubernetes. Learn how vLLM enhances expert parallelism and communication for large models. For detailed insights, check the full article! üìä #MachineLearning #AI #Kubernetes #DeepLearning #OpenSource</description>
    </item>
    <item>
      <title>Scaling DeepSeek-style MoEs with vLLM and llm-d using Wide EP</title>
      <link>/articles/article-2025-09-08-9551/</link>
      <pubDate>Mon, 08 Sep 2025 14:02:38 +0000</pubDate>
      <guid>/articles/article-2025-09-08-9551/</guid>
      <description>üîç Exciting advancements in serving large-scale Mixture of Experts (MoE) language models are discussed in a recent article on vLLM and llm-d. The article covers the architectural changes in vLLM that enhance the efficiency of DeepSeek-style models. Key innovations include multi-head latent attention and sparse configurations with hundreds of experts. llm-d enables high-performance deployments in Kubernetes, offering intelligent scheduling and expert parallelism for efficient scaling. Learn&amp;hellip;</description>
    </item>
    <item>
      <title>Multicluster authentication with Ansible Automation Platform</title>
      <link>/articles/article-2025-09-08-9394/</link>
      <pubDate>Mon, 08 Sep 2025 07:00:54 +0000</pubDate>
      <guid>/articles/article-2025-09-08-9394/</guid>
      <description>Implementing multicluster authentication between Red Hat Ansible Automation Platform and Red Hat Advanced Cluster Management can enhance security and streamline operations. This integration allows for centralized authentication, reducing credential proliferation. Key features include dynamic token management and network security via Cluster Proxy. For successful implementation, ensure both ManagedServiceAccount and Cluster Proxy are enabled in your setup. Access detailed steps and best&amp;hellip;</description>
    </item>
    <item>
      <title>Verify Cosign bring-your-own PKI signature on OpenShift</title>
      <link>/articles/article-2025-09-08-9395/</link>
      <pubDate>Mon, 08 Sep 2025 07:00:51 +0000</pubDate>
      <guid>/articles/article-2025-09-08-9395/</guid>
      <description>üöÄ Red Hat OpenShift 4.16 introduces ClusterImagePolicy and ImagePolicy for sigstore verification. These tech preview features support Fulcio CA and public key policies. üîç The bring-your-own PKI (BYO-PKI) feature, available from OpenShift 4.19, allows validation of container images using existing X.509 certificates. üîß The article outlines how to sign images with Cosign and configure OpenShift for signature verification using ClusterImagePolicy. #OpenShift #Cosign #BYOPKI #ContainerSecurity&amp;hellip;</description>
    </item>
    <item>
      <title>What&#39;s new in network observability 1.9</title>
      <link>/articles/article-2025-09-05-7761/</link>
      <pubDate>Fri, 05 Sep 2025 07:01:17 +0000</pubDate>
      <guid>/articles/article-2025-09-05-7761/</guid>
      <description>üöÄ Exciting updates in Network Observability 1.9! This version enhances insights into network traffic with features like IPsec tracking, flowlogs-pipeline filter queries, and UDN mapping. It is compatible with Red Hat OpenShift Container Platform 4.19 and older releases. Learn how to enable IPsec and explore the new CLI enhancements for capturing flows, metrics, and packets. For detailed installation instructions, refer to the OpenShift documentation. üìäüîç #NetworkObservability #RedHat&amp;hellip;</description>
    </item>
    <item>
      <title>Customize your deployments with the Red Hat Developer Hub Operator</title>
      <link>/articles/article-2025-09-04-7736/</link>
      <pubDate>Thu, 04 Sep 2025 16:53:23 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7736/</guid>
      <description>üöÄ The Red Hat Developer Hub enhances internal developer portals when paired with Red Hat OpenShift. Key updates in version 1.2 include: - A new Argo CD front-end plug-in for better UX. - Enhanced orchestration capabilities for software templates. - Improved provenance tracking through ScaffoldedFrom metadata. Deployment is streamlined using the Red Hat Developer Hub Operator. Access your Backstage instance easily with the provided route. For detailed customization, a Backstage custom resource&amp;hellip;</description>
    </item>
    <item>
      <title>How to migrate from Fluentd to Vector in OpenShift 4</title>
      <link>/articles/article-2025-09-04-7703/</link>
      <pubDate>Thu, 04 Sep 2025 07:01:18 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7703/</guid>
      <description>üîÑ &lt;strong&gt;Migrating from Fluentd to Vector in OpenShift 4&lt;/strong&gt; üîÑ This article provides a comprehensive guide for migrating the default log collector in OpenShift 4 from Fluentd to Vector. With Fluentd being deprecated in Logging 5.X, this transition is essential to access the new features in Logging 6.0. Vector serves as a log collector and analyzer, simplifying the processing of logs for real-time analysis. It allows logs to be sent to destinations like Amazon CloudWatch and supports JSON formatted&amp;hellip;</description>
    </item>
    <item>
      <title>How platform engineering accelerates enterprise AI adoption</title>
      <link>/articles/article-2025-09-04-7704/</link>
      <pubDate>Thu, 04 Sep 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7704/</guid>
      <description>üöÄ Platform engineering is reshaping enterprise AI adoption. By integrating technologies like Kafka and service mesh, organizations can enhance AI deployments. üîç Key challenges include reproducibility and compliance. Platform engineering addresses these by providing self-service access and standardized environments, enabling developers and data scientists to innovate efficiently. üíª Red Hat OpenShift and Developer Hub are pivotal in making AI resources accessible while ensuring governance. #AI&amp;hellip;</description>
    </item>
    <item>
      <title>How to deploy Azure Red Hat OpenShift using Terraform</title>
      <link>/articles/article-2025-09-04-7705/</link>
      <pubDate>Thu, 04 Sep 2025 07:01:13 +0000</pubDate>
      <guid>/articles/article-2025-09-04-7705/</guid>
      <description>üöÄ Learn how to deploy Azure Red Hat OpenShift using Terraform! This article covers the steps to set up and configure your Azure infrastructure with Terraform, ensuring compliance using Azure policies. It emphasizes the importance of governance rules and the use of policy-as-code for better resource management. Key prerequisites include Terraform CLI, Azure CLI, and proper role assignments. The setup involves creating a network, configuring security, and deploying the OpenShift cluster with&amp;hellip;</description>
    </item>
    <item>
      <title>Effective observability with Red Hat build of OpenTelemetry</title>
      <link>/articles/article-2025-09-03-7652/</link>
      <pubDate>Wed, 03 Sep 2025 07:01:17 +0000</pubDate>
      <guid>/articles/article-2025-09-03-7652/</guid>
      <description>üöÄ Discover the power of observability with the Red Hat build of OpenTelemetry! This framework enables comprehensive metrics and logs reporting, crucial for monitoring your applications and infrastructure. It simplifies data collection and management while providing scalability and flexibility. Key features include: - Unified data collection - Seamless integration with monitoring tools - Enterprise-grade support from Red Hat Explore how to get started and enhance your observability practices!&amp;hellip;</description>
    </item>
    <item>
      <title>vLLM with torch.compile: Efficient LLM inference on PyTorch</title>
      <link>/articles/article-2025-09-03-7653/</link>
      <pubDate>Wed, 03 Sep 2025 07:01:11 +0000</pubDate>
      <guid>/articles/article-2025-09-03-7653/</guid>
      <description>üöÄ Efficient LLM inference is crucial in today‚Äôs diverse tech landscape. The article discusses how &lt;strong&gt;torch.compile&lt;/strong&gt;, PyTorch&amp;rsquo;s JIT compiler, streamlines performance by automatically optimizing kernels. This reduces the burden on developers, allowing them to focus on model design rather than manual tuning. Incorporated into &lt;strong&gt;vLLM&lt;/strong&gt;, torch.compile enhances usability and performance through custom compiler passes. It supports dynamic batch sizes and improves startup times with caching&amp;hellip;</description>
    </item>
    <item>
      <title>Your LLM is too large: How I generate production-ready failure analysis on a toaster</title>
      <link>/articles/article-2025-09-02-7602/</link>
      <pubDate>Tue, 02 Sep 2025 07:00:53 +0000</pubDate>
      <guid>/articles/article-2025-09-02-7602/</guid>
      <description>Running production-grade Kubernetes failure analysis on a cost-effective edge device can streamline troubleshooting. Using Llama 3.2:3B with 4-bit quantization, root cause analysis is achieved in just 70 seconds. This method incorporates pattern preprocessing to efficiently identify known failures without overwhelming the system with raw logs. Real-world results show a significant cost reduction, from $0.30-3.00 per analysis to less than $0.001, while providing actionable insights. Explore&amp;hellip;</description>
    </item>
    <item>
      <title>Migrate your OpenShift logging stack from Elasticsearch to Loki</title>
      <link>/articles/article-2025-09-01-7578/</link>
      <pubDate>Mon, 01 Sep 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-09-01-7578/</guid>
      <description>üöÄ To leverage the latest logging features in Red Hat OpenShift 6.0, migrating from Elasticsearch to Loki is essential. This guide details how to test changes in development and plan for production implementations. Loki, a scalable log aggregation system, offers improved performance by using log labels. It allows multiple tenants, which simplifies resource management. üîÑ The migration process involves running both stacks in parallel, ensuring old logs remain accessible via Elasticsearch while&amp;hellip;</description>
    </item>
    <item>
      <title>Migrating Ansible Automation Platform 2.4 to 2.5</title>
      <link>/articles/article-2025-08-29-7509/</link>
      <pubDate>Fri, 29 Aug 2025 07:01:20 +0000</pubDate>
      <guid>/articles/article-2025-08-29-7509/</guid>
      <description>üöÄ Migrating from Ansible Automation Platform 2.4 to 2.5 involves careful steps to ensure a smooth transition. This article outlines the preparation, export, and import process using the configify.aapconfig collection. Key points include: - Ensure Ansible Automation Platform 2.5 is deployed separately. - Follow similar steps as migrating from AWX 25. - Focus on user roles and authentication changes in the new version. For detailed steps, refer to the article! üìú #Ansible #Automation #DevOps&amp;hellip;</description>
    </item>
    <item>
      <title>Multicluster resiliency with global load balancing and mesh federation</title>
      <link>/articles/article-2025-08-28-7451/</link>
      <pubDate>Thu, 28 Aug 2025 07:01:21 +0000</pubDate>
      <guid>/articles/article-2025-08-28-7451/</guid>
      <description>Explore the new architecture for multicluster resiliency using global load balancing and mesh federation! üåê This approach combines a global load balancer and a federated service mesh to enhance service availability and disaster recovery, particularly for stateless workloads. New capabilities in Red Hat OpenShift Service Mesh 3.0 and Red Hat Connectivity Link now allow for more robust deployments. Learn how to configure these tools for optimal performance! #Multicluster #RedHat #CloudComputing&amp;hellip;</description>
    </item>
    <item>
      <title>Simplify local prototyping with Camel JBang infrastructure</title>
      <link>/articles/article-2025-08-28-7452/</link>
      <pubDate>Thu, 28 Aug 2025 07:01:18 +0000</pubDate>
      <guid>/articles/article-2025-08-28-7452/</guid>
      <description>üöÄ Apache Camel simplifies integration with systems like databases and APIs through minimal coding. üåü Camel JBang, a command-line interface, enhances prototyping by allowing rapid creation and testing of integration flows without complex setups. üîß Its infra command quickly launches backends like Kafka or ActiveMQ, streamlining the development process and reducing setup time. For more details, check out the full article! #ApacheCamel #CamelJBang #Integration #Development #Prototyping</description>
    </item>
    <item>
      <title>Smart deployments at scale: Leveraging ApplicationSets and Helm with cluster labels in Red Hat Advanced Cluster Management for Kubernetes</title>
      <link>/articles/article-2025-08-27-7203/</link>
      <pubDate>Wed, 27 Aug 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7203/</guid>
      <description>Managing multiple Kubernetes clusters can be complex, but Red Hat Advanced Cluster Management simplifies this process. üåê It offers a centralized platform to oversee the entire lifecycle of Kubernetes clusters, ensuring consistent health monitoring and policy enforcement across environments. Combining ApplicationSets and Helm with cluster labels allows for tailored deployments, adapting configurations based on specific cluster characteristics. This integration streamlines operations and&amp;hellip;</description>
    </item>
    <item>
      <title>How to verify container signatures in disconnected OpenShift</title>
      <link>/articles/article-2025-08-27-7204/</link>
      <pubDate>Wed, 27 Aug 2025 07:01:15 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7204/</guid>
      <description>üîç Discover how to verify container signatures in disconnected OpenShift environments using the latest tools from sigstore! The article explores the use of oc-mirror v2 in Red Hat OpenShift 4.19, allowing mirroring of container images and their cryptographic signatures. It provides a proof of concept and detailed configuration steps for enabling signature verification with CoSign. Check it out for practical insights! üõ†Ô∏èüîí #OpenShift #ContainerSecurity #Sigstore #RedHat #DevOps</description>
    </item>
    <item>
      <title>Event-driven ingestion of Keycloak entities</title>
      <link>/articles/article-2025-08-27-7205/</link>
      <pubDate>Wed, 27 Aug 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7205/</guid>
      <description>üöÄ Discover a solution to delayed updates in entity information with the Backstage Events System! This article details a Proof of Concept (PoC) that enables near real-time synchronization of Keycloak entities into Red Hat Developer Hub (RHDH). Key benefits include immediate updates and efficient, incremental syncing, reducing API calls and CPU usage. Learn how to set up the PoC and optimize your developer catalog! üîó Check out the PoC code: [GitHub Link] #Keycloak #RedHat #EventDriven&amp;hellip;</description>
    </item>
    <item>
      <title>BGP dynamic routing with Fast Data Path on RHOSO 18</title>
      <link>/articles/article-2025-08-27-7206/</link>
      <pubDate>Wed, 27 Aug 2025 07:01:08 +0000</pubDate>
      <guid>/articles/article-2025-08-27-7206/</guid>
      <description>Exploring the performance of dynamic routing with OVN-BGP-Agent and Fast Data Path on RHOSO 18 has yielded insightful findings. üöÄ A recent Proof of Concept assessed throughput, packet loss, stability, and resource utilization using Trex and BIRD. The results show high throughput, especially with large frames, and stable performance over extended periods. üìà However, there are limitations, including bottlenecks for small packets and some manual configuration challenges. Insights from this study&amp;hellip;</description>
    </item>
    <item>
      <title>A VM tuning case study: Balancing power and performance on AMD processors</title>
      <link>/articles/article-2025-08-26-7173/</link>
      <pubDate>Tue, 26 Aug 2025 07:01:25 +0000</pubDate>
      <guid>/articles/article-2025-08-26-7173/</guid>
      <description>During a server deployment, a significant performance gap was found between bare metal and virtual machine (VM) workloads. Optimizations, including adjusting system profiles and enabling CPU scaling drivers, were implemented. These changes resulted in notable improvements in VM performance, with the tuned VM even surpassing the original bare-metal completion times. The study highlights how targeted adjustments can lead to substantial gains in efficiency. üîßüíª‚ö°Ô∏è #VMTuning&amp;hellip;</description>
    </item>
    <item>
      <title>Optimize GPU utilization with Kueue and KEDA</title>
      <link>/articles/article-2025-08-26-7174/</link>
      <pubDate>Tue, 26 Aug 2025 07:01:23 +0000</pubDate>
      <guid>/articles/article-2025-08-26-7174/</guid>
      <description>Explore how integrating Kueue and KEDA can optimize GPU utilization in AI workloads! üöÄ This proof of concept showcases a method to enhance resource efficiency on OpenShift AI. The combination allows scaling long-running workloads to zero when idle, reducing costs significantly. Learn how to implement this strategy with a focus on resource management and effective workload scheduling. üìäüíª #AI #GPUUtilization #OpenShift #Kubernetes #CloudComputing</description>
    </item>
    <item>
      <title>Implement AI safeguards with Python and Llama Stack</title>
      <link>/articles/article-2025-08-26-7175/</link>
      <pubDate>Tue, 26 Aug 2025 07:01:20 +0000</pubDate>
      <guid>/articles/article-2025-08-26-7175/</guid>
      <description>üöÄ Exploring AI safety with Llama Stack! This article highlights how to implement guardrails in AI applications using Python and Llama Stack. It introduces two main built-in guardrails: Llama Guard, which filters unsafe content, and Prompt Guard, designed to prevent circumvention of safety measures. The post provides insights into setting up Llama Stack and utilizing these guardrails effectively in Python. #AI #LlamaStack #Python #MachineLearning #AIsafety</description>
    </item>
    <item>
      <title>LLM Compressor 0.7.0 release recap</title>
      <link>/articles/article-2025-08-25-6534/</link>
      <pubDate>Mon, 25 Aug 2025 16:09:49 +0000</pubDate>
      <guid>/articles/article-2025-08-25-6534/</guid>
      <description>üöÄ LLM Compressor has released version 0.7.0, enhancing performance for quantizing large language models. Key updates include: 1Ô∏è‚É£ New QuIP and SpinQuant-style transforms for improved accuracy. 2Ô∏è‚É£ Mixed-precision support with FP4 enhancements for better layer quantization. 3Ô∏è‚É£ DeepSeek v3-style block quantization for efficient compression without calibration data. Explore more about these features! #LLMCompressor #AI #MachineLearning #Quantization #TechUpdate</description>
    </item>
    <item>
      <title>What is an image mode 3-way merge?</title>
      <link>/articles/article-2025-08-25-6331/</link>
      <pubDate>Mon, 25 Aug 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-08-25-6331/</guid>
      <description>üîç Curious about the 3-way merge in Red Hat Enterprise Linux (RHEL)? In image mode, a new filesystem image is created to manage updates. This process includes a third version, older than the current and new images, to reduce conflicts. The merge prioritizes local changes, ensuring personalized settings remain intact. Utilizing OSTree, RHEL manages multiple OS installations effectively, making the merging process smoother. üñ•Ô∏è‚ú® #RedHat #Linux #3WayMerge #OSTree #TechUpdates</description>
    </item>
    <item>
      <title>Least-privilege installation of OpenShift IPI on AWS</title>
      <link>/articles/article-2025-08-22-6295/</link>
      <pubDate>Fri, 22 Aug 2025 07:16:18 +0000</pubDate>
      <guid>/articles/article-2025-08-22-6295/</guid>
      <description>üîí The latest guide on installing OpenShift IPI on AWS emphasizes a secure, least-privilege approach. By using the cloud credential operator utility (ccoctl) and setting credentials mode to manual, users can create narrowly-defined IAM roles. üõ†Ô∏è This method eliminates long-lived AWS access keys, relying instead on short-term AWS STS credentials. The ccoctl &amp;ndash;dry-run feature allows for auditing IAM policies before applying them, enhancing security. üìä Key points include understanding the IAM&amp;hellip;</description>
    </item>
    <item>
      <title>Integrate Azure DevOps into Red Hat Developer Hub workflows</title>
      <link>/articles/article-2025-08-22-6296/</link>
      <pubDate>Fri, 22 Aug 2025 07:16:13 +0000</pubDate>
      <guid>/articles/article-2025-08-22-6296/</guid>
      <description>üöÄ Exciting news for developers! Integrating Azure DevOps with Red Hat Developer Hub creates a seamless CI/CD experience. Azure DevOps enhances source control and deployment, while Red Hat Developer Hub centralizes tools and documentation. Key plug-ins include Azure Scaffolder and Azure DevOps, enabling improved collaboration and faster delivery. For setup, ensure Azure Entra ID is configured and follow the detailed steps for integration. Learn more about optimizing your workflows!&amp;hellip;</description>
    </item>
    <item>
      <title>How to auto-register Red Hat Edge Manager with MicroShift</title>
      <link>/articles/article-2025-08-21-5016/</link>
      <pubDate>Thu, 21 Aug 2025 07:01:31 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5016/</guid>
      <description>üöÄ Red Hat Edge Manager, in Technology Preview, offers a fleet management solution for edge devices. It ensures security, simplifies management, and provides real-time visibility. üîß The article details how to auto-register Edge Manager with Red Hat MicroShift using Red Hat Advanced Cluster Management for Kubernetes 2.13. üìã Key steps include enabling Edge Manager, setting up the flightctl command, and configuring auto-registration. Explore how these tools can enhance your edge device&amp;hellip;</description>
    </item>
    <item>
      <title>The hidden pitfalls of Kafka tiered storage</title>
      <link>/articles/article-2025-08-21-5019/</link>
      <pubDate>Thu, 21 Aug 2025 07:01:29 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5019/</guid>
      <description>üöÄ Apache Kafka 3.9.0 introduces tiered storage for improved long-term data retention and cost efficiency. This feature allows independent scaling of compute and storage resources, leading to better client isolation. However, challenges remain in reading remote data. The article outlines two key problems and offers solutions, emphasizing important configurations like &lt;code&gt;fetch.max.bytes&lt;/code&gt; and &lt;code&gt;max.partition.fetch.bytes&lt;/code&gt;. Kafka 4.2.0 promises improvements to address these issues, enhancing&amp;hellip;</description>
    </item>
    <item>
      <title>Unleash controlled chaos with krknctl</title>
      <link>/articles/article-2025-08-21-5020/</link>
      <pubDate>Thu, 21 Aug 2025 07:01:25 +0000</pubDate>
      <guid>/articles/article-2025-08-21-5020/</guid>
      <description>Unleash the power of chaos engineering with &lt;strong&gt;krknctl&lt;/strong&gt;! üéâ This command-line interface simplifies testing system resilience by orchestrating chaos scenarios using container images from krkn-hub. Key features include instant autocompletion, dynamic graph orchestration, and versatile container support with Podman or Docker. With pre-compiled binaries available, you can start your chaos engineering journey in minutes. Discover more and elevate your systems today! üîçüíª #ChaosEngineering #DevOps&amp;hellip;</description>
    </item>
    <item>
      <title>Your agent, your rules: A deep dive into the Responses API with Llama Stack</title>
      <link>/articles/article-2025-08-20-5021/</link>
      <pubDate>Wed, 20 Aug 2025 07:01:24 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5021/</guid>
      <description>üîç The OpenAI Responses API simplifies AI application development by managing complex orchestration. However, it is tied to specific models and a proprietary cloud service. Enter Llama Stack, an open-source server that offers a compatible Responses API and lets you deploy on your hardware with your chosen models. It supports advanced features like Retrieval-augmented Generation (RAG) for accurate answers without compromising document privacy. Explore how Llama Stack can transform your AI&amp;hellip;</description>
    </item>
    <item>
      <title>Build a container image for a Quarkus project using Buildpacks</title>
      <link>/articles/article-2025-08-20-5024/</link>
      <pubDate>Wed, 20 Aug 2025 07:01:22 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5024/</guid>
      <description>üöÄ Learn how to build container images for your Quarkus projects using the Container Image Buildpack extension! This method eliminates the need for a Dockerfile, streamlining your CI/CD workflow. üîß The extension leverages the Java Buildpack Client to simplify application deployment in Kubernetes. Ensure you have Podman/Docker, JDK 21+, and Maven 3.9+ to get started. üì¶ With just a few Maven commands, you can create, build, and push your images to container registries effortlessly. #Quarkus&amp;hellip;</description>
    </item>
    <item>
      <title>How I built an agentic application for Docling with MCP</title>
      <link>/articles/article-2025-08-20-5025/</link>
      <pubDate>Wed, 20 Aug 2025 07:01:20 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5025/</guid>
      <description>üåê Exciting developments in AI with the Model Context Protocol (MCP) from Anthropic! Released in November 2024, MCP enables large language models to communicate seamlessly with various tools. üõ†Ô∏è With thousands of open-source MCP servers available, many developers are now creating agentic applications. However, there&amp;rsquo;s still untapped potential in fully utilizing MCP‚Äôs capabilities. üìÑ My journey began during my internship at Red Hat, where I worked with Docling, an open-source data preprocessor&amp;hellip;.</description>
    </item>
    <item>
      <title>Building trustworthy AI: A developer&#39;s guide to production-ready systems</title>
      <link>/articles/article-2025-08-20-5028/</link>
      <pubDate>Wed, 20 Aug 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-08-20-5028/</guid>
      <description>üåê Building trustworthy AI is essential in today&amp;rsquo;s development landscape. As AI engineers and developers, focusing on trust, safety, and transparency is crucial for creating reliable applications. üîç AI systems should be assessed based on their potential impact, categorized into high, moderate, and minimal tiers. This impacts design choices and operational guardrails. üí° Best practices include documenting training data, testing for bias, ensuring explainability, and providing human&amp;hellip;</description>
    </item>
    <item>
      <title>Build on multi-arch clusters with builds for Red Hat OpenShift</title>
      <link>/articles/article-2025-08-19-5030/</link>
      <pubDate>Tue, 19 Aug 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-08-19-5030/</guid>
      <description>üöÄ Discover how to streamline multi-arch builds with Red Hat OpenShift! This article explains the builds for Red Hat OpenShift operator, allowing you to create a single build object for mixed architecture clusters. Key steps include installing the oc client, configuring the ClusterBuildStrategy, and verifying image builds for different architectures. Learn more about simplifying your build process! #RedHat #OpenShift #MultiArch #CloudComputing #DevOps</description>
    </item>
    <item>
      <title>How to enhance Agent2Agent (A2A) security</title>
      <link>/articles/article-2025-08-19-5032/</link>
      <pubDate>Tue, 19 Aug 2025 07:01:14 +0000</pubDate>
      <guid>/articles/article-2025-08-19-5032/</guid>
      <description>üîí The Agent2Agent (A2A) protocol by Google facilitates communication between AI agents, allowing seamless interaction across different vendors. Each agent can serve as a client or remote agent depending on the context. üåê Communication involves retrieving an Agent Card, which contains essential details for task execution. Security measures such as HTTPS and authentication protocols are crucial for protecting these interactions. üõ°Ô∏è Developers implementing A2A should remain vigilant about&amp;hellip;</description>
    </item>
    <item>
      <title>Getting started with llm-d for distributed AI inference</title>
      <link>/articles/article-2025-08-19-5035/</link>
      <pubDate>Tue, 19 Aug 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-08-19-5035/</guid>
      <description>üåê As large language models (LLMs) evolve, so must their infrastructure. Introducing &lt;strong&gt;llm-d&lt;/strong&gt;, a Kubernetes-native distributed inference stack designed to enhance AI applications. It optimizes for complex reasoning, long-running prompts, and modular scaling. Key features include smart load balancing, split-phase inference, and disaggregated caching for efficiency. This innovation addresses the unique challenges of LLM inference, making it more cost-effective and performant. Join the growing&amp;hellip;</description>
    </item>
    <item>
      <title>Manage Advanced Cluster Management policies using Ansible</title>
      <link>/articles/article-2025-08-14-4991/</link>
      <pubDate>Thu, 14 Aug 2025 07:01:15 +0000</pubDate>
      <guid>/articles/article-2025-08-14-4991/</guid>
      <description>Managing multiple Kubernetes clusters can be complex, especially with the need for consistent security and compliance. This article discusses how Red Hat Advanced Cluster Management simplifies this process through centralized management. Ansible automation enhances policy management by ensuring consistency, repeatability, and compliance across clusters. It also covers the use of the external secrets operator for secure credential management with AWS Secrets Manager. For more details, check&amp;hellip;</description>
    </item>
    <item>
      <title>Integrate vLLM inference on macOS/iOS with Alamofire and Apple Foundation</title>
      <link>/articles/article-2025-08-14-4992/</link>
      <pubDate>Thu, 14 Aug 2025 07:01:13 +0000</pubDate>
      <guid>/articles/article-2025-08-14-4992/</guid>
      <description>Unlock the potential of vLLM inference in your macOS/iOS apps! üì±üíª This article explores how to use Apple Foundation and Alamofire for seamless communication with vLLM via an OpenAI-compatible Chat Completions endpoint. It covers essential topics such as data encoding, error handling, and processing streaming results. For hands-on experience, grab the sample code from GitHub and start building! üöÄüîó #vLLM #macOS #iOSDevelopment #OpenAI #Alamofire</description>
    </item>
    <item>
      <title>Enhancing system resilience with Krkn chaos dashboard</title>
      <link>/articles/article-2025-08-14-4993/</link>
      <pubDate>Thu, 14 Aug 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-08-14-4993/</guid>
      <description>üîß In today&amp;rsquo;s digital landscape, system resilience is crucial for businesses. The Krkn chaos dashboard is an open-source tool designed to enhance Kubernetes environments by simulating failures to identify vulnerabilities. üìä The dashboard allows teams to easily design and monitor chaos experiments, providing real-time updates on system health and generating detailed reports on failures. üíª With user-friendly features, it encourages regular chaos testing, helping teams improve their system&amp;rsquo;s&amp;hellip;</description>
    </item>
    <item>
      <title>How to secure your Jenkins pipeline with Red Hat Advanced Developer Suite</title>
      <link>/articles/article-2025-08-14-4994/</link>
      <pubDate>Thu, 14 Aug 2025 07:01:08 +0000</pubDate>
      <guid>/articles/article-2025-08-14-4994/</guid>
      <description>Enhance your Jenkins pipeline security with Red Hat Advanced Developer Suite! üîí This suite integrates cryptographic signing, SBOM validation, and runtime enforcement to ensure a secure CI/CD process. Each stage‚Äîfrom commit to deployment‚Äînow includes proof of compliance. Key features include: - Trusted Artifact Signer for image signing. - Profile Analyzer for risk assessment. - Advanced Cluster Security for policy enforcement. Learn how to keep your deployment velocity while lowering risks! üöÄüîß&amp;hellip;</description>
    </item>
    <item>
      <title>How to deploy an image mode update in offline and air-gapped environments</title>
      <link>/articles/article-2025-08-13-4884/</link>
      <pubDate>Wed, 13 Aug 2025 07:01:07 +0000</pubDate>
      <guid>/articles/article-2025-08-13-4884/</guid>
      <description>Need to deploy image mode updates in offline or air-gapped environments? Red Hat Enterprise Linux offers a flexible solution that doesn&amp;rsquo;t rely on network connections. This method is ideal for security or hardware limitations. üåêüîí Key steps include preparing an external storage device, copying the necessary images, and applying updates directly to the offline system. While effective, this approach can be time-consuming and requires on-site deployment. If your system can connect online, consider&amp;hellip;</description>
    </item>
    <item>
      <title>How to install Offline Knowledge Portal on a local system</title>
      <link>/articles/article-2025-08-13-4885/</link>
      <pubDate>Wed, 13 Aug 2025 07:01:05 +0000</pubDate>
      <guid>/articles/article-2025-08-13-4885/</guid>
      <description>Unlock the Red Hat Offline Knowledge Portal for easy access to documentation and guides without an internet connection! üìöüíª To install, ensure you have a Red Hat Satellite subscription, a web browser, and enough disk space. Follow these steps: 1Ô∏è‚É£ Generate your access key. 2Ô∏è‚É£ Log in to the registry and pull the image. 3Ô∏è‚É£ Run the podman image to verify. 4Ô∏è‚É£ Access the portal at http://localhost:8080. Explore valuable resources anytime, anywhere! üåê‚ú® #RedHat #KnowledgePortal #OfflineAccess&amp;hellip;</description>
    </item>
    <item>
      <title>New features in Bunsen</title>
      <link>/articles/article-2025-08-13-4886/</link>
      <pubDate>Wed, 13 Aug 2025 07:01:02 +0000</pubDate>
      <guid>/articles/article-2025-08-13-4886/</guid>
      <description>üöÄ Bunsen has rolled out new features to enhance user experience! The updated web interface now includes a simplified project chooser, making it easier to select projects and modify search criteria. A cookie support feature allows users to save search settings for future use, streamlining the process. üç™ Additionally, the testrun overview section is customizable, letting users sort results by various columns. The new &amp;ldquo;filter by testcase&amp;rdquo; feature helps identify regressions in test results more&amp;hellip;</description>
    </item>
    <item>
      <title>Windows image-building service for OpenShift Virtualization</title>
      <link>/articles/article-2025-08-12-4887/</link>
      <pubDate>Tue, 12 Aug 2025 15:16:06 +0000</pubDate>
      <guid>/articles/article-2025-08-12-4887/</guid>
      <description>üöÄ Red Hat OpenShift Pipelines now allows for seamless management of virtual machines (VMs) in your CI/CD process. By integrating OpenShift Pipelines with OpenShift Virtualization, developers can automate the creation of standardized Windows golden images, enhancing VM provisioning. Key features include: - Management of pipelines as Kubernetes Custom Resources (CRs). - Simplified collaboration through source control management (SCM). - Streamlined operations by treating VMs as native objects&amp;hellip;</description>
    </item>
    <item>
      <title>Build your first Software Template for Backstage</title>
      <link>/articles/article-2025-08-12-4888/</link>
      <pubDate>Tue, 12 Aug 2025 12:31:14 +0000</pubDate>
      <guid>/articles/article-2025-08-12-4888/</guid>
      <description>üöÄ More organizations are adopting platform engineering and internal developer portals (IDPs) to enhance onboarding and self-service capabilities. This article details how to create a Software Template for Backstage using Red Hat Developer Hub. The template automates developer tasks, enabling faster application repository creation on GitHub with a CI pipeline. Prerequisites include admin access to Red Hat Developer Hub and GitHub integration setup. The guide offers step-by-step instructions&amp;hellip;</description>
    </item>
    <item>
      <title>How to build a simple agentic AI server with MCP</title>
      <link>/articles/article-2025-08-12-4889/</link>
      <pubDate>Tue, 12 Aug 2025 07:16:11 +0000</pubDate>
      <guid>/articles/article-2025-08-12-4889/</guid>
      <description>üåê As AI agents evolve, the need for reliable connections to real-world data grows. The Model Context Protocol (MCP) offers a standardized way to connect AI systems securely and efficiently. In a recent article, a simple MCP server was built to fetch weather data from the Open-Meteo API. This server allows AI models to interact with external tools and data, enhancing their functionality. To explore MCP, developers can set up their environment and create tools to access data easily. The article&amp;hellip;</description>
    </item>
    <item>
      <title>Boost AI efficiency with GPU autoscaling on OpenShift</title>
      <link>/articles/article-2025-08-12-4890/</link>
      <pubDate>Tue, 12 Aug 2025 07:16:07 +0000</pubDate>
      <guid>/articles/article-2025-08-12-4890/</guid>
      <description>Unlock AI potential with GPU autoscaling on OpenShift! üöÄ Dynamic autoscaling is essential for maintaining efficiency and availability in modern applications. Red Hat OpenShift offers features like horizontal pod autoscaling (HPA) and custom metrics autoscaler (KEDA) to optimize resource allocation and manage workloads effectively. KEDA enhances traditional scaling methods by utilizing external metrics, enabling better performance for GPU-accelerated applications. üìà Learn how to implement&amp;hellip;</description>
    </item>
    <item>
      <title>Disaster recovery approaches for Red Hat OpenShift Virtualization, part 2</title>
      <link>/articles/article-2025-08-11-4857/</link>
      <pubDate>Mon, 11 Aug 2025 15:31:15 +0000</pubDate>
      <guid>/articles/article-2025-08-11-4857/</guid>
      <description>üåê Discover effective disaster recovery strategies for Red Hat OpenShift Virtualization! This follow-up article explores orchestrating application failover using Kubernetes-native constructs and GitOps workflows. It emphasizes how to manage workloads during disruptions, focusing on redeployment and prioritization. Key practices include using Node Selectors and automation tools like Ansible and Helm for seamless transitions between primary and DR sites. Regular DR rehearsals and clear&amp;hellip;</description>
    </item>
    <item>
      <title>How to migrate smart inventories to constructed inventories</title>
      <link>/articles/article-2025-08-11-4858/</link>
      <pubDate>Mon, 11 Aug 2025 07:01:11 +0000</pubDate>
      <guid>/articles/article-2025-08-11-4858/</guid>
      <description>üöÄ Red Hat is set to discontinue support for smart inventories in favor of constructed inventories. This shift aims to address the limitations and challenges smart inventories present. üîÑ Migrating to constructed inventories can be complex, especially for large organizations. This article outlines a semi-automated process to simplify the transition, requiring human review to ensure accuracy. üìã Key migration steps include converting filtering conditions, reviewing configurations, and applying&amp;hellip;</description>
    </item>
    <item>
      <title>How to use Minio for Ansible automation hub</title>
      <link>/articles/article-2025-08-11-4859/</link>
      <pubDate>Mon, 11 Aug 2025 07:01:07 +0000</pubDate>
      <guid>/articles/article-2025-08-11-4859/</guid>
      <description>Learn how to configure MinIO as a backend for the Ansible Automation Hub in Red Hat environments. This setup provides a self-hosted, cost-effective alternative to cloud storage solutions like AWS S3. The article covers: 1Ô∏è‚É£ Setting up MinIO on an OpenShift cluster. 2Ô∏è‚É£ Integrating it with the Ansible Automation Platform. This method is ideal for air-gapped or on-premise deployments. #Ansible #MinIO #OpenShift #CloudStorage #DevOps</description>
    </item>
    <item>
      <title>Ollama vs. vLLM: A deep dive into performance benchmarking</title>
      <link>/articles/article-2025-08-08-4711/</link>
      <pubDate>Fri, 08 Aug 2025 07:16:15 +0000</pubDate>
      <guid>/articles/article-2025-08-08-4711/</guid>
      <description>Ollama and vLLM serve distinct roles in the AI landscape. Ollama is designed for local development and prototyping, while vLLM excels in high-performance production environments. In benchmarks, vLLM outperformed Ollama with a peak throughput of 793 TPS compared to Ollama&amp;rsquo;s 41 TPS and lower latency across all concurrency levels. Ollama prioritizes ease of use, making it suitable for individual developers, whereas vLLM is built for scalability, catering to enterprise applications. For detailed&amp;hellip;</description>
    </item>
    <item>
      <title>Upgrade from RHEL 9 to RHEL 10 with Red Hat Satellite 6.17</title>
      <link>/articles/article-2025-08-08-4712/</link>
      <pubDate>Fri, 08 Aug 2025 07:16:11 +0000</pubDate>
      <guid>/articles/article-2025-08-08-4712/</guid>
      <description>üöÄ Red Hat Enterprise Linux (RHEL) 10 is now available! For system admins managing large environments, upgrading from RHEL 9 to RHEL 10 can be simplified using Red Hat Satellite 6.17 and Leapp. These tools help ensure consistency, compliance, and minimal downtime during the upgrade process. Leapp automates checks and resolves compatibility issues, while Satellite manages repository synchronization and system tracking. Before upgrading, ensure your Satellite is properly configured and&amp;hellip;</description>
    </item>
    <item>
      <title>Batch inference on OpenShift AI with Ray Data, vLLM, and CodeFlare</title>
      <link>/articles/article-2025-08-07-4690/</link>
      <pubDate>Thu, 07 Aug 2025 07:01:16 +0000</pubDate>
      <guid>/articles/article-2025-08-07-4690/</guid>
      <description>Explore how to run batch inference at scale with OpenShift AI using the CodeFlare SDK, Ray Data, and vLLM. This approach helps bridge the gap between local development and production execution, enabling data scientists to efficiently process large datasets without needing deep infrastructure knowledge. The article outlines the differences between online and offline inference, focusing on the latter for large-scale tasks. It provides a step-by-step guide on connecting to a Ray cluster and&amp;hellip;</description>
    </item>
    <item>
      <title>Build trust in your CI/CD pipelines with OpenShift Pipelines</title>
      <link>/articles/article-2025-08-07-4691/</link>
      <pubDate>Thu, 07 Aug 2025 07:01:13 +0000</pubDate>
      <guid>/articles/article-2025-08-07-4691/</guid>
      <description>üîí Red Hat OpenShift Pipelines provide a cloud-native CI/CD solution using Tekton. This article highlights the use of OpenShift sandboxed containers, which isolate workloads in virtual machines, enhancing security for tasks needing elevated privileges. üåê For untrusted environments, OpenShift confidential containers (CoCo) further protect pipeline data by running containers in isolated hardware enclaves, safeguarding against admin access. üí° The integration of these technologies ensures secure,&amp;hellip;</description>
    </item>
    <item>
      <title>Simplify access management for Red Hat Insights for Red Hat Enterprise Linux with new system roles</title>
      <link>/articles/article-2025-08-06-4103/</link>
      <pubDate>Wed, 06 Aug 2025 07:16:10 +0000</pubDate>
      <guid>/articles/article-2025-08-06-4103/</guid>
      <description>Managing user access for Red Hat Enterprise Linux (RHEL) just became simpler! üöÄ Red Hat has introduced three new system roles in the User Access service of the Hybrid Cloud Console: 1Ô∏è‚É£ &lt;strong&gt;RHEL Administrator&lt;/strong&gt;: Full privileges for managing configurations and vulnerabilities. 2Ô∏è‚É£ &lt;strong&gt;RHEL Operator&lt;/strong&gt;: Broad capabilities for editing configurations, but with some restrictions. 3Ô∏è‚É£ &lt;strong&gt;RHEL Viewer&lt;/strong&gt;: Read-only access for viewing system data. These roles enhance security and streamline user management&amp;hellip;</description>
    </item>
    <item>
      <title>Intro to Redis and PostgreSQL in Red Hat SAP environments</title>
      <link>/articles/article-2025-08-06-4104/</link>
      <pubDate>Wed, 06 Aug 2025 07:16:07 +0000</pubDate>
      <guid>/articles/article-2025-08-06-4104/</guid>
      <description>üöÄ Discover how Redis and PostgreSQL can enhance SQL query performance in SAP environments! This article guides SAP and Red Hat admins in leveraging these technologies for better caching. üîç Key points include: - PostgreSQL and Redis can be deployed alongside SAP applications. - Redis offers granular control over caching, improving performance. - A Python program example showcases data caching. For more insights, check the full article! #Redis #PostgreSQL #SAP #Caching #DataManagement</description>
    </item>
    <item>
      <title>Getting started with managed clusters migration</title>
      <link>/articles/article-2025-08-05-90/</link>
      <pubDate>Tue, 05 Aug 2025 07:01:14 +0000</pubDate>
      <guid>/articles/article-2025-08-05-90/</guid>
      <description>üöÄ Red Hat Advanced Cluster Management 2.13 introduces a new developer preview feature: Managed Cluster Migration. This feature is beneficial when you need to migrate managed clusters due to instability, excess clusters, or selective transfers to another hub cluster. To get started, ensure both hub clusters are imported, running the same version, and have the managed-service account add-on enabled. You can then create a ManagedClusterMigration custom resource to facilitate the migration. For&amp;hellip;</description>
    </item>
    <item>
      <title>Retrieval-augmented generation with Llama Stack and Python</title>
      <link>/articles/article-2025-08-05-91/</link>
      <pubDate>Tue, 05 Aug 2025 07:01:12 +0000</pubDate>
      <guid>/articles/article-2025-08-05-91/</guid>
      <description>üöÄ Learn how to implement retrieval-augmented generation (RAG) using Python and Llama Stack! This article explores how RAG enhances AI responses by providing relevant context from documents, like Node.js reference architecture. By transforming data into vectors, the application retrieves pertinent document chunks to improve answer quality. The setup process involves running a Llama Stack instance and managing vector databases for efficient data handling. For developers interested in leveraging&amp;hellip;</description>
    </item>
    <item>
      <title>Introducing incident detection in Red Hat Advanced Cluster Management for Kubernetes 2.14</title>
      <link>/articles/article-2025-08-05-92/</link>
      <pubDate>Tue, 05 Aug 2025 07:01:10 +0000</pubDate>
      <guid>/articles/article-2025-08-05-92/</guid>
      <description>üöÄ Red Hat Advanced Cluster Management for Kubernetes 2.14 introduces incident detection, helping teams manage alert storms more effectively. This feature groups related alerts into manageable incidents, allowing for better root cause analysis and prioritization. To utilize this, install the Cluster Observability Operator on each cluster. It simplifies navigation between incidents within managed clusters. For installation details and to explore this feature, check the latest documentation&amp;hellip;.</description>
    </item>
    <item>
      <title>How to deploy multiple OpenStack environments on OpenShift</title>
      <link>/articles/article-2025-08-05-93/</link>
      <pubDate>Tue, 05 Aug 2025 07:01:07 +0000</pubDate>
      <guid>/articles/article-2025-08-05-93/</guid>
      <description>Red Hat OpenStack Services on OpenShift introduces a new deployment architecture that enhances Infrastructure-as-a-Service (IaaS) environments. This architecture utilizes distributed control plane services in pods, which significantly reduces resource consumption compared to previous versions. A key feature of the latest release is the ability to run multiple OpenStack Services across different namespaces within the same OpenShift infrastructure, supporting development, staging, testing, and&amp;hellip;</description>
    </item>
    <item>
      <title>Optimize workloads with right-sizing recommendations</title>
      <link>/articles/article-2025-08-04-94/</link>
      <pubDate>Mon, 04 Aug 2025 13:46:13 +0000</pubDate>
      <guid>/articles/article-2025-08-04-94/</guid>
      <description>üöÄ Introducing the Right-Sizing Recommendations in Red Hat Advanced Cluster Management for Kubernetes! This new capability helps users identify over-provisioned and under-utilized resources across clusters, promoting efficient infrastructure use and cost savings. By analyzing real-time CPU and memory consumption, it offers actionable recommendations for workload optimization. Key features include a Grafana dashboard for resource metrics, customizable data filtering, and policy-driven&amp;hellip;</description>
    </item>
    <item>
      <title>How to use Red Hat Quay as a proxy cache</title>
      <link>/articles/article-2025-08-04-95/</link>
      <pubDate>Mon, 04 Aug 2025 07:01:06 +0000</pubDate>
      <guid>/articles/article-2025-08-04-95/</guid>
      <description>Unlock the potential of Red Hat Quay as a proxy cache for container images! üåê This guide details how to set up a Red Hat OpenShift cluster and enable proxy caching in Red Hat Quay. Start by configuring the FEATURE_PROXY_CACHE flag in the config.yaml file, then create an organization for remote image proxying. Learn how to pull images from external sources like Docker Hub and deploy applications seamlessly. üöÄ For more insights, check out the full article! #RedHat #ContainerRegistry #OpenShift&amp;hellip;</description>
    </item>
    <item>
      <title>.NET container troubleshooting in OpenShift 4</title>
      <link>/articles/article-2025-08-04-96/</link>
      <pubDate>Mon, 04 Aug 2025 07:01:03 +0000</pubDate>
      <guid>/articles/article-2025-08-04-96/</guid>
      <description>üöÄ The .NET framework is a robust tool for deploying applications across platforms like Windows, Linux, and macOS. Red Hat offers a containerized version specifically for OpenShift. üîç The article by Tom Deseyn outlines steps for creating .NET container images and troubleshooting common issues. It highlights methods for memory analysis using tools like &lt;code&gt;dotnet dump&lt;/code&gt;. üìä For developers looking to optimize their .NET applications in OpenShift, this is a valuable resource. #DotNet #OpenShift&amp;hellip;</description>
    </item>
    <item>
      <title>Automatic certificate provisioning with cert-manager and DNS challenge</title>
      <link>/articles/article-2025-08-01-97/</link>
      <pubDate>Fri, 01 Aug 2025 07:01:18 +0000</pubDate>
      <guid>/articles/article-2025-08-01-97/</guid>
      <description>Learn how to automate certificate management in OpenShift using the cert-manager operator. üîê This article outlines the use of the ACME protocol with Identity Management (IdM) to streamline certificate issuance and renewal through a DNS challenge. It highlights the setup process with Red Hat Enterprise Linux (RHEL) 10 and OpenShift 4.14. Discover the benefits of reducing manual certificate management, which can lead to inefficiencies and errors. Read more to enhance your OpenShift&amp;hellip;</description>
    </item>
    <item>
      <title>5 steps to consistently patch RHEL and Windows systems</title>
      <link>/articles/article-2025-08-01-98/</link>
      <pubDate>Fri, 01 Aug 2025 07:01:15 +0000</pubDate>
      <guid>/articles/article-2025-08-01-98/</guid>
      <description>Staying updated on patching RHEL and Windows systems is crucial for security and operational efficiency. üõ°Ô∏è Using Red Hat Ansible Automation Platform can streamline this process by automating patch management for both systems. This reduces friction between teams and ensures compliance. Key steps include building a centralized inventory, creating job templates, applying patches with safety checks, validating success, and leveraging event-driven automation for proactive patching. üìä Explore more&amp;hellip;</description>
    </item>
    <item>
      <title>IBM Hyper Protect with OpenShift sandboxed containers</title>
      <link>/articles/article-2025-07-31-99/</link>
      <pubDate>Thu, 31 Jul 2025 07:01:17 +0000</pubDate>
      <guid>/articles/article-2025-07-31-99/</guid>
      <description>IBM is advancing data security with Hyper Protect Confidential Containers (HPCC) for Red Hat OpenShift. This solution protects sensitive workloads in untrusted environments, essential for industries like finance and healthcare. Using OpenShift sandboxed containers, HPCC ensures VM-level isolation for confidential computing. It addresses vulnerabilities of traditional containers by employing hardware-based trusted execution environments. Learn how HPCC enhances data protection and supports&amp;hellip;</description>
    </item>
  </channel>
</rss>
